{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to do\n",
    "- set up `accelerate` lib (redo the configs in a controlled manner) - `accelerate config`\n",
    "- use the LlaMma model I was just given access to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarisation: DistilBART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': \" An ornate key was buried beneath the floorboards of a watchmaker's shop . The key, adorned with intricate engravings, sparked a curiosity in him that refused to wane . He spent days poring over ancient tomes and manuscripts, hoping to uncover its origin . Then, late one evening, he stumbled upon a forgotten tale .\"}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from accelerate import infer_auto_device_map\n",
    "\n",
    "\n",
    "pipe = pipeline(\"summarization\", model=\"sshleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "text = \"\"\"\n",
    "In a quiet town nestled between rolling hills and dense forests, a peculiar event took place that would be spoken of for generations. It began on a misty morning when an elderly watchmaker named Elias discovered an ornate key buried beneath the floorboards of his shop. The key, adorned with intricate engravings resembling constellations, sparked a curiosity in him that refused to wane. He spent days poring over ancient tomes and manuscripts, hoping to uncover its origin, yet every answer led to more questions. Then, late one evening, he stumbled upon a forgotten tale—an old legend of a hidden chamber beneath the town’s cathedral, said to contain an artifact of immeasurable power. Driven by an insatiable thirst for knowledge, Elias embarked on a journey deep beneath the city, where he discovered a door that perfectly matched the key’s intricate design. His hands trembled as he turned the key, unlocking a secret lost to time. What lay beyond would change everything.\n",
    "\"\"\"\n",
    "\n",
    "# Generate summary\n",
    "summary = pipe(text) \n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 19:20:34] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 19:20:34] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 19:20:34] No CPU tracking mode found. Falling back on CPU constant mode. \n",
      " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 19:20:36] CPU Model on constant consumption mode: AMD EPYC 7742 64-Core Processor\n",
      "[codecarbon INFO @ 19:20:36] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 19:20:36] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 19:20:36] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 19:20:36]   Platform system: Linux-5.15.0-113-generic-x86_64-with-glibc2.31\n",
      "[codecarbon INFO @ 19:20:36]   Python version: 3.10.14\n",
      "[codecarbon INFO @ 19:20:36]   CodeCarbon version: 2.8.3\n",
      "[codecarbon INFO @ 19:20:36]   Available RAM : 503.532 GB\n",
      "[codecarbon INFO @ 19:20:36]   CPU count: 128\n",
      "[codecarbon INFO @ 19:20:36]   CPU model: AMD EPYC 7742 64-Core Processor\n",
      "[codecarbon INFO @ 19:20:36]   GPU count: 4\n",
      "[codecarbon INFO @ 19:20:36]   GPU model: 4 x NVIDIA A100-PCIE-40GB\n",
      "[codecarbon INFO @ 19:20:39] Saving emissions data to file /home/228755@hertie-school.lan/thesis/emissions.csv\n",
      "[codecarbon INFO @ 19:20:40] Energy consumed for RAM : 0.000030 kWh. RAM Power : 188.8243260383606 W\n",
      "[codecarbon INFO @ 19:20:40] Energy consumed for all CPUs : 0.000018 kWh. Total CPU Power : 112.5 W\n",
      "[codecarbon INFO @ 19:20:40] Energy consumed for all GPUs : 0.000026 kWh. Total GPU Power : 164.84008188535725 W\n",
      "[codecarbon INFO @ 19:20:40] 0.000074 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.8000308861770503e-05"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (a) Using codecarbon: estimates energy usage based on the CPU/GPU and time:\n",
    "    \n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "tracker = EmissionsTracker()\n",
    "tracker.start()\n",
    "\n",
    "# Run your inference code\n",
    "pipe(text)\n",
    "\n",
    "tracker.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/sys/class/powercap/intel-rapl/intel-rapl:0/energy_uj'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;129m@measure_energy\u001b[39m(domains\u001b[38;5;241m=\u001b[39m[RaplPackageDomain(\u001b[38;5;241m0\u001b[39m)])\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun_inference\u001b[39m():\n\u001b[1;32m      8\u001b[0m     pipe(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is a test.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mrun_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/thesis/thesis/lib/python3.10/site-packages/pyJoules/energy_meter.py:295\u001b[0m, in \u001b[0;36mmeasure_energy.<locals>.decorator_measure_energy.<locals>.wrapper_measure\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    294\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapper_measure\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 295\u001b[0m     \u001b[43menergy_meter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    296\u001b[0m     val \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    297\u001b[0m     energy_meter\u001b[38;5;241m.\u001b[39mstop()\n",
      "File \u001b[0;32m~/thesis/thesis/lib/python3.10/site-packages/pyJoules/energy_meter.py:103\u001b[0m, in \u001b[0;36mEnergyMeter.start\u001b[0;34m(self, tag)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m, tag: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     98\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    Begin a new energy trace\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \n\u001b[1;32m    101\u001b[0m \u001b[38;5;124;03m    :param tag: sample name\u001b[39;00m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m     new_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_measure_new_state\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_first_state \u001b[38;5;241m=\u001b[39m new_state\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_state \u001b[38;5;241m=\u001b[39m new_state\n",
      "File \u001b[0;32m~/thesis/thesis/lib/python3.10/site-packages/pyJoules/energy_meter.py:79\u001b[0m, in \u001b[0;36mEnergyMeter._measure_new_state\u001b[0;34m(self, tag)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_measure_new_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, tag):\n\u001b[1;32m     78\u001b[0m     timestamp \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 79\u001b[0m     values \u001b[38;5;241m=\u001b[39m [device\u001b[38;5;241m.\u001b[39mget_energy() \u001b[38;5;28;01mfor\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevices]\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m EnergyState(timestamp, tag \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_tag, values)\n",
      "File \u001b[0;32m~/thesis/thesis/lib/python3.10/site-packages/pyJoules/energy_meter.py:79\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_measure_new_state\u001b[39m(\u001b[38;5;28mself\u001b[39m, tag):\n\u001b[1;32m     78\u001b[0m     timestamp \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 79\u001b[0m     values \u001b[38;5;241m=\u001b[39m [\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_energy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m device \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevices]\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m EnergyState(timestamp, tag \u001b[38;5;28;01mif\u001b[39;00m tag \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_tag, values)\n",
      "File \u001b[0;32m~/thesis/thesis/lib/python3.10/site-packages/pyJoules/device/rapl_device.py:219\u001b[0m, in \u001b[0;36mRaplDevice.get_energy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_energy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 219\u001b[0m     energies \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_energy_value(\u001b[38;5;28mopen\u001b[39m(api_file_name, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m api_file_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_file_names]\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m energies\n",
      "File \u001b[0;32m~/thesis/thesis/lib/python3.10/site-packages/pyJoules/device/rapl_device.py:219\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_energy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 219\u001b[0m     energies \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_energy_value(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mapi_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m api_file_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_file_names]\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m energies\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/sys/class/powercap/intel-rapl/intel-rapl:0/energy_uj'"
     ]
    }
   ],
   "source": [
    "#  Using pyJoules for Fine-Grained Profiling - gives per-function energy consumption:\n",
    "\n",
    "from pyJoules.device.rapl_device import RaplPackageDomain\n",
    "from pyJoules.energy_meter import measure_energy\n",
    "\n",
    "@measure_energy(domains=[RaplPackageDomain(0)])\n",
    "def run_inference():\n",
    "    pipe(\"This is a test.\")\n",
    "\n",
    "run_inference()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                           aten::linear         4.50%      27.229ms        33.98%     205.429ms      58.460us       0.000us         0.00%     133.890ms      38.102us          3514  \n",
      "                                            aten::addmm        13.74%      83.056ms        23.21%     140.348ms      40.751us     118.968ms        48.51%     118.968ms      34.544us          3444  \n",
      "                                 ampere_sgemm_128x32_tn         0.00%       0.000us         0.00%       0.000us       0.000us      51.535ms        21.02%      51.535ms      20.353us          2532  \n",
      "                     aten::scaled_dot_product_attention         1.73%      10.482ms         9.64%      58.267ms      68.388us       0.000us         0.00%      39.469ms      46.325us           852  \n",
      "          aten::_scaled_dot_product_efficient_attention         1.40%       8.448ms         7.90%      47.785ms      56.085us       0.000us         0.00%      39.469ms      46.325us           852  \n",
      "                     aten::_efficient_attention_forward         1.96%      11.878ms         4.89%      29.535ms      34.666us      39.469ms        16.10%      39.469ms      46.325us           852  \n",
      "fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEf...         0.00%       0.000us         0.00%       0.000us       0.000us      39.469ms        16.10%      39.469ms      46.325us           852  \n",
      "void gemmSN_TN_kernel<float, 128, 16, 2, 4, 4, 4, tr...         0.00%       0.000us         0.00%       0.000us       0.000us      27.522ms        11.22%      27.522ms      56.167us           490  \n",
      "                       ampere_sgemm_128x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us      24.856ms        10.14%      24.856ms      59.182us           420  \n",
      "void cublasLt::splitKreduce_kernel<32, 16, int, floa...         0.00%       0.000us         0.00%       0.000us       0.000us      17.871ms         7.29%      17.871ms       6.079us          2940  \n",
      "                                           aten::matmul         0.09%     526.714us         0.47%       2.832ms      40.456us       0.000us         0.00%      14.921ms     213.161us            70  \n",
      "                                               aten::mm         0.24%       1.436ms         0.33%       2.014ms      28.772us      14.921ms         6.08%      14.921ms     213.161us            70  \n",
      "                                       aten::layer_norm         0.79%       4.769ms         9.16%      55.374ms      40.866us       0.000us         0.00%      12.469ms       9.202us          1355  \n",
      "                                aten::native_layer_norm         3.52%      21.297ms         8.37%      50.605ms      37.347us      12.460ms         5.08%      12.469ms       9.202us          1355  \n",
      "void at::native::(anonymous namespace)::vectorized_l...         0.00%       0.000us         0.00%       0.000us       0.000us      12.460ms         5.08%      12.460ms       9.195us          1355  \n",
      "                        ampere_sgemm_32x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us      12.106ms         4.94%      12.106ms     168.134us            72  \n",
      "                                             aten::topk         0.71%       4.309ms         1.78%      10.769ms     153.843us      11.768ms         4.80%      11.768ms     168.114us            70  \n",
      "                                     aten::index_select         2.02%      12.203ms         4.14%      25.027ms      25.486us      10.203ms         4.16%      10.215ms      10.402us           982  \n",
      "void at::native::(anonymous namespace)::indexSelectS...         0.00%       0.000us         0.00%       0.000us       0.000us      10.182ms         4.15%      10.182ms      10.390us           980  \n",
      "                                              aten::add         3.58%      21.663ms         6.10%      36.901ms      19.219us       7.682ms         3.13%       7.682ms       4.001us          1920  \n",
      "                                            aten::copy_         1.96%      11.878ms         7.98%      48.229ms      16.816us       7.547ms         3.08%       7.547ms       2.631us          2868  \n",
      "                                              aten::cat         1.82%      10.999ms         2.77%      16.774ms      18.679us       6.849ms         2.79%       6.849ms       7.627us           898  \n",
      "void at::native::mbtopk::radixFindKthValues<float, u...         0.00%       0.000us         0.00%       0.000us       0.000us       6.467ms         2.64%       6.467ms      23.098us           280  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us       6.458ms         2.63%       6.458ms       7.799us           828  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       5.306ms         2.16%       5.306ms       3.916us          1355  \n",
      "                         Memcpy DtoD (Device -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us       4.955ms         2.02%       4.955ms       3.051us          1624  \n",
      "                                             aten::isin         0.46%       2.778ms         2.01%      12.147ms      86.762us       0.000us         0.00%       3.063ms      21.878us           140  \n",
      "                                      aten::log_softmax         0.02%     146.521us         0.21%       1.269ms      18.135us       0.000us         0.00%       2.665ms      38.066us            70  \n",
      "                                     aten::_log_softmax         0.11%     649.550us         0.19%       1.123ms      16.042us       2.665ms         1.09%       2.665ms      38.066us            70  \n",
      "void at::native::(anonymous namespace)::cunn_SoftMax...         0.00%       0.000us         0.00%       0.000us       0.000us       2.665ms         1.09%       2.665ms      38.066us            70  \n",
      "                                             aten::item         0.26%       1.566ms         3.83%      23.170ms      23.009us       0.000us         0.00%       2.554ms       2.536us          1007  \n",
      "                              aten::_local_scalar_dense         0.81%       4.905ms         3.57%      21.604ms      21.454us       2.554ms         1.04%       2.554ms       2.536us          1007  \n",
      "                         Memcpy DtoH (Device -> Pinned)         0.00%       0.000us         0.00%       0.000us       0.000us       2.554ms         1.04%       2.554ms       2.541us          1005  \n",
      "                                              aten::any         0.78%       4.721ms         1.71%      10.358ms      24.258us       1.381ms         0.56%       2.167ms       5.074us           427  \n",
      "                                               aten::to         0.35%       2.089ms         5.55%      33.535ms      12.293us       0.000us         0.00%       2.036ms       0.746us          2728  \n",
      "                                         aten::_to_copy         0.70%       4.244ms         5.20%      31.445ms      28.051us       0.000us         0.00%       2.036ms       1.816us          1121  \n",
      "                                             aten::gelu         0.76%       4.584ms         1.59%       9.605ms      22.233us       1.872ms         0.76%       1.872ms       4.334us           432  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us       1.872ms         0.76%       1.872ms       4.334us           432  \n",
      "                                            aten::clone         0.24%       1.473ms         1.52%       9.173ms      27.381us       0.000us         0.00%       1.669ms       4.983us           335  \n",
      "                                               aten::eq         0.77%       4.665ms         1.21%       7.288ms      17.147us       1.611ms         0.66%       1.611ms       3.790us           425  \n",
      "void at::native::mbtopk::computeBlockwiseWithinKCoun...         0.00%       0.000us         0.00%       0.000us       0.000us       1.548ms         0.63%       1.548ms       5.529us           280  \n",
      "                       Memcpy DtoH (Device -> Pageable)         0.00%       0.000us         0.00%       0.000us       0.000us       1.465ms         0.60%       1.465ms       2.649us           553  \n",
      "                                            aten::fill_         0.41%       2.498ms         0.97%       5.885ms      10.699us       1.420ms         0.58%       1.420ms       2.581us           550  \n",
      "void at::native::reduce_kernel<128, 4, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us       1.381ms         0.56%       1.381ms       9.934us           139  \n",
      "                                        aten::embedding         0.16%     983.398us         0.90%       5.441ms      38.317us       0.000us         0.00%       1.186ms       8.352us           142  \n",
      "void at_cuda_detail::cub::DeviceScanByKeyKernel<at_c...         0.00%       0.000us         0.00%       0.000us       0.000us       1.077ms         0.44%       1.077ms       7.696us           140  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       1.047ms         0.43%       1.047ms       7.482us           140  \n",
      "                                           aten::arange         0.24%       1.475ms         1.07%       6.488ms      23.007us     497.831us         0.20%     995.662us       3.531us           282  \n",
      "                                            aten::where         0.17%       1.051ms         0.70%       4.239ms      38.534us     414.976us         0.17%     963.867us       8.762us           110  \n",
      "                                            aten::index         0.43%       2.629ms         0.71%       4.279ms      30.783us     941.028us         0.38%     941.028us       6.770us           139  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     941.028us         0.38%     941.028us       6.770us           139  \n",
      "                                       aten::is_nonzero         0.08%     480.724us         1.50%       9.057ms      25.586us       0.000us         0.00%     913.331us       2.580us           354  \n",
      "void at::native::mbtopk::gatherTopK<float, unsigned ...         0.00%       0.000us         0.00%       0.000us       0.000us     886.763us         0.36%     886.763us      12.668us            70  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     814.716us         0.33%     814.716us       2.859us           285  \n",
      "void at::native::elementwise_kernel<128, 4, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     792.754us         0.32%     792.754us       5.703us           139  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     753.558us         0.31%     753.558us       2.711us           278  \n",
      "void at::native::bitonicSortKVInPlace<-2, -1, 16, 16...         0.00%       0.000us         0.00%       0.000us       0.000us     734.904us         0.30%     734.904us      10.499us            70  \n",
      "                       Memcpy HtoD (Pageable -> Device)         0.00%       0.000us         0.00%       0.000us       0.000us     709.369us         0.29%     709.369us       1.933us           367  \n",
      "                                       aten::index_put_         0.11%     679.774us         2.18%      13.177ms      47.061us       0.000us         0.00%     586.757us       2.096us           280  \n",
      "                                 aten::_index_put_impl_         0.54%       3.251ms         2.07%      12.497ms      44.633us      45.599us         0.02%     586.757us       2.096us           280  \n",
      "                                            aten::zeros         0.11%     678.783us         0.71%       4.319ms      20.373us       0.000us         0.00%     517.533us       2.441us           212  \n",
      "                                            aten::zero_         0.09%     548.438us         0.43%       2.607ms      12.299us       0.000us         0.00%     517.533us       2.441us           212  \n",
      "void (anonymous namespace)::elementwise_kernel_with_...         0.00%       0.000us         0.00%       0.000us       0.000us     497.831us         0.20%     497.831us       3.531us           141  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     480.519us         0.20%     480.519us       3.314us           145  \n",
      "                                              aten::max         0.17%       1.028ms         0.35%       2.109ms      29.292us     477.409us         0.19%     477.409us       6.631us            72  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us     466.113us         0.19%     466.113us       6.659us            70  \n",
      "                                           aten::__or__         0.04%     238.683us         0.39%       2.373ms      17.193us       0.000us         0.00%     428.008us       3.102us           138  \n",
      "                                       aten::bitwise_or         0.23%       1.363ms         0.35%       2.134ms      15.464us     428.008us         0.17%     428.008us       3.102us           138  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     428.008us         0.17%     428.008us       3.102us           138  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     414.976us         0.17%     414.976us       7.545us            55  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     408.426us         0.17%     408.426us       8.335us            49  \n",
      "                                       aten::contiguous         0.01%      70.161us         0.23%       1.390ms      28.949us       0.000us         0.00%     397.803us       8.288us            48  \n",
      "void at::native::unrolled_elementwise_kernel<at::nat...         0.00%       0.000us         0.00%       0.000us       0.000us     392.078us         0.16%     392.078us       2.781us           141  \n",
      "void at::native::(anonymous namespace)::CatArrayBatc...         0.00%       0.000us         0.00%       0.000us       0.000us     391.880us         0.16%     391.880us       5.598us            70  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     343.691us         0.14%     343.691us       2.420us           142  \n",
      "void at_cuda_detail::cub::DeviceScanByKeyInitKernel<...         0.00%       0.000us         0.00%       0.000us       0.000us     337.296us         0.14%     337.296us       2.409us           140  \n",
      "                                             aten::full         0.07%     441.080us         0.43%       2.590ms      18.770us       0.000us         0.00%     335.210us       2.429us           138  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     316.813us         0.13%     316.813us       2.475us           128  \n",
      "                                        Memset (Device)         0.00%       0.000us         0.00%       0.000us       0.000us     281.397us         0.11%     281.397us       2.010us           140  \n",
      "                                              aten::mul         0.15%     880.423us         0.22%       1.310ms      18.198us     272.456us         0.11%     272.456us       3.784us            72  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     269.320us         0.11%     269.320us       3.793us            71  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     263.544us         0.11%     263.544us       3.660us            72  \n",
      "void at::native::mbtopk::computeBlockwiseKthCounts<u...         0.00%       0.000us         0.00%       0.000us       0.000us     262.446us         0.11%     262.446us       3.749us            70  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us     255.376us         0.10%     255.376us       3.648us            70  \n",
      "                                               aten::ge         0.15%     922.314us         0.25%       1.509ms      21.870us     252.760us         0.10%     252.760us       3.663us            69  \n",
      "                                              aten::div         0.14%     836.919us         0.21%       1.289ms      18.416us     244.661us         0.10%     244.661us       3.495us            70  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     244.661us         0.10%     244.661us       3.495us            70  \n",
      "                                        aten::remainder         0.15%     889.619us         0.22%       1.353ms      19.323us     242.229us         0.10%     242.229us       3.460us            70  \n",
      "void at::native::vectorized_elementwise_kernel<4, at...         0.00%       0.000us         0.00%       0.000us       0.000us     242.229us         0.10%     242.229us       3.460us            70  \n",
      "void at::native::vectorized_elementwise_kernel<2, at...         0.00%       0.000us         0.00%       0.000us       0.000us     203.892us         0.08%     203.892us       2.913us            70  \n",
      "                                              aten::all         0.12%     741.253us         0.35%       2.093ms      29.485us       7.200us         0.00%     196.147us       2.763us            71  \n",
      "void at::native::mbtopk::fill<unsigned int, unsigned...         0.00%       0.000us         0.00%       0.000us       0.000us     172.248us         0.07%     172.248us       2.461us            70  \n",
      "                                    aten::scalar_tensor         0.03%     204.708us         0.19%       1.125ms      20.454us       0.000us         0.00%     133.915us       2.435us            55  \n",
      "void at::native::index_elementwise_kernel<128, 4, at...         0.00%       0.000us         0.00%       0.000us       0.000us      45.599us         0.02%      45.599us       6.514us             7  \n",
      "                                           Buffer Flush         0.06%     339.599us         0.06%     358.894us      59.816us      44.541us         0.02%      44.541us       7.423us             6  \n",
      "void at::native::(anonymous namespace)::indexSelectL...         0.00%       0.000us         0.00%       0.000us       0.000us      21.663us         0.01%      21.663us      10.831us             2  \n",
      "                                aten::repeat_interleave         0.00%      18.304us         0.02%     134.933us      44.978us       0.000us         0.00%      20.095us       6.698us             3  \n",
      "void at::native::reduce_kernel<512, 1, at::native::R...         0.00%       0.000us         0.00%       0.000us       0.000us      11.296us         0.00%      11.296us       5.648us             2  \n",
      "                                               aten::lt         0.01%      50.164us         0.01%      79.749us      26.583us      10.784us         0.00%      10.784us       3.595us             3  \n",
      "void at::native::elementwise_kernel<128, 2, at::nati...         0.00%       0.000us         0.00%       0.000us       0.000us       9.472us         0.00%       9.472us       4.736us             2  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 604.561ms\n",
      "Self CUDA time total: 245.222ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PyTorch Profiler (For Model-Specific Inference Profiling) - this shows GPU execution time, which can be combined with nvidia-smi power draw to estimate Joules per inference.\n",
    "import torch\n",
    "\n",
    "with torch.profiler.profile(\n",
    "    activities=[torch.profiler.ProfilerActivity.CPU, torch.profiler.ProfilerActivity.CUDA],\n",
    "    record_shapes=True\n",
    ") as prof:\n",
    "    pipe(text)\n",
    "\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text generation: Llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda\n",
      "[codecarbon INFO @ 17:45:35] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 17:45:35] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 17:45:35] No CPU tracking mode found. Falling back on CPU constant mode. \n",
      " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 17:45:36] CPU Model on constant consumption mode: AMD EPYC 7742 64-Core Processor\n",
      "[codecarbon INFO @ 17:45:36] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 17:45:36] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 17:45:36] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 17:45:36]   Platform system: Linux-5.15.0-113-generic-x86_64-with-glibc2.31\n",
      "[codecarbon INFO @ 17:45:36]   Python version: 3.10.14\n",
      "[codecarbon INFO @ 17:45:36]   CodeCarbon version: 2.8.3\n",
      "[codecarbon INFO @ 17:45:36]   Available RAM : 503.532 GB\n",
      "[codecarbon INFO @ 17:45:36]   CPU count: 128\n",
      "[codecarbon INFO @ 17:45:36]   CPU model: AMD EPYC 7742 64-Core Processor\n",
      "[codecarbon INFO @ 17:45:36]   GPU count: 4\n",
      "[codecarbon INFO @ 17:45:36]   GPU model: 4 x NVIDIA A100-PCIE-40GB\n",
      "[codecarbon INFO @ 17:45:40] Saving emissions data to file /home/228755@hertie-school.lan/thesis/emissions.csv\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "[codecarbon INFO @ 17:45:41] Energy consumed for RAM : 0.000073 kWh. RAM Power : 188.8243260383606 W\n",
      "[codecarbon INFO @ 17:45:41] Energy consumed for all CPUs : 0.000044 kWh. Total CPU Power : 112.5 W\n",
      "[codecarbon INFO @ 17:45:41] Energy consumed for all GPUs : 0.000143 kWh. Total GPU Power : 367.691980844516 W\n",
      "[codecarbon INFO @ 17:45:41] 0.000259 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a man who was so afraid of the dark that he would hide in his closet during the night. He would come out of his closet only to go to sleep, and he would wake up in the morning feeling like he had slept through the night. This man was so afraid of the dark that he would hide in his closet during the night. He would come out of his closet only to go to sleep, and he would wake up in the morning feeling like\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "from accelerate import infer_auto_device_map\n",
    "import torch\n",
    "from codecarbon import EmissionsTracker\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "pipe = pipeline(\"text-generation\", model=\"meta-llama/Llama-3.2-1B\", device=device)\n",
    "\n",
    "tracker = EmissionsTracker()\n",
    "tracker.start()\n",
    "\n",
    "output = pipe(\"Once upon a time\", max_length=100, num_return_sequences=1)\n",
    "\n",
    "tracker.stop()\n",
    "\n",
    "print(output[0]['generated_text'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[codecarbon INFO @ 17:48:11] [setup] RAM Tracking...\n",
      "[codecarbon INFO @ 17:48:11] [setup] CPU Tracking...\n",
      "[codecarbon WARNING @ 17:48:11] No CPU tracking mode found. Falling back on CPU constant mode. \n",
      " Linux OS detected: Please ensure RAPL files exist at \\sys\\class\\powercap\\intel-rapl to measure CPU\n",
      "\n",
      "[codecarbon INFO @ 17:48:12] CPU Model on constant consumption mode: AMD EPYC 7742 64-Core Processor\n",
      "[codecarbon INFO @ 17:48:12] [setup] GPU Tracking...\n",
      "[codecarbon INFO @ 17:48:12] Tracking Nvidia GPU via pynvml\n",
      "[codecarbon INFO @ 17:48:12] >>> Tracker's metadata:\n",
      "[codecarbon INFO @ 17:48:12]   Platform system: Linux-5.15.0-113-generic-x86_64-with-glibc2.31\n",
      "[codecarbon INFO @ 17:48:12]   Python version: 3.10.14\n",
      "[codecarbon INFO @ 17:48:12]   CodeCarbon version: 2.8.3\n",
      "[codecarbon INFO @ 17:48:12]   Available RAM : 503.532 GB\n",
      "[codecarbon INFO @ 17:48:12]   CPU count: 128\n",
      "[codecarbon INFO @ 17:48:12]   CPU model: AMD EPYC 7742 64-Core Processor\n",
      "[codecarbon INFO @ 17:48:12]   GPU count: 4\n",
      "[codecarbon INFO @ 17:48:12]   GPU model: 4 x NVIDIA A100-PCIE-40GB\n",
      "[codecarbon INFO @ 17:48:15] Saving emissions data to file /home/228755@hertie-school.lan/thesis/emissions.csv\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "[codecarbon INFO @ 17:48:16] Energy consumed for RAM : 0.000073 kWh. RAM Power : 188.8243260383606 W\n",
      "[codecarbon INFO @ 17:48:16] Energy consumed for all CPUs : 0.000044 kWh. Total CPU Power : 112.5 W\n",
      "[codecarbon INFO @ 17:48:17] Energy consumed for all GPUs : 0.000147 kWh. Total GPU Power : 378.9555943223109 W\n",
      "[codecarbon INFO @ 17:48:17] 0.000263 kWh of electricity used since the beginning.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a little girl named Lillie. Lillie was a very bright little girl, but she was also very curious. She wanted to know everything about everything. She wanted to know how things worked, and she wanted to know why things worked the way they did.\n",
      "One day, Lillie was sitting on her bed, reading a book about the wonders of the world. She was fascinated by the descriptions of the different animals and plants, and she wanted\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from accelerate import dispatch_model\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Automatically distribute across GPUs\n",
    "device_map = infer_auto_device_map(model)\n",
    "model = dispatch_model(model, device_map=device_map)\n",
    "\n",
    "input_ids = tokenizer(\"Once upon a time\", return_tensors=\"pt\").input_ids.to(model.device)\n",
    "\n",
    "tracker = EmissionsTracker()\n",
    "tracker.start()\n",
    "\n",
    "output = model.generate(input_ids, max_length=100)\n",
    "\n",
    "tracker.stop()\n",
    "\n",
    "print(tokenizer.decode(output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# translation: T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m T5Tokenizer, T5ForConditionalGeneration\n\u001b[0;32m----> 3\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mT5Tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle/flan-t5-small\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m T5ForConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoogle/flan-t5-small\u001b[39m\u001b[38;5;124m\"\u001b[39m, device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranslate English to German: How old are you?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/thesis/thesis/lib/python3.10/site-packages/transformers/utils/import_utils.py:1736\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[0;32m-> 1736\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/thesis/thesis/lib/python3.10/site-packages/transformers/utils/import_utils.py:1724\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1722\u001b[0m failed \u001b[38;5;241m=\u001b[39m [msg\u001b[38;5;241m.\u001b[39mformat(name) \u001b[38;5;28;01mfor\u001b[39;00m available, msg \u001b[38;5;129;01min\u001b[39;00m checks \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m available()]\n\u001b[1;32m   1723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m failed:\n\u001b[0;32m-> 1724\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(failed))\n",
      "\u001b[0;31mImportError\u001b[0m: \nT5Tokenizer requires the SentencePiece library but it was not found in your environment. Checkout the instructions on the\ninstallation page of its repo: https://github.com/google/sentencepiece#installation and follow the ones\nthat match your environment. Please note that you may need to restart your runtime after installation.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from accelerate import infer_auto_device_map\n",
    "\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-small\", device_map=\"auto\")\n",
    "\n",
    "input_text = \"translate English to German: How old are you?\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(input_ids)\n",
    "print(tokenizer.decode(outputs[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

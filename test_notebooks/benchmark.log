[RANK-PROCESS-0][[36m2025-03-14 11:05:04,505[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Setting torch.distributed cuda device to 0[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:04,603[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Initializing torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:04,795[0m][[34mdatasets[0m][[32mINFO[0m] - PyTorch version 2.1.2 available.[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:06,686[0m][[34mpytorch[0m][[32mINFO[0m] - Allocating pytorch backend[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:06,687[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Seeding backend with 42[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:06,688[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Benchmarking a Transformers model[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:07,977[0m][[34minference[0m][[32mINFO[0m] - Allocating inference scenario[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:07,978[0m][[34minference[0m][[32mINFO[0m] - 	+ Updating Text Generation kwargs with default values[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:07,978[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Text Generation report[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:07,979[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:07,980[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:07,980[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Per-Token Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:07,980[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:07,980[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Memory tracker[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:07,980[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking RAM memory of process 3002246[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:07,980[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking GPU memory of devices [0][0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:07,981[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking Allocated/Reserved memory of 1 Pytorch CUDA devices[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:07,981[0m][[34minference[0m][[32mINFO[0m] - 	+ Generating inputs for task text-generation[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:08,009[0m][[34minference[0m][[32mINFO[0m] - 	+ Running model loading tracking[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:23,937[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating backend temporary directory[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:23,938[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating no weights model[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:23,938[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating no weights model directory[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:23,939[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating no weights model state dict[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:23,940[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Saving no weights model safetensors[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:23,942[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Saving no weights model pretrained config[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:23,947[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading model with random weights[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:23,949[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading Transformers model using device context manager for fast initialization[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:24,383[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Enabling eval mode[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:24,388[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Cleaning up backend temporary directory[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:24,420[0m][[34minference[0m][[32mINFO[0m] - 	+ Preparing inputs for backend pytorch[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:24,572[0m][[34minference[0m][[32mINFO[0m] - 	+ Warming up backend for Text Generation[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:29,844[0m][[34minference[0m][[32mINFO[0m] - 	+ Running Per-Token Text Generation latency tracking[0m
[RANK-PROCESS-0][[36m2025-03-14 11:05:58,163[0m][[34minference[0m][[32mINFO[0m] - 	+ Running Text Generation memory tracking[0m
[RANK-PROCESS-0][[36m2025-03-14 11:06:31,734[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Benchmark completed successfully[0m
[RANK-PROCESS-0][[36m2025-03-14 11:06:31,758[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Destroying torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-14 11:06:31,759[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting rank process[0m
[ISOLATED-PROCESS][[36m2025-03-14 11:07:00,641[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Sending outputs to main process[0m
[ISOLATED-PROCESS][[36m2025-03-14 11:07:00,646[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting isolated process[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:28,561[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Setting torch.distributed cuda device to 0[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:28,614[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Initializing torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:28,668[0m][[34mdatasets[0m][[32mINFO[0m] - PyTorch version 2.1.2 available.[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:30,074[0m][[34mpytorch[0m][[32mINFO[0m] - Allocating pytorch backend[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:30,074[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Seeding backend with 42[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:30,075[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Benchmarking a Transformers model[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:31,286[0m][[34minference[0m][[32mINFO[0m] - Allocating inference scenario[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:31,287[0m][[34minference[0m][[32mINFO[0m] - 	+ Updating Text Generation kwargs with default values[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:31,287[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Text Generation report[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:31,289[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:31,289[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:31,289[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Per-Token Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:31,289[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:31,289[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Memory tracker[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:31,290[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking RAM memory of process 3004524[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:31,290[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking GPU memory of devices [0][0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:31,290[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking Allocated/Reserved memory of 1 Pytorch CUDA devices[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:31,291[0m][[34minference[0m][[32mINFO[0m] - 	+ Generating inputs for task text-generation[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:31,321[0m][[34minference[0m][[32mINFO[0m] - 	+ Running model loading tracking[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:47,132[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating backend temporary directory[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:47,133[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating no weights model[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:47,133[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating no weights model directory[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:47,134[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating no weights model state dict[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:47,136[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Saving no weights model safetensors[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:47,141[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Saving no weights model pretrained config[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:47,149[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading model with random weights[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:47,151[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading Transformers model using device context manager for fast initialization[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:47,565[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Enabling eval mode[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:47,568[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Cleaning up backend temporary directory[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:47,588[0m][[34minference[0m][[32mINFO[0m] - 	+ Preparing inputs for backend pytorch[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:47,698[0m][[34minference[0m][[32mINFO[0m] - 	+ Warming up backend for Text Generation[0m
[RANK-PROCESS-0][[36m2025-03-14 11:07:53,191[0m][[34minference[0m][[32mINFO[0m] - 	+ Running Per-Token Text Generation latency tracking[0m
[RANK-PROCESS-0][[36m2025-03-14 11:08:24,548[0m][[34minference[0m][[32mINFO[0m] - 	+ Running Text Generation memory tracking[0m
[RANK-PROCESS-0][[36m2025-03-14 11:09:00,978[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Benchmark completed successfully[0m
[RANK-PROCESS-0][[36m2025-03-14 11:09:00,994[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Destroying torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-14 11:09:00,995[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting rank process[0m
[ISOLATED-PROCESS][[36m2025-03-14 11:09:24,151[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Sending outputs to main process[0m
[ISOLATED-PROCESS][[36m2025-03-14 11:09:24,153[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting isolated process[0m

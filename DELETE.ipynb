{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e873d585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_architecture_total_params',\n",
       " 'variables_max_output_tokens',\n",
       " 'global_energy_metrics_local_process_results_cpu_energy_process_3',\n",
       " 'variables_number_input_prompts',\n",
       " 'global_energy_metrics_global_experiment_results_total_energy_joules',\n",
       " 'global_energy_metrics_global_experiment_results_cpu_power_avg',\n",
       " 'variables_batching_options_adaptive_batching',\n",
       " 'global_energy_metrics_local_process_results_total_energy_joules_process_1',\n",
       " 'global_energy_metrics_local_process_results_gpu_energy_process_3',\n",
       " 'compute_metrics_compute_utilisation_cpu_memory_usage_bytes',\n",
       " 'global_energy_metrics_global_experiment_results_total_energy_kwh',\n",
       " 'compute_metrics_compute_utilisation_gpu_utilization_percent_0',\n",
       " 'variables_latency_simulation_simulate_burst',\n",
       " 'global_energy_metrics_local_process_results_gpu_power_process_3',\n",
       " 'variables_decoder_config_decoder_temperature',\n",
       " 'variables_config_name',\n",
       " 'variables_latency_simulation_burst_size',\n",
       " 'global_energy_metrics_local_process_results_cpu_power_process_3',\n",
       " 'variables_quantisation_load_in_8bit',\n",
       " 'variables_backend',\n",
       " 'global_energy_metrics_global_derived_quantities_tokens_per_joule',\n",
       " 'global_energy_metrics_local_process_results_cpu_energy_process_1',\n",
       " 'inference_metrics_inference_performance_total_inference_time_sec',\n",
       " 'compute_metrics_compute_utilisation_gpu_utilization_percent_1',\n",
       " 'global_energy_metrics_per-process_emissions_1',\n",
       " 'setup_model',\n",
       " 'compute_metrics_memory_gpu_max_memory_allocated_bytes',\n",
       " 'global_energy_metrics_global_experiment_results_ram_energy_total',\n",
       " 'variables_sharding_config_fsdp_config_use_orig_params',\n",
       " 'variables_batching_options_batch_size___fixed_batching',\n",
       " 'variables_accelerate_config_distributed_type',\n",
       " 'global_energy_metrics_local_process_results_gpu_power_process_2',\n",
       " 'variables_quantisation_quantization',\n",
       " 'global_energy_metrics_global_experiment_results_ram_power_avg',\n",
       " 'global_energy_metrics_local_process_results_ram_power_process_0',\n",
       " 'variables_query_rate',\n",
       " 'global_energy_metrics_local_process_results_cpu_power_process_2',\n",
       " 'inference_metrics_inference_performance_throughput_tokens_per_sec',\n",
       " 'global_energy_metrics_per-process_emissions_0',\n",
       " 'global_energy_metrics_per-process_emissions_2',\n",
       " 'global_energy_metrics_local_process_results_ram_energy_process_2',\n",
       " 'global_energy_metrics_local_process_results_gpu_energy_process_0',\n",
       " 'inference_metrics_raw_inference_metrics_total_input_tokens',\n",
       " 'global_energy_metrics_local_process_results_ram_power_process_2',\n",
       " 'variables_batching_options_adaptive_max_tokens',\n",
       " 'global_energy_metrics_local_process_results_gpu_energy_process_1',\n",
       " 'setup_available_cpu_count',\n",
       " 'global_energy_metrics_local_process_results_total_energy_kwh_process_0',\n",
       " 'global_energy_metrics_local_process_results_ram_power_process_1',\n",
       " 'global_energy_metrics_experiment_id',\n",
       " 'global_energy_metrics_local_process_results_gpu_power_process_1',\n",
       " 'variables_latency_simulation_simulate',\n",
       " 'variables_sharding_config_sharding_strategy',\n",
       " 'variables_latency_simulation_delay_min',\n",
       " 'global_energy_metrics_local_process_results_ram_energy_process_1',\n",
       " 'compute_metrics_compute_utilisation_gpu_utilization_percent_2',\n",
       " 'global_energy_metrics_global_experiment_results_gpu_power_avg',\n",
       " 'setup_region',\n",
       " 'global_energy_metrics_global_experiment_results_cpu_energy_total',\n",
       " 'variables_latency_simulation_burst_interval',\n",
       " 'global_energy_metrics_global_experiment_results_gpu_energy_total',\n",
       " 'variables_inference_type',\n",
       " 'global_energy_metrics_local_process_results_ram_power_process_3',\n",
       " 'setup_gpu_model',\n",
       " 'global_energy_metrics_local_process_results_cpu_power_process_0',\n",
       " 'compute_metrics_memory_gpu_current_memory_allocated_bytes',\n",
       " 'global_energy_metrics_local_process_results_total_energy_joules_process_0',\n",
       " 'variables_quantisation_cached_flops_for_quantised_models',\n",
       " 'compute_metrics_memory_gpu_max_memory_reserved_bytes',\n",
       " 'variables_decoder_config_decoder_top_k',\n",
       " 'global_energy_metrics_local_process_results_cpu_power_process_1',\n",
       " 'global_energy_metrics_local_process_results_total_energy_kwh_process_2',\n",
       " 'variables_sharding_config_fsdp_config_cpu_offload',\n",
       " 'variables_decode_token_to_text',\n",
       " 'global_energy_metrics_local_process_results_gpu_power_process_0',\n",
       " 'compute_metrics_memory_gpu_current_memory_reserved_bytes',\n",
       " 'variables_accelerate_config_num_processes',\n",
       " 'variables_latency_simulation_delay_max',\n",
       " 'global_energy_metrics_local_process_results_ram_energy_process_0',\n",
       " 'setup_date_time',\n",
       " 'variables_decoder_config_decoder_top_p',\n",
       " 'compute_metrics_flops',\n",
       " 'setup_experiment_id',\n",
       " 'variables_quantisation_load_in_4bit',\n",
       " 'global_energy_metrics_local_process_results_total_energy_joules_process_2',\n",
       " 'global_energy_metrics_local_process_results_total_energy_joules_process_3',\n",
       " 'variables_fp_precision',\n",
       " 'model_architecture_architecture',\n",
       " 'global_energy_metrics_local_process_results_cpu_energy_process_0',\n",
       " 'setup_task_type',\n",
       " 'setup_country',\n",
       " 'setup_os',\n",
       " 'global_energy_metrics_local_process_results_total_energy_kwh_process_1',\n",
       " 'global_energy_metrics_global_derived_quantities_flops_per_joule',\n",
       " 'inference_metrics_raw_inference_metrics_number_input_prompts',\n",
       " 'variables_max_input_tokens',\n",
       " 'setup_is_encoder_decoder',\n",
       " 'variables_batching_options_max_batch_size___adaptive_batching',\n",
       " 'setup_python_version',\n",
       " 'setup_cpu_model',\n",
       " 'global_energy_metrics_global_derived_quantities_joules_per_flop',\n",
       " 'global_energy_metrics_per-process_emissions_3',\n",
       " 'inference_metrics_raw_inference_metrics_total_generated_tokens',\n",
       " 'setup_available_gpu_count',\n",
       " 'global_energy_metrics_local_process_results_cpu_energy_process_2',\n",
       " 'compute_metrics_compute_utilisation_gpu_utilization_percent_3',\n",
       " 'compute_metrics_compute_utilisation_cpu_usage_percent',\n",
       " 'global_energy_metrics_local_process_results_total_energy_kwh_process_3',\n",
       " 'global_energy_metrics_local_process_results_gpu_energy_process_2',\n",
       " 'global_energy_metrics_global_derived_quantities_joules_per_token',\n",
       " 'global_energy_metrics_local_process_results_ram_energy_process_3',\n",
       " 'inference_metrics_inference_performance_throughput_queries_per_sec',\n",
       " 'inference_metrics_inference_performance_average_latency_ms_per_batch']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "df = pd.read_csv('results/controlled_results.csv')\n",
    "df.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4270860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16384])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['inference_metrics_raw_inference_metrics_total_generated_tokens'].unique()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

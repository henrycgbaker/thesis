{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will later move this into function script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_files = [\"controlled\", \"scenarios\", \"grid\", \"text_generation\"]\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "def process_possible_files(func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Loops over the global list 'possible_files', calls the provided function on each file,\n",
    "    and creates a global variable with the naming convention 'df_<file>_cleaned'\n",
    "    to store the resulting DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        func (callable): A function that takes at least a file name (first argument).\n",
    "        *args: Additional positional arguments that 'func' needs.\n",
    "        **kwargs: Additional keyword arguments that 'func' needs.\n",
    "    \n",
    "    The function will also attempt to display each transposed DataFrame.\n",
    "    \"\"\"\n",
    "    for file in possible_files:\n",
    "        try:\n",
    "            var_name = f\"df_{file}_cleaned\"\n",
    "            # Run the provided function on the file, passing along any additional arguments.\n",
    "            result_df = func(file, *args, **kwargs)\n",
    "            # Dynamically create a global variable with the result.\n",
    "            globals()[var_name] = result_df\n",
    "            print(f\"Found & inspecting: {var_name}\")\n",
    "            display(result_df.T)\n",
    "        except Exception as e:\n",
    "            print(f\"{file} did not process correctly: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variables_latency_simulation_burst_size\n",
      "variables_latency_simulation_simulate\n",
      "inference_metrics_raw_inference_metrics_number_input_prompts\n",
      "global_energy_metrics_local_process_results_ram_energy_process_0\n",
      "compute_metrics_compute_utilisation_cpu_memory_usage_bytes\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_3\n",
      "inference_metrics_inference_performance_throughput_queries_per_sec\n",
      "variables_config_name\n",
      "global_energy_metrics_global_experiment_results_gpu_power_avg\n",
      "global_energy_metrics_local_process_results_ram_power_process_1\n",
      "setup_available_cpu_count\n",
      "setup_experiment_id\n",
      "variables_quantisation_load_in_4bit\n",
      "variables_number_input_prompts\n",
      "compute_metrics_memory_gpu_max_memory_allocated_bytes\n",
      "global_energy_metrics_local_process_results_gpu_power_process_3\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_1\n",
      "variables_max_input_tokens\n",
      "global_energy_metrics_global_derived_quantities_joules_per_flop\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_3\n",
      "setup_cpu_model\n",
      "global_energy_metrics_global_experiment_results_cpu_energy_total\n",
      "variables_inference_type\n",
      "variables_sharding_config_fsdp_config_cpu_offload\n",
      "model_architecture_architecture\n",
      "variables_max_output_tokens\n",
      "inference_metrics_inference_performance_total_inference_time_sec\n",
      "variables_accelerate_config_num_processes\n",
      "global_energy_metrics_local_process_results_cpu_power_process_3\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_2\n",
      "setup_available_gpu_count\n",
      "variables_quantisation_load_in_8bit\n",
      "compute_metrics_memory_gpu_current_memory_reserved_bytes\n",
      "variables_backend\n",
      "variables_sharding_config_fsdp_config_use_orig_params\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_3\n",
      "variables_query_rate\n",
      "inference_metrics_raw_inference_metrics_total_generated_tokens\n",
      "variables_accelerate_config_distributed_type\n",
      "compute_metrics_memory_gpu_current_memory_allocated_bytes\n",
      "setup_date_time\n",
      "variables_decoder_config_decoding_mode\n",
      "setup_task_type\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_2\n",
      "inference_metrics_raw_inference_metrics_total_input_tokens\n",
      "setup_country\n",
      "variables_batching_options_adaptive_max_tokens\n",
      "variables_latency_simulation_simulate_burst\n",
      "variables_decoder_config_decoder_top_p\n",
      "global_energy_metrics_local_process_results_ram_power_process_2\n",
      "compute_metrics_compute_utilisation_cpu_usage_percent\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_3\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_0\n",
      "variables_quantisation_quantization\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_2\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_1\n",
      "variables_batching_options_adaptive_batching\n",
      "setup_python_version\n",
      "inference_metrics_inference_performance_throughput_tokens_per_sec\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_1\n",
      "variables_latency_simulation_delay_max\n",
      "global_energy_metrics_local_process_results_cpu_power_process_0\n",
      "global_energy_metrics_global_derived_quantities_flops_per_joule\n",
      "variables_latency_simulation_burst_interval\n",
      "global_energy_metrics_local_process_results_gpu_power_process_1\n",
      "global_energy_metrics_local_process_results_ram_power_process_0\n",
      "variables_fp_precision\n",
      "global_energy_metrics_local_process_results_cpu_power_process_2\n",
      "global_energy_metrics_global_experiment_results_total_energy_joules\n",
      "global_energy_metrics_local_process_results_gpu_power_process_0\n",
      "global_energy_metrics_local_process_results_cpu_power_process_1\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_0\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_0\n",
      "setup_region\n",
      "model_architecture_total_params\n",
      "variables_decoder_config_decoder_temperature\n",
      "inference_metrics_inference_performance_average_latency_ms_per_batch\n",
      "global_energy_metrics_local_process_results_ram_energy_process_3\n",
      "compute_metrics_memory_gpu_max_memory_reserved_bytes\n",
      "variables_batching_options_max_batch_size___adaptive_batching\n",
      "global_energy_metrics_local_process_results_ram_energy_process_1\n",
      "variables_latency_simulation_delay_min\n",
      "global_energy_metrics_local_process_results_gpu_power_process_2\n",
      "setup_gpu_model\n",
      "global_energy_metrics_global_experiment_results_ram_power_avg\n",
      "variables_sharding_config_sharding_strategy\n",
      "variables_decoder_config_decoder_top_k\n",
      "global_energy_metrics_local_process_results_ram_energy_process_2\n",
      "global_energy_metrics_per-process_emissions_2\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_2\n",
      "global_energy_metrics_per-process_emissions_3\n",
      "global_energy_metrics_global_experiment_results_cpu_power_avg\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_2\n",
      "global_energy_metrics_global_derived_quantities_tokens_per_joule\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_1\n",
      "setup_is_encoder_decoder\n",
      "setup_model\n",
      "variables_decode_token_to_text\n",
      "setup_os\n",
      "global_energy_metrics_global_experiment_results_total_energy_kwh\n",
      "global_energy_metrics_global_derived_quantities_joules_per_token\n",
      "global_energy_metrics_experiment_id\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_0\n",
      "global_energy_metrics_global_experiment_results_gpu_energy_total\n",
      "variables_batching_options_batch_size___fixed_batching\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_3\n",
      "global_energy_metrics_per-process_emissions_0\n",
      "variables_quantisation_cached_flops_for_quantised_models\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_0\n",
      "global_energy_metrics_global_experiment_results_ram_energy_total\n",
      "global_energy_metrics_local_process_results_ram_power_process_3\n",
      "compute_metrics_flops\n",
      "global_energy_metrics_per-process_emissions_1\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_1\n"
     ]
    }
   ],
   "source": [
    "notebook_dir = os.getcwd()\n",
    "df = pd.read_csv(\"scenarios_results.csv\")\n",
    "\n",
    "columns = list(df.columns)\n",
    "for col in columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column(col: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean a single column name by:\n",
    "      - Stripping whitespace and replacing any non-standard quotes.\n",
    "      - Checking for per-process metric patterns.\n",
    "      - Applying special renames.\n",
    "      - Removing the 'variables_' prefix if present.\n",
    "      - Otherwise, attempting to strip off any messy prefixes using a known list of tokens.\n",
    "    \n",
    "    If no known token is found, the original (normalized) column name is returned.\n",
    "    \"\"\"\n",
    "    # Normalize the column string: remove extra whitespace and fix common issues with quotes.\n",
    "    col = col.strip()\n",
    "    col = col.replace(\"“\", \"\\\"\").replace(\"”\", \"\\\"\")\n",
    "    \n",
    "    # 1. Special exact mappings.\n",
    "    special_mappings = {\n",
    "        \"setup_cpu_model\": \"cpu_model\",\n",
    "        \"setup_gpu_model\": \"gpu_model\",\n",
    "        \"model_architecture_total_params\": \"total_params\",  # now maps to total_params\n",
    "        \"model_architecture_architecture\": \"model_arch\"\n",
    "    }\n",
    "    if col in special_mappings:\n",
    "        return special_mappings[col]\n",
    "    \n",
    "    # 2. Remove the 'variables_' prefix if it exists.\n",
    "    if col.startswith(\"variables_\"):\n",
    "        col = col[len(\"variables_\"):]\n",
    "    \n",
    "    # 3. First, check if it is a per-process metric column.\n",
    "    per_process_patterns = [\n",
    "        r'(cpu_power_process_\\d+)',\n",
    "        r'(gpu_power_process_\\d+)',\n",
    "        r'(ram_power_process_\\d+)',\n",
    "        r'(cpu_energy_process_\\d+)',\n",
    "        r'(gpu_energy_process_\\d+)',\n",
    "        r'(ram_energy_process_\\d+)',\n",
    "        r'(total_energy_kwh_process_\\d+)',\n",
    "        r'(total_energy_joules_process_\\d+)'\n",
    "    ]\n",
    "    for pattern in per_process_patterns:\n",
    "        match = re.search(pattern, col)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    \n",
    "    # 4. For non-per-process columns, search for a known token in the cleaned column.\n",
    "    tokens = [\n",
    "        \"config_name\", \"experiment_id\", \"date_time\", \"model\", \"is_encoder_decoder\",\n",
    "        \"task_type\", \"available_gpu_count\", \"gpu_model\", \"available_cpu_count\", \"cpu_model\",\n",
    "        \"os\", \"python_version\", \"country\", \"region\", \"fsdp_use_orig_params\", \"fsdp_cpu_offload\",\n",
    "        \"sharding_strategy\", \"distributed_type\", \"num_processes\", \"max_input_tokens\", \"max_output_tokens\",\n",
    "        \"number_input_prompts\", \"decode_token_to_text\", \"decoder_temperature\", \"decoder_top_k\", \"decoder_top_p\",\n",
    "        \"query_rate\", \"latency_simulate\", \"latency_delay_min\", \"latency_delay_max\", \"latency_simulate_burst\",\n",
    "        \"latency_burst_interval\", \"latency_burst_size\", \"fp_precision\", \"quantization\", \"load_in_8bit\",\n",
    "        \"load_in_4bit\", \"cached_flops_for_quantised_models\", \"batch_size___fixed_batching\", \"adaptive_batching\",\n",
    "        \"adaptive_max_tokens\", \"max_batch_size___adaptive_batching\", \"inference_type\", \"backend\", \"total_params\",\n",
    "        \"architecture\", \"total_input_tokens\", \"total_generated_tokens\", \"total_inference_time_sec\", \n",
    "        \"average_latency_ms_per_batch\", \"throughput_queries_per_sec\", \"throughput_tokens_per_sec\", \"flops\",\n",
    "        \"gpu_current_memory_allocated_bytes\", \"gpu_max_memory_allocated_bytes\", \"gpu_current_memory_reserved_bytes\",\n",
    "        \"gpu_max_memory_reserved_bytes\", \"gpu_utilization_percent\", \"cpu_usage_percent\", \"cpu_memory_usage_bytes\",\n",
    "        # Per-process metrics:\n",
    "        \"cpu_power_process_0\", \"gpu_power_process_0\", \"ram_power_process_0\",\n",
    "        \"cpu_energy_process_0\", \"gpu_energy_process_0\", \"ram_energy_process_0\",\n",
    "        \"total_energy_kwh_process_0\", \"total_energy_joules_process_0\",\n",
    "        # Global averages and totals:\n",
    "        \"cpu_power_avg\", \"gpu_power_avg\", \"ram_power_avg\", \"cpu_energy_total\", \"gpu_energy_total\", \"ram_energy_total\",\n",
    "        \"total_energy_kwh\", \"total_energy_joules\", \"tokens_per_joule\", \"joules_per_token\", \"flops_per_joule\", \"joules_per_flop\",\n",
    "        \"per-process_emissions\"\n",
    "    ]\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in col:\n",
    "            idx = col.find(token)\n",
    "            return col[idx:]\n",
    "    \n",
    "    return col\n",
    "\n",
    "def resolve_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Resolve duplicate columns in the DataFrame.\n",
    "    \n",
    "    For any column that appears more than once:\n",
    "      - For 'adaptive_batching', if duplicates exist, prefer the one with a boolean dtype;\n",
    "        otherwise, pick the first occurrence.\n",
    "      - For all other columns (including 'experiment_id' and 'number_input_prompts'),\n",
    "        keep only the first occurrence.\n",
    "    \"\"\"\n",
    "    # Build a mapping of column name to list of indices where it occurs.\n",
    "    seen = {}\n",
    "    for idx, col in enumerate(df.columns):\n",
    "        seen.setdefault(col, []).append(idx)\n",
    "    \n",
    "    # Choose one index per duplicate group.\n",
    "    chosen_indices = []\n",
    "    for col, indices in seen.items():\n",
    "        if len(indices) == 1:\n",
    "            chosen_indices.append(indices[0])\n",
    "        else:\n",
    "            if col == \"adaptive_batching\":\n",
    "                # Look for a column with boolean type.\n",
    "                bool_idx = None\n",
    "                for i in indices:\n",
    "                    if pd.api.types.is_bool_dtype(df.iloc[:, i]):\n",
    "                        bool_idx = i\n",
    "                        break\n",
    "                chosen_indices.append(bool_idx if bool_idx is not None else indices[0])\n",
    "            else:\n",
    "                # For experiment_id, number_input_prompts, or any duplicate, keep the first occurrence.\n",
    "                chosen_indices.append(indices[0])\n",
    "    \n",
    "    # Sort indices to preserve the original order.\n",
    "    chosen_indices.sort()\n",
    "    return df.iloc[:, chosen_indices]\n",
    "\n",
    "def clean_and_reorder_columns(df: pd.DataFrame, desired_order: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean DataFrame columns by:\n",
    "      1. Renaming each column to remove extraneous prefixes and apply special mappings.\n",
    "      2. Removing duplicates (applying special resolution for some columns).\n",
    "      3. Reordering columns into the order specified by 'desired_order'. Any columns not explicitly mentioned\n",
    "         will be appended at the end.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with messy, flattened column names.\n",
    "        desired_order (list): List of column names (after cleaning) indicating the preferred ordering.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with cleaned and reordered columns.\n",
    "    \"\"\"\n",
    "    # Build mapping from original column names to cleaned names.\n",
    "    mapping = {col: clean_column(col) for col in df.columns}\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    df = df.rename(columns=mapping)\n",
    "    \n",
    "    # Resolve duplicates as required.\n",
    "    df = resolve_duplicates(df)\n",
    "    \n",
    "    # Reorder columns: first, the ones matching the desired order.\n",
    "    ordered_cols = [col for col in desired_order if col in df.columns]\n",
    "    # Then, append any remaining columns.\n",
    "    remaining_cols = [col for col in df.columns if col not in desired_order]\n",
    "    final_order = ordered_cols + remaining_cols\n",
    "    \n",
    "    return df[final_order]\n",
    "\n",
    "# Example desired order list\n",
    "desired_order = [\n",
    "    \"config_name\",\n",
    "    \"experiment_id\",\n",
    "    \"date_time\",\n",
    "    \"model\",\n",
    "    # num_process\n",
    "    \"num_processes\",\n",
    "    # batching\n",
    "    \"batch_size___fixed_batching\",\n",
    "    # decodeer\n",
    "    \"decoder_temperature\",\n",
    "    \"decoder_top_k\",\n",
    "    \"decoder_top_p\",\n",
    "    # latency\n",
    "    \"latency_simulation_simulate\"\n",
    "    \"latency_simulation_delay_max\",\n",
    "    \"latency_simulation_delay_min\",\n",
    "    \"latency_simulation_simulate_burst\",\n",
    "    \"latency_simulation_burst_size\",\n",
    "    \"latency_simulation_burst_interval\",\n",
    "    # precision / quantisation\n",
    "    \"fp_precision\",\n",
    "    \"quantization\",\n",
    "    \"load_in_8bit\",\n",
    "    \"load_in_4bit\",\n",
    "    \"cached_flops_for_quantised_models\",\n",
    "    \n",
    "    # UNUSED PARAMS\n",
    "    \"sharding_strategy\",\n",
    "    \"sharding_config_fsdp_config_use_orig_params\",\n",
    "    \"sharding_config_fsdp_config_cpu_offload\",\n",
    "    \"adaptive_batching\",\n",
    "    \"adaptive_max_tokens\",\n",
    "    \"query_rate\",\n",
    "    \"total_input_tokens\",\n",
    "    \"total_generated_tokens\"\n",
    "    \n",
    "    # CONSTANT SETUP ====\n",
    "    \"date_time\",\n",
    "    \"is_encoder_decoder\",\n",
    "    \"task_type\",\n",
    "    \"available_gpu_count\",\n",
    "    \"gpu_model\",\n",
    "    \"available_cpu_count\",\n",
    "    \"cpu_model\",\n",
    "    \"os\",\n",
    "    \"python_version\",\n",
    "    \"country\",\n",
    "    \"region\",\n",
    "    \"distributed_type\",\n",
    "    \"decode_token_to_text\",\n",
    "    \"inference_type\",\n",
    "    \"backend\",\n",
    "    \"total_params\",\n",
    "    \"model_arch\",\n",
    "\n",
    "    # Validation (should be same):\n",
    "    \"max_input_tokens\",\n",
    "    \"max_output_tokens\",\n",
    "    \"number_input_prompts\",\n",
    "    \n",
    "    # RESULTS =====\n",
    "    # energy\n",
    "    \"total_energy_kwh\",\n",
    "    \"total_energy_joules\",\n",
    "    # FLOPS\n",
    "    \"flops\",\n",
    "    \"tokens_per_joule\",\n",
    "    \"joules_per_token\",\n",
    "    \"flops_per_joule\",\n",
    "    \"joules_per_flop\",\n",
    "    \"total_inference_time_sec\", \n",
    "    # inference performance\n",
    "    \"average_latency_ms_per_batch\",\n",
    "    \"throughput_queries_per_sec\",\n",
    "    \"throughput_tokens_per_sec\",\n",
    "    # CPU utilization\n",
    "    \"cpu_usage_percent\",\n",
    "    \"cpu_memory_usage_bytes\",\n",
    "    # GPU utilization\n",
    "    \"gpu_utilization_percent_0\", \"gpu_utilization_percent_1\", \"gpu_utilization_percent_2\", \"gpu_utilization_percent_3\",\n",
    "    # Compute mem\n",
    "    \"gpu_current_memory_allocated_bytes\",\n",
    "    \"gpu_max_memory_allocated_bytes\",\n",
    "    \"gpu_current_memory_reserved_bytes\",\n",
    "    \"gpu_max_memory_reserved_bytes\",\n",
    "    # Per-process metrics:\n",
    "    \"cpu_power_process_0\", \"cpu_power_process_1\", \"cpu_power_process_2\", \"cpu_power_process_3\",\n",
    "    \"gpu_power_process_0\", \"gpu_power_process_1\", \"gpu_power_process_2\", \"gpu_power_process_3\",\n",
    "    \"ram_power_process_0\", \"ram_power_process_1\", \"ram_power_process_2\", \"ram_power_process_3\",\n",
    "    \"cpu_energy_process_0\", \"cpu_energy_process_1\", \"cpu_energy_process_2\", \"cpu_energy_process_3\",\n",
    "    \"gpu_energy_process_0\", \"gpu_energy_process_1\", \"gpu_energy_process_2\", \"gpu_energy_process_3\",\n",
    "    \"ram_energy_process_0\", \"ram_energy_process_1\", \"ram_energy_process_2\", \"ram_energy_process_3\",\n",
    "    \"total_energy_kwh_process_0\", \"total_energy_kwh_process_1\", \"total_energy_kwh_process_2\", \"total_energy_kwh_process_3\",\n",
    "    \"total_energy_joules_process_0\", \"total_energy_joules_process_1\", \"total_energy_joules_process_2\", \"total_energy_joules_process_3\",\n",
    "    # Global averages and totals:\n",
    "    \"cpu_power_avg\",\n",
    "    \"gpu_power_avg\",\n",
    "    \"ram_power_avg\",\n",
    "    \"cpu_energy_total\",\n",
    "    \"gpu_energy_total\",\n",
    "    \"ram_energy_total\",\n",
    "    # per-process_emsisisons\n",
    "    \"per-process_emissions_0\", \"per-process_emissions_1\", \"per-process_emissions_2\",\"per-process_emissions_3\"\n",
    "]\n",
    "\n",
    "def inspect_results(name, desired_order):\n",
    "    input_file = f\"{name}_results.csv\"\n",
    "    \n",
    "    df = pd.read_csv(input_file)\n",
    "    df_cleaned = clean_and_reorder_columns(df, desired_order)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "# COME BACK TO THIS\n",
    "#process_possible_files(func=clean_and_reorder_columns, \n",
    "#                       desired_order=desired_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "controlled did not exist: [Errno 2] No such file or directory: 'controlled_results.csv'\n",
      "Found & inspecting: df_scenarios_cleaned\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>config_name</th>\n",
       "      <td>A1_Max_Throughput_Exploit</td>\n",
       "      <td>A2_Precision_Minimalist</td>\n",
       "      <td>A3_Quantisation_Gaming</td>\n",
       "      <td>default</td>\n",
       "      <td>A5_Parallel_Overdrive</td>\n",
       "      <td>R2_Low_Latency_Chatbot_Deployment</td>\n",
       "      <td>R3_Balanced_Enterprise_Service</td>\n",
       "      <td>R4_High_Load_Cloud_API_Deployment</td>\n",
       "      <td>R5_Real_Time_Mobile_Inference</td>\n",
       "      <td>R6_Medium_Scale_Language_Model_Serving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>88</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <td>April 11, 2025 at 09:26:09 AM</td>\n",
       "      <td>April 11, 2025 at 09:26:45 AM</td>\n",
       "      <td>April 11, 2025 at 09:27:20 AM</td>\n",
       "      <td>April 11, 2025 at 09:28:53 AM</td>\n",
       "      <td>April 11, 2025 at 09:29:30 AM</td>\n",
       "      <td>April 11, 2025 at 09:32:17 AM</td>\n",
       "      <td>April 11, 2025 at 09:34:13 AM</td>\n",
       "      <td>April 11, 2025 at 09:35:31 AM</td>\n",
       "      <td>April 11, 2025 at 09:52:12 AM</td>\n",
       "      <td>April 11, 2025 at 09:52:53 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_processes</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size___fixed_batching</th>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_temperature</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_k</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_p</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate_burst</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_size</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_interval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp_precision</th>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantization</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_8bit</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_4bit</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharding_strategy</th>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharding_config_fsdp_config_use_orig_params</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharding_config_fsdp_config_cpu_offload</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive_batching</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive_max_tokens</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_rate</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_input_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_encoder_decoder</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_type</th>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_gpu_count</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_model</th>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_cpu_count</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_model</th>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>os</th>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python_version</th>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distributed_type</th>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decode_token_to_text</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inference_type</th>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backend</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_params</th>\n",
       "      <td>1100048384</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_arch</th>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_input_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_output_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_input_prompts</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh</th>\n",
       "      <td>0.013223</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.007356</td>\n",
       "      <td>0.005716</td>\n",
       "      <td>0.040431</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.040048</td>\n",
       "      <td>0.008429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules</th>\n",
       "      <td>47602.027224</td>\n",
       "      <td>6172.265465</td>\n",
       "      <td>2452.230798</td>\n",
       "      <td>11249.925529</td>\n",
       "      <td>26479.81109</td>\n",
       "      <td>20576.854237</td>\n",
       "      <td>145551.227246</td>\n",
       "      <td>9583.955319</td>\n",
       "      <td>144173.372804</td>\n",
       "      <td>30343.668594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops</th>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>16949970993152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens_per_joule</th>\n",
       "      <td>0.344187</td>\n",
       "      <td>2.654455</td>\n",
       "      <td>6.681263</td>\n",
       "      <td>1.456365</td>\n",
       "      <td>0.618736</td>\n",
       "      <td>0.796234</td>\n",
       "      <td>0.112565</td>\n",
       "      <td>1.709524</td>\n",
       "      <td>0.101114</td>\n",
       "      <td>0.539948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_token</th>\n",
       "      <td>2.905397</td>\n",
       "      <td>0.376725</td>\n",
       "      <td>0.149672</td>\n",
       "      <td>0.686641</td>\n",
       "      <td>1.616199</td>\n",
       "      <td>1.255912</td>\n",
       "      <td>8.883742</td>\n",
       "      <td>0.584958</td>\n",
       "      <td>9.889791</td>\n",
       "      <td>1.852031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops_per_joule</th>\n",
       "      <td>21733194.74657</td>\n",
       "      <td>167611735.734102</td>\n",
       "      <td>421878776.19706</td>\n",
       "      <td>91960086.784679</td>\n",
       "      <td>640109211.326309</td>\n",
       "      <td>823739663.881693</td>\n",
       "      <td>7107766.437801</td>\n",
       "      <td>1768577839.650868</td>\n",
       "      <td>7175694.844886</td>\n",
       "      <td>558599924.750814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_flop</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_inference_time_sec</th>\n",
       "      <td>11.096081</td>\n",
       "      <td>4.970398</td>\n",
       "      <td>9.531417</td>\n",
       "      <td>69.845126</td>\n",
       "      <td>6.284194</td>\n",
       "      <td>86.120057</td>\n",
       "      <td>42.836278</td>\n",
       "      <td>53.885367</td>\n",
       "      <td>976.021093</td>\n",
       "      <td>12.368555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_latency_ms_per_batch</th>\n",
       "      <td>11096.081339</td>\n",
       "      <td>4970.398136</td>\n",
       "      <td>4765.708533</td>\n",
       "      <td>8730.640718</td>\n",
       "      <td>3142.096803</td>\n",
       "      <td>2691.251768</td>\n",
       "      <td>10709.069527</td>\n",
       "      <td>3367.835437</td>\n",
       "      <td>7625.16479</td>\n",
       "      <td>3092.138661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_queries_per_sec</th>\n",
       "      <td>11.535604</td>\n",
       "      <td>25.752464</td>\n",
       "      <td>13.429273</td>\n",
       "      <td>1.832626</td>\n",
       "      <td>20.368564</td>\n",
       "      <td>1.486297</td>\n",
       "      <td>2.988121</td>\n",
       "      <td>2.375413</td>\n",
       "      <td>0.131145</td>\n",
       "      <td>10.348824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_tokens_per_sec</th>\n",
       "      <td>1476.557309</td>\n",
       "      <td>3296.315416</td>\n",
       "      <td>1718.946919</td>\n",
       "      <td>234.57614</td>\n",
       "      <td>2607.176199</td>\n",
       "      <td>190.246043</td>\n",
       "      <td>382.479541</td>\n",
       "      <td>304.052861</td>\n",
       "      <td>14.936153</td>\n",
       "      <td>1324.649522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_usage_percent</th>\n",
       "      <td>5.5</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_memory_usage_bytes</th>\n",
       "      <td>2715783168</td>\n",
       "      <td>2638508032</td>\n",
       "      <td>2673549312</td>\n",
       "      <td>2712358912</td>\n",
       "      <td>3099574272</td>\n",
       "      <td>2005184512</td>\n",
       "      <td>2711977984</td>\n",
       "      <td>3103125504</td>\n",
       "      <td>2694705152</td>\n",
       "      <td>3104542720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_current_memory_allocated_bytes</th>\n",
       "      <td>1577541632</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1576560640</td>\n",
       "      <td>4419853312</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>1576947200</td>\n",
       "      <td>4419853312</td>\n",
       "      <td>1576178688</td>\n",
       "      <td>4419853312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_max_memory_allocated_bytes</th>\n",
       "      <td>1577541632</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1576560640</td>\n",
       "      <td>4419853312</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>1576947200</td>\n",
       "      <td>4419853312</td>\n",
       "      <td>1576178688</td>\n",
       "      <td>4419853312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_current_memory_reserved_bytes</th>\n",
       "      <td>3577741312</td>\n",
       "      <td>2621440000</td>\n",
       "      <td>1986002944</td>\n",
       "      <td>2707423232</td>\n",
       "      <td>6870269952</td>\n",
       "      <td>12343836672</td>\n",
       "      <td>2839543808</td>\n",
       "      <td>6339690496</td>\n",
       "      <td>2665480192</td>\n",
       "      <td>4922015744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_max_memory_reserved_bytes</th>\n",
       "      <td>3577741312</td>\n",
       "      <td>2621440000</td>\n",
       "      <td>1986002944</td>\n",
       "      <td>2707423232</td>\n",
       "      <td>6870269952</td>\n",
       "      <td>12343836672</td>\n",
       "      <td>2839543808</td>\n",
       "      <td>6339690496</td>\n",
       "      <td>2665480192</td>\n",
       "      <td>4922015744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_0</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_1</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_2</th>\n",
       "      <td>112.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_3</th>\n",
       "      <td>112.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_0</th>\n",
       "      <td>791.788134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>179.704454</td>\n",
       "      <td>52.794036</td>\n",
       "      <td>897.963025</td>\n",
       "      <td>171.907373</td>\n",
       "      <td>404.914269</td>\n",
       "      <td>80.621122</td>\n",
       "      <td>39.818412</td>\n",
       "      <td>622.460527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>302.820212</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>693.727217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.875217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527.52292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_2</th>\n",
       "      <td>723.637883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>716.813226</td>\n",
       "      <td>NaN</td>\n",
       "      <td>593.80482</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>566.509722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_3</th>\n",
       "      <td>433.516185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>440.413189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>476.328763</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>631.050066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_0</th>\n",
       "      <td>0.947717</td>\n",
       "      <td>0.920308</td>\n",
       "      <td>0.933053</td>\n",
       "      <td>0.946954</td>\n",
       "      <td>1.081133</td>\n",
       "      <td>0.698569</td>\n",
       "      <td>0.946426</td>\n",
       "      <td>1.081238</td>\n",
       "      <td>0.939752</td>\n",
       "      <td>1.081843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_1</th>\n",
       "      <td>0.978775</td>\n",
       "      <td>0.967795</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.851801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992685</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.881829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_2</th>\n",
       "      <td>0.981771</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.852765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.870511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_3</th>\n",
       "      <td>0.984708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.874648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.992981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.871479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_0</th>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.00019</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.029887</td>\n",
       "      <td>0.000384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_1</th>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_2</th>\n",
       "      <td>0.000481</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_3</th>\n",
       "      <td>0.000745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_0</th>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.005762</td>\n",
       "      <td>0.00099</td>\n",
       "      <td>0.00995</td>\n",
       "      <td>0.001713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_1</th>\n",
       "      <td>0.002812</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008117</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_2</th>\n",
       "      <td>0.002612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_3</th>\n",
       "      <td>0.003751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00175</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_0</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_1</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_2</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_3</th>\n",
       "      <td>0.000006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_0</th>\n",
       "      <td>0.002251</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.005716</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.040048</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_1</th>\n",
       "      <td>0.003373</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_2</th>\n",
       "      <td>0.003097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_3</th>\n",
       "      <td>0.004501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_0</th>\n",
       "      <td>8103.220083</td>\n",
       "      <td>2853.013689</td>\n",
       "      <td>2452.230798</td>\n",
       "      <td>11249.925529</td>\n",
       "      <td>5591.718676</td>\n",
       "      <td>20576.854237</td>\n",
       "      <td>25516.342787</td>\n",
       "      <td>9583.955319</td>\n",
       "      <td>144173.372804</td>\n",
       "      <td>7559.95657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_1</th>\n",
       "      <td>12144.024856</td>\n",
       "      <td>3319.251776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6853.997395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35892.851217</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7731.953568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_2</th>\n",
       "      <td>11149.682659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6739.469001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32807.532851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7476.56876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_3</th>\n",
       "      <td>16205.099626</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7294.626019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51334.500392</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7575.189696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_avg</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_avg</th>\n",
       "      <td>487.235551</td>\n",
       "      <td>151.410106</td>\n",
       "      <td>179.704454</td>\n",
       "      <td>52.794036</td>\n",
       "      <td>687.229164</td>\n",
       "      <td>171.907373</td>\n",
       "      <td>496.980767</td>\n",
       "      <td>80.621122</td>\n",
       "      <td>39.818412</td>\n",
       "      <td>586.885809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_avg</th>\n",
       "      <td>0.973243</td>\n",
       "      <td>0.944052</td>\n",
       "      <td>0.933053</td>\n",
       "      <td>0.946954</td>\n",
       "      <td>0.915087</td>\n",
       "      <td>0.698569</td>\n",
       "      <td>0.980666</td>\n",
       "      <td>1.081238</td>\n",
       "      <td>0.939752</td>\n",
       "      <td>0.926415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_total</th>\n",
       "      <td>0.002127</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.029887</td>\n",
       "      <td>0.001544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_total</th>\n",
       "      <td>0.011079</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.006385</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.03286</td>\n",
       "      <td>0.00099</td>\n",
       "      <td>0.00995</td>\n",
       "      <td>0.006874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_total</th>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_0</th>\n",
       "      <td>0.00118</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.00119</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>0.015256</td>\n",
       "      <td>0.000791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_1</th>\n",
       "      <td>0.001715</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_2</th>\n",
       "      <td>0.000857</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_3</th>\n",
       "      <td>0.001285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_generated_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>14578</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_config_decoding_mode</th>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_k</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_k</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_p</td>\n",
       "      <td>greedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             0  \\\n",
       "config_name                                                          A1_Max_Throughput_Exploit   \n",
       "experiment_id                                                                               78   \n",
       "date_time                                                        April 11, 2025 at 09:26:09 AM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                256   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                              True   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.013223   \n",
       "total_energy_joules                                                               47602.027224   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.344187   \n",
       "joules_per_token                                                                      2.905397   \n",
       "flops_per_joule                                                                 21733194.74657   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             11.096081   \n",
       "average_latency_ms_per_batch                                                      11096.081339   \n",
       "throughput_queries_per_sec                                                           11.535604   \n",
       "throughput_tokens_per_sec                                                          1476.557309   \n",
       "cpu_usage_percent                                                                          5.5   \n",
       "cpu_memory_usage_bytes                                                              2715783168   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1577541632   \n",
       "gpu_max_memory_allocated_bytes                                                      1577541632   \n",
       "gpu_current_memory_reserved_bytes                                                   3577741312   \n",
       "gpu_max_memory_reserved_bytes                                                       3577741312   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 791.788134   \n",
       "gpu_power_process_1                                                                        0.0   \n",
       "gpu_power_process_2                                                                 723.637883   \n",
       "gpu_power_process_3                                                                 433.516185   \n",
       "ram_power_process_0                                                                   0.947717   \n",
       "ram_power_process_1                                                                   0.978775   \n",
       "ram_power_process_2                                                                   0.981771   \n",
       "ram_power_process_3                                                                   0.984708   \n",
       "cpu_energy_process_0                                                                  0.000344   \n",
       "cpu_energy_process_1                                                                  0.000557   \n",
       "cpu_energy_process_2                                                                  0.000481   \n",
       "cpu_energy_process_3                                                                  0.000745   \n",
       "gpu_energy_process_0                                                                  0.001904   \n",
       "gpu_energy_process_1                                                                  0.002812   \n",
       "gpu_energy_process_2                                                                  0.002612   \n",
       "gpu_energy_process_3                                                                  0.003751   \n",
       "ram_energy_process_0                                                                  0.000003   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000006   \n",
       "total_energy_kwh_process_0                                                            0.002251   \n",
       "total_energy_kwh_process_1                                                            0.003373   \n",
       "total_energy_kwh_process_2                                                            0.003097   \n",
       "total_energy_kwh_process_3                                                            0.004501   \n",
       "total_energy_joules_process_0                                                      8103.220083   \n",
       "total_energy_joules_process_1                                                     12144.024856   \n",
       "total_energy_joules_process_2                                                     11149.682659   \n",
       "total_energy_joules_process_3                                                     16205.099626   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       487.235551   \n",
       "ram_power_avg                                                                         0.973243   \n",
       "cpu_energy_total                                                                      0.002127   \n",
       "gpu_energy_total                                                                      0.011079   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                                0.00118   \n",
       "per-process_emissions_1                                                               0.001715   \n",
       "per-process_emissions_2                                                               0.000857   \n",
       "per-process_emissions_3                                                               0.001285   \n",
       "latency_simulation_simulate                                                              False   \n",
       "total_generated_tokens                                                                   16384   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "models                                                                           1034544128000   \n",
       "\n",
       "                                                                                             1  \\\n",
       "config_name                                                            A2_Precision_Minimalist   \n",
       "experiment_id                                                                               79   \n",
       "date_time                                                        April 11, 2025 at 09:26:45 AM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                2   \n",
       "batch_size___fixed_batching                                                                128   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          2   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.001715   \n",
       "total_energy_joules                                                                6172.265465   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      2.654455   \n",
       "joules_per_token                                                                      0.376725   \n",
       "flops_per_joule                                                               167611735.734102   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              4.970398   \n",
       "average_latency_ms_per_batch                                                       4970.398136   \n",
       "throughput_queries_per_sec                                                           25.752464   \n",
       "throughput_tokens_per_sec                                                          3296.315416   \n",
       "cpu_usage_percent                                                                          3.6   \n",
       "cpu_memory_usage_bytes                                                              2638508032   \n",
       "gpu_utilization_percent_0                                                                  2.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                  5.0   \n",
       "gpu_utilization_percent_3                                                                  2.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   2621440000   \n",
       "gpu_max_memory_reserved_bytes                                                       2621440000   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                        NaN   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                        0.0   \n",
       "gpu_power_process_1                                                                 302.820212   \n",
       "gpu_power_process_2                                                                        NaN   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   0.920308   \n",
       "ram_power_process_1                                                                   0.967795   \n",
       "ram_power_process_2                                                                        NaN   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                   0.00019   \n",
       "cpu_energy_process_1                                                                  0.000202   \n",
       "cpu_energy_process_2                                                                       NaN   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                  0.000601   \n",
       "gpu_energy_process_1                                                                  0.000718   \n",
       "gpu_energy_process_2                                                                       NaN   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                  0.000001   \n",
       "ram_energy_process_1                                                                  0.000002   \n",
       "ram_energy_process_2                                                                       NaN   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.000793   \n",
       "total_energy_kwh_process_1                                                            0.000922   \n",
       "total_energy_kwh_process_2                                                                 NaN   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                      2853.013689   \n",
       "total_energy_joules_process_1                                                      3319.251776   \n",
       "total_energy_joules_process_2                                                              NaN   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       151.410106   \n",
       "ram_power_avg                                                                         0.944052   \n",
       "cpu_energy_total                                                                      0.000393   \n",
       "gpu_energy_total                                                                      0.001319   \n",
       "ram_energy_total                                                                      0.000003   \n",
       "per-process_emissions_0                                                               0.000302   \n",
       "per-process_emissions_1                                                               0.000351   \n",
       "per-process_emissions_2                                                                    NaN   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "total_generated_tokens                                                                   16384   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "models                                                                           1034544128000   \n",
       "\n",
       "                                                                                             2  \\\n",
       "config_name                                                             A3_Quantisation_Gaming   \n",
       "experiment_id                                                                               80   \n",
       "date_time                                                        April 11, 2025 at 09:27:20 AM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                1   \n",
       "batch_size___fixed_batching                                                                 64   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          1   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.000681   \n",
       "total_energy_joules                                                                2452.230798   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      6.681263   \n",
       "joules_per_token                                                                      0.149672   \n",
       "flops_per_joule                                                                421878776.19706   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              9.531417   \n",
       "average_latency_ms_per_batch                                                       4765.708533   \n",
       "throughput_queries_per_sec                                                           13.429273   \n",
       "throughput_tokens_per_sec                                                          1718.946919   \n",
       "cpu_usage_percent                                                                          3.6   \n",
       "cpu_memory_usage_bytes                                                              2673549312   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                  1.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1986002944   \n",
       "gpu_max_memory_reserved_bytes                                                       1986002944   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                        NaN   \n",
       "cpu_power_process_2                                                                        NaN   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                 179.704454   \n",
       "gpu_power_process_1                                                                        NaN   \n",
       "gpu_power_process_2                                                                        NaN   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   0.933053   \n",
       "ram_power_process_1                                                                        NaN   \n",
       "ram_power_process_2                                                                        NaN   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                  0.000297   \n",
       "cpu_energy_process_1                                                                       NaN   \n",
       "cpu_energy_process_2                                                                       NaN   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                  0.000383   \n",
       "gpu_energy_process_1                                                                       NaN   \n",
       "gpu_energy_process_2                                                                       NaN   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                  0.000002   \n",
       "ram_energy_process_1                                                                       NaN   \n",
       "ram_energy_process_2                                                                       NaN   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.000681   \n",
       "total_energy_kwh_process_1                                                                 NaN   \n",
       "total_energy_kwh_process_2                                                                 NaN   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                      2452.230798   \n",
       "total_energy_joules_process_1                                                              NaN   \n",
       "total_energy_joules_process_2                                                              NaN   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       179.704454   \n",
       "ram_power_avg                                                                         0.933053   \n",
       "cpu_energy_total                                                                      0.000297   \n",
       "gpu_energy_total                                                                      0.000383   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000259   \n",
       "per-process_emissions_1                                                                    NaN   \n",
       "per-process_emissions_2                                                                    NaN   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "total_generated_tokens                                                                   16384   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "models                                                                           1034544128000   \n",
       "\n",
       "                                                                                             3  \\\n",
       "config_name                                                                            default   \n",
       "experiment_id                                                                               81   \n",
       "date_time                                                        April 11, 2025 at 09:28:53 AM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                1   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                              True   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          1   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.003125   \n",
       "total_energy_joules                                                               11249.925529   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      1.456365   \n",
       "joules_per_token                                                                      0.686641   \n",
       "flops_per_joule                                                                91960086.784679   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             69.845126   \n",
       "average_latency_ms_per_batch                                                       8730.640718   \n",
       "throughput_queries_per_sec                                                            1.832626   \n",
       "throughput_tokens_per_sec                                                            234.57614   \n",
       "cpu_usage_percent                                                                          4.3   \n",
       "cpu_memory_usage_bytes                                                              2712358912   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                 47.0   \n",
       "gpu_utilization_percent_3                                                                 50.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1576560640   \n",
       "gpu_max_memory_allocated_bytes                                                      1576560640   \n",
       "gpu_current_memory_reserved_bytes                                                   2707423232   \n",
       "gpu_max_memory_reserved_bytes                                                       2707423232   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                        NaN   \n",
       "cpu_power_process_2                                                                        NaN   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                  52.794036   \n",
       "gpu_power_process_1                                                                        NaN   \n",
       "gpu_power_process_2                                                                        NaN   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   0.946954   \n",
       "ram_power_process_1                                                                        NaN   \n",
       "ram_power_process_2                                                                        NaN   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                  0.002144   \n",
       "cpu_energy_process_1                                                                       NaN   \n",
       "cpu_energy_process_2                                                                       NaN   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                  0.000966   \n",
       "gpu_energy_process_1                                                                       NaN   \n",
       "gpu_energy_process_2                                                                       NaN   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                  0.000015   \n",
       "ram_energy_process_1                                                                       NaN   \n",
       "ram_energy_process_2                                                                       NaN   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.003125   \n",
       "total_energy_kwh_process_1                                                                 NaN   \n",
       "total_energy_kwh_process_2                                                                 NaN   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                     11249.925529   \n",
       "total_energy_joules_process_1                                                              NaN   \n",
       "total_energy_joules_process_2                                                              NaN   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        52.794036   \n",
       "ram_power_avg                                                                         0.946954   \n",
       "cpu_energy_total                                                                      0.002144   \n",
       "gpu_energy_total                                                                      0.000966   \n",
       "ram_energy_total                                                                      0.000015   \n",
       "per-process_emissions_0                                                                0.00119   \n",
       "per-process_emissions_1                                                                    NaN   \n",
       "per-process_emissions_2                                                                    NaN   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "total_generated_tokens                                                                   16384   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "models                                                                           1034544128000   \n",
       "\n",
       "                                                                                             4  \\\n",
       "config_name                                                              A5_Parallel_Overdrive   \n",
       "experiment_id                                                                               82   \n",
       "date_time                                                        April 11, 2025 at 09:29:30 AM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 64   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.007356   \n",
       "total_energy_joules                                                                26479.81109   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.618736   \n",
       "joules_per_token                                                                      1.616199   \n",
       "flops_per_joule                                                               640109211.326309   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              6.284194   \n",
       "average_latency_ms_per_batch                                                       3142.096803   \n",
       "throughput_queries_per_sec                                                           20.368564   \n",
       "throughput_tokens_per_sec                                                          2607.176199   \n",
       "cpu_usage_percent                                                                          5.2   \n",
       "cpu_memory_usage_bytes                                                              3099574272   \n",
       "gpu_utilization_percent_0                                                                  3.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  4419853312   \n",
       "gpu_max_memory_allocated_bytes                                                      4419853312   \n",
       "gpu_current_memory_reserved_bytes                                                   6870269952   \n",
       "gpu_max_memory_reserved_bytes                                                       6870269952   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 897.963025   \n",
       "gpu_power_process_1                                                                 693.727217   \n",
       "gpu_power_process_2                                                                 716.813226   \n",
       "gpu_power_process_3                                                                 440.413189   \n",
       "ram_power_process_0                                                                   1.081133   \n",
       "ram_power_process_1                                                                   0.851801   \n",
       "ram_power_process_2                                                                   0.852765   \n",
       "ram_power_process_3                                                                   0.874648   \n",
       "cpu_energy_process_0                                                                  0.000198   \n",
       "cpu_energy_process_1                                                                  0.000248   \n",
       "cpu_energy_process_2                                                                  0.000243   \n",
       "cpu_energy_process_3                                                                  0.000275   \n",
       "gpu_energy_process_0                                                                  0.001353   \n",
       "gpu_energy_process_1                                                                  0.001654   \n",
       "gpu_energy_process_2                                                                  0.001628   \n",
       "gpu_energy_process_3                                                                   0.00175   \n",
       "ram_energy_process_0                                                                  0.000002   \n",
       "ram_energy_process_1                                                                  0.000002   \n",
       "ram_energy_process_2                                                                  0.000002   \n",
       "ram_energy_process_3                                                                  0.000002   \n",
       "total_energy_kwh_process_0                                                            0.001553   \n",
       "total_energy_kwh_process_1                                                            0.001904   \n",
       "total_energy_kwh_process_2                                                            0.001872   \n",
       "total_energy_kwh_process_3                                                            0.002026   \n",
       "total_energy_joules_process_0                                                      5591.718676   \n",
       "total_energy_joules_process_1                                                      6853.997395   \n",
       "total_energy_joules_process_2                                                      6739.469001   \n",
       "total_energy_joules_process_3                                                      7294.626019   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       687.229164   \n",
       "ram_power_avg                                                                         0.915087   \n",
       "cpu_energy_total                                                                      0.000964   \n",
       "gpu_energy_total                                                                      0.006385   \n",
       "ram_energy_total                                                                      0.000007   \n",
       "per-process_emissions_0                                                               0.000772   \n",
       "per-process_emissions_1                                                               0.000725   \n",
       "per-process_emissions_2                                                               0.000592   \n",
       "per-process_emissions_3                                                               0.000713   \n",
       "latency_simulation_simulate                                                              False   \n",
       "total_generated_tokens                                                                   16384   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "models                                                                           1034544128000   \n",
       "\n",
       "                                                                                             5  \\\n",
       "config_name                                                  R2_Low_Latency_Chatbot_Deployment   \n",
       "experiment_id                                                                               86   \n",
       "date_time                                                        April 11, 2025 at 09:32:17 AM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                1   \n",
       "batch_size___fixed_batching                                                                  4   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                              0.01   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          1   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.005716   \n",
       "total_energy_joules                                                               20576.854237   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.796234   \n",
       "joules_per_token                                                                      1.255912   \n",
       "flops_per_joule                                                               823739663.881693   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             86.120057   \n",
       "average_latency_ms_per_batch                                                       2691.251768   \n",
       "throughput_queries_per_sec                                                            1.486297   \n",
       "throughput_tokens_per_sec                                                           190.246043   \n",
       "cpu_usage_percent                                                                          3.6   \n",
       "cpu_memory_usage_bytes                                                              2005184512   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                  1.0   \n",
       "gpu_utilization_percent_3                                                                  3.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  12343836672   \n",
       "gpu_max_memory_reserved_bytes                                                      12343836672   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                        NaN   \n",
       "cpu_power_process_2                                                                        NaN   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                 171.907373   \n",
       "gpu_power_process_1                                                                        NaN   \n",
       "gpu_power_process_2                                                                        NaN   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   0.698569   \n",
       "ram_power_process_1                                                                        NaN   \n",
       "ram_power_process_2                                                                        NaN   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                  0.002648   \n",
       "cpu_energy_process_1                                                                       NaN   \n",
       "cpu_energy_process_2                                                                       NaN   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                  0.003054   \n",
       "gpu_energy_process_1                                                                       NaN   \n",
       "gpu_energy_process_2                                                                       NaN   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                  0.000014   \n",
       "ram_energy_process_1                                                                       NaN   \n",
       "ram_energy_process_2                                                                       NaN   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.005716   \n",
       "total_energy_kwh_process_1                                                                 NaN   \n",
       "total_energy_kwh_process_2                                                                 NaN   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                     20576.854237   \n",
       "total_energy_joules_process_1                                                              NaN   \n",
       "total_energy_joules_process_2                                                              NaN   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       171.907373   \n",
       "ram_power_avg                                                                         0.698569   \n",
       "cpu_energy_total                                                                      0.002648   \n",
       "gpu_energy_total                                                                      0.003054   \n",
       "ram_energy_total                                                                      0.000014   \n",
       "per-process_emissions_0                                                               0.002177   \n",
       "per-process_emissions_1                                                                    NaN   \n",
       "per-process_emissions_2                                                                    NaN   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "latency_simulation_simulate                                                               True   \n",
       "total_generated_tokens                                                                   16384   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                              0.05   \n",
       "models                                                                           1034544128000   \n",
       "\n",
       "                                                                                             6  \\\n",
       "config_name                                                     R3_Balanced_Enterprise_Service   \n",
       "experiment_id                                                                               87   \n",
       "date_time                                                        April 11, 2025 at 09:34:13 AM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 32   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.5   \n",
       "latency_simulation_simulate_burst                                                         True   \n",
       "latency_simulation_burst_size                                                                5   \n",
       "latency_simulation_burst_interval                                                          4.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                              True   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.040431   \n",
       "total_energy_joules                                                              145551.227246   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.112565   \n",
       "joules_per_token                                                                      8.883742   \n",
       "flops_per_joule                                                                 7107766.437801   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             42.836278   \n",
       "average_latency_ms_per_batch                                                      10709.069527   \n",
       "throughput_queries_per_sec                                                            2.988121   \n",
       "throughput_tokens_per_sec                                                           382.479541   \n",
       "cpu_usage_percent                                                                          5.1   \n",
       "cpu_memory_usage_bytes                                                              2711977984   \n",
       "gpu_utilization_percent_0                                                                 10.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                 92.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1576947200   \n",
       "gpu_max_memory_allocated_bytes                                                      1576947200   \n",
       "gpu_current_memory_reserved_bytes                                                   2839543808   \n",
       "gpu_max_memory_reserved_bytes                                                       2839543808   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 404.914269   \n",
       "gpu_power_process_1                                                                 512.875217   \n",
       "gpu_power_process_2                                                                  593.80482   \n",
       "gpu_power_process_3                                                                 476.328763   \n",
       "ram_power_process_0                                                                   0.946426   \n",
       "ram_power_process_1                                                                   0.992685   \n",
       "ram_power_process_2                                                                   0.990571   \n",
       "ram_power_process_3                                                                   0.992981   \n",
       "cpu_energy_process_0                                                                  0.001317   \n",
       "cpu_energy_process_1                                                                  0.001839   \n",
       "cpu_energy_process_2                                                                  0.001676   \n",
       "cpu_energy_process_3                                                                  0.002681   \n",
       "gpu_energy_process_0                                                                  0.005762   \n",
       "gpu_energy_process_1                                                                  0.008117   \n",
       "gpu_energy_process_2                                                                  0.007424   \n",
       "gpu_energy_process_3                                                                  0.011557   \n",
       "ram_energy_process_0                                                                  0.000009   \n",
       "ram_energy_process_1                                                                  0.000014   \n",
       "ram_energy_process_2                                                                  0.000013   \n",
       "ram_energy_process_3                                                                  0.000021   \n",
       "total_energy_kwh_process_0                                                            0.007088   \n",
       "total_energy_kwh_process_1                                                             0.00997   \n",
       "total_energy_kwh_process_2                                                            0.009113   \n",
       "total_energy_kwh_process_3                                                             0.01426   \n",
       "total_energy_joules_process_0                                                     25516.342787   \n",
       "total_energy_joules_process_1                                                     35892.851217   \n",
       "total_energy_joules_process_2                                                     32807.532851   \n",
       "total_energy_joules_process_3                                                     51334.500392   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       496.980767   \n",
       "ram_power_avg                                                                         0.980666   \n",
       "cpu_energy_total                                                                      0.007513   \n",
       "gpu_energy_total                                                                       0.03286   \n",
       "ram_energy_total                                                                      0.000058   \n",
       "per-process_emissions_0                                                               0.005432   \n",
       "per-process_emissions_1                                                                 0.0027   \n",
       "per-process_emissions_2                                                               0.003472   \n",
       "per-process_emissions_3                                                               0.003798   \n",
       "latency_simulation_simulate                                                               True   \n",
       "total_generated_tokens                                                                   16384   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               1.5   \n",
       "models                                                                           1034544128000   \n",
       "\n",
       "                                                                                             7  \\\n",
       "config_name                                                  R4_High_Load_Cloud_API_Deployment   \n",
       "experiment_id                                                                               88   \n",
       "date_time                                                        April 11, 2025 at 09:35:31 AM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                1   \n",
       "batch_size___fixed_batching                                                                  8   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                              0.05   \n",
       "latency_simulation_simulate_burst                                                         True   \n",
       "latency_simulation_burst_size                                                                5   \n",
       "latency_simulation_burst_interval                                                          2.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          1   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.002662   \n",
       "total_energy_joules                                                                9583.955319   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      1.709524   \n",
       "joules_per_token                                                                      0.584958   \n",
       "flops_per_joule                                                              1768577839.650868   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             53.885367   \n",
       "average_latency_ms_per_batch                                                       3367.835437   \n",
       "throughput_queries_per_sec                                                            2.375413   \n",
       "throughput_tokens_per_sec                                                           304.052861   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              3103125504   \n",
       "gpu_utilization_percent_0                                                                  4.0   \n",
       "gpu_utilization_percent_1                                                                 10.0   \n",
       "gpu_utilization_percent_2                                                                  3.0   \n",
       "gpu_utilization_percent_3                                                                 17.0   \n",
       "gpu_current_memory_allocated_bytes                                                  4419853312   \n",
       "gpu_max_memory_allocated_bytes                                                      4419853312   \n",
       "gpu_current_memory_reserved_bytes                                                   6339690496   \n",
       "gpu_max_memory_reserved_bytes                                                       6339690496   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                        NaN   \n",
       "cpu_power_process_2                                                                        NaN   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                  80.621122   \n",
       "gpu_power_process_1                                                                        NaN   \n",
       "gpu_power_process_2                                                                        NaN   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   1.081238   \n",
       "ram_power_process_1                                                                        NaN   \n",
       "ram_power_process_2                                                                        NaN   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                  0.001658   \n",
       "cpu_energy_process_1                                                                       NaN   \n",
       "cpu_energy_process_2                                                                       NaN   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                   0.00099   \n",
       "gpu_energy_process_1                                                                       NaN   \n",
       "gpu_energy_process_2                                                                       NaN   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                  0.000014   \n",
       "ram_energy_process_1                                                                       NaN   \n",
       "ram_energy_process_2                                                                       NaN   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.002662   \n",
       "total_energy_kwh_process_1                                                                 NaN   \n",
       "total_energy_kwh_process_2                                                                 NaN   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                      9583.955319   \n",
       "total_energy_joules_process_1                                                              NaN   \n",
       "total_energy_joules_process_2                                                              NaN   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        80.621122   \n",
       "ram_power_avg                                                                         1.081238   \n",
       "cpu_energy_total                                                                      0.001658   \n",
       "gpu_energy_total                                                                       0.00099   \n",
       "ram_energy_total                                                                      0.000014   \n",
       "per-process_emissions_0                                                               0.001014   \n",
       "per-process_emissions_1                                                                    NaN   \n",
       "per-process_emissions_2                                                                    NaN   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "latency_simulation_simulate                                                               True   \n",
       "total_generated_tokens                                                                   16384   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "latency_simulation_delay_max                                                               0.2   \n",
       "models                                                                           1034544128000   \n",
       "\n",
       "                                                                                             8  \\\n",
       "config_name                                                      R5_Real_Time_Mobile_Inference   \n",
       "experiment_id                                                                               89   \n",
       "date_time                                                        April 11, 2025 at 09:52:12 AM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                1   \n",
       "batch_size___fixed_batching                                                                  1   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.2   \n",
       "latency_simulation_simulate_burst                                                         True   \n",
       "latency_simulation_burst_size                                                                8   \n",
       "latency_simulation_burst_interval                                                          5.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                              True   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          1   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.040048   \n",
       "total_energy_joules                                                              144173.372804   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.101114   \n",
       "joules_per_token                                                                      9.889791   \n",
       "flops_per_joule                                                                 7175694.844886   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                            976.021093   \n",
       "average_latency_ms_per_batch                                                        7625.16479   \n",
       "throughput_queries_per_sec                                                            0.131145   \n",
       "throughput_tokens_per_sec                                                            14.936153   \n",
       "cpu_usage_percent                                                                          3.5   \n",
       "cpu_memory_usage_bytes                                                              2694705152   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                 78.0   \n",
       "gpu_utilization_percent_3                                                                 26.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1576178688   \n",
       "gpu_max_memory_allocated_bytes                                                      1576178688   \n",
       "gpu_current_memory_reserved_bytes                                                   2665480192   \n",
       "gpu_max_memory_reserved_bytes                                                       2665480192   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                        NaN   \n",
       "cpu_power_process_2                                                                        NaN   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                  39.818412   \n",
       "gpu_power_process_1                                                                        NaN   \n",
       "gpu_power_process_2                                                                        NaN   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   0.939752   \n",
       "ram_power_process_1                                                                        NaN   \n",
       "ram_power_process_2                                                                        NaN   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                  0.029887   \n",
       "cpu_energy_process_1                                                                       NaN   \n",
       "cpu_energy_process_2                                                                       NaN   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                   0.00995   \n",
       "gpu_energy_process_1                                                                       NaN   \n",
       "gpu_energy_process_2                                                                       NaN   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                  0.000212   \n",
       "ram_energy_process_1                                                                       NaN   \n",
       "ram_energy_process_2                                                                       NaN   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.040048   \n",
       "total_energy_kwh_process_1                                                                 NaN   \n",
       "total_energy_kwh_process_2                                                                 NaN   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                    144173.372804   \n",
       "total_energy_joules_process_1                                                              NaN   \n",
       "total_energy_joules_process_2                                                              NaN   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        39.818412   \n",
       "ram_power_avg                                                                         0.939752   \n",
       "cpu_energy_total                                                                      0.029887   \n",
       "gpu_energy_total                                                                       0.00995   \n",
       "ram_energy_total                                                                      0.000212   \n",
       "per-process_emissions_0                                                               0.015256   \n",
       "per-process_emissions_1                                                                    NaN   \n",
       "per-process_emissions_2                                                                    NaN   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "latency_simulation_simulate                                                               True   \n",
       "total_generated_tokens                                                                   14578   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.6   \n",
       "models                                                                           1034544128000   \n",
       "\n",
       "                                                                                             9  \n",
       "config_name                                             R6_Medium_Scale_Language_Model_Serving  \n",
       "experiment_id                                                                               90  \n",
       "date_time                                                        April 11, 2025 at 09:52:53 AM  \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0  \n",
       "num_processes                                                                                4  \n",
       "batch_size___fixed_batching                                                                 32  \n",
       "decoder_temperature                                                                        1.0  \n",
       "decoder_top_k                                                                                0  \n",
       "decoder_top_p                                                                              0.0  \n",
       "latency_simulation_delay_min                                                              0.01  \n",
       "latency_simulation_simulate_burst                                                        False  \n",
       "latency_simulation_burst_size                                                                0  \n",
       "latency_simulation_burst_interval                                                          0.0  \n",
       "fp_precision                                                                     torch.float16  \n",
       "quantization                                                                             False  \n",
       "load_in_8bit                                                                             False  \n",
       "load_in_4bit                                                                             False  \n",
       "sharding_strategy                                                                     NO_SHARD  \n",
       "sharding_config_fsdp_config_use_orig_params                                              False  \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False  \n",
       "adaptive_batching                                                                        False  \n",
       "adaptive_max_tokens                                                                          0  \n",
       "query_rate                                                                                 1.0  \n",
       "total_input_tokens                                                                       16384  \n",
       "is_encoder_decoder                                                                       False  \n",
       "task_type                                                                      text_generation  \n",
       "available_gpu_count                                                                          4  \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB  \n",
       "available_cpu_count                                                                        128  \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor  \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31  \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]  \n",
       "country                                                                                Germany  \n",
       "region                                                                                  saxony  \n",
       "distributed_type                                                     DistributedType.MULTI_GPU  \n",
       "decode_token_to_text                                                                      True  \n",
       "inference_type                                                                 pure_generative  \n",
       "backend                                                                                pytorch  \n",
       "total_params                                                                        1100048384  \n",
       "model_arch                                                       Unknown (no config attribute)  \n",
       "max_input_tokens                                                                           128  \n",
       "max_output_tokens                                                                          128  \n",
       "number_input_prompts                                                                       128  \n",
       "total_energy_kwh                                                                      0.008429  \n",
       "total_energy_joules                                                               30343.668594  \n",
       "flops                                                                           16949970993152  \n",
       "tokens_per_joule                                                                      0.539948  \n",
       "joules_per_token                                                                      1.852031  \n",
       "flops_per_joule                                                               558599924.750814  \n",
       "joules_per_flop                                                                            0.0  \n",
       "total_inference_time_sec                                                             12.368555  \n",
       "average_latency_ms_per_batch                                                       3092.138661  \n",
       "throughput_queries_per_sec                                                           10.348824  \n",
       "throughput_tokens_per_sec                                                          1324.649522  \n",
       "cpu_usage_percent                                                                          5.5  \n",
       "cpu_memory_usage_bytes                                                              3104542720  \n",
       "gpu_utilization_percent_0                                                                  4.0  \n",
       "gpu_utilization_percent_1                                                                100.0  \n",
       "gpu_utilization_percent_2                                                                100.0  \n",
       "gpu_utilization_percent_3                                                                100.0  \n",
       "gpu_current_memory_allocated_bytes                                                  4419853312  \n",
       "gpu_max_memory_allocated_bytes                                                      4419853312  \n",
       "gpu_current_memory_reserved_bytes                                                   4922015744  \n",
       "gpu_max_memory_reserved_bytes                                                       4922015744  \n",
       "cpu_power_process_0                                                                      112.5  \n",
       "cpu_power_process_1                                                                      112.5  \n",
       "cpu_power_process_2                                                                      112.5  \n",
       "cpu_power_process_3                                                                      112.5  \n",
       "gpu_power_process_0                                                                 622.460527  \n",
       "gpu_power_process_1                                                                  527.52292  \n",
       "gpu_power_process_2                                                                 566.509722  \n",
       "gpu_power_process_3                                                                 631.050066  \n",
       "ram_power_process_0                                                                   1.081843  \n",
       "ram_power_process_1                                                                   0.881829  \n",
       "ram_power_process_2                                                                   0.870511  \n",
       "ram_power_process_3                                                                   0.871479  \n",
       "cpu_energy_process_0                                                                  0.000384  \n",
       "cpu_energy_process_1                                                                  0.000394  \n",
       "cpu_energy_process_2                                                                  0.000381  \n",
       "cpu_energy_process_3                                                                  0.000385  \n",
       "gpu_energy_process_0                                                                  0.001713  \n",
       "gpu_energy_process_1                                                                  0.001751  \n",
       "gpu_energy_process_2                                                                  0.001694  \n",
       "gpu_energy_process_3                                                                  0.001717  \n",
       "ram_energy_process_0                                                                  0.000003  \n",
       "ram_energy_process_1                                                                  0.000003  \n",
       "ram_energy_process_2                                                                  0.000003  \n",
       "ram_energy_process_3                                                                  0.000003  \n",
       "total_energy_kwh_process_0                                                              0.0021  \n",
       "total_energy_kwh_process_1                                                            0.002148  \n",
       "total_energy_kwh_process_2                                                            0.002077  \n",
       "total_energy_kwh_process_3                                                            0.002104  \n",
       "total_energy_joules_process_0                                                       7559.95657  \n",
       "total_energy_joules_process_1                                                      7731.953568  \n",
       "total_energy_joules_process_2                                                       7476.56876  \n",
       "total_energy_joules_process_3                                                      7575.189696  \n",
       "cpu_power_avg                                                                            112.5  \n",
       "gpu_power_avg                                                                       586.885809  \n",
       "ram_power_avg                                                                         0.926415  \n",
       "cpu_energy_total                                                                      0.001544  \n",
       "gpu_energy_total                                                                      0.006874  \n",
       "ram_energy_total                                                                      0.000011  \n",
       "per-process_emissions_0                                                               0.000791  \n",
       "per-process_emissions_1                                                               0.000818  \n",
       "per-process_emissions_2                                                               0.000802  \n",
       "per-process_emissions_3                                                                 0.0008  \n",
       "latency_simulation_simulate                                                               True  \n",
       "total_generated_tokens                                                                   16384  \n",
       "decoder_config_decoding_mode                                                            greedy  \n",
       "latency_simulation_delay_max                                                               0.1  \n",
       "models                                                                           1034544128000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid did not exist: [Errno 2] No such file or directory: 'grid_results.csv'\n",
      "text_generation did not exist: [Errno 2] No such file or directory: 'text_generation_results.csv'\n"
     ]
    }
   ],
   "source": [
    "def inspect_results(name, desired_order):\n",
    "    input_file = f\"{name}_results.csv\"\n",
    "    \n",
    "    df = pd.read_csv(input_file)\n",
    "    df_cleaned = clean_and_reorder_columns(df, desired_order)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "possible_files = [\"controlled\", \"scenarios\", \"grid\", \"text_generation\"]\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "for file in possible_files:\n",
    "    try:\n",
    "        var_name = f\"df_{file}_cleaned\"\n",
    "        globals()[var_name] = inspect_results(file, desired_order)  # dynamically create variable\n",
    "        print(f\"Found & inspecting: {var_name}\")\n",
    "        display(globals()[var_name].T)\n",
    "    except Exception as e:\n",
    "        print(f\"{file} did not exist: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing controlled: 'df_controlled_cleaned'\n",
      "Found & inspecting dropped version: df_scenarios_dropped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>config_name</th>\n",
       "      <td>A1_Max_Throughput_Exploit</td>\n",
       "      <td>A2_Precision_Minimalist</td>\n",
       "      <td>A3_Quantisation_Gaming</td>\n",
       "      <td>default</td>\n",
       "      <td>A5_Parallel_Overdrive</td>\n",
       "      <td>R2_Low_Latency_Chatbot_Deployment</td>\n",
       "      <td>R3_Balanced_Enterprise_Service</td>\n",
       "      <td>R4_High_Load_Cloud_API_Deployment</td>\n",
       "      <td>R5_Real_Time_Mobile_Inference</td>\n",
       "      <td>R6_Medium_Scale_Language_Model_Serving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <td>78</td>\n",
       "      <td>79</td>\n",
       "      <td>80</td>\n",
       "      <td>81</td>\n",
       "      <td>82</td>\n",
       "      <td>86</td>\n",
       "      <td>87</td>\n",
       "      <td>88</td>\n",
       "      <td>89</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <td>April 11, 2025 at 09:26:09 AM</td>\n",
       "      <td>April 11, 2025 at 09:26:45 AM</td>\n",
       "      <td>April 11, 2025 at 09:27:20 AM</td>\n",
       "      <td>April 11, 2025 at 09:28:53 AM</td>\n",
       "      <td>April 11, 2025 at 09:29:30 AM</td>\n",
       "      <td>April 11, 2025 at 09:32:17 AM</td>\n",
       "      <td>April 11, 2025 at 09:34:13 AM</td>\n",
       "      <td>April 11, 2025 at 09:35:31 AM</td>\n",
       "      <td>April 11, 2025 at 09:52:12 AM</td>\n",
       "      <td>April 11, 2025 at 09:52:53 AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_processes</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size___fixed_batching</th>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_temperature</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_k</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_p</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate_burst</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_size</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_interval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp_precision</th>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantization</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_8bit</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_4bit</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_input_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_params</th>\n",
       "      <td>1100048384</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_input_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_output_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_input_prompts</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh</th>\n",
       "      <td>0.013223</td>\n",
       "      <td>0.001715</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.007356</td>\n",
       "      <td>0.005716</td>\n",
       "      <td>0.040431</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.040048</td>\n",
       "      <td>0.008429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules</th>\n",
       "      <td>47602.027224</td>\n",
       "      <td>6172.265465</td>\n",
       "      <td>2452.230798</td>\n",
       "      <td>11249.925529</td>\n",
       "      <td>26479.81109</td>\n",
       "      <td>20576.854237</td>\n",
       "      <td>145551.227246</td>\n",
       "      <td>9583.955319</td>\n",
       "      <td>144173.372804</td>\n",
       "      <td>30343.668594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops</th>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>16949970993152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens_per_joule</th>\n",
       "      <td>0.344187</td>\n",
       "      <td>2.654455</td>\n",
       "      <td>6.681263</td>\n",
       "      <td>1.456365</td>\n",
       "      <td>0.618736</td>\n",
       "      <td>0.796234</td>\n",
       "      <td>0.112565</td>\n",
       "      <td>1.709524</td>\n",
       "      <td>0.101114</td>\n",
       "      <td>0.539948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_token</th>\n",
       "      <td>2.905397</td>\n",
       "      <td>0.376725</td>\n",
       "      <td>0.149672</td>\n",
       "      <td>0.686641</td>\n",
       "      <td>1.616199</td>\n",
       "      <td>1.255912</td>\n",
       "      <td>8.883742</td>\n",
       "      <td>0.584958</td>\n",
       "      <td>9.889791</td>\n",
       "      <td>1.852031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops_per_joule</th>\n",
       "      <td>21733194.74657</td>\n",
       "      <td>167611735.734102</td>\n",
       "      <td>421878776.19706</td>\n",
       "      <td>91960086.784679</td>\n",
       "      <td>640109211.326309</td>\n",
       "      <td>823739663.881693</td>\n",
       "      <td>7107766.437801</td>\n",
       "      <td>1768577839.650868</td>\n",
       "      <td>7175694.844886</td>\n",
       "      <td>558599924.750814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_flop</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_inference_time_sec</th>\n",
       "      <td>11.096081</td>\n",
       "      <td>4.970398</td>\n",
       "      <td>9.531417</td>\n",
       "      <td>69.845126</td>\n",
       "      <td>6.284194</td>\n",
       "      <td>86.120057</td>\n",
       "      <td>42.836278</td>\n",
       "      <td>53.885367</td>\n",
       "      <td>976.021093</td>\n",
       "      <td>12.368555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_latency_ms_per_batch</th>\n",
       "      <td>11096.081339</td>\n",
       "      <td>4970.398136</td>\n",
       "      <td>4765.708533</td>\n",
       "      <td>8730.640718</td>\n",
       "      <td>3142.096803</td>\n",
       "      <td>2691.251768</td>\n",
       "      <td>10709.069527</td>\n",
       "      <td>3367.835437</td>\n",
       "      <td>7625.16479</td>\n",
       "      <td>3092.138661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_queries_per_sec</th>\n",
       "      <td>11.535604</td>\n",
       "      <td>25.752464</td>\n",
       "      <td>13.429273</td>\n",
       "      <td>1.832626</td>\n",
       "      <td>20.368564</td>\n",
       "      <td>1.486297</td>\n",
       "      <td>2.988121</td>\n",
       "      <td>2.375413</td>\n",
       "      <td>0.131145</td>\n",
       "      <td>10.348824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_tokens_per_sec</th>\n",
       "      <td>1476.557309</td>\n",
       "      <td>3296.315416</td>\n",
       "      <td>1718.946919</td>\n",
       "      <td>234.57614</td>\n",
       "      <td>2607.176199</td>\n",
       "      <td>190.246043</td>\n",
       "      <td>382.479541</td>\n",
       "      <td>304.052861</td>\n",
       "      <td>14.936153</td>\n",
       "      <td>1324.649522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_0</th>\n",
       "      <td>0.002251</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.001553</td>\n",
       "      <td>0.005716</td>\n",
       "      <td>0.007088</td>\n",
       "      <td>0.002662</td>\n",
       "      <td>0.040048</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_1</th>\n",
       "      <td>0.003373</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_2</th>\n",
       "      <td>0.003097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_3</th>\n",
       "      <td>0.004501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_avg</th>\n",
       "      <td>487.235551</td>\n",
       "      <td>151.410106</td>\n",
       "      <td>179.704454</td>\n",
       "      <td>52.794036</td>\n",
       "      <td>687.229164</td>\n",
       "      <td>171.907373</td>\n",
       "      <td>496.980767</td>\n",
       "      <td>80.621122</td>\n",
       "      <td>39.818412</td>\n",
       "      <td>586.885809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_avg</th>\n",
       "      <td>0.973243</td>\n",
       "      <td>0.944052</td>\n",
       "      <td>0.933053</td>\n",
       "      <td>0.946954</td>\n",
       "      <td>0.915087</td>\n",
       "      <td>0.698569</td>\n",
       "      <td>0.980666</td>\n",
       "      <td>1.081238</td>\n",
       "      <td>0.939752</td>\n",
       "      <td>0.926415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_total</th>\n",
       "      <td>0.002127</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.007513</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.029887</td>\n",
       "      <td>0.001544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_total</th>\n",
       "      <td>0.011079</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.006385</td>\n",
       "      <td>0.003054</td>\n",
       "      <td>0.03286</td>\n",
       "      <td>0.00099</td>\n",
       "      <td>0.00995</td>\n",
       "      <td>0.006874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_generated_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>14578</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_config_decoding_mode</th>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_k</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_k</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_p</td>\n",
       "      <td>greedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    0  \\\n",
       "config_name                                 A1_Max_Throughput_Exploit   \n",
       "experiment_id                                                      78   \n",
       "date_time                               April 11, 2025 at 09:26:09 AM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                       256   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                     True   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.013223   \n",
       "total_energy_joules                                      47602.027224   \n",
       "flops                                                   1034544128000   \n",
       "tokens_per_joule                                             0.344187   \n",
       "joules_per_token                                             2.905397   \n",
       "flops_per_joule                                        21733194.74657   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    11.096081   \n",
       "average_latency_ms_per_batch                             11096.081339   \n",
       "throughput_queries_per_sec                                  11.535604   \n",
       "throughput_tokens_per_sec                                 1476.557309   \n",
       "total_energy_kwh_process_0                                   0.002251   \n",
       "total_energy_kwh_process_1                                   0.003373   \n",
       "total_energy_kwh_process_2                                   0.003097   \n",
       "total_energy_kwh_process_3                                   0.004501   \n",
       "gpu_power_avg                                              487.235551   \n",
       "ram_power_avg                                                0.973243   \n",
       "cpu_energy_total                                             0.002127   \n",
       "gpu_energy_total                                             0.011079   \n",
       "latency_simulation_simulate                                     False   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                   greedy   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "\n",
       "                                                                    1  \\\n",
       "config_name                                   A2_Precision_Minimalist   \n",
       "experiment_id                                                      79   \n",
       "date_time                               April 11, 2025 at 09:26:45 AM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       2   \n",
       "batch_size___fixed_batching                                       128   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.001715   \n",
       "total_energy_joules                                       6172.265465   \n",
       "flops                                                   1034544128000   \n",
       "tokens_per_joule                                             2.654455   \n",
       "joules_per_token                                             0.376725   \n",
       "flops_per_joule                                      167611735.734102   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     4.970398   \n",
       "average_latency_ms_per_batch                              4970.398136   \n",
       "throughput_queries_per_sec                                  25.752464   \n",
       "throughput_tokens_per_sec                                 3296.315416   \n",
       "total_energy_kwh_process_0                                   0.000793   \n",
       "total_energy_kwh_process_1                                   0.000922   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                              151.410106   \n",
       "ram_power_avg                                                0.944052   \n",
       "cpu_energy_total                                             0.000393   \n",
       "gpu_energy_total                                             0.001319   \n",
       "latency_simulation_simulate                                     False   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                   greedy   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "\n",
       "                                                                    2  \\\n",
       "config_name                                    A3_Quantisation_Gaming   \n",
       "experiment_id                                                      80   \n",
       "date_time                               April 11, 2025 at 09:27:20 AM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       1   \n",
       "batch_size___fixed_batching                                        64   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                      50   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.000681   \n",
       "total_energy_joules                                       2452.230798   \n",
       "flops                                                   1034544128000   \n",
       "tokens_per_joule                                             6.681263   \n",
       "joules_per_token                                             0.149672   \n",
       "flops_per_joule                                       421878776.19706   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     9.531417   \n",
       "average_latency_ms_per_batch                              4765.708533   \n",
       "throughput_queries_per_sec                                  13.429273   \n",
       "throughput_tokens_per_sec                                 1718.946919   \n",
       "total_energy_kwh_process_0                                   0.000681   \n",
       "total_energy_kwh_process_1                                        NaN   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                              179.704454   \n",
       "ram_power_avg                                                0.933053   \n",
       "cpu_energy_total                                             0.000297   \n",
       "gpu_energy_total                                             0.000383   \n",
       "latency_simulation_simulate                                     False   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                    top_k   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "\n",
       "                                                                    3  \\\n",
       "config_name                                                   default   \n",
       "experiment_id                                                      81   \n",
       "date_time                               April 11, 2025 at 09:28:53 AM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       1   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                     True   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.003125   \n",
       "total_energy_joules                                      11249.925529   \n",
       "flops                                                   1034544128000   \n",
       "tokens_per_joule                                             1.456365   \n",
       "joules_per_token                                             0.686641   \n",
       "flops_per_joule                                       91960086.784679   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    69.845126   \n",
       "average_latency_ms_per_batch                              8730.640718   \n",
       "throughput_queries_per_sec                                   1.832626   \n",
       "throughput_tokens_per_sec                                   234.57614   \n",
       "total_energy_kwh_process_0                                   0.003125   \n",
       "total_energy_kwh_process_1                                        NaN   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                               52.794036   \n",
       "ram_power_avg                                                0.946954   \n",
       "cpu_energy_total                                             0.002144   \n",
       "gpu_energy_total                                             0.000966   \n",
       "latency_simulation_simulate                                     False   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                   greedy   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "\n",
       "                                                                    4  \\\n",
       "config_name                                     A5_Parallel_Overdrive   \n",
       "experiment_id                                                      82   \n",
       "date_time                               April 11, 2025 at 09:29:30 AM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        64   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.007356   \n",
       "total_energy_joules                                       26479.81109   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.618736   \n",
       "joules_per_token                                             1.616199   \n",
       "flops_per_joule                                      640109211.326309   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     6.284194   \n",
       "average_latency_ms_per_batch                              3142.096803   \n",
       "throughput_queries_per_sec                                  20.368564   \n",
       "throughput_tokens_per_sec                                 2607.176199   \n",
       "total_energy_kwh_process_0                                   0.001553   \n",
       "total_energy_kwh_process_1                                   0.001904   \n",
       "total_energy_kwh_process_2                                   0.001872   \n",
       "total_energy_kwh_process_3                                   0.002026   \n",
       "gpu_power_avg                                              687.229164   \n",
       "ram_power_avg                                                0.915087   \n",
       "cpu_energy_total                                             0.000964   \n",
       "gpu_energy_total                                             0.006385   \n",
       "latency_simulation_simulate                                     False   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                   greedy   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "\n",
       "                                                                    5  \\\n",
       "config_name                         R2_Low_Latency_Chatbot_Deployment   \n",
       "experiment_id                                                      86   \n",
       "date_time                               April 11, 2025 at 09:32:17 AM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       1   \n",
       "batch_size___fixed_batching                                         4   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.9   \n",
       "latency_simulation_delay_min                                     0.01   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.005716   \n",
       "total_energy_joules                                      20576.854237   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.796234   \n",
       "joules_per_token                                             1.255912   \n",
       "flops_per_joule                                      823739663.881693   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    86.120057   \n",
       "average_latency_ms_per_batch                              2691.251768   \n",
       "throughput_queries_per_sec                                   1.486297   \n",
       "throughput_tokens_per_sec                                  190.246043   \n",
       "total_energy_kwh_process_0                                   0.005716   \n",
       "total_energy_kwh_process_1                                        NaN   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                              171.907373   \n",
       "ram_power_avg                                                0.698569   \n",
       "cpu_energy_total                                             0.002648   \n",
       "gpu_energy_total                                             0.003054   \n",
       "latency_simulation_simulate                                      True   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                    top_p   \n",
       "latency_simulation_delay_max                                     0.05   \n",
       "\n",
       "                                                                    6  \\\n",
       "config_name                            R3_Balanced_Enterprise_Service   \n",
       "experiment_id                                                      87   \n",
       "date_time                               April 11, 2025 at 09:34:13 AM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        32   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                      50   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.5   \n",
       "latency_simulation_simulate_burst                                True   \n",
       "latency_simulation_burst_size                                       5   \n",
       "latency_simulation_burst_interval                                 4.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                     True   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.040431   \n",
       "total_energy_joules                                     145551.227246   \n",
       "flops                                                   1034544128000   \n",
       "tokens_per_joule                                             0.112565   \n",
       "joules_per_token                                             8.883742   \n",
       "flops_per_joule                                        7107766.437801   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    42.836278   \n",
       "average_latency_ms_per_batch                             10709.069527   \n",
       "throughput_queries_per_sec                                   2.988121   \n",
       "throughput_tokens_per_sec                                  382.479541   \n",
       "total_energy_kwh_process_0                                   0.007088   \n",
       "total_energy_kwh_process_1                                    0.00997   \n",
       "total_energy_kwh_process_2                                   0.009113   \n",
       "total_energy_kwh_process_3                                    0.01426   \n",
       "gpu_power_avg                                              496.980767   \n",
       "ram_power_avg                                                0.980666   \n",
       "cpu_energy_total                                             0.007513   \n",
       "gpu_energy_total                                              0.03286   \n",
       "latency_simulation_simulate                                      True   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                    top_k   \n",
       "latency_simulation_delay_max                                      1.5   \n",
       "\n",
       "                                                                    7  \\\n",
       "config_name                         R4_High_Load_Cloud_API_Deployment   \n",
       "experiment_id                                                      88   \n",
       "date_time                               April 11, 2025 at 09:35:31 AM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       1   \n",
       "batch_size___fixed_batching                                         8   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                     0.05   \n",
       "latency_simulation_simulate_burst                                True   \n",
       "latency_simulation_burst_size                                       5   \n",
       "latency_simulation_burst_interval                                 2.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.002662   \n",
       "total_energy_joules                                       9583.955319   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             1.709524   \n",
       "joules_per_token                                             0.584958   \n",
       "flops_per_joule                                     1768577839.650868   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    53.885367   \n",
       "average_latency_ms_per_batch                              3367.835437   \n",
       "throughput_queries_per_sec                                   2.375413   \n",
       "throughput_tokens_per_sec                                  304.052861   \n",
       "total_energy_kwh_process_0                                   0.002662   \n",
       "total_energy_kwh_process_1                                        NaN   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                               80.621122   \n",
       "ram_power_avg                                                1.081238   \n",
       "cpu_energy_total                                             0.001658   \n",
       "gpu_energy_total                                              0.00099   \n",
       "latency_simulation_simulate                                      True   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                   greedy   \n",
       "latency_simulation_delay_max                                      0.2   \n",
       "\n",
       "                                                                    8  \\\n",
       "config_name                             R5_Real_Time_Mobile_Inference   \n",
       "experiment_id                                                      89   \n",
       "date_time                               April 11, 2025 at 09:52:12 AM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       1   \n",
       "batch_size___fixed_batching                                         1   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.9   \n",
       "latency_simulation_delay_min                                      0.2   \n",
       "latency_simulation_simulate_burst                                True   \n",
       "latency_simulation_burst_size                                       8   \n",
       "latency_simulation_burst_interval                                 5.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                     True   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.040048   \n",
       "total_energy_joules                                     144173.372804   \n",
       "flops                                                   1034544128000   \n",
       "tokens_per_joule                                             0.101114   \n",
       "joules_per_token                                             9.889791   \n",
       "flops_per_joule                                        7175694.844886   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                   976.021093   \n",
       "average_latency_ms_per_batch                               7625.16479   \n",
       "throughput_queries_per_sec                                   0.131145   \n",
       "throughput_tokens_per_sec                                   14.936153   \n",
       "total_energy_kwh_process_0                                   0.040048   \n",
       "total_energy_kwh_process_1                                        NaN   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                               39.818412   \n",
       "ram_power_avg                                                0.939752   \n",
       "cpu_energy_total                                             0.029887   \n",
       "gpu_energy_total                                              0.00995   \n",
       "latency_simulation_simulate                                      True   \n",
       "total_generated_tokens                                          14578   \n",
       "decoder_config_decoding_mode                                    top_p   \n",
       "latency_simulation_delay_max                                      0.6   \n",
       "\n",
       "                                                                        9  \n",
       "config_name                        R6_Medium_Scale_Language_Model_Serving  \n",
       "experiment_id                                                          90  \n",
       "date_time                                   April 11, 2025 at 09:52:53 AM  \n",
       "model                                  TinyLlama/TinyLlama-1.1B-Chat-v1.0  \n",
       "num_processes                                                           4  \n",
       "batch_size___fixed_batching                                            32  \n",
       "decoder_temperature                                                   1.0  \n",
       "decoder_top_k                                                           0  \n",
       "decoder_top_p                                                         0.0  \n",
       "latency_simulation_delay_min                                         0.01  \n",
       "latency_simulation_simulate_burst                                   False  \n",
       "latency_simulation_burst_size                                           0  \n",
       "latency_simulation_burst_interval                                     0.0  \n",
       "fp_precision                                                torch.float16  \n",
       "quantization                                                        False  \n",
       "load_in_8bit                                                        False  \n",
       "load_in_4bit                                                        False  \n",
       "total_input_tokens                                                  16384  \n",
       "total_params                                                   1100048384  \n",
       "max_input_tokens                                                      128  \n",
       "max_output_tokens                                                     128  \n",
       "number_input_prompts                                                  128  \n",
       "total_energy_kwh                                                 0.008429  \n",
       "total_energy_joules                                          30343.668594  \n",
       "flops                                                      16949970993152  \n",
       "tokens_per_joule                                                 0.539948  \n",
       "joules_per_token                                                 1.852031  \n",
       "flops_per_joule                                          558599924.750814  \n",
       "joules_per_flop                                                       0.0  \n",
       "total_inference_time_sec                                        12.368555  \n",
       "average_latency_ms_per_batch                                  3092.138661  \n",
       "throughput_queries_per_sec                                      10.348824  \n",
       "throughput_tokens_per_sec                                     1324.649522  \n",
       "total_energy_kwh_process_0                                         0.0021  \n",
       "total_energy_kwh_process_1                                       0.002148  \n",
       "total_energy_kwh_process_2                                       0.002077  \n",
       "total_energy_kwh_process_3                                       0.002104  \n",
       "gpu_power_avg                                                  586.885809  \n",
       "ram_power_avg                                                    0.926415  \n",
       "cpu_energy_total                                                 0.001544  \n",
       "gpu_energy_total                                                 0.006874  \n",
       "latency_simulation_simulate                                          True  \n",
       "total_generated_tokens                                              16384  \n",
       "decoder_config_decoding_mode                                       greedy  \n",
       "latency_simulation_delay_max                                          0.1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing grid: 'df_grid_cleaned'\n",
      "Error processing text_generation: 'df_text_generation_cleaned'\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [\n",
    "    \"sharding_strategy\",\n",
    "    \"sharding_config_fsdp_config_use_orig_params\",\n",
    "    \"sharding_config_fsdp_config_cpu_offload\",\n",
    "    \"adaptive_batching\",\n",
    "    \"adaptive_max_tokens\",\n",
    "    \"query_rate\",\n",
    "    \"is_encoder_decoder\",\n",
    "    \"task_type\",\n",
    "    \"available_gpu_count\",\n",
    "    \"gpu_model\",\n",
    "    \"available_cpu_count\",\n",
    "    \"cpu_model\",\n",
    "    \"os\",\n",
    "    \"python_version\",\n",
    "    \"country\",\n",
    "    \"region\",\n",
    "    \"distributed_type\",\n",
    "    \"decode_token_to_text\",\n",
    "    \"inference_type\",\n",
    "    \"backend\",\n",
    "    \"model_arch\",\n",
    "    \"gpu_current_memory_allocated_bytes\",\n",
    "    \"gpu_max_memory_allocated_bytes\",\n",
    "    \"gpu_current_memory_reserved_bytes\",\n",
    "    \"gpu_max_memory_reserved_bytes\",\n",
    "    \"per-process_emissions_0\", \"per-process_emissions_1\", \"per-process_emissions_2\",\"per-process_emissions_3\" # OR IS THIS NICE TO HAVE?\n",
    "]\n",
    "\n",
    "# second round of dropping (at some point come back to these)\n",
    "columns_to_drop_2 = [\n",
    "    \"cpu_usage_percent\",\n",
    "    \"cpu_memory_usage_bytes\",\n",
    "    \"gpu_utilization_percent_0\",\n",
    "    \"gpu_utilization_percent_1\",\n",
    "    \"gpu_utilization_percent_2\",\n",
    "    \"gpu_utilization_percent_3\",\n",
    "    \"gpu_current_memory_allocated_bytes\",\n",
    "    \"gpu_max_memory_allocated_bytes\",\n",
    "    \"cpu_current_memory_allocated_bytes\",\n",
    "    \"cpu_max_memory_allocated_bytes\",\n",
    "    \"cpu_power_process_0\",\n",
    "    \"cpu_power_process_1\",\n",
    "    \"cpu_power_process_2\",\n",
    "    \"cpu_power_process_3\",\n",
    "    \"gpu_power_process_0\",\n",
    "    \"gpu_power_process_1\",\n",
    "    \"gpu_power_process_2\",\n",
    "    \"gpu_power_process_3\",\n",
    "    \"ram_power_process_0\",\n",
    "    \"ram_power_process_1\",\n",
    "    \"ram_power_process_2\",\n",
    "    \"ram_power_process_3\",\n",
    "    \"cpu_energy_process_0\",\n",
    "    \"cpu_energy_process_1\",\n",
    "    \"cpu_energy_process_2\",\n",
    "    \"cpu_energy_process_3\",\n",
    "    \"gpu_energy_process_0\",\n",
    "    \"gpu_energy_process_1\",\n",
    "    \"gpu_energy_process_2\",\n",
    "    \"gpu_energy_process_3\",\n",
    "    \"ram_energy_process_0\",\n",
    "    \"ram_energy_process_1\",\n",
    "    \"ram_energy_process_2\",\n",
    "    \"ram_energy_process_3\",\n",
    "    \"total_energy_joules_process_0\",\n",
    "    \"total_energy_joules_process_1\",\n",
    "    \"total_energy_joules_process_2\",\n",
    "    \"total_energy_joules_process_3\",\n",
    "    \"cpu_power_avg\",\n",
    "    \"ram_energy_total\",\n",
    "    \"models\"\n",
    "]\n",
    "\n",
    "for file in possible_files:\n",
    "    try:\n",
    "        cleaned_var = f\"df_{file}_cleaned\"   # e.g., df_controlled_cleaned\n",
    "        dropped_var = f\"df_{file}_dropped\"     # e.g., df_controlled_dropped\n",
    "        \n",
    "        # Drop the specified columns from the cleaned DataFrame.\n",
    "        globals()[dropped_var] = globals()[cleaned_var].drop(columns=columns_to_drop, errors='ignore')\n",
    "        globals()[dropped_var] = globals()[dropped_var].drop(columns=columns_to_drop_2, errors='ignore')\n",
    "        print(f\"Found & inspecting dropped version: {dropped_var}\")\n",
    "        display(globals()[dropped_var].T)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_controlled_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "\n",
      "df_scenarios_dropped has multiple FLOP counts:\n",
      "Unique FLOPs: [ 1034544128000 16949970993152]\n",
      "\n",
      "FLOP value: 1034544128000\n",
      "Associated config_name(s): ['A1_Max_Throughput_Exploit' 'A2_Precision_Minimalist'\n",
      " 'A3_Quantisation_Gaming' 'default' 'R3_Balanced_Enterprise_Service'\n",
      " 'R5_Real_Time_Mobile_Inference']\n",
      "\n",
      "FLOP value: 16949970993152\n",
      "Associated config_name(s): ['A5_Parallel_Overdrive' 'R2_Low_Latency_Chatbot_Deployment'\n",
      " 'R4_High_Load_Cloud_API_Deployment'\n",
      " 'R6_Medium_Scale_Language_Model_Serving']\n",
      "--------------------------------------------------\n",
      "df_grid_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_text_generation_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check all flops are constant\n",
    "\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    \n",
    "    if var_dropped in globals():\n",
    "        try:\n",
    "            df = globals()[var_dropped]\n",
    "            \n",
    "            # Check how many unique flops exist\n",
    "            unique_flops = df['flops'].unique()\n",
    "            \n",
    "            if len(unique_flops) > 1:\n",
    "                print(f\"\\n{var_dropped} has multiple FLOP counts:\")\n",
    "                print(f\"Unique FLOPs: {unique_flops}\")\n",
    "                \n",
    "                # Find rows for each different flop value\n",
    "                for flop_val in unique_flops:\n",
    "                    subset = df[df['flops'] == flop_val]\n",
    "                    config_names = subset['config_name'].unique()\n",
    "                    \n",
    "                    print(f\"\\nFLOP value: {flop_val}\")\n",
    "                    print(f\"Associated config_name(s): {config_names}\")\n",
    "                print(\"-\" * 50)\n",
    "            else:\n",
    "                print(f\"\\n{var_dropped} has only one unique FLOP value, skipping.\")\n",
    "                print(\"-\" * 50)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Problem inspecting {var_dropped}: {e}\")\n",
    "    else:\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_controlled_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "\n",
      "df_scenarios_dropped has multiple FLOP counts:\n",
      "Unique FLOPs: [ 1034544128000 16949970993152]\n",
      "Differentiating columns:\n",
      "Column: quantization\n",
      "  FLOP 1034544128000: True\n",
      "  FLOP 16949970993152: False\n",
      "--------------------------------------------------\n",
      "df_grid_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_text_generation_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def identify_flop_differentiators(df, flops_col='flops', exclude_cols=None):\n",
    "    \"\"\"\n",
    "    Identify columns that are constant within each FLOP group but differ between groups.\n",
    "    \n",
    "    Parameters:\n",
    "      df (pd.DataFrame): The DataFrame containing the data.\n",
    "      flops_col (str): Name of the column used for grouping the FLOPs.\n",
    "      exclude_cols (list, optional): List of columns to exclude from the comparison.\n",
    "      \n",
    "    Returns:\n",
    "      dict: A dictionary where keys are the column names that differentiate FLOP groups,\n",
    "            and values are dictionaries mapping each unique FLOP value to the constant value\n",
    "            observed in that group.\n",
    "            \n",
    "    Example output:\n",
    "    {\n",
    "      'config_name': {1034544128000: 'A1_Max_Throughput_Exploit', \n",
    "                      16949970993152: 'A5_Parallel_Overdrive'},\n",
    "      'some_other_col': {1034544128000: 'value1', \n",
    "                         16949970993152: 'value2'}\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Optionally exclude some columns, including the flops column itself.\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = []\n",
    "    exclude_cols = set(exclude_cols + [flops_col])\n",
    "    \n",
    "    differentiators = {}\n",
    "    unique_flops = df[flops_col].unique()\n",
    "    \n",
    "    # Loop over each column in df excluding the ones in exclude_cols.\n",
    "    for col in df.columns:\n",
    "        if col in exclude_cols:\n",
    "            continue\n",
    "        \n",
    "        # For each group (by flops), get the unique values for this column.\n",
    "        group_values = {}\n",
    "        valid = True  # assume column is constant per group unless we find more than one unique value.\n",
    "        for flop in unique_flops:\n",
    "            values = df[df[flops_col] == flop][col].unique()\n",
    "            if len(values) == 1:\n",
    "                group_values[flop] = values[0]\n",
    "            else:\n",
    "                # If any FLOP group has more than one value, then this column doesn't differentiate consistently.\n",
    "                valid = False\n",
    "                break\n",
    "        # Check if the column is valid and if it truly differentiates between groups.\n",
    "        if valid and len(set(group_values.values())) > 1:\n",
    "            differentiators[col] = group_values\n",
    "    \n",
    "    return differentiators\n",
    "\n",
    "\n",
    "\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    if var_dropped in globals():\n",
    "        try:\n",
    "            df = globals()[var_dropped]\n",
    "            \n",
    "            # Check if there is more than one FLOP count.\n",
    "            unique_flops = df['flops'].unique()\n",
    "            if len(unique_flops) > 1:\n",
    "                print(f\"\\n{var_dropped} has multiple FLOP counts:\")\n",
    "                print(f\"Unique FLOPs: {unique_flops}\")\n",
    "                \n",
    "                # Identify columns that differ consistently between FLOP groups.\n",
    "                diff_cols = identify_flop_differentiators(df)\n",
    "                if diff_cols:\n",
    "                    print(\"Differentiating columns:\")\n",
    "                    for col, mapping in diff_cols.items():\n",
    "                        print(f\"Column: {col}\")\n",
    "                        for flop, val in mapping.items():\n",
    "                            print(f\"  FLOP {flop}: {val}\")\n",
    "                else:\n",
    "                    print(\"No consistently differentiating columns were found.\")\n",
    "                print(\"-\" * 50)\n",
    "            else:\n",
    "                print(f\"\\n{var_dropped} has only one unique FLOP value, skipping.\")\n",
    "                print(\"-\" * 50)\n",
    "        except Exception as e:\n",
    "            print(f\"Problem inspecting {var_dropped}: {e}\")\n",
    "    else:\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_controlled_dropped does not exist, skipping.\n",
      "df_grid_dropped does not exist, skipping.\n",
      "df_text_generation_dropped does not exist, skipping.\n"
     ]
    }
   ],
   "source": [
    "# DEFINE NEW VARS\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    \n",
    "    if var_dropped not in globals():\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df = globals()[var_dropped]\n",
    "        \n",
    "        df['flops_per_token'] = df['flops'] / df['total_generated_tokens']\n",
    "        df['energy_per_token_kwh'] = df['total_energy_kwh'] / df['total_generated_tokens']\n",
    "        df['divergence_energy_flops_per_token'] = df['energy_per_token_kwh'] / df['flops_per_token']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {var_dropped}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_controlled_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "Index(['config_name', 'experiment_id', 'date_time', 'model', 'num_processes',\n",
      "       'batch_size___fixed_batching', 'decoder_temperature', 'decoder_top_k',\n",
      "       'decoder_top_p', 'latency_simulation_delay_min',\n",
      "       'latency_simulation_simulate_burst', 'latency_simulation_burst_size',\n",
      "       'latency_simulation_burst_interval', 'fp_precision', 'quantization',\n",
      "       'load_in_8bit', 'load_in_4bit', 'total_input_tokens', 'total_params',\n",
      "       'max_input_tokens', 'max_output_tokens', 'number_input_prompts',\n",
      "       'total_energy_kwh', 'total_energy_joules', 'flops', 'tokens_per_joule',\n",
      "       'joules_per_token', 'flops_per_joule', 'joules_per_flop',\n",
      "       'total_inference_time_sec', 'average_latency_ms_per_batch',\n",
      "       'throughput_queries_per_sec', 'throughput_tokens_per_sec',\n",
      "       'total_energy_kwh_process_0', 'total_energy_kwh_process_1',\n",
      "       'total_energy_kwh_process_2', 'total_energy_kwh_process_3',\n",
      "       'gpu_power_avg', 'ram_power_avg', 'cpu_energy_total',\n",
      "       'gpu_energy_total', 'latency_simulation_simulate',\n",
      "       'total_generated_tokens', 'decoder_config_decoding_mode',\n",
      "       'latency_simulation_delay_max', 'flops_per_token',\n",
      "       'energy_per_token_kwh', 'divergence_energy_flops_per_token'],\n",
      "      dtype='object')\n",
      "--------------------------------------------------\n",
      "df_grid_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_text_generation_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# CHECK COLUMN NAMES\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    \n",
    "    if var_dropped not in globals():\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        print(\"-\" * 50)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        df = globals()[var_dropped]\n",
    "        print(df.columns)\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {var_dropped}: {e}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_controlled_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "['A1_Max_Throughput_Exploit' 'A2_Precision_Minimalist'\n",
      " 'A3_Quantisation_Gaming' 'default' 'A5_Parallel_Overdrive'\n",
      " 'R2_Low_Latency_Chatbot_Deployment' 'R3_Balanced_Enterprise_Service'\n",
      " 'R4_High_Load_Cloud_API_Deployment' 'R5_Real_Time_Mobile_Inference'\n",
      " 'R6_Medium_Scale_Language_Model_Serving']\n",
      "--------------------------------------------------\n",
      "df_grid_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_text_generation_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# CHECK CONFIG NAMES\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    \n",
    "    if var_dropped not in globals():\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        print(\"-\" * 50)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        df = globals()[var_dropped]\n",
    "        print(df['config_name'].unique())\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {var_dropped}: {e}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_controlled_dropped' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 101\u001b[0m\n\u001b[1;32m     98\u001b[0m families \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_processes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatching\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecis\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatency\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fam \u001b[38;5;129;01min\u001b[39;00m families:\n\u001b[0;32m--> 101\u001b[0m     plot_family(\u001b[43mdf_controlled_dropped\u001b[49m, fam, metric1\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflops_per_token\u001b[39m\u001b[38;5;124m\"\u001b[39m, metric2\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergy_per_token_kwh\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_controlled_dropped' is not defined"
     ]
    }
   ],
   "source": [
    "#cut this\n",
    "\n",
    "def extract_altered_value(config_name, family):\n",
    "    \"\"\"\n",
    "    Given a config name and a family, extract the altered value.\n",
    "    For each family, a different rule is applied:\n",
    "    \n",
    "    - num_processes: extract the integer after \"num_processes_\"\n",
    "    - batching: extract the integer after \"batching_\"\n",
    "    - precis: extract the precision setting; if quant4 is True, return \"load_in_4bit=True\",\n",
    "              otherwise return the float precision (e.g., \"float32\" or \"float16\")\n",
    "    - decoding: extract the decoder_temperature (as a float) from the config name.\n",
    "    - latency: if the config is exactly \"latency_False\", return \"No latency\"; otherwise, \n",
    "               extract and join all numeric values in the config string.\n",
    "    \"\"\"\n",
    "    if family == \"num_processes\":\n",
    "        m = re.search(r'num_processes_(\\d+)', config_name)\n",
    "        return int(m.group(1)) if m else config_name\n",
    "    \n",
    "    elif family == \"batching\":\n",
    "        m = re.search(r'batching_(\\d+)', config_name)\n",
    "        return int(m.group(1)) if m else config_name\n",
    "    \n",
    "    elif family == \"precis\":\n",
    "        m = re.search(r'precis_(float\\d+)', config_name)\n",
    "        precision = m.group(1) if m else None\n",
    "        # If quant4 is True, we assume load_in_4bit is the relevant setting. COME BACK TO THIS!!!\n",
    "        if \"quant4_True\" in config_name:\n",
    "            return \"load_in_4bit=True\"\n",
    "        else:\n",
    "            return precision\n",
    "        \n",
    "    elif family == \"decoding\":\n",
    "        # This family might have several variants. We extract the decoder_temperature. COME BACK TO\n",
    "        m = re.search(r'decoder_temperature_([\\d\\.]+)', config_name)\n",
    "        return float(m.group(1)) if m else config_name\n",
    "    \n",
    "    elif family == \"latency\":\n",
    "        # If it's simply \"latency_False\", nothing was altered.\n",
    "        if config_name == \"latency_False\":\n",
    "            return \"No latency\"\n",
    "        else:\n",
    "            # Find all numbers (either integer or float) in the string.\n",
    "            numbers = re.findall(r'\\d+\\.\\d+|\\d+', config_name)\n",
    "            return \", \".join(numbers)\n",
    "    else:\n",
    "        return config_name\n",
    "\n",
    "def plot_family(df, family, metric1, metric2):\n",
    "    \"\"\"\n",
    "    For a given family, subset the DataFrame (rows whose config_name starts with family).\n",
    "    Create a new column that holds the altered value for that family, sort the data by that value,\n",
    "    and plot two metrics against this altered value.\n",
    "    \n",
    "    Parameters:\n",
    "      - df: a DataFrame with a \"config_name\" column.\n",
    "      - family: the family string (e.g. \"num_processes\", \"batching\", etc).\n",
    "      - metric1: name of the first metric column to plot on the left Y axis (e.g., \"flops_per_token\").\n",
    "      - metric2: name of the second metric column to plot on the right Y axis (e.g., \"total_energy_kwh\").\n",
    "    \"\"\"\n",
    "    # Subset rows where config_name starts with the family string.\n",
    "    df_family = df[df['config_name'].str.startswith(family)].copy()\n",
    "    \n",
    "    # Apply the parser to create an \"altered_value\" column.\n",
    "    df_family['altered_value'] = df_family['config_name'].apply(lambda x: extract_altered_value(x, family))\n",
    "    \n",
    "    # Attempt to sort by altered_value.\n",
    "    # If the values are numeric, convert them.\n",
    "    try:\n",
    "        df_family['altered_value'] = pd.to_numeric(df_family['altered_value'])\n",
    "    except:\n",
    "        pass  # leave as string if conversion fails\n",
    "    \n",
    "    df_family.sort_values('altered_value', inplace=True)\n",
    "    \n",
    "    # Create a plot with twin y-axes.\n",
    "    fig, ax1 = plt.subplots(figsize=(8,5))\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # Plot metric1 on ax1 and metric2 on ax2.\n",
    "    ax1.plot(df_family['altered_value'], df_family[metric1], marker='o', label=metric1, color='blue')\n",
    "    ax2.plot(df_family['altered_value'], df_family[metric2], marker='s', label=metric2, color='red')\n",
    "    \n",
    "    ax1.set_xlabel(f'{family} configuration')\n",
    "    ax1.set_ylabel(metric1, color='blue')\n",
    "    ax2.set_ylabel(metric2, color='red')\n",
    "    plt.title(f'{family}: {metric1} and {metric2} vs altered setting')\n",
    "    \n",
    "    # Combine the legends.\n",
    "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='best')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "families = [\"num_processes\", \"batching\", \"precis\", \"decoding\", \"latency\"]\n",
    "\n",
    "for fam in families:\n",
    "    plot_family(df_controlled_dropped, fam, metric1=\"flops_per_token\", metric2=\"energy_per_token_kwh\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# RESTART FROM HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR CONTROLLED EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>config_name</th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>model</th>\n",
       "      <th>num_processes</th>\n",
       "      <th>batch_size___fixed_batching</th>\n",
       "      <th>decoder_temperature</th>\n",
       "      <th>decoder_top_k</th>\n",
       "      <th>decoder_top_p</th>\n",
       "      <th>latency_simulation_delay_min</th>\n",
       "      <th>latency_simulation_simulate_burst</th>\n",
       "      <th>latency_simulation_burst_size</th>\n",
       "      <th>latency_simulation_burst_interval</th>\n",
       "      <th>fp_precision</th>\n",
       "      <th>quantization</th>\n",
       "      <th>load_in_8bit</th>\n",
       "      <th>load_in_4bit</th>\n",
       "      <th>total_input_tokens</th>\n",
       "      <th>total_params</th>\n",
       "      <th>max_input_tokens</th>\n",
       "      <th>max_output_tokens</th>\n",
       "      <th>number_input_prompts</th>\n",
       "      <th>total_energy_kwh</th>\n",
       "      <th>total_energy_joules</th>\n",
       "      <th>flops</th>\n",
       "      <th>tokens_per_joule</th>\n",
       "      <th>joules_per_token</th>\n",
       "      <th>flops_per_joule</th>\n",
       "      <th>joules_per_flop</th>\n",
       "      <th>total_inference_time_sec</th>\n",
       "      <th>average_latency_ms_per_batch</th>\n",
       "      <th>throughput_queries_per_sec</th>\n",
       "      <th>throughput_tokens_per_sec</th>\n",
       "      <th>total_energy_kwh_process_0</th>\n",
       "      <th>total_energy_kwh_process_1</th>\n",
       "      <th>total_energy_kwh_process_2</th>\n",
       "      <th>total_energy_kwh_process_3</th>\n",
       "      <th>gpu_power_avg</th>\n",
       "      <th>ram_power_avg</th>\n",
       "      <th>cpu_energy_total</th>\n",
       "      <th>gpu_energy_total</th>\n",
       "      <th>latency_simulation_simulate</th>\n",
       "      <th>total_generated_tokens</th>\n",
       "      <th>decoder_config_decoding_mode</th>\n",
       "      <th>latency_simulation_delay_max</th>\n",
       "      <th>flops_per_token</th>\n",
       "      <th>energy_per_token_kwh</th>\n",
       "      <th>divergence_energy_flops_per_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [config_name, experiment_id, date_time, model, num_processes, batch_size___fixed_batching, decoder_temperature, decoder_top_k, decoder_top_p, latency_simulation_delay_min, latency_simulation_simulate_burst, latency_simulation_burst_size, latency_simulation_burst_interval, fp_precision, quantization, load_in_8bit, load_in_4bit, total_input_tokens, total_params, max_input_tokens, max_output_tokens, number_input_prompts, total_energy_kwh, total_energy_joules, flops, tokens_per_joule, joules_per_token, flops_per_joule, joules_per_flop, total_inference_time_sec, average_latency_ms_per_batch, throughput_queries_per_sec, throughput_tokens_per_sec, total_energy_kwh_process_0, total_energy_kwh_process_1, total_energy_kwh_process_2, total_energy_kwh_process_3, gpu_power_avg, ram_power_avg, cpu_energy_total, gpu_energy_total, latency_simulation_simulate, total_generated_tokens, decoder_config_decoding_mode, latency_simulation_delay_max, flops_per_token, energy_per_token_kwh, divergence_energy_flops_per_token]\n",
       "Index: []"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if file == possible_files[controlled]:\n",
    "    \n",
    "    df = df_controlled_dropped\n",
    "    \n",
    "    configs = ['num_processes', 'decoder', 'latency', 'batching', 'precis']\n",
    "    dfs = {config: df[df['config_name'].str.startswith(config)] for config in configs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_processes_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# First, organise your separate dfs into a list of (name, df) pairs\u001b[39;00m\n\u001b[1;32m      2\u001b[0m dfs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m----> 3\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNum Processes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mnum_processes_df\u001b[49m),\n\u001b[1;32m      4\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBatching\u001b[39m\u001b[38;5;124m\"\u001b[39m, batching_df),\n\u001b[1;32m      5\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecision\u001b[39m\u001b[38;5;124m\"\u001b[39m, precics_df),\n\u001b[1;32m      6\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDecoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, decoding_df),\n\u001b[1;32m      7\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLatency\u001b[39m\u001b[38;5;124m\"\u001b[39m, latency_df)\n\u001b[1;32m      8\u001b[0m ]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, df \u001b[38;5;129;01min\u001b[39;00m dfs:\n\u001b[1;32m     11\u001b[0m     fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_processes_df' is not defined"
     ]
    }
   ],
   "source": [
    "if file == possible_files[controlled]:\n",
    "    \n",
    "for name, df in dfs:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # ----- First subplot: Divergence Energy vs Batch Size -----\n",
    "    axes[0].plot(\n",
    "        df['num_processes'],\n",
    "        df['divergence_energy_flops_per_token'],\n",
    "        marker='o', \n",
    "        linestyle='-',\n",
    "        color='orange'\n",
    "    )\n",
    "    axes[0].set_xlabel('Batch Size (Fixed Batching)')\n",
    "    axes[0].set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "    axes[0].set_title(f'Divergence Energy vs Batch Size ({name})')\n",
    "    axes[0].set_xticks(df['num_processes'])\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # ----- Second subplot: Two Y-axes with Energy per Token and FLOPs per Token -----\n",
    "    ax1 = axes[1]\n",
    "    line1, = ax1.plot(\n",
    "        df['num_processes'], \n",
    "        df['energy_per_token_kwh'], \n",
    "        marker='o', \n",
    "        linestyle='-', \n",
    "        color='blue', \n",
    "        label='Energy per Token (kWh)'\n",
    "    )\n",
    "    ax1.set_xlabel('Batch Size (Fixed Batching)')\n",
    "    ax1.set_ylabel('Energy per Token (kWh)', color='blue')\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax1.set_xticks(df['num_processes'])\n",
    "    ax1.set_title(f'Metrics vs Batch Size ({name})')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    line2, = ax2.plot(\n",
    "        df['num_processes'], \n",
    "        df['flops_per_token'], \n",
    "        marker='s', \n",
    "        linestyle='--', \n",
    "        color='red', \n",
    "        label='FLOPs per Token'\n",
    "    )\n",
    "    ax2.set_ylabel('FLOPs per Token', color='red')\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    # Combine legends\n",
    "    lines = [line1, line2]\n",
    "    labels = [line.get_label() for line in lines]\n",
    "    ax1.legend(lines, labels, loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Step 1: Create a new 'precision' column for plotting\n",
    "    def determine_precision(row):\n",
    "        if row.get('load_in_4bit', False):\n",
    "            return 'INT4'\n",
    "        elif row.get('load_in_8bit', False):\n",
    "            return 'INT8'\n",
    "        elif row.get('fp_precision') == 'torch.float16':\n",
    "            return 'FP16'\n",
    "        else:\n",
    "            return 'FP32'\n",
    "\n",
    "    precics_df['precision'] = precics_df.apply(determine_precision, axis=1)\n",
    "\n",
    "    # Step 2: Define custom precision order\n",
    "    precision_order = ['FP32', 'FP16', 'INT8', 'INT4']\n",
    "\n",
    "    # Step 3: Sort the dataframe according to precision order\n",
    "    precics_df['precision'] = pd.Categorical(precics_df['precision'], categories=precision_order, ordered=True)\n",
    "    precics_df = precics_df.sort_values('precision')\n",
    "\n",
    "    # Step 4: Plotting\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # ----- First subplot: Divergence Energy vs Precision -----\n",
    "    axes[0].plot(\n",
    "        precics_df['precision'],\n",
    "        precics_df['divergence_energy_flops_per_token'],\n",
    "        marker='o', \n",
    "        linestyle='-',\n",
    "        color='orange'\n",
    "    )\n",
    "    axes[0].set_xlabel('Precision')\n",
    "    axes[0].set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "    axes[0].set_title('Divergence Energy vs Precision')\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # ----- Second subplot: Two Y-axes with Energy per Token and FLOPs per Token -----\n",
    "    ax1 = axes[1]\n",
    "    line1, = ax1.plot(\n",
    "        precics_df['precision'], \n",
    "        precics_df['energy_per_token_kwh'], \n",
    "        marker='o', \n",
    "        linestyle='-', \n",
    "        color='blue', \n",
    "        label='Energy per Token (kWh)'\n",
    "    )\n",
    "    ax1.set_xlabel('Precision')\n",
    "    ax1.set_ylabel('Energy per Token (kWh)', color='blue')\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax1.set_title('Metrics vs Precision')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    line2, = ax2.plot(\n",
    "        precics_df['precision'], \n",
    "        precics_df['flops_per_token'], \n",
    "        marker='s', \n",
    "        linestyle='--', \n",
    "        color='red', \n",
    "        label='FLOPs per Token'\n",
    "    )\n",
    "    ax2.set_ylabel('FLOPs per Token', color='red')\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    # Combine legends\n",
    "    lines = [line1, line2]\n",
    "    labels = [line.get_label() for line in lines]\n",
    "    ax1.legend(lines, labels, loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == possible_files[controlled]:\n",
    "\n",
    "    # --- Step 1: Filter the dataframe based on the config names ---\n",
    "    config_names = [\n",
    "        'decoding_greedy_decoder_temperature_0',\n",
    "        'decoding_greedy_decoder_temperature_0.7',\n",
    "        'decoding_greedy_decoder_temperature_1.0',\n",
    "        'decoding_greedy_decoder_temperature_1.3',\n",
    "        'decoding_top_k_decoder_top_k_50_decoder_temperature_0',\n",
    "        'decoding_top_k_decoder_top_k_50_decoder_temperature_0.7',\n",
    "        'decoding_top_k_decoder_top_k_50_decoder_temperature_1.0',\n",
    "        'decoding_top_k_decoder_top_k_50_decoder_temperature_1.3',\n",
    "        'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0',\n",
    "        'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.7',\n",
    "        'decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.0',\n",
    "        'decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.3'\n",
    "    ]\n",
    "    filtered_decoding = decoding_df[decoding_df['config_name'].isin(config_names)].copy()\n",
    "\n",
    "    # --- Step 2: Extract method and temperature from the config_name ---\n",
    "    def extract_method_and_temp(config):\n",
    "        if config.startswith(\"decoding_greedy_decoder_temperature_\"):\n",
    "            temp = float(config.split(\"decoding_greedy_decoder_temperature_\")[-1])\n",
    "            return \"greedy\", temp\n",
    "        elif config.startswith(\"decoding_top_k_decoder_top_k_50_decoder_temperature_\"):\n",
    "            temp = float(config.split(\"decoding_top_k_decoder_top_k_50_decoder_temperature_\")[-1])\n",
    "            return \"top_k\", temp\n",
    "        elif config.startswith(\"decoding_top_p_decoder_top_p_0.9_decoder_temperature_\"):\n",
    "            temp = float(config.split(\"decoding_top_p_decoder_top_p_0.9_decoder_temperature_\")[-1])\n",
    "            return \"top_p\", temp\n",
    "        else:\n",
    "            return \"unknown\", None\n",
    "\n",
    "    # Apply the extraction function and assign to new columns\n",
    "    filtered_decoding[['method', 'temperature']] = filtered_decoding['config_name'].apply(\n",
    "        lambda x: pd.Series(extract_method_and_temp(x))\n",
    "    )\n",
    "\n",
    "    # Optionally sort the dataframe by method and temperature for clarity.\n",
    "    filtered_decoding = filtered_decoding.sort_values(['method', 'temperature'])\n",
    "\n",
    "    # --- Step 3: Plotting ---\n",
    "\n",
    "    # Define colors for each method\n",
    "    colors = {\n",
    "        'greedy': 'blue',\n",
    "        'top_k': 'green',\n",
    "        'top_p': 'red'\n",
    "    }\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # --- Left subplot: Divergence Energy vs Temperature ---\n",
    "    ax_left = axes[0]\n",
    "    methods = filtered_decoding['method'].unique()\n",
    "    for m in methods:\n",
    "        subdf = filtered_decoding[filtered_decoding['method'] == m]\n",
    "        ax_left.plot(subdf['temperature'], subdf['divergence_energy_flops_per_token'],\n",
    "                    marker='o', linestyle='-', label=m, color=colors.get(m))\n",
    "    ax_left.set_xlabel('Decoder Temperature')\n",
    "    ax_left.set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "    ax_left.set_title('Divergence Energy vs Decoder Temperature')\n",
    "    ax_left.grid(True)\n",
    "    ax_left.legend(title=\"Method\")\n",
    "\n",
    "    # --- Right subplot: Two Y-axes with Energy per Token and FLOPs per Token ---\n",
    "    ax1 = axes[1]\n",
    "    # Primary axis for Energy per Token\n",
    "    for m in methods:\n",
    "        subdf = filtered_decoding[filtered_decoding['method'] == m]\n",
    "        ax1.plot(subdf['temperature'], subdf['energy_per_token_kwh'],\n",
    "                marker='o', linestyle='-', label=f'{m} Energy', color=colors.get(m))\n",
    "    ax1.set_xlabel('Decoder Temperature')\n",
    "    ax1.set_ylabel('Energy per Token (kWh)', color='black')\n",
    "    ax1.set_title('Metrics vs Decoder Temperature')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Secondary axis for FLOPs per Token\n",
    "    ax2 = ax1.twinx()\n",
    "    for m in methods:\n",
    "        subdf = filtered_decoding[filtered_decoding['method'] == m]\n",
    "        ax2.plot(subdf['temperature'], subdf['flops_per_token'],\n",
    "                marker='s', linestyle='--', label=f'{m} FLOPs', color=colors.get(m))\n",
    "    ax2.set_ylabel('FLOPs per Token', color='black')\n",
    "\n",
    "    # --- Combine legends from both axes ---\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == possible_files[controlled]:\n",
    "\n",
    "    # --- 1. Filter the latency_df to only keep the specified configurations ---\n",
    "    latency_configs = [\n",
    "        'latency_False',\n",
    "        'latency_True_latency_0.05_latency_0.2_latency_False',\n",
    "        'latency_True_latency_0.2_latency_0.6_latency_False',\n",
    "        'latency_True_latency_0.05_latency_0.2_latency_True_latency_4.0_latency_5',\n",
    "        'latency_True_latency_0.2_latency_0.6_latency_True_latency_5.0_latency_8'\n",
    "    ]\n",
    "    latency_filtered = latency_df[latency_df['config_name'].isin(latency_configs)].copy()\n",
    "\n",
    "    # --- 2. Define a function to parse the config string ---\n",
    "    def parse_latency_config(config):\n",
    "        \"\"\"\n",
    "        Parses a latency configuration string and returns a dict with:\n",
    "        - simulate (boolean)\n",
    "        - delay_min (float or None)\n",
    "        - delay_max (float or None)\n",
    "        - simulate_burst (boolean or None)\n",
    "        - burst_size (float or None)\n",
    "        - burst_interval (float or None)\n",
    "        \"\"\"\n",
    "        tokens = config.split('_')\n",
    "        \n",
    "        # There will be extra \"latency\" tokens in the string.\n",
    "        # Look at the total number of tokens:\n",
    "        # For baseline: e.g., \"latency_False\" -> tokens: [\"latency\", \"False\"]\n",
    "        # Without burst: 8 tokens, e.g.:\n",
    "        #   [\"latency\", \"True\", \"latency\", \"0.05\", \"latency\", \"0.2\", \"latency\", \"False\"]\n",
    "        # With burst: 12 tokens, e.g.:\n",
    "        #   [\"latency\", \"True\", \"latency\", \"0.05\", \"latency\", \"0.2\", \"latency\", \"True\", \"latency\", \"4.0\", \"latency\", \"5\"]\n",
    "        res = {}\n",
    "        if len(tokens) == 2:\n",
    "            # Baseline: no simulation\n",
    "            res['simulate'] = (tokens[1] == \"True\")\n",
    "            res['delay_min'] = None\n",
    "            res['delay_max'] = None\n",
    "            res['simulate_burst'] = None\n",
    "            res['burst_size'] = None\n",
    "            res['burst_interval'] = None\n",
    "        elif len(tokens) == 8:\n",
    "            # Without burst: tokens at positions 1, 3, 5, and 7 are our values.\n",
    "            res['simulate'] = (tokens[1] == \"True\")\n",
    "            res['delay_min'] = float(tokens[3])\n",
    "            res['delay_max'] = float(tokens[5])\n",
    "            res['simulate_burst'] = (tokens[7] == \"True\")\n",
    "            res['burst_size'] = None\n",
    "            res['burst_interval'] = None\n",
    "        elif len(tokens) == 12:\n",
    "            # With burst: tokens at positions 1, 3, 5, 7, 9, and 11.\n",
    "            res['simulate'] = (tokens[1] == \"True\")\n",
    "            res['delay_min'] = float(tokens[3])\n",
    "            res['delay_max'] = float(tokens[5])\n",
    "            res['simulate_burst'] = (tokens[7] == \"True\")\n",
    "            res['burst_size'] = float(tokens[9])\n",
    "            res['burst_interval'] = float(tokens[11])\n",
    "        else:\n",
    "            res['simulate'] = None\n",
    "            res['delay_min'] = None\n",
    "            res['delay_max'] = None\n",
    "            res['simulate_burst'] = None\n",
    "            res['burst_size'] = None\n",
    "            res['burst_interval'] = None\n",
    "        return res\n",
    "\n",
    "    # Apply the parser so that we have new columns for the latency parameters\n",
    "    latency_params = latency_filtered['config_name'].apply(lambda x: pd.Series(parse_latency_config(x)))\n",
    "    latency_filtered = pd.concat([latency_filtered, latency_params], axis=1)\n",
    "\n",
    "    # --- 3. Create a user-friendly label for each configuration ---\n",
    "    def make_latency_label(row):\n",
    "        if row['simulate'] is False:\n",
    "            return \"No simulation\"\n",
    "        elif row['simulate'] is True and row['simulate_burst'] is False:\n",
    "            return f\"Sim ({row['delay_min']}-{row['delay_max']})\"\n",
    "        elif row['simulate'] is True and row['simulate_burst'] is True:\n",
    "            return f\"Sim ({row['delay_min']}-{row['delay_max']}) Burst ({row['burst_size']},{row['burst_interval']})\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "\n",
    "    latency_filtered['latency_label'] = latency_filtered.apply(make_latency_label, axis=1)\n",
    "\n",
    "    # --- 4. Order the configurations as desired ---\n",
    "    order_labels = [\n",
    "        \"No simulation\",\n",
    "        \"Sim (0.05-0.2)\",\n",
    "        \"Sim (0.2-0.6)\",\n",
    "        \"Sim (0.05-0.2) Burst (4.0,5)\",\n",
    "        \"Sim (0.2-0.6) Burst (5.0,8)\"\n",
    "    ]\n",
    "    latency_filtered['latency_label'] = pd.Categorical(latency_filtered['latency_label'], \n",
    "                                                        categories=order_labels, ordered=True)\n",
    "    latency_filtered = latency_filtered.sort_values('latency_label')\n",
    "\n",
    "    # --- 5. Create the two subplots ---\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Left Subplot: Divergence Energy vs Latency Configuration (categorical x-axis)\n",
    "    axes[0].plot(\n",
    "        latency_filtered['latency_label'],\n",
    "        latency_filtered['divergence_energy_flops_per_token'],\n",
    "        marker='o',\n",
    "        linestyle='-',\n",
    "        color='orange'\n",
    "    )\n",
    "    axes[0].set_xlabel('Latency Configuration')\n",
    "    axes[0].set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "    axes[0].set_title('Divergence Energy vs Latency Config')\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Right Subplot: Two y-axes for Energy per Token and FLOPs per Token\n",
    "    ax1 = axes[1]\n",
    "    line1, = ax1.plot(\n",
    "        latency_filtered['latency_label'],\n",
    "        latency_filtered['energy_per_token_kwh'],\n",
    "        marker='o',\n",
    "        linestyle='-',\n",
    "        color='blue',\n",
    "        label='Energy per Token (kWh)'\n",
    "    )\n",
    "    ax1.set_xlabel('Latency Configuration')\n",
    "    ax1.set_ylabel('Energy per Token (kWh)', color='blue')\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax1.set_title('Metrics vs Latency Config')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Create secondary y-axis for FLOPs per Token\n",
    "    ax2 = ax1.twinx()\n",
    "    line2, = ax2.plot(\n",
    "        latency_filtered['latency_label'],\n",
    "        latency_filtered['flops_per_token'],\n",
    "        marker='s',\n",
    "        linestyle='--',\n",
    "        color='red',\n",
    "        label='FLOPs per Token'\n",
    "    )\n",
    "    ax2.set_ylabel('FLOPs per Token', color='red')\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    # Combine legends from both axes\n",
    "    lines = [line1, line2]\n",
    "    labels = [line.get_label() for line in lines]\n",
    "    ax1.legend(lines, labels, loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == possible_files[controlled]:\n",
    "    print(f\"var energy: {df_controlled_dropped.total_energy_kwh.max()} / {df_controlled_dropped.total_energy_kwh.min()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORK OUT STANDARD DEVIATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[79], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# If distribution is very skewed: log-transform\u001b[39;00m\n\u001b[1;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m---> 20\u001b[0m plt\u001b[38;5;241m.\u001b[39mhist(\u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mlog(df_scenarios_dropped[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotal_energy_kwh\u001b[39m\u001b[38;5;124m'\u001b[39m]), bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     21\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistribution of Log-Transformed Total Energy (kWh)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLog(Total Energy (kWh))\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Histogram of raw total_energy_kwh\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_scenarios_dropped['total_energy_kwh'], bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Total Energy (kWh)')\n",
    "plt.xlabel('Total Energy (kWh)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot to spot outliers\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.boxplot(df_scenarios_dropped['total_energy_kwh'], vert=False)\n",
    "plt.title('Boxplot of Total Energy (kWh)')\n",
    "plt.xlabel('Total Energy (kWh)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# If distribution is very skewed: log-transform\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(np.log(df_scenarios_dropped['total_energy_kwh']), bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Log-Transformed Total Energy (kWh)')\n",
    "plt.xlabel('Log(Total Energy (kWh))')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for Scenario Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == possible_files[\"scenario\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scenarios_dropped.total_energy_kwh.max() / df_scenarios_dropped.total_energy_kwh.min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

configuration_run_id,configuration_run_title,setup,variables,model_architecture,inference_metrics,compute_metrics,global_energy_metrics,process_0_energy,process_1_energy,process_2_energy,process_3_energy
0138,CONFIGURATION_RUN_#0138,"{""experiment_id"": ""0138"", ""date_time"": ""April 05, 2025 at 07:32:16 PM"", ""model"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""available_gpu_count"": 4, ""gpu_model"": ""4 x NVIDIA A100-PCIE-40GB"", ""available_cpu_count"": 128, ""cpu_model"": ""AMD EPYC 7742 64-Core Processor"", ""os"": ""Linux-5.15.0-113-generic-x86_64-with-glibc2.31"", ""python_version"": ""3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]"", ""country"": ""Germany"", ""region"": ""saxony""}","{""config_name"": ""na"", ""max_input_tokens"": 100, ""max_output_tokens"": 100, ""number_input_prompts"": 100, ""decode_token_to_text"": true, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 50, ""decoder_top_p"": 0.95}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 4, ""delay_max"": 0.3, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""fp_precision"": ""torch.float32"", ""quantisation"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": null}, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 3000, ""max_batch_size___adaptive_batching"": 100}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""accelerate_config"": {""distributed_type"": ""DistributedType.NO"", ""num_processes"": 1}, ""inference_type"": ""pure_generative"", ""backend"": ""pytorch""}","{""total_params"": 1100048384, ""num_hidden_layers"": 22, ""hidden_size"": 2048, ""num_attention_heads"": 32, ""intermediate_size"": 5632}","{""raw_inference_metrics"": {""number_input_prompts"": 100, ""total_input_tokens"": 10000, ""total_generated_tokens"": 10000}, ""inference_performance"": {""total_inference_time_sec"": 32.027431403286755, ""average_latency_ms_per_batch"": 4575.347343326679, ""throughput_queries_per_sec"": 3.1223234464483993, ""throughput_tokens_per_sec"": 312.23234464483994}}","{""flops"": 0.0, ""memory"": {""gpu_current_memory_allocated_bytes"": 4409393664, ""gpu_max_memory_allocated_bytes"": 4409393664, ""gpu_current_memory_reserved_bytes"": 4758437888, ""gpu_max_memory_reserved_bytes"": 4758437888}, ""compute_utilisation"": {""gpu_utilization_percent"": [100.0, 0.0, 0.0, 0.0], ""cpu_usage_percent"": 98.6, ""cpu_memory_usage_bytes"": 2252906496}}","{""experiment_id"": ""0138"", ""local_process_results"": {""cpu_power"": {""0"": 112.5}, ""gpu_power"": {""0"": 385.95843507085215}, ""ram_power"": {""0"": 0.7839174270629884}, ""cpu_energy"": {""0"": 0.00105452502125263}, ""gpu_energy"": {""0"": 0.0030379652081435893}, ""ram_energy"": {""0"": 5.453907211657688e-06}, ""total_energy_kwh"": {""0"": 0.004097944136607877}, ""total_energy_joules"": {""0"": 14752.598891788357}}, ""global_experiment_results"": {""cpu_power_avg"": 112.5, ""gpu_power_avg"": 385.95843507085215, ""ram_power_avg"": 0.7839174270629884, ""cpu_energy_total"": 0.00105452502125263, ""gpu_energy_total"": 0.0030379652081435893, ""ram_energy_total"": 5.453907211657688e-06, ""total_energy_kwh"": 0.004097944136607877, ""total_energy_joules"": 14752.598891788357}, ""global_derived_quantities"": {""tokens_per_joule"": 0.6778466677872084, ""joules_per_token"": 1.4752598891788355, ""flops_per_joule"": 0.0, ""joules_per_flop"": 0}, ""per-process_emissions"": [0.0015611118188407708]}","{""process_id"": 3227712, ""local_process_index"": 0, ""energy_results"": {""cpu_power"": 112.5, ""gpu_power"": 385.95843507085215, ""ram_power"": 0.7839174270629884, ""cpu_energy"": 0.00105452502125263, ""gpu_energy"": 0.0030379652081435893, ""ram_energy"": 5.453907211657688e-06, ""total_energy_kwh"": 0.004097944136607877, ""total_energy_joules"": 14752.598891788357, ""final_emissions"": 0.0015611118188407708}}","""NA""","""NA""","""NA"""
0139,CONFIGURATION_RUN_#0139,"{""experiment_id"": ""0139"", ""date_time"": ""April 05, 2025 at 07:33:56 PM"", ""model"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""available_gpu_count"": 4, ""gpu_model"": ""4 x NVIDIA A100-PCIE-40GB"", ""available_cpu_count"": 128, ""cpu_model"": ""AMD EPYC 7742 64-Core Processor"", ""os"": ""Linux-5.15.0-113-generic-x86_64-with-glibc2.31"", ""python_version"": ""3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]"", ""country"": ""Germany"", ""region"": ""saxony""}","{""config_name"": ""a1_max_throughput_exploit"", ""max_input_tokens"": 100, ""max_output_tokens"": 100, ""number_input_prompts"": 100, ""decode_token_to_text"": true, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 50, ""decoder_top_p"": 0.95}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 4, ""delay_max"": 0.3, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""fp_precision"": ""torch.float16"", ""quantisation"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 10345441280000}, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 3000, ""max_batch_size___adaptive_batching"": 100}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""accelerate_config"": {""distributed_type"": ""DistributedType.NO"", ""num_processes"": 1}, ""inference_type"": ""pure_generative"", ""backend"": ""pytorch""}","{""total_params"": 1100048384, ""num_hidden_layers"": 22, ""hidden_size"": 2048, ""num_attention_heads"": 32, ""intermediate_size"": 5632}","{""raw_inference_metrics"": {""number_input_prompts"": 100, ""total_input_tokens"": 10000, ""total_generated_tokens"": 10000}, ""inference_performance"": {""total_inference_time_sec"": 40.52234203601256, ""average_latency_ms_per_batch"": 40522.34203601256, ""throughput_queries_per_sec"": 2.467774441840729, ""throughput_tokens_per_sec"": 246.7774441840729}}","{""flops"": 10345441280000, ""memory"": {""gpu_current_memory_allocated_bytes"": 1315031040, ""gpu_max_memory_allocated_bytes"": 1315031040, ""gpu_current_memory_reserved_bytes"": 2483027968, ""gpu_max_memory_reserved_bytes"": 2483027968}, ""compute_utilisation"": {""gpu_utilization_percent"": [100.0, 0.0, 0.0, 0.0], ""cpu_usage_percent"": 98.5, ""cpu_memory_usage_bytes"": 3174780928}}","{""experiment_id"": ""0139"", ""local_process_results"": {""cpu_power"": {""0"": 112.5}, ""gpu_power"": {""0"": 268.77462306341323}, ""ram_power"": {""0"": 1.1076021194458008}, ""cpu_energy"": {""0"": 0.0013055846045172076}, ""gpu_energy"": {""0"": 0.003655189868588593}, ""ram_energy"": {""0"": 1.1005898012116198e-05}, ""total_energy_kwh"": {""0"": 0.004971780371117916}, ""total_energy_joules"": {""0"": 17898.4093360245}}, ""global_experiment_results"": {""cpu_power_avg"": 112.5, ""gpu_power_avg"": 268.77462306341323, ""ram_power_avg"": 1.1076021194458008, ""cpu_energy_total"": 0.0013055846045172076, ""gpu_energy_total"": 0.003655189868588593, ""ram_energy_total"": 1.1005898012116198e-05, ""total_energy_kwh"": 0.004971780371117916, ""total_energy_joules"": 17898.4093360245}, ""global_derived_quantities"": {""tokens_per_joule"": 0.5587088669311409, ""joules_per_token"": 1.7898409336024497, ""flops_per_joule"": 578008977.5451452, ""joules_per_flop"": 1.730076934526325e-09}, ""per-process_emissions"": [0.0018939997323773703]}","{""process_id"": 3228537, ""local_process_index"": 0, ""energy_results"": {""cpu_power"": 112.5, ""gpu_power"": 268.77462306341323, ""ram_power"": 1.1076021194458008, ""cpu_energy"": 0.0013055846045172076, ""gpu_energy"": 0.003655189868588593, ""ram_energy"": 1.1005898012116198e-05, ""total_energy_kwh"": 0.004971780371117916, ""total_energy_joules"": 17898.4093360245, ""final_emissions"": 0.0018939997323773703}}","""NA""","""NA""","""NA"""
0140,CONFIGURATION_RUN_#0140,"{""experiment_id"": ""0140"", ""date_time"": ""April 05, 2025 at 07:34:13 PM"", ""model"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""available_gpu_count"": 2, ""gpu_model"": ""4 x NVIDIA A100-PCIE-40GB"", ""available_cpu_count"": 128, ""cpu_model"": ""AMD EPYC 7742 64-Core Processor"", ""os"": ""Linux-5.15.0-113-generic-x86_64-with-glibc2.31"", ""python_version"": ""3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]"", ""country"": ""Germany"", ""region"": ""saxony""}","{""config_name"": ""a2_precision_minimalist"", ""max_input_tokens"": 100, ""max_output_tokens"": 100, ""number_input_prompts"": 100, ""decode_token_to_text"": true, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 50, ""decoder_top_p"": 0.95}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 4, ""delay_max"": 0.3, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""fp_precision"": ""torch.float16"", ""quantisation"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 10345441280000}, ""batching_options"": {""batch_size___fixed_batching"": 128}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""accelerate_config"": {""distributed_type"": ""DistributedType.NO"", ""num_processes"": 1}, ""inference_type"": ""pure_generative"", ""backend"": ""pytorch""}","{""total_params"": 615606272, ""num_hidden_layers"": 22, ""hidden_size"": 2048, ""num_attention_heads"": 32, ""intermediate_size"": 5632}","{""raw_inference_metrics"": {""number_input_prompts"": 100, ""total_input_tokens"": 10000, ""total_generated_tokens"": 10000}, ""inference_performance"": {""total_inference_time_sec"": 6.113123851828277, ""average_latency_ms_per_batch"": 6113.123851828277, ""throughput_queries_per_sec"": 16.358248650580276, ""throughput_tokens_per_sec"": 1635.8248650580274}}","{""flops"": 10345441280000, ""memory"": {""gpu_current_memory_allocated_bytes"": 825651200, ""gpu_max_memory_allocated_bytes"": 825651200, ""gpu_current_memory_reserved_bytes"": 2571108352, ""gpu_max_memory_reserved_bytes"": 2571108352}, ""compute_utilisation"": {""gpu_utilization_percent"": [100.0, 0.0, 0.0, 0.0], ""cpu_usage_percent"": 95.9, ""cpu_memory_usage_bytes"": 5122183168}}","{""experiment_id"": ""0140"", ""local_process_results"": {""cpu_power"": {""0"": 112.5}, ""gpu_power"": {""0"": 301.8877908898471}, ""ram_power"": {""0"": 1.7889018058776855}, ""cpu_energy"": {""0"": 0.00023686702199483988}, ""gpu_energy"": {""0"": 0.0005577748906517854}, ""ram_energy"": {""0"": 3.0431601428176015e-06}, ""total_energy_kwh"": {""0"": 0.000797685072789443}, ""total_energy_joules"": {""0"": 2871.6662620419947}}, ""global_experiment_results"": {""cpu_power_avg"": 112.5, ""gpu_power_avg"": 301.8877908898471, ""ram_power_avg"": 1.7889018058776855, ""cpu_energy_total"": 0.00023686702199483988, ""gpu_energy_total"": 0.0005577748906517854, ""ram_energy_total"": 3.0431601428176015e-06, ""total_energy_kwh"": 0.000797685072789443, ""total_energy_joules"": 2871.6662620419947}, ""global_derived_quantities"": {""tokens_per_joule"": 3.4822988075533416, ""joules_per_token"": 0.28716662620419947, ""flops_per_joule"": 3602591783.2957115, ""joules_per_flop"": 2.77577938371131e-10}, ""per-process_emissions"": [0.00030387812847913835]}","{""process_id"": 3228537, ""local_process_index"": 0, ""energy_results"": {""cpu_power"": 112.5, ""gpu_power"": 301.8877908898471, ""ram_power"": 1.7889018058776855, ""cpu_energy"": 0.00023686702199483988, ""gpu_energy"": 0.0005577748906517854, ""ram_energy"": 3.0431601428176015e-06, ""total_energy_kwh"": 0.000797685072789443, ""total_energy_joules"": 2871.6662620419947, ""final_emissions"": 0.00030387812847913835}}","""NA""","""NA""","""NA"""
0141,CONFIGURATION_RUN_#0141,"{""experiment_id"": ""0141"", ""date_time"": ""April 05, 2025 at 07:34:33 PM"", ""model"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""available_gpu_count"": 1, ""gpu_model"": ""4 x NVIDIA A100-PCIE-40GB"", ""available_cpu_count"": 128, ""cpu_model"": ""AMD EPYC 7742 64-Core Processor"", ""os"": ""Linux-5.15.0-113-generic-x86_64-with-glibc2.31"", ""python_version"": ""3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]"", ""country"": ""Germany"", ""region"": ""saxony""}","{""config_name"": ""a3_quantisation_gaming"", ""max_input_tokens"": 100, ""max_output_tokens"": 100, ""number_input_prompts"": 100, ""decode_token_to_text"": true, ""decoder_config"": {""decoder_temperature"": 0.7, ""decoder_top_k"": 50, ""decoder_top_p"": 0.95}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 4, ""delay_max"": 0.3, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""fp_precision"": ""torch.float16"", ""quantisation"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 10345441280000}, ""batching_options"": {""batch_size___fixed_batching"": 64}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""accelerate_config"": {""distributed_type"": ""DistributedType.NO"", ""num_processes"": 1}, ""inference_type"": ""pure_generative"", ""backend"": ""pytorch""}","{""total_params"": 615606272, ""num_hidden_layers"": 22, ""hidden_size"": 2048, ""num_attention_heads"": 32, ""intermediate_size"": 5632}","{""raw_inference_metrics"": {""number_input_prompts"": 100, ""total_input_tokens"": 10000, ""total_generated_tokens"": 10000}, ""inference_performance"": {""total_inference_time_sec"": 10.191092994762585, ""average_latency_ms_per_batch"": 5095.546497381292, ""throughput_queries_per_sec"": 9.812490186419856, ""throughput_tokens_per_sec"": 981.2490186419856}}","{""flops"": 10345441280000, ""memory"": {""gpu_current_memory_allocated_bytes"": 825782272, ""gpu_max_memory_allocated_bytes"": 825782272, ""gpu_current_memory_reserved_bytes"": 1931476992, ""gpu_max_memory_reserved_bytes"": 1931476992}, ""compute_utilisation"": {""gpu_utilization_percent"": [100.0, 0.0, 0.0, 0.0], ""cpu_usage_percent"": 98.2, ""cpu_memory_usage_bytes"": 5890134016}}","{""experiment_id"": ""0141"", ""local_process_results"": {""cpu_power"": {""0"": 112.5}, ""gpu_power"": {""0"": 238.01154797343534}, ""ram_power"": {""0"": 2.057105541229248}, ""cpu_energy"": {""0"": 0.00035425275729357973}, ""gpu_energy"": {""0"": 0.0007136830709484343}, ""ram_energy"": {""0"": 5.005783290095551e-06}, ""total_energy_kwh"": {""0"": 0.0010729416115321097}, ""total_energy_joules"": {""0"": 3862.589801515595}}, ""global_experiment_results"": {""cpu_power_avg"": 112.5, ""gpu_power_avg"": 238.01154797343534, ""ram_power_avg"": 2.057105541229248, ""cpu_energy_total"": 0.00035425275729357973, ""gpu_energy_total"": 0.0007136830709484343, ""ram_energy_total"": 5.005783290095551e-06, ""total_energy_kwh"": 0.0010729416115321097, ""total_energy_joules"": 3862.589801515595}, ""global_derived_quantities"": {""tokens_per_joule"": 2.588936572057489, ""joules_per_token"": 0.38625898015155946, ""flops_per_joule"": 2678369128.3865237, ""joules_per_flop"": 3.733615316132358e-10}, ""per-process_emissions"": [0.0004087371069131572]}","{""process_id"": 3228537, ""local_process_index"": 0, ""energy_results"": {""cpu_power"": 112.5, ""gpu_power"": 238.01154797343534, ""ram_power"": 2.057105541229248, ""cpu_energy"": 0.00035425275729357973, ""gpu_energy"": 0.0007136830709484343, ""ram_energy"": 5.005783290095551e-06, ""total_energy_kwh"": 0.0010729416115321097, ""total_energy_joules"": 3862.589801515595, ""final_emissions"": 0.0004087371069131572}}","""NA""","""NA""","""NA"""
0142,CONFIGURATION_RUN_#0142,"{""experiment_id"": ""0142"", ""date_time"": ""April 05, 2025 at 07:37:12 PM"", ""model"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""available_gpu_count"": 1, ""gpu_model"": ""4 x NVIDIA A100-PCIE-40GB"", ""available_cpu_count"": 128, ""cpu_model"": ""AMD EPYC 7742 64-Core Processor"", ""os"": ""Linux-5.15.0-113-generic-x86_64-with-glibc2.31"", ""python_version"": ""3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]"", ""country"": ""Germany"", ""region"": ""saxony""}","{""config_name"": ""a4_latency_ignorance_exploit"", ""max_input_tokens"": 100, ""max_output_tokens"": 100, ""number_input_prompts"": 100, ""decode_token_to_text"": true, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 50, ""decoder_top_p"": 0.95}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 4, ""delay_max"": 0.3, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""fp_precision"": ""torch.float16"", ""quantisation"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 10345441280000}, ""batching_options"": {""batch_size___fixed_batching"": 32}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""accelerate_config"": {""distributed_type"": ""DistributedType.NO"", ""num_processes"": 1}, ""inference_type"": ""pure_generative"", ""backend"": ""pytorch""}","{""total_params"": 1100048384, ""num_hidden_layers"": 22, ""hidden_size"": 2048, ""num_attention_heads"": 32, ""intermediate_size"": 5632}","{""raw_inference_metrics"": {""number_input_prompts"": 100, ""total_input_tokens"": 10000, ""total_generated_tokens"": 10000}, ""inference_performance"": {""total_inference_time_sec"": 149.66027094284073, ""average_latency_ms_per_batch"": 37415.06773571018, ""throughput_queries_per_sec"": 0.6681800010785273, ""throughput_tokens_per_sec"": 66.81800010785273}}","{""flops"": 10345441280000, ""memory"": {""gpu_current_memory_allocated_bytes"": 1314790400, ""gpu_max_memory_allocated_bytes"": 1314790400, ""gpu_current_memory_reserved_bytes"": 2197815296, ""gpu_max_memory_reserved_bytes"": 2197815296}, ""compute_utilisation"": {""gpu_utilization_percent"": [100.0, 0.0, 0.0, 0.0], ""cpu_usage_percent"": 96.2, ""cpu_memory_usage_bytes"": 6233419776}}","{""experiment_id"": ""0142"", ""local_process_results"": {""cpu_power"": {""0"": 112.5}, ""gpu_power"": {""0"": 214.66575416870475}, ""ram_power"": {""0"": 2.1769967079162598}, ""cpu_energy"": {""0"": 0.004617535697027051}, ""gpu_energy"": {""0"": 0.008697843902716329}, ""ram_energy"": {""0"": 7.496226956062784e-05}, ""total_energy_kwh"": {""0"": 0.013390341869304}, ""total_energy_joules"": {""0"": 48205.230729494404}}, ""global_experiment_results"": {""cpu_power_avg"": 112.5, ""gpu_power_avg"": 214.66575416870475, ""ram_power_avg"": 2.1769967079162598, ""cpu_energy_total"": 0.004617535697027051, ""gpu_energy_total"": 0.008697843902716329, ""ram_energy_total"": 7.496226956062784e-05, ""total_energy_kwh"": 0.013390341869304, ""total_energy_joules"": 48205.230729494404}, ""global_derived_quantities"": {""tokens_per_joule"": 0.20744636730639052, ""joules_per_token"": 4.820523072949441, ""flops_per_joule"": 214612421.1717575, ""joules_per_flop"": 4.659562547871752e-09}, ""per-process_emissions"": [0.005101050735111359]}","{""process_id"": 3228537, ""local_process_index"": 0, ""energy_results"": {""cpu_power"": 112.5, ""gpu_power"": 214.66575416870475, ""ram_power"": 2.1769967079162598, ""cpu_energy"": 0.004617535697027051, ""gpu_energy"": 0.008697843902716329, ""ram_energy"": 7.496226956062784e-05, ""total_energy_kwh"": 0.013390341869304, ""total_energy_joules"": 48205.230729494404, ""final_emissions"": 0.005101050735111359}}","""NA""","""NA""","""NA"""
0143,CONFIGURATION_RUN_#0143,"{""experiment_id"": ""0143"", ""date_time"": ""April 05, 2025 at 07:37:28 PM"", ""model"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""available_gpu_count"": 4, ""gpu_model"": ""4 x NVIDIA A100-PCIE-40GB"", ""available_cpu_count"": 128, ""cpu_model"": ""AMD EPYC 7742 64-Core Processor"", ""os"": ""Linux-5.15.0-113-generic-x86_64-with-glibc2.31"", ""python_version"": ""3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]"", ""country"": ""Germany"", ""region"": ""saxony""}","{""config_name"": ""a5_parallel_overdrive"", ""max_input_tokens"": 100, ""max_output_tokens"": 100, ""number_input_prompts"": 100, ""decode_token_to_text"": true, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 50, ""decoder_top_p"": 0.95}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 4, ""delay_max"": 0.3, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""fp_precision"": ""torch.float16"", ""quantisation"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": null}, ""batching_options"": {""batch_size___fixed_batching"": 64}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""accelerate_config"": {""distributed_type"": ""DistributedType.NO"", ""num_processes"": 1}, ""inference_type"": ""pure_generative"", ""backend"": ""pytorch""}","{""total_params"": 1100048384, ""num_hidden_layers"": 22, ""hidden_size"": 2048, ""num_attention_heads"": 32, ""intermediate_size"": 5632}","{""raw_inference_metrics"": {""number_input_prompts"": 100, ""total_input_tokens"": 10000, ""total_generated_tokens"": 10000}, ""inference_performance"": {""total_inference_time_sec"": 7.216156058013439, ""average_latency_ms_per_batch"": 3608.0780290067196, ""throughput_queries_per_sec"": 13.857793428531997, ""throughput_tokens_per_sec"": 1385.7793428531998}}","{""flops"": 0.0, ""memory"": {""gpu_current_memory_allocated_bytes"": 3516984832, ""gpu_max_memory_allocated_bytes"": 3516984832, ""gpu_current_memory_reserved_bytes"": 4179623936, ""gpu_max_memory_reserved_bytes"": 4179623936}, ""compute_utilisation"": {""gpu_utilization_percent"": [100.0, 0.0, 0.0, 0.0], ""cpu_usage_percent"": 98.3, ""cpu_memory_usage_bytes"": 6489305088}}","{""experiment_id"": ""0143"", ""local_process_results"": {""cpu_power"": {""0"": 112.5}, ""gpu_power"": {""0"": 331.4716333890531}, ""ram_power"": {""0"": 2.2648444175720215}, ""cpu_energy"": {""0"": 0.00025886610687302894}, ""gpu_energy"": {""0"": 0.0007393197581180289}, ""ram_energy"": {""0"": 4.236614035819941e-06}, ""total_energy_kwh"": {""0"": 0.0010024224790268778}, ""total_energy_joules"": {""0"": 3608.7209244967603}}, ""global_experiment_results"": {""cpu_power_avg"": 112.5, ""gpu_power_avg"": 331.4716333890531, ""ram_power_avg"": 2.2648444175720215, ""cpu_energy_total"": 0.00025886610687302894, ""gpu_energy_total"": 0.0007393197581180289, ""ram_energy_total"": 4.236614035819941e-06, ""total_energy_kwh"": 0.0010024224790268778, ""total_energy_joules"": 3608.7209244967603}, ""global_derived_quantities"": {""tokens_per_joule"": 2.7710649311000712, ""joules_per_token"": 0.360872092449676, ""flops_per_joule"": 0.0, ""joules_per_flop"": 0}, ""per-process_emissions"": [0.00038187284338528913]}","{""process_id"": 3228537, ""local_process_index"": 0, ""energy_results"": {""cpu_power"": 112.5, ""gpu_power"": 331.4716333890531, ""ram_power"": 2.2648444175720215, ""cpu_energy"": 0.00025886610687302894, ""gpu_energy"": 0.0007393197581180289, ""ram_energy"": 4.236614035819941e-06, ""total_energy_kwh"": 0.0010024224790268778, ""total_energy_joules"": 3608.7209244967603, ""final_emissions"": 0.00038187284338528913}}","""NA""","""NA""","""NA"""
0144,CONFIGURATION_RUN_#0144,"{""experiment_id"": ""0144"", ""date_time"": ""April 05, 2025 at 07:38:17 PM"", ""model"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""available_gpu_count"": 2, ""gpu_model"": ""4 x NVIDIA A100-PCIE-40GB"", ""available_cpu_count"": 128, ""cpu_model"": ""AMD EPYC 7742 64-Core Processor"", ""os"": ""Linux-5.15.0-113-generic-x86_64-with-glibc2.31"", ""python_version"": ""3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]"", ""country"": ""Germany"", ""region"": ""saxony""}","{""config_name"": ""r1_standard_production"", ""max_input_tokens"": 100, ""max_output_tokens"": 100, ""number_input_prompts"": 100, ""decode_token_to_text"": true, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 50, ""decoder_top_p"": 0.95}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""fp_precision"": ""torch.float32"", ""quantisation"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": null}, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 3000, ""max_batch_size___adaptive_batching"": 100}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""accelerate_config"": {""distributed_type"": ""DistributedType.NO"", ""num_processes"": 1}, ""inference_type"": ""pure_generative"", ""backend"": ""pytorch""}","{""total_params"": 1100048384, ""num_hidden_layers"": 22, ""hidden_size"": 2048, ""num_attention_heads"": 32, ""intermediate_size"": 5632}","{""raw_inference_metrics"": {""number_input_prompts"": 100, ""total_input_tokens"": 10000, ""total_generated_tokens"": 10000}, ""inference_performance"": {""total_inference_time_sec"": 39.54867582512088, ""average_latency_ms_per_batch"": 5649.810832160126, ""throughput_queries_per_sec"": 2.5285296641077704, ""throughput_tokens_per_sec"": 252.85296641077704}}","{""flops"": 0.0, ""memory"": {""gpu_current_memory_allocated_bytes"": 6611588096, ""gpu_max_memory_allocated_bytes"": 6611588096, ""gpu_current_memory_reserved_bytes"": 6958350336, ""gpu_max_memory_reserved_bytes"": 6958350336}, ""compute_utilisation"": {""gpu_utilization_percent"": [100.0, 0.0, 0.0, 0.0], ""cpu_usage_percent"": 98.2, ""cpu_memory_usage_bytes"": 6565412864}}","{""experiment_id"": ""0144"", ""local_process_results"": {""cpu_power"": {""0"": 112.5}, ""gpu_power"": {""0"": 0.0}, ""ram_power"": {""0"": 2.2929439544677734}, ""cpu_energy"": {""0"": 0.0012936895400926008}, ""gpu_energy"": {""0"": 0.002859955065744657}, ""ram_energy"": {""0"": 2.215216263405973e-05}, ""total_energy_kwh"": {""0"": 0.004175796768471318}, ""total_energy_joules"": {""0"": 15032.868366496743}}, ""global_experiment_results"": {""cpu_power_avg"": 112.5, ""gpu_power_avg"": 0.0, ""ram_power_avg"": 2.2929439544677734, ""cpu_energy_total"": 0.0012936895400926008, ""gpu_energy_total"": 0.002859955065744657, ""ram_energy_total"": 2.215216263405973e-05, ""total_energy_kwh"": 0.004175796768471318, ""total_energy_joules"": 15032.868366496743}, ""global_derived_quantities"": {""tokens_per_joule"": 0.665209044355545, ""joules_per_token"": 1.5032868366496743, ""flops_per_joule"": 0.0, ""joules_per_flop"": 0}, ""per-process_emissions"": [0.0015907697789491486]}","{""process_id"": 3228537, ""local_process_index"": 0, ""energy_results"": {""cpu_power"": 112.5, ""gpu_power"": 0.0, ""ram_power"": 2.2929439544677734, ""cpu_energy"": 0.0012936895400926008, ""gpu_energy"": 0.002859955065744657, ""ram_energy"": 2.215216263405973e-05, ""total_energy_kwh"": 0.004175796768471318, ""total_energy_joules"": 15032.868366496743, ""final_emissions"": 0.0015907697789491486}}","""NA""","""NA""","""NA"""
0145,CONFIGURATION_RUN_#0145,"{""experiment_id"": ""0145"", ""date_time"": ""April 05, 2025 at 07:39:53 PM"", ""model"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""available_gpu_count"": 1, ""gpu_model"": ""4 x NVIDIA A100-PCIE-40GB"", ""available_cpu_count"": 128, ""cpu_model"": ""AMD EPYC 7742 64-Core Processor"", ""os"": ""Linux-5.15.0-113-generic-x86_64-with-glibc2.31"", ""python_version"": ""3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]"", ""country"": ""Germany"", ""region"": ""saxony""}","{""config_name"": ""r2_low_latency_chatbot"", ""max_input_tokens"": 100, ""max_output_tokens"": 100, ""number_input_prompts"": 100, ""decode_token_to_text"": true, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 50, ""decoder_top_p"": 0.95}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.01, ""delay_max"": 0.05, ""simulate_burst"": false}, ""fp_precision"": ""torch.float32"", ""quantisation"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": null}, ""batching_options"": {""batch_size___fixed_batching"": 4}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""accelerate_config"": {""distributed_type"": ""DistributedType.NO"", ""num_processes"": 1}, ""inference_type"": ""pure_generative"", ""backend"": ""pytorch""}","{""total_params"": 1100048384, ""num_hidden_layers"": 22, ""hidden_size"": 2048, ""num_attention_heads"": 32, ""intermediate_size"": 5632}","{""raw_inference_metrics"": {""number_input_prompts"": 100, ""total_input_tokens"": 10000, ""total_generated_tokens"": 10000}, ""inference_performance"": {""total_inference_time_sec"": 84.07263463153504, ""average_latency_ms_per_batch"": 3362.9053852614015, ""throughput_queries_per_sec"": 1.1894476774549745, ""throughput_tokens_per_sec"": 118.94476774549744}}","{""flops"": 0.0, ""memory"": {""gpu_current_memory_allocated_bytes"": 8809593856, ""gpu_max_memory_allocated_bytes"": 8809593856, ""gpu_current_memory_reserved_bytes"": 8933867520, ""gpu_max_memory_reserved_bytes"": 8933867520}, ""compute_utilisation"": {""gpu_utilization_percent"": [100.0, 0.0, 0.0, 0.0], ""cpu_usage_percent"": 96.4, ""cpu_memory_usage_bytes"": 6467862528}}","{""experiment_id"": ""0145"", ""local_process_results"": {""cpu_power"": {""0"": 112.5}, ""gpu_power"": {""0"": 141.02973451661316}, ""ram_power"": {""0"": 2.2588748931884766}, ""cpu_energy"": {""0"": 0.0026632633095869085}, ""gpu_energy"": {""0"": 0.005218803341705325}, ""ram_energy"": {""0"": 4.352074186260849e-05}, ""total_energy_kwh"": {""0"": 0.00792558739315484}, ""total_energy_joules"": {""0"": 28532.114615357423}}, ""global_experiment_results"": {""cpu_power_avg"": 112.5, ""gpu_power_avg"": 141.02973451661316, ""ram_power_avg"": 2.2588748931884766, ""cpu_energy_total"": 0.0026632633095869085, ""gpu_energy_total"": 0.005218803341705325, ""ram_energy_total"": 4.352074186260849e-05, ""total_energy_kwh"": 0.00792558739315484, ""total_energy_joules"": 28532.114615357423}, ""global_derived_quantities"": {""tokens_per_joule"": 0.35048225954544204, ""joules_per_token"": 2.853211461535742, ""flops_per_joule"": 0.0, ""joules_per_flop"": 0}, ""per-process_emissions"": [0.0030192525174223364]}","{""process_id"": 3228537, ""local_process_index"": 0, ""energy_results"": {""cpu_power"": 112.5, ""gpu_power"": 141.02973451661316, ""ram_power"": 2.2588748931884766, ""cpu_energy"": 0.0026632633095869085, ""gpu_energy"": 0.005218803341705325, ""ram_energy"": 4.352074186260849e-05, ""total_energy_kwh"": 0.00792558739315484, ""total_energy_joules"": 28532.114615357423, ""final_emissions"": 0.0030192525174223364}}","""NA""","""NA""","""NA"""
0146,CONFIGURATION_RUN_#0146,"{""experiment_id"": ""0146"", ""date_time"": ""April 05, 2025 at 07:42:40 PM"", ""model"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""available_gpu_count"": 2, ""gpu_model"": ""4 x NVIDIA A100-PCIE-40GB"", ""available_cpu_count"": 128, ""cpu_model"": ""AMD EPYC 7742 64-Core Processor"", ""os"": ""Linux-5.15.0-113-generic-x86_64-with-glibc2.31"", ""python_version"": ""3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]"", ""country"": ""Germany"", ""region"": ""saxony""}","{""config_name"": ""r3_balanced_enterprise_service"", ""max_input_tokens"": 100, ""max_output_tokens"": 100, ""number_input_prompts"": 100, ""decode_token_to_text"": true, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 50, ""decoder_top_p"": 0.95}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""fp_precision"": ""torch.float16"", ""quantisation"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 10345441280000}, ""batching_options"": {""batch_size___fixed_batching"": 32}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""accelerate_config"": {""distributed_type"": ""DistributedType.NO"", ""num_processes"": 1}, ""inference_type"": ""pure_generative"", ""backend"": ""pytorch""}","{""total_params"": 1100048384, ""num_hidden_layers"": 22, ""hidden_size"": 2048, ""num_attention_heads"": 32, ""intermediate_size"": 5632}","{""raw_inference_metrics"": {""number_input_prompts"": 100, ""total_input_tokens"": 10000, ""total_generated_tokens"": 10000}, ""inference_performance"": {""total_inference_time_sec"": 156.23335747700185, ""average_latency_ms_per_batch"": 39058.33936925046, ""throughput_queries_per_sec"": 0.6400681750356699, ""throughput_tokens_per_sec"": 64.00681750356699}}","{""flops"": 10345441280000, ""memory"": {""gpu_current_memory_allocated_bytes"": 1313738752, ""gpu_max_memory_allocated_bytes"": 1313738752, ""gpu_current_memory_reserved_bytes"": 5773459456, ""gpu_max_memory_reserved_bytes"": 5773459456}, ""compute_utilisation"": {""gpu_utilization_percent"": [100.0, 0.0, 0.0, 0.0], ""cpu_usage_percent"": 98.6, ""cpu_memory_usage_bytes"": 6423539712}}","{""experiment_id"": ""0146"", ""local_process_results"": {""cpu_power"": {""0"": 112.5}, ""gpu_power"": {""0"": 276.6724691841634}, ""ram_power"": {""0"": 2.2433953285217285}, ""cpu_energy"": {""0"": 0.004808907552236634}, ""gpu_energy"": {""0"": 0.010457728088404394}, ""ram_energy"": {""0"": 8.244150368786646e-05}, ""total_energy_kwh"": {""0"": 0.015349077144328881}, ""total_energy_joules"": {""0"": 55256.677719583975}}, ""global_experiment_results"": {""cpu_power_avg"": 112.5, ""gpu_power_avg"": 276.6724691841634, ""ram_power_avg"": 2.2433953285217285, ""cpu_energy_total"": 0.004808907552236634, ""gpu_energy_total"": 0.010457728088404394, ""ram_energy_total"": 8.244150368786646e-05, ""total_energy_kwh"": 0.015349077144328881, ""total_energy_joules"": 55256.677719583975}, ""global_derived_quantities"": {""tokens_per_joule"": 0.1809736019734646, ""joules_per_token"": 5.525667771958398, ""flops_per_joule"": 187225177.244657, ""joules_per_flop"": 5.341161988556951e-09}, ""per-process_emissions"": [0.005847230938132088]}","{""process_id"": 3228537, ""local_process_index"": 0, ""energy_results"": {""cpu_power"": 112.5, ""gpu_power"": 276.6724691841634, ""ram_power"": 2.2433953285217285, ""cpu_energy"": 0.004808907552236634, ""gpu_energy"": 0.010457728088404394, ""ram_energy"": 8.244150368786646e-05, ""total_energy_kwh"": 0.015349077144328881, ""total_energy_joules"": 55256.677719583975, ""final_emissions"": 0.005847230938132088}}","""NA""","""NA""","""NA"""
0147,CONFIGURATION_RUN_#0147,"{""experiment_id"": ""0147"", ""date_time"": ""April 05, 2025 at 07:43:43 PM"", ""model"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""available_gpu_count"": 1, ""gpu_model"": ""4 x NVIDIA A100-PCIE-40GB"", ""available_cpu_count"": 128, ""cpu_model"": ""AMD EPYC 7742 64-Core Processor"", ""os"": ""Linux-5.15.0-113-generic-x86_64-with-glibc2.31"", ""python_version"": ""3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]"", ""country"": ""Germany"", ""region"": ""saxony""}","{""config_name"": ""r4_high_load_api"", ""max_input_tokens"": 100, ""max_output_tokens"": 100, ""number_input_prompts"": 100, ""decode_token_to_text"": true, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 50, ""decoder_top_p"": 0.95}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.05, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 2.0, ""burst_size"": 5}, ""fp_precision"": ""torch.float32"", ""quantisation"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": null}, ""batching_options"": {""batch_size___fixed_batching"": 8}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""accelerate_config"": {""distributed_type"": ""DistributedType.NO"", ""num_processes"": 1}, ""inference_type"": ""pure_generative"", ""backend"": ""pytorch""}","{""total_params"": 1100048384, ""num_hidden_layers"": 22, ""hidden_size"": 2048, ""num_attention_heads"": 32, ""intermediate_size"": 5632}","{""raw_inference_metrics"": {""number_input_prompts"": 100, ""total_input_tokens"": 10000, ""total_generated_tokens"": 10000}, ""inference_performance"": {""total_inference_time_sec"": 51.92303602397442, ""average_latency_ms_per_batch"": 3994.0796941518784, ""throughput_queries_per_sec"": 1.925927442952816, ""throughput_tokens_per_sec"": 192.5927442952816}}","{""flops"": 0.0, ""memory"": {""gpu_current_memory_allocated_bytes"": 5714192384, ""gpu_max_memory_allocated_bytes"": 5714192384, ""gpu_current_memory_reserved_bytes"": 5892997120, ""gpu_max_memory_reserved_bytes"": 5892997120}, ""compute_utilisation"": {""gpu_utilization_percent"": [100.0, 0.0, 0.0, 0.0], ""cpu_usage_percent"": 97.4, ""cpu_memory_usage_bytes"": 6605332480}}","{""experiment_id"": ""0147"", ""local_process_results"": {""cpu_power"": {""0"": 112.5}, ""gpu_power"": {""0"": 0.0}, ""ram_power"": {""0"": 2.3068857192993164}, ""cpu_energy"": {""0"": 0.0016957925945025635}, ""gpu_energy"": {""0"": 0.003288175686094519}, ""ram_energy"": {""0"": 2.858740714752347e-05}, ""total_energy_kwh"": {""0"": 0.0050125556877446045}, ""total_energy_joules"": {""0"": 18045.200475880574}}, ""global_experiment_results"": {""cpu_power_avg"": 112.5, ""gpu_power_avg"": 0.0, ""ram_power_avg"": 2.3068857192993164, ""cpu_energy_total"": 0.0016957925945025635, ""gpu_energy_total"": 0.003288175686094519, ""ram_energy_total"": 2.858740714752347e-05, ""total_energy_kwh"": 0.0050125556877446045, ""total_energy_joules"": 18045.200475880574}, ""global_derived_quantities"": {""tokens_per_joule"": 0.5541639735932065, ""joules_per_token"": 1.8045200475880576, ""flops_per_joule"": 0.0, ""joules_per_flop"": 0}, ""per-process_emissions"": [0.0019095330892463071]}","{""process_id"": 3228537, ""local_process_index"": 0, ""energy_results"": {""cpu_power"": 112.5, ""gpu_power"": 0.0, ""ram_power"": 2.3068857192993164, ""cpu_energy"": 0.0016957925945025635, ""gpu_energy"": 0.003288175686094519, ""ram_energy"": 2.858740714752347e-05, ""total_energy_kwh"": 0.0050125556877446045, ""total_energy_joules"": 18045.200475880574, ""final_emissions"": 0.0019095330892463071}}","""NA""","""NA""","""NA"""

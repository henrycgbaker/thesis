{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will later move this into function script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def create_column_mapping(desired_order, actual_columns):\n",
    "    \"\"\"\n",
    "    Creates a mapping between desired logical column names and actual CSV columns.\n",
    "    Tries to match based on substring containment or exact match.\n",
    "    \"\"\"\n",
    "    column_map = {}\n",
    "    \n",
    "    for desired in desired_order:\n",
    "        matches = [col for col in actual_columns if desired.lower() in col.lower()]\n",
    "        \n",
    "        if len(matches) == 1:\n",
    "            column_map[desired] = matches[0]\n",
    "        elif len(matches) > 1:\n",
    "            # If multiple matches, prefer exact match if it exists\n",
    "            exact_matches = [col for col in matches if col.lower() == desired.lower()]\n",
    "            if exact_matches:\n",
    "                column_map[desired] = exact_matches[0]\n",
    "            else:\n",
    "                # Otherwise pick first match (or could ask user)\n",
    "                column_map[desired] = matches[0]\n",
    "        else:\n",
    "            column_map[desired] = None  # No match found\n",
    "    \n",
    "    return column_map\n",
    "\n",
    "\n",
    "desired_order = [\n",
    "    # From \"setup\"\n",
    "    \"experiment_id\",\n",
    "    \"date_time\",\n",
    "    \"model\",\n",
    "    \"is_encoder_decoder\",\n",
    "    \"task_type\",\n",
    "    \"available_gpu_count\",\n",
    "    \"gpu_model\",\n",
    "    \"available_cpu_count\",\n",
    "    \"cpu_model\",\n",
    "    \"os\",\n",
    "    \"python_version\",\n",
    "    \"country\",\n",
    "    \"region\",\n",
    "    \n",
    "    # From \"variables\"\n",
    "    \"config_name\",\n",
    "    \"max_input_tokens\",\n",
    "    \"max_output_tokens\",\n",
    "    \"number_input_prompts\",\n",
    "    \"decode_token_to_text\",\n",
    "    \"decoder_temperature\",\n",
    "    \"decoder_top_k\",\n",
    "    \"decoder_top_p\",\n",
    "    \"query_rate\",\n",
    "    \"simulate_latency\",\n",
    "    \"latency_delay_min\",\n",
    "    \"latency_delay_max\",\n",
    "    \"simulate_burst\",\n",
    "    \"burst_interval\",\n",
    "    \"burst_size\",\n",
    "    \"fp_precision\",\n",
    "    \"quantization\",\n",
    "    \"load_in_8bit\",\n",
    "    \"load_in_4bit\",\n",
    "    \"cached_flops_for_quantised_models\",\n",
    "    \"batch_size___fixed_batching\",\n",
    "    \"adaptive_batching\",\n",
    "    \"adaptive_max_tokens\",\n",
    "    \"max_batch_size___adaptive_batching\",\n",
    "    \"use_orig_params\",\n",
    "    \"cpu_offload\",\n",
    "    \"sharding_strategy\",\n",
    "    \"distributed_type\",\n",
    "    \"num_processes\",\n",
    "    \"inference_type\",\n",
    "    \"backend\",\n",
    "    \n",
    "    # From \"model_architecture\"\n",
    "    \"total_params\",\n",
    "    \"architecture\",\n",
    "    \n",
    "    # From \"results\" - \"inference_metrics\" - \"raw_inference_metrics\"\n",
    "    \"total_input_tokens\",\n",
    "    \"total_generated_tokens\",\n",
    "    \n",
    "    # From \"results\" - \"inference_metrics\" - \"inference_performance\"\n",
    "    \"total_inference_time_sec\",\n",
    "    \"average_latency_ms_per_batch\",\n",
    "    \"throughput_queries_per_sec\",\n",
    "    \"throughput_tokens_per_sec\",\n",
    "    \n",
    "    # From \"results\" - \"compute_metrics\"\n",
    "    \"flops\",\n",
    "    \n",
    "    # From \"results\" - \"compute_metrics\" - \"memory\"\n",
    "    \"gpu_current_memory_allocated_bytes\",\n",
    "    \"gpu_max_memory_allocated_bytes\",\n",
    "    \"gpu_current_memory_reserved_bytes\",\n",
    "    \"gpu_max_memory_reserved_bytes\",\n",
    "    \n",
    "    # From \"results\" - \"compute_metrics\" - \"compute_utilisation\"\n",
    "    \"gpu_utilization_percent_0\",\n",
    "    \"gpu_utilization_percent_1\",\n",
    "    \"gpu_utilization_percent_2\",\n",
    "    \"gpu_utilization_percent_3\",\n",
    "    \"cpu_usage_percent\",\n",
    "    \"cpu_memory_usage_bytes\",\n",
    "    \n",
    "    # From \"results\" - \"global_energy_metrics\" - \"global_experiment_results\"\n",
    "    \"cpu_power_avg\",\n",
    "    \"gpu_power_avg\",\n",
    "    \"ram_power_avg\",\n",
    "    \"cpu_energy_total\",\n",
    "    \"gpu_energy_total\",\n",
    "    \"ram_energy_total\",\n",
    "    \"total_energy_kwh\",\n",
    "    \"total_energy_joules\",\n",
    "    \n",
    "    # From \"results\" - \"global_energy_metrics\" - \"global_derived_quantities\"\n",
    "    \"tokens_per_joule\",\n",
    "    \"joules_per_token\",\n",
    "    \"flops_per_joule\",\n",
    "    \"joules_per_flop\",\n",
    "    \n",
    "    # From \"results\" - \"global_energy_metrics\" - \"per-process_emissions\"\n",
    "    \"per_process_emissions_0\",\n",
    "    \"per_process_emissions_1\",\n",
    "    \"per_process_emissions_2\",\n",
    "    \"per_process_emissions_3\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment_id --> setup_experiment_id\n",
      "date_time --> setup_date_time\n",
      "model --> setup_model\n",
      "is_encoder_decoder --> setup_is_encoder_decoder\n",
      "task_type --> setup_task_type\n",
      "available_gpu_count --> setup_available_gpu_count\n",
      "gpu_model --> setup_gpu_model\n",
      "available_cpu_count --> setup_available_cpu_count\n",
      "cpu_model --> setup_cpu_model\n",
      "os --> setup_os\n",
      "python_version --> setup_python_version\n",
      "country --> setup_country\n",
      "region --> setup_region\n",
      "config_name --> variables_config_name\n",
      "max_input_tokens --> variables_max_input_tokens\n",
      "max_output_tokens --> variables_max_output_tokens\n",
      "number_input_prompts --> inference_metrics_raw_inference_metrics_number_input_prompts\n",
      "decode_token_to_text --> variables_decode_token_to_text\n",
      "decoder_temperature --> variables_decoder_config_decoder_temperature\n",
      "decoder_top_k --> variables_decoder_config_decoder_top_k\n",
      "decoder_top_p --> variables_decoder_config_decoder_top_p\n",
      "query_rate --> variables_query_rate\n",
      "simulate_latency --> None\n",
      "latency_delay_min --> None\n",
      "latency_delay_max --> None\n",
      "simulate_burst --> variables_latency_simulation_simulate_burst\n",
      "burst_interval --> variables_latency_simulation_burst_interval\n",
      "burst_size --> variables_latency_simulation_burst_size\n",
      "fp_precision --> variables_fp_precision\n",
      "quantization --> variables_quantisation_quantization\n",
      "load_in_8bit --> variables_quantisation_load_in_8bit\n",
      "load_in_4bit --> variables_quantisation_load_in_4bit\n",
      "cached_flops_for_quantised_models --> variables_quantisation_cached_flops_for_quantised_models\n",
      "batch_size___fixed_batching --> variables_batching_options_batch_size___fixed_batching\n",
      "adaptive_batching --> variables_batching_options_max_batch_size___adaptive_batching\n",
      "adaptive_max_tokens --> variables_batching_options_adaptive_max_tokens\n",
      "max_batch_size___adaptive_batching --> variables_batching_options_max_batch_size___adaptive_batching\n",
      "use_orig_params --> variables_sharding_config_fsdp_config_use_orig_params\n",
      "cpu_offload --> variables_sharding_config_fsdp_config_cpu_offload\n",
      "sharding_strategy --> variables_sharding_config_sharding_strategy\n",
      "distributed_type --> variables_accelerate_config_distributed_type\n",
      "num_processes --> variables_accelerate_config_num_processes\n",
      "inference_type --> variables_inference_type\n",
      "backend --> variables_backend\n",
      "total_params --> model_architecture_total_params\n",
      "architecture --> model_architecture_total_params\n",
      "total_input_tokens --> inference_metrics_raw_inference_metrics_total_input_tokens\n",
      "total_generated_tokens --> inference_metrics_raw_inference_metrics_total_generated_tokens\n",
      "total_inference_time_sec --> inference_metrics_inference_performance_total_inference_time_sec\n",
      "average_latency_ms_per_batch --> inference_metrics_inference_performance_average_latency_ms_per_batch\n",
      "throughput_queries_per_sec --> inference_metrics_inference_performance_throughput_queries_per_sec\n",
      "throughput_tokens_per_sec --> inference_metrics_inference_performance_throughput_tokens_per_sec\n",
      "flops --> compute_metrics_flops\n",
      "gpu_current_memory_allocated_bytes --> compute_metrics_memory_gpu_current_memory_allocated_bytes\n",
      "gpu_max_memory_allocated_bytes --> compute_metrics_memory_gpu_max_memory_allocated_bytes\n",
      "gpu_current_memory_reserved_bytes --> compute_metrics_memory_gpu_current_memory_reserved_bytes\n",
      "gpu_max_memory_reserved_bytes --> compute_metrics_memory_gpu_max_memory_reserved_bytes\n",
      "gpu_utilization_percent_0 --> compute_metrics_compute_utilisation_gpu_utilization_percent_0\n",
      "gpu_utilization_percent_1 --> compute_metrics_compute_utilisation_gpu_utilization_percent_1\n",
      "gpu_utilization_percent_2 --> compute_metrics_compute_utilisation_gpu_utilization_percent_2\n",
      "gpu_utilization_percent_3 --> compute_metrics_compute_utilisation_gpu_utilization_percent_3\n",
      "cpu_usage_percent --> compute_metrics_compute_utilisation_cpu_usage_percent\n",
      "cpu_memory_usage_bytes --> compute_metrics_compute_utilisation_cpu_memory_usage_bytes\n",
      "cpu_power_avg --> global_energy_metrics_global_experiment_results_cpu_power_avg\n",
      "gpu_power_avg --> global_energy_metrics_global_experiment_results_gpu_power_avg\n",
      "ram_power_avg --> global_energy_metrics_global_experiment_results_ram_power_avg\n",
      "cpu_energy_total --> global_energy_metrics_global_experiment_results_cpu_energy_total\n",
      "gpu_energy_total --> global_energy_metrics_global_experiment_results_gpu_energy_total\n",
      "ram_energy_total --> global_energy_metrics_global_experiment_results_ram_energy_total\n",
      "total_energy_kwh --> global_energy_metrics_local_process_results_total_energy_kwh_process_0\n",
      "total_energy_joules --> global_energy_metrics_global_experiment_results_total_energy_joules\n",
      "tokens_per_joule --> global_energy_metrics_global_derived_quantities_tokens_per_joule\n",
      "joules_per_token --> global_energy_metrics_global_derived_quantities_joules_per_token\n",
      "flops_per_joule --> global_energy_metrics_global_derived_quantities_flops_per_joule\n",
      "joules_per_flop --> global_energy_metrics_global_derived_quantities_joules_per_flop\n",
      "per_process_emissions_0 --> None\n",
      "per_process_emissions_1 --> None\n",
      "per_process_emissions_2 --> None\n",
      "per_process_emissions_3 --> None\n"
     ]
    }
   ],
   "source": [
    "# Load your DataFrame\n",
    "df = pd.read_csv(\"results/text_generation_results.csv\")\n",
    "\n",
    "# Create the mapping\n",
    "column_map = create_column_mapping(desired_order, df.columns)\n",
    "\n",
    "# Print mapping nicely\n",
    "for logical_name, actual_name in column_map.items():\n",
    "    print(f\"{logical_name} --> {actual_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>model</th>\n",
       "      <th>is_encoder_decoder</th>\n",
       "      <th>task_type</th>\n",
       "      <th>available_gpu_count</th>\n",
       "      <th>gpu_model</th>\n",
       "      <th>available_cpu_count</th>\n",
       "      <th>cpu_model</th>\n",
       "      <th>os</th>\n",
       "      <th>...</th>\n",
       "      <th>ram_power_avg</th>\n",
       "      <th>cpu_energy_total</th>\n",
       "      <th>gpu_energy_total</th>\n",
       "      <th>ram_energy_total</th>\n",
       "      <th>total_energy_kwh</th>\n",
       "      <th>total_energy_joules</th>\n",
       "      <th>tokens_per_joule</th>\n",
       "      <th>joules_per_token</th>\n",
       "      <th>flops_per_joule</th>\n",
       "      <th>joules_per_flop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>April 06, 2025 at 10:59:58 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696441</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>5102.086685</td>\n",
       "      <td>0.097999</td>\n",
       "      <td>10.204173</td>\n",
       "      <td>1.013844e+08</td>\n",
       "      <td>9.863449e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>April 06, 2025 at 11:00:36 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699668</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000357</td>\n",
       "      <td>5407.209328</td>\n",
       "      <td>0.092469</td>\n",
       "      <td>10.814419</td>\n",
       "      <td>9.566341e+07</td>\n",
       "      <td>1.045332e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>April 06, 2025 at 11:01:16 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702201</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>5583.389461</td>\n",
       "      <td>0.089551</td>\n",
       "      <td>11.166779</td>\n",
       "      <td>9.264481e+07</td>\n",
       "      <td>1.079391e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>April 06, 2025 at 11:02:15 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682693</td>\n",
       "      <td>0.002785</td>\n",
       "      <td>0.010686</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.003387</td>\n",
       "      <td>48545.677786</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>97.091356</td>\n",
       "      <td>1.065537e+07</td>\n",
       "      <td>9.384941e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>April 06, 2025 at 11:02:55 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701552</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.001447</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>6303.964264</td>\n",
       "      <td>0.079315</td>\n",
       "      <td>12.607929</td>\n",
       "      <td>8.205504e+07</td>\n",
       "      <td>1.218694e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9</td>\n",
       "      <td>April 06, 2025 at 11:03:33 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697485</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.001171</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>5145.915184</td>\n",
       "      <td>0.097164</td>\n",
       "      <td>10.291830</td>\n",
       "      <td>1.005209e+08</td>\n",
       "      <td>9.948179e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>April 06, 2025 at 11:04:12 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700556</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>4994.111035</td>\n",
       "      <td>0.100118</td>\n",
       "      <td>9.988222</td>\n",
       "      <td>1.035764e+08</td>\n",
       "      <td>9.654709e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11</td>\n",
       "      <td>April 06, 2025 at 11:04:52 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699086</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>5011.062364</td>\n",
       "      <td>0.099779</td>\n",
       "      <td>10.022125</td>\n",
       "      <td>1.032260e+08</td>\n",
       "      <td>9.687479e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>April 06, 2025 at 11:05:31 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.949414</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>4146.470730</td>\n",
       "      <td>0.120584</td>\n",
       "      <td>8.292941</td>\n",
       "      <td>1.247500e+08</td>\n",
       "      <td>8.016035e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16</td>\n",
       "      <td>April 06, 2025 at 11:07:07 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702280</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>5089.767787</td>\n",
       "      <td>0.098236</td>\n",
       "      <td>10.179536</td>\n",
       "      <td>1.016298e+08</td>\n",
       "      <td>9.839634e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>17</td>\n",
       "      <td>April 06, 2025 at 11:07:45 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703517</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>5090.163238</td>\n",
       "      <td>0.098229</td>\n",
       "      <td>10.180326</td>\n",
       "      <td>1.016219e+08</td>\n",
       "      <td>9.840398e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18</td>\n",
       "      <td>April 06, 2025 at 11:08:25 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697269</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>5029.316835</td>\n",
       "      <td>0.099417</td>\n",
       "      <td>10.058634</td>\n",
       "      <td>1.028514e+08</td>\n",
       "      <td>9.722769e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19</td>\n",
       "      <td>April 06, 2025 at 11:09:13 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688788</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.006475</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>28450.529987</td>\n",
       "      <td>0.017574</td>\n",
       "      <td>56.901060</td>\n",
       "      <td>1.818146e+07</td>\n",
       "      <td>5.500110e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>April 06, 2025 at 11:09:55 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696975</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>12502.268522</td>\n",
       "      <td>0.039993</td>\n",
       "      <td>25.004537</td>\n",
       "      <td>4.137426e+07</td>\n",
       "      <td>2.416962e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>21</td>\n",
       "      <td>April 06, 2025 at 11:10:35 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696452</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>9143.679525</td>\n",
       "      <td>0.054683</td>\n",
       "      <td>18.287359</td>\n",
       "      <td>5.657154e+07</td>\n",
       "      <td>1.767673e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22</td>\n",
       "      <td>April 06, 2025 at 11:11:15 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.702542</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.001317</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>5897.676687</td>\n",
       "      <td>0.084779</td>\n",
       "      <td>11.795353</td>\n",
       "      <td>8.770777e+07</td>\n",
       "      <td>1.140150e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>23</td>\n",
       "      <td>April 06, 2025 at 11:11:55 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700258</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>0.001446</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>6253.579628</td>\n",
       "      <td>0.079954</td>\n",
       "      <td>12.507159</td>\n",
       "      <td>8.271616e+07</td>\n",
       "      <td>1.208954e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>24</td>\n",
       "      <td>April 06, 2025 at 11:12:35 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.700001</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>5219.134529</td>\n",
       "      <td>0.095801</td>\n",
       "      <td>10.438269</td>\n",
       "      <td>9.911070e+07</td>\n",
       "      <td>1.008973e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>25</td>\n",
       "      <td>April 06, 2025 at 11:13:15 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697353</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>5216.701888</td>\n",
       "      <td>0.095846</td>\n",
       "      <td>10.433404</td>\n",
       "      <td>9.915691e+07</td>\n",
       "      <td>1.008503e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>26</td>\n",
       "      <td>April 06, 2025 at 11:13:55 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701431</td>\n",
       "      <td>0.000310</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>5673.983335</td>\n",
       "      <td>0.088122</td>\n",
       "      <td>11.347967</td>\n",
       "      <td>9.116559e+07</td>\n",
       "      <td>1.096905e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>27</td>\n",
       "      <td>April 06, 2025 at 11:14:32 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699233</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>4699.183521</td>\n",
       "      <td>0.106401</td>\n",
       "      <td>9.398367</td>\n",
       "      <td>1.100770e+08</td>\n",
       "      <td>9.084549e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>28</td>\n",
       "      <td>April 06, 2025 at 11:15:09 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.965965</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>3832.205347</td>\n",
       "      <td>0.130473</td>\n",
       "      <td>7.664411</td>\n",
       "      <td>1.349803e+08</td>\n",
       "      <td>7.408491e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>29</td>\n",
       "      <td>April 06, 2025 at 11:15:48 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698765</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>5197.332598</td>\n",
       "      <td>0.096203</td>\n",
       "      <td>10.394665</td>\n",
       "      <td>9.952645e+07</td>\n",
       "      <td>1.004758e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>30</td>\n",
       "      <td>April 06, 2025 at 11:16:29 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697740</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000355</td>\n",
       "      <td>5417.247647</td>\n",
       "      <td>0.092298</td>\n",
       "      <td>10.834495</td>\n",
       "      <td>9.548614e+07</td>\n",
       "      <td>1.047272e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>31</td>\n",
       "      <td>April 06, 2025 at 11:17:28 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.682946</td>\n",
       "      <td>0.002737</td>\n",
       "      <td>0.010584</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>48002.605723</td>\n",
       "      <td>0.010416</td>\n",
       "      <td>96.005211</td>\n",
       "      <td>1.077592e+07</td>\n",
       "      <td>9.279953e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>35</td>\n",
       "      <td>April 06, 2025 at 11:19:11 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701948</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>5073.650277</td>\n",
       "      <td>0.098548</td>\n",
       "      <td>10.147301</td>\n",
       "      <td>1.019526e+08</td>\n",
       "      <td>9.808475e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>36</td>\n",
       "      <td>April 06, 2025 at 11:19:51 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697837</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>5043.961526</td>\n",
       "      <td>0.099128</td>\n",
       "      <td>10.087923</td>\n",
       "      <td>1.025527e+08</td>\n",
       "      <td>9.751080e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>37</td>\n",
       "      <td>April 06, 2025 at 11:20:31 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697765</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000640</td>\n",
       "      <td>9036.042300</td>\n",
       "      <td>0.055334</td>\n",
       "      <td>18.072085</td>\n",
       "      <td>5.724542e+07</td>\n",
       "      <td>1.746865e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>41</td>\n",
       "      <td>April 06, 2025 at 11:22:13 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696810</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>5061.086703</td>\n",
       "      <td>0.098793</td>\n",
       "      <td>10.122173</td>\n",
       "      <td>1.022057e+08</td>\n",
       "      <td>9.784187e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>42</td>\n",
       "      <td>April 06, 2025 at 11:22:54 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.696916</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>10829.451815</td>\n",
       "      <td>0.046170</td>\n",
       "      <td>21.658904</td>\n",
       "      <td>4.776530e+07</td>\n",
       "      <td>2.093570e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>43</td>\n",
       "      <td>April 06, 2025 at 11:23:31 PM</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>4</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>128</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.695093</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>5005.142065</td>\n",
       "      <td>0.099897</td>\n",
       "      <td>10.010284</td>\n",
       "      <td>1.033481e+08</td>\n",
       "      <td>9.676034e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31 rows Ã— 72 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    experiment_id                      date_time  \\\n",
       "0               4  April 06, 2025 at 10:59:58 PM   \n",
       "1               5  April 06, 2025 at 11:00:36 PM   \n",
       "2               6  April 06, 2025 at 11:01:16 PM   \n",
       "3               7  April 06, 2025 at 11:02:15 PM   \n",
       "4               8  April 06, 2025 at 11:02:55 PM   \n",
       "5               9  April 06, 2025 at 11:03:33 PM   \n",
       "6              10  April 06, 2025 at 11:04:12 PM   \n",
       "7              11  April 06, 2025 at 11:04:52 PM   \n",
       "8              12  April 06, 2025 at 11:05:31 PM   \n",
       "9              16  April 06, 2025 at 11:07:07 PM   \n",
       "10             17  April 06, 2025 at 11:07:45 PM   \n",
       "11             18  April 06, 2025 at 11:08:25 PM   \n",
       "12             19  April 06, 2025 at 11:09:13 PM   \n",
       "13             20  April 06, 2025 at 11:09:55 PM   \n",
       "14             21  April 06, 2025 at 11:10:35 PM   \n",
       "15             22  April 06, 2025 at 11:11:15 PM   \n",
       "16             23  April 06, 2025 at 11:11:55 PM   \n",
       "17             24  April 06, 2025 at 11:12:35 PM   \n",
       "18             25  April 06, 2025 at 11:13:15 PM   \n",
       "19             26  April 06, 2025 at 11:13:55 PM   \n",
       "20             27  April 06, 2025 at 11:14:32 PM   \n",
       "21             28  April 06, 2025 at 11:15:09 PM   \n",
       "22             29  April 06, 2025 at 11:15:48 PM   \n",
       "23             30  April 06, 2025 at 11:16:29 PM   \n",
       "24             31  April 06, 2025 at 11:17:28 PM   \n",
       "25             35  April 06, 2025 at 11:19:11 PM   \n",
       "26             36  April 06, 2025 at 11:19:51 PM   \n",
       "27             37  April 06, 2025 at 11:20:31 PM   \n",
       "28             41  April 06, 2025 at 11:22:13 PM   \n",
       "29             42  April 06, 2025 at 11:22:54 PM   \n",
       "30             43  April 06, 2025 at 11:23:31 PM   \n",
       "\n",
       "                                 model  is_encoder_decoder        task_type  \\\n",
       "0   TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "1   TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "2   TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "3   TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "4   TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "5   TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "6   TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "7   TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "8   TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "9   TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "10  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "11  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "12  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "13  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "14  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "15  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "16  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "17  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "18  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "19  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "20  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "21  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "22  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "23  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "24  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "25  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "26  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "27  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "28  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "29  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "30  TinyLlama/TinyLlama-1.1B-Chat-v1.0               False  text_generation   \n",
       "\n",
       "    available_gpu_count                  gpu_model  available_cpu_count  \\\n",
       "0                     4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "1                     4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "2                     4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "3                     4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "4                     4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "5                     4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "6                     4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "7                     4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "8                     4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "9                     4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "10                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "11                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "12                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "13                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "14                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "15                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "16                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "17                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "18                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "19                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "20                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "21                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "22                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "23                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "24                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "25                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "26                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "27                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "28                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "29                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "30                    4  4 x NVIDIA A100-PCIE-40GB                  128   \n",
       "\n",
       "                          cpu_model  \\\n",
       "0   AMD EPYC 7742 64-Core Processor   \n",
       "1   AMD EPYC 7742 64-Core Processor   \n",
       "2   AMD EPYC 7742 64-Core Processor   \n",
       "3   AMD EPYC 7742 64-Core Processor   \n",
       "4   AMD EPYC 7742 64-Core Processor   \n",
       "5   AMD EPYC 7742 64-Core Processor   \n",
       "6   AMD EPYC 7742 64-Core Processor   \n",
       "7   AMD EPYC 7742 64-Core Processor   \n",
       "8   AMD EPYC 7742 64-Core Processor   \n",
       "9   AMD EPYC 7742 64-Core Processor   \n",
       "10  AMD EPYC 7742 64-Core Processor   \n",
       "11  AMD EPYC 7742 64-Core Processor   \n",
       "12  AMD EPYC 7742 64-Core Processor   \n",
       "13  AMD EPYC 7742 64-Core Processor   \n",
       "14  AMD EPYC 7742 64-Core Processor   \n",
       "15  AMD EPYC 7742 64-Core Processor   \n",
       "16  AMD EPYC 7742 64-Core Processor   \n",
       "17  AMD EPYC 7742 64-Core Processor   \n",
       "18  AMD EPYC 7742 64-Core Processor   \n",
       "19  AMD EPYC 7742 64-Core Processor   \n",
       "20  AMD EPYC 7742 64-Core Processor   \n",
       "21  AMD EPYC 7742 64-Core Processor   \n",
       "22  AMD EPYC 7742 64-Core Processor   \n",
       "23  AMD EPYC 7742 64-Core Processor   \n",
       "24  AMD EPYC 7742 64-Core Processor   \n",
       "25  AMD EPYC 7742 64-Core Processor   \n",
       "26  AMD EPYC 7742 64-Core Processor   \n",
       "27  AMD EPYC 7742 64-Core Processor   \n",
       "28  AMD EPYC 7742 64-Core Processor   \n",
       "29  AMD EPYC 7742 64-Core Processor   \n",
       "30  AMD EPYC 7742 64-Core Processor   \n",
       "\n",
       "                                                os  ... ram_power_avg  \\\n",
       "0   Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.696441   \n",
       "1   Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.699668   \n",
       "2   Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.702201   \n",
       "3   Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.682693   \n",
       "4   Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.701552   \n",
       "5   Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.697485   \n",
       "6   Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.700556   \n",
       "7   Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.699086   \n",
       "8   Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.949414   \n",
       "9   Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.702280   \n",
       "10  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.703517   \n",
       "11  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.697269   \n",
       "12  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.688788   \n",
       "13  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.696975   \n",
       "14  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.696452   \n",
       "15  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.702542   \n",
       "16  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.700258   \n",
       "17  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.700001   \n",
       "18  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.697353   \n",
       "19  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.701431   \n",
       "20  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.699233   \n",
       "21  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.965965   \n",
       "22  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.698765   \n",
       "23  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.697740   \n",
       "24  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.682946   \n",
       "25  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.701948   \n",
       "26  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.697837   \n",
       "27  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.697765   \n",
       "28  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.696810   \n",
       "29  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.696916   \n",
       "30  Linux-5.15.0-113-generic-x86_64-with-glibc2.31  ...      0.695093   \n",
       "\n",
       "   cpu_energy_total gpu_energy_total ram_energy_total  total_energy_kwh  \\\n",
       "0          0.000255         0.001161         0.000001          0.000349   \n",
       "1          0.000274         0.001226         0.000002          0.000357   \n",
       "2          0.000315         0.001234         0.000002          0.000375   \n",
       "3          0.002785         0.010686         0.000013          0.003387   \n",
       "4          0.000302         0.001447         0.000002          0.000454   \n",
       "5          0.000257         0.001171         0.000001          0.000365   \n",
       "6          0.000249         0.001137         0.000001          0.000330   \n",
       "7          0.000254         0.001136         0.000001          0.000338   \n",
       "8          0.000254         0.000896         0.000002          0.000289   \n",
       "9          0.000258         0.001154         0.000001          0.000349   \n",
       "10         0.000250         0.001163         0.000001          0.000358   \n",
       "11         0.000250         0.001145         0.000001          0.000351   \n",
       "12         0.001421         0.006475         0.000007          0.001976   \n",
       "13         0.000593         0.002877         0.000003          0.000887   \n",
       "14         0.000436         0.002101         0.000002          0.000636   \n",
       "15         0.000320         0.001317         0.000002          0.000393   \n",
       "16         0.000289         0.001446         0.000002          0.000422   \n",
       "17         0.000273         0.001175         0.000002          0.000343   \n",
       "18         0.000263         0.001184         0.000001          0.000376   \n",
       "19         0.000310         0.001264         0.000002          0.000422   \n",
       "20         0.000238         0.001066         0.000001          0.000319   \n",
       "21         0.000244         0.000819         0.000002          0.000269   \n",
       "22         0.000260         0.001182         0.000001          0.000343   \n",
       "23         0.000278         0.001225         0.000002          0.000355   \n",
       "24         0.002737         0.010584         0.000013          0.003307   \n",
       "25         0.000258         0.001150         0.000001          0.000338   \n",
       "26         0.000250         0.001150         0.000001          0.000347   \n",
       "27         0.000438         0.002070         0.000002          0.000640   \n",
       "28         0.000252         0.001153         0.000001          0.000349   \n",
       "29         0.000489         0.002517         0.000002          0.000747   \n",
       "30         0.000254         0.001135         0.000001          0.000343   \n",
       "\n",
       "    total_energy_joules  tokens_per_joule  joules_per_token  flops_per_joule  \\\n",
       "0           5102.086685          0.097999         10.204173     1.013844e+08   \n",
       "1           5407.209328          0.092469         10.814419     9.566341e+07   \n",
       "2           5583.389461          0.089551         11.166779     9.264481e+07   \n",
       "3          48545.677786          0.010300         97.091356     1.065537e+07   \n",
       "4           6303.964264          0.079315         12.607929     8.205504e+07   \n",
       "5           5145.915184          0.097164         10.291830     1.005209e+08   \n",
       "6           4994.111035          0.100118          9.988222     1.035764e+08   \n",
       "7           5011.062364          0.099779         10.022125     1.032260e+08   \n",
       "8           4146.470730          0.120584          8.292941     1.247500e+08   \n",
       "9           5089.767787          0.098236         10.179536     1.016298e+08   \n",
       "10          5090.163238          0.098229         10.180326     1.016219e+08   \n",
       "11          5029.316835          0.099417         10.058634     1.028514e+08   \n",
       "12         28450.529987          0.017574         56.901060     1.818146e+07   \n",
       "13         12502.268522          0.039993         25.004537     4.137426e+07   \n",
       "14          9143.679525          0.054683         18.287359     5.657154e+07   \n",
       "15          5897.676687          0.084779         11.795353     8.770777e+07   \n",
       "16          6253.579628          0.079954         12.507159     8.271616e+07   \n",
       "17          5219.134529          0.095801         10.438269     9.911070e+07   \n",
       "18          5216.701888          0.095846         10.433404     9.915691e+07   \n",
       "19          5673.983335          0.088122         11.347967     9.116559e+07   \n",
       "20          4699.183521          0.106401          9.398367     1.100770e+08   \n",
       "21          3832.205347          0.130473          7.664411     1.349803e+08   \n",
       "22          5197.332598          0.096203         10.394665     9.952645e+07   \n",
       "23          5417.247647          0.092298         10.834495     9.548614e+07   \n",
       "24         48002.605723          0.010416         96.005211     1.077592e+07   \n",
       "25          5073.650277          0.098548         10.147301     1.019526e+08   \n",
       "26          5043.961526          0.099128         10.087923     1.025527e+08   \n",
       "27          9036.042300          0.055334         18.072085     5.724542e+07   \n",
       "28          5061.086703          0.098793         10.122173     1.022057e+08   \n",
       "29         10829.451815          0.046170         21.658904     4.776530e+07   \n",
       "30          5005.142065          0.099897         10.010284     1.033481e+08   \n",
       "\n",
       "    joules_per_flop  \n",
       "0      9.863449e-09  \n",
       "1      1.045332e-08  \n",
       "2      1.079391e-08  \n",
       "3      9.384941e-08  \n",
       "4      1.218694e-08  \n",
       "5      9.948179e-09  \n",
       "6      9.654709e-09  \n",
       "7      9.687479e-09  \n",
       "8      8.016035e-09  \n",
       "9      9.839634e-09  \n",
       "10     9.840398e-09  \n",
       "11     9.722769e-09  \n",
       "12     5.500110e-08  \n",
       "13     2.416962e-08  \n",
       "14     1.767673e-08  \n",
       "15     1.140150e-08  \n",
       "16     1.208954e-08  \n",
       "17     1.008973e-08  \n",
       "18     1.008503e-08  \n",
       "19     1.096905e-08  \n",
       "20     9.084549e-09  \n",
       "21     7.408491e-09  \n",
       "22     1.004758e-08  \n",
       "23     1.047272e-08  \n",
       "24     9.279953e-08  \n",
       "25     9.808475e-09  \n",
       "26     9.751080e-09  \n",
       "27     1.746865e-08  \n",
       "28     9.784187e-09  \n",
       "29     2.093570e-08  \n",
       "30     9.676034e-09  \n",
       "\n",
       "[31 rows x 72 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rebuild DataFrame using mapped columns\n",
    "ordered_cols = [column_map[d] for d in desired_order if column_map[d] is not None]\n",
    "\n",
    "df_ordered = df[ordered_cols]\n",
    "df_ordered.columns = [d for d in desired_order if column_map[d] is not None]  # rename to logical names\n",
    "df_ordered\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

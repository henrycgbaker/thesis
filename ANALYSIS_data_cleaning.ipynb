{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will later move this into function script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_energy_metrics_local_process_results_gpu_power_process_3\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_1\n",
      "variables_decoder_config_decoder_top_k\n",
      "variables_quantisation_load_in_8bit\n",
      "global_energy_metrics_per-process_emissions_2\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_2\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_2\n",
      "variables_backend\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_2\n",
      "global_energy_metrics_global_derived_quantities_flops_per_joule\n",
      "variables_max_output_tokens\n",
      "variables_batching_options_adaptive_batching\n",
      "global_energy_metrics_local_process_results_ram_energy_process_2\n",
      "global_energy_metrics_local_process_results_ram_power_process_0\n",
      "setup_country\n",
      "setup_available_gpu_count\n",
      "variables_latency_simulation_simulate\n",
      "setup_is_encoder_decoder\n",
      "model_architecture_architecture\n",
      "global_energy_metrics_local_process_results_cpu_power_process_3\n",
      "inference_metrics_inference_performance_total_inference_time_sec\n",
      "setup_gpu_model\n",
      "variables_latency_simulation_delay_min\n",
      "variables_quantisation_cached_flops_for_quantised_models\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_0\n",
      "setup_date_time\n",
      "global_energy_metrics_global_experiment_results_ram_power_avg\n",
      "global_energy_metrics_local_process_results_ram_energy_process_0\n",
      "compute_metrics_compute_utilisation_cpu_usage_percent\n",
      "variables_decoder_config_decoder_temperature\n",
      "global_energy_metrics_global_derived_quantities_joules_per_token\n",
      "global_energy_metrics_local_process_results_gpu_power_process_2\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_1\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_2\n",
      "global_energy_metrics_per-process_emissions_1\n",
      "inference_metrics_inference_performance_throughput_tokens_per_sec\n",
      "global_energy_metrics_global_experiment_results_ram_energy_total\n",
      "variables_sharding_config_sharding_strategy\n",
      "variables_latency_simulation_burst_size\n",
      "variables_sharding_config_fsdp_config_cpu_offload\n",
      "variables_sharding_config_fsdp_config_use_orig_params\n",
      "compute_metrics_flops\n",
      "global_energy_metrics_local_process_results_cpu_power_process_1\n",
      "compute_metrics_memory_gpu_max_memory_reserved_bytes\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_0\n",
      "global_energy_metrics_local_process_results_ram_power_process_1\n",
      "variables_batching_options_max_batch_size___adaptive_batching\n",
      "variables_quantisation_load_in_4bit\n",
      "global_energy_metrics_local_process_results_ram_energy_process_1\n",
      "setup_task_type\n",
      "variables_accelerate_config_distributed_type\n",
      "variables_accelerate_config_num_processes\n",
      "variables_latency_simulation_delay_max\n",
      "global_energy_metrics_local_process_results_ram_power_process_2\n",
      "variables_batching_options_adaptive_max_tokens\n",
      "global_energy_metrics_global_experiment_results_total_energy_kwh\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_1\n",
      "setup_python_version\n",
      "global_energy_metrics_global_experiment_results_total_energy_joules\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_0\n",
      "inference_metrics_inference_performance_throughput_queries_per_sec\n",
      "inference_metrics_raw_inference_metrics_total_generated_tokens\n",
      "model_architecture_total_params\n",
      "global_energy_metrics_global_derived_quantities_tokens_per_joule\n",
      "variables_latency_simulation_simulate_burst\n",
      "global_energy_metrics_global_experiment_results_gpu_energy_total\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_2\n",
      "variables_decode_token_to_text\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_1\n",
      "inference_metrics_inference_performance_average_latency_ms_per_batch\n",
      "variables_decoder_config_decoder_top_p\n",
      "variables_quantisation_quantization\n",
      "setup_os\n",
      "variables_fp_precision\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_3\n",
      "compute_metrics_memory_gpu_current_memory_reserved_bytes\n",
      "compute_metrics_memory_gpu_max_memory_allocated_bytes\n",
      "compute_metrics_compute_utilisation_cpu_memory_usage_bytes\n",
      "variables_latency_simulation_burst_interval\n",
      "variables_number_input_prompts\n",
      "variables_query_rate\n",
      "global_energy_metrics_global_experiment_results_cpu_energy_total\n",
      "global_energy_metrics_global_derived_quantities_joules_per_flop\n",
      "setup_region\n",
      "variables_batching_options_batch_size___fixed_batching\n",
      "variables_max_input_tokens\n",
      "setup_cpu_model\n",
      "setup_available_cpu_count\n",
      "variables_decoder_config_decoding_mode\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_3\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_3\n",
      "global_energy_metrics_local_process_results_cpu_power_process_2\n",
      "variables_inference_type\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_3\n",
      "global_energy_metrics_global_experiment_results_cpu_power_avg\n",
      "global_energy_metrics_local_process_results_gpu_power_process_0\n",
      "global_energy_metrics_local_process_results_gpu_power_process_1\n",
      "global_energy_metrics_experiment_id\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_3\n",
      "global_energy_metrics_local_process_results_cpu_power_process_0\n",
      "global_energy_metrics_per-process_emissions_3\n",
      "inference_metrics_raw_inference_metrics_total_input_tokens\n",
      "global_energy_metrics_per-process_emissions_0\n",
      "compute_metrics_memory_gpu_current_memory_allocated_bytes\n",
      "variables_config_name\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_1\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_0\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_0\n",
      "global_energy_metrics_local_process_results_ram_power_process_3\n",
      "setup_model\n",
      "inference_metrics_raw_inference_metrics_number_input_prompts\n",
      "global_energy_metrics_local_process_results_ram_energy_process_3\n",
      "global_energy_metrics_global_experiment_results_gpu_power_avg\n",
      "setup_experiment_id\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('results/controlled_results.csv')\n",
    "columns = list(df.columns)\n",
    "for col in columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column(col: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean a single column name by:\n",
    "      - Stripping whitespace and replacing any non-standard quotes.\n",
    "      - Checking for per-process metric patterns.\n",
    "      - Applying special renames.\n",
    "      - Removing the 'variables_' prefix if present.\n",
    "      - Otherwise, attempting to strip off any messy prefixes using a known list of tokens.\n",
    "    \n",
    "    If no known token is found, the original (normalized) column name is returned.\n",
    "    \"\"\"\n",
    "    # Normalize the column string: remove extra whitespace and fix common issues with quotes.\n",
    "    col = col.strip()\n",
    "    col = col.replace(\"“\", \"\\\"\").replace(\"”\", \"\\\"\")\n",
    "    \n",
    "    # 1. Special exact mappings.\n",
    "    special_mappings = {\n",
    "        \"setup_cpu_model\": \"cpu_model\",\n",
    "        \"setup_gpu_model\": \"gpu_model\",\n",
    "        \"model_architecture_total_params\": \"total_params\",  # now maps to total_params\n",
    "        \"model_architecture_architecture\": \"model_arch\"\n",
    "    }\n",
    "    if col in special_mappings:\n",
    "        return special_mappings[col]\n",
    "    \n",
    "    # 2. Remove the 'variables_' prefix if it exists.\n",
    "    if col.startswith(\"variables_\"):\n",
    "        col = col[len(\"variables_\"):]\n",
    "    \n",
    "    # 3. First, check if it is a per-process metric column.\n",
    "    per_process_patterns = [\n",
    "        r'(cpu_power_process_\\d+)',\n",
    "        r'(gpu_power_process_\\d+)',\n",
    "        r'(ram_power_process_\\d+)',\n",
    "        r'(cpu_energy_process_\\d+)',\n",
    "        r'(gpu_energy_process_\\d+)',\n",
    "        r'(ram_energy_process_\\d+)',\n",
    "        r'(total_energy_kwh_process_\\d+)',\n",
    "        r'(total_energy_joules_process_\\d+)'\n",
    "    ]\n",
    "    for pattern in per_process_patterns:\n",
    "        match = re.search(pattern, col)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    \n",
    "    # 4. For non-per-process columns, search for a known token in the cleaned column.\n",
    "    tokens = [\n",
    "        \"config_name\", \"experiment_id\", \"date_time\", \"model\", \"is_encoder_decoder\",\n",
    "        \"task_type\", \"available_gpu_count\", \"gpu_model\", \"available_cpu_count\", \"cpu_model\",\n",
    "        \"os\", \"python_version\", \"country\", \"region\", \"fsdp_use_orig_params\", \"fsdp_cpu_offload\",\n",
    "        \"sharding_strategy\", \"distributed_type\", \"num_processes\", \"max_input_tokens\", \"max_output_tokens\",\n",
    "        \"number_input_prompts\", \"decode_token_to_text\", \"decoder_temperature\", \"decoder_top_k\", \"decoder_top_p\",\n",
    "        \"query_rate\", \"latency_simulate\", \"latency_delay_min\", \"latency_delay_max\", \"latency_simulate_burst\",\n",
    "        \"latency_burst_interval\", \"latency_burst_size\", \"fp_precision\", \"quantization\", \"load_in_8bit\",\n",
    "        \"load_in_4bit\", \"cached_flops_for_quantised_models\", \"batch_size___fixed_batching\", \"adaptive_batching\",\n",
    "        \"adaptive_max_tokens\", \"max_batch_size___adaptive_batching\", \"inference_type\", \"backend\", \"total_params\",\n",
    "        \"architecture\", \"total_input_tokens\", \"total_generated_tokens\", \"total_inference_time_sec\", \n",
    "        \"average_latency_ms_per_batch\", \"throughput_queries_per_sec\", \"throughput_tokens_per_sec\", \"flops\",\n",
    "        \"gpu_current_memory_allocated_bytes\", \"gpu_max_memory_allocated_bytes\", \"gpu_current_memory_reserved_bytes\",\n",
    "        \"gpu_max_memory_reserved_bytes\", \"gpu_utilization_percent\", \"cpu_usage_percent\", \"cpu_memory_usage_bytes\",\n",
    "        # Per-process metrics:\n",
    "        \"cpu_power_process_0\", \"gpu_power_process_0\", \"ram_power_process_0\",\n",
    "        \"cpu_energy_process_0\", \"gpu_energy_process_0\", \"ram_energy_process_0\",\n",
    "        \"total_energy_kwh_process_0\", \"total_energy_joules_process_0\",\n",
    "        # Global averages and totals:\n",
    "        \"cpu_power_avg\", \"gpu_power_avg\", \"ram_power_avg\", \"cpu_energy_total\", \"gpu_energy_total\", \"ram_energy_total\",\n",
    "        \"total_energy_kwh\", \"total_energy_joules\", \"tokens_per_joule\", \"joules_per_token\", \"flops_per_joule\", \"joules_per_flop\",\n",
    "        \"per-process_emissions\"\n",
    "    ]\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in col:\n",
    "            idx = col.find(token)\n",
    "            return col[idx:]\n",
    "    \n",
    "    return col\n",
    "\n",
    "def resolve_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Resolve duplicate columns in the DataFrame.\n",
    "    \n",
    "    For any column that appears more than once:\n",
    "      - For 'adaptive_batching', if duplicates exist, prefer the one with a boolean dtype;\n",
    "        otherwise, pick the first occurrence.\n",
    "      - For all other columns (including 'experiment_id' and 'number_input_prompts'),\n",
    "        keep only the first occurrence.\n",
    "    \"\"\"\n",
    "    # Build a mapping of column name to list of indices where it occurs.\n",
    "    seen = {}\n",
    "    for idx, col in enumerate(df.columns):\n",
    "        seen.setdefault(col, []).append(idx)\n",
    "    \n",
    "    # Choose one index per duplicate group.\n",
    "    chosen_indices = []\n",
    "    for col, indices in seen.items():\n",
    "        if len(indices) == 1:\n",
    "            chosen_indices.append(indices[0])\n",
    "        else:\n",
    "            if col == \"adaptive_batching\":\n",
    "                # Look for a column with boolean type.\n",
    "                bool_idx = None\n",
    "                for i in indices:\n",
    "                    if pd.api.types.is_bool_dtype(df.iloc[:, i]):\n",
    "                        bool_idx = i\n",
    "                        break\n",
    "                chosen_indices.append(bool_idx if bool_idx is not None else indices[0])\n",
    "            else:\n",
    "                # For experiment_id, number_input_prompts, or any duplicate, keep the first occurrence.\n",
    "                chosen_indices.append(indices[0])\n",
    "    \n",
    "    # Sort indices to preserve the original order.\n",
    "    chosen_indices.sort()\n",
    "    return df.iloc[:, chosen_indices]\n",
    "\n",
    "def clean_and_reorder_columns(df: pd.DataFrame, desired_order: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean DataFrame columns by:\n",
    "      1. Renaming each column to remove extraneous prefixes and apply special mappings.\n",
    "      2. Removing duplicates (applying special resolution for some columns).\n",
    "      3. Reordering columns into the order specified by 'desired_order'. Any columns not explicitly mentioned\n",
    "         will be appended at the end.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with messy, flattened column names.\n",
    "        desired_order (list): List of column names (after cleaning) indicating the preferred ordering.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with cleaned and reordered columns.\n",
    "    \"\"\"\n",
    "    # Build mapping from original column names to cleaned names.\n",
    "    mapping = {col: clean_column(col) for col in df.columns}\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    df = df.rename(columns=mapping)\n",
    "    \n",
    "    # Resolve duplicates as required.\n",
    "    df = resolve_duplicates(df)\n",
    "    \n",
    "    # Reorder columns: first, the ones matching the desired order.\n",
    "    ordered_cols = [col for col in desired_order if col in df.columns]\n",
    "    # Then, append any remaining columns.\n",
    "    remaining_cols = [col for col in df.columns if col not in desired_order]\n",
    "    final_order = ordered_cols + remaining_cols\n",
    "    \n",
    "    return df[final_order]\n",
    "\n",
    "# Example desired order list\n",
    "desired_order = [\n",
    "    \"config_name\",\n",
    "    \"experiment_id\",\n",
    "    \"date_time\",\n",
    "    \"model\",\n",
    "    # num_process\n",
    "    \"num_processes\",\n",
    "    # batching\n",
    "    \"batch_size___fixed_batching\",\n",
    "    # decodeer\n",
    "    \"decoder_temperature\",\n",
    "    \"decoder_top_k\",\n",
    "    \"decoder_top_p\",\n",
    "    # latency\n",
    "    \"latency_simulation_simulate\"\n",
    "    \"latency_simulation_delay_max\",\n",
    "    \"latency_simulation_delay_min\",\n",
    "    \"latency_simulation_simulate_burst\",\n",
    "    \"latency_simulation_burst_size\",\n",
    "    \"latency_simulation_burst_interval\",\n",
    "    # precision / quantisation\n",
    "    \"fp_precision\",\n",
    "    \"quantization\",\n",
    "    \"load_in_8bit\",\n",
    "    \"load_in_4bit\",\n",
    "    \"cached_flops_for_quantised_models\",\n",
    "    \n",
    "    # UNUSED PARAMS\n",
    "    \"sharding_strategy\",\n",
    "    \"sharding_config_fsdp_config_use_orig_params\",\n",
    "    \"sharding_config_fsdp_config_cpu_offload\",\n",
    "    \"adaptive_batching\",\n",
    "    \"adaptive_max_tokens\",\n",
    "    \"query_rate\",\n",
    "    \"total_input_tokens\",\n",
    "    \"total_generated_tokens\"\n",
    "    \n",
    "    # CONSTANT SETUP ====\n",
    "    \"date_time\",\n",
    "    \"is_encoder_decoder\",\n",
    "    \"task_type\",\n",
    "    \"available_gpu_count\",\n",
    "    \"gpu_model\",\n",
    "    \"available_cpu_count\",\n",
    "    \"cpu_model\",\n",
    "    \"os\",\n",
    "    \"python_version\",\n",
    "    \"country\",\n",
    "    \"region\",\n",
    "    \"distributed_type\",\n",
    "    \"decode_token_to_text\",\n",
    "    \"inference_type\",\n",
    "    \"backend\",\n",
    "    \"total_params\",\n",
    "    \"model_arch\",\n",
    "\n",
    "    # Validation (should be same):\n",
    "    \"max_input_tokens\",\n",
    "    \"max_output_tokens\",\n",
    "    \"number_input_prompts\",\n",
    "    \n",
    "    # RESULTS =====\n",
    "    # energy\n",
    "    \"total_energy_kwh\",\n",
    "    \"total_energy_joules\",\n",
    "    # FLOPS\n",
    "    \"flops\",\n",
    "    \"tokens_per_joule\",\n",
    "    \"joules_per_token\",\n",
    "    \"flops_per_joule\",\n",
    "    \"joules_per_flop\",\n",
    "    \"total_inference_time_sec\", \n",
    "    # inference performance\n",
    "    \"average_latency_ms_per_batch\",\n",
    "    \"throughput_queries_per_sec\",\n",
    "    \"throughput_tokens_per_sec\",\n",
    "    # CPU utilization\n",
    "    \"cpu_usage_percent\",\n",
    "    \"cpu_memory_usage_bytes\",\n",
    "    # GPU utilization\n",
    "    \"gpu_utilization_percent_0\", \"gpu_utilization_percent_1\", \"gpu_utilization_percent_2\", \"gpu_utilization_percent_3\",\n",
    "    # Compute mem\n",
    "    \"gpu_current_memory_allocated_bytes\",\n",
    "    \"gpu_max_memory_allocated_bytes\",\n",
    "    \"gpu_current_memory_reserved_bytes\",\n",
    "    \"gpu_max_memory_reserved_bytes\",\n",
    "    # Per-process metrics:\n",
    "    \"cpu_power_process_0\", \"cpu_power_process_1\", \"cpu_power_process_2\", \"cpu_power_process_3\",\n",
    "    \"gpu_power_process_0\", \"gpu_power_process_1\", \"gpu_power_process_2\", \"gpu_power_process_3\",\n",
    "    \"ram_power_process_0\", \"ram_power_process_1\", \"ram_power_process_2\", \"ram_power_process_3\",\n",
    "    \"cpu_energy_process_0\", \"cpu_energy_process_1\", \"cpu_energy_process_2\", \"cpu_energy_process_3\",\n",
    "    \"gpu_energy_process_0\", \"gpu_energy_process_1\", \"gpu_energy_process_2\", \"gpu_energy_process_3\",\n",
    "    \"ram_energy_process_0\", \"ram_energy_process_1\", \"ram_energy_process_2\", \"ram_energy_process_3\",\n",
    "    \"total_energy_kwh_process_0\", \"total_energy_kwh_process_1\", \"total_energy_kwh_process_2\", \"total_energy_kwh_process_3\",\n",
    "    \"total_energy_joules_process_0\", \"total_energy_joules_process_1\", \"total_energy_joules_process_2\", \"total_energy_joules_process_3\",\n",
    "    # Global averages and totals:\n",
    "    \"cpu_power_avg\",\n",
    "    \"gpu_power_avg\",\n",
    "    \"ram_power_avg\",\n",
    "    \"cpu_energy_total\",\n",
    "    \"gpu_energy_total\",\n",
    "    \"ram_energy_total\",\n",
    "    # per-process_emsisisons\n",
    "    \"per-process_emissions_0\", \"per-process_emissions_1\", \"per-process_emissions_2\",\"per-process_emissions_3\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found & inspecting: df_controlled_cleaned\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>config_name</th>\n",
       "      <td>num_processes_1</td>\n",
       "      <td>num_processes_2</td>\n",
       "      <td>num_processes_3</td>\n",
       "      <td>num_processes_4</td>\n",
       "      <td>batching_1</td>\n",
       "      <td>batching_2</td>\n",
       "      <td>batching_4</td>\n",
       "      <td>batching_8</td>\n",
       "      <td>batching_16</td>\n",
       "      <td>batching_32</td>\n",
       "      <td>batching_64</td>\n",
       "      <td>precis_float32_quant_False_quant8_False_quant4...</td>\n",
       "      <td>precis_float16_quant_False_quant8_False_quant4...</td>\n",
       "      <td>precis_float16_quant_True_quant8_True_quant4_F...</td>\n",
       "      <td>precis_float16_quant_True_quant8_False_quant4_...</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.7</td>\n",
       "      <td>decoding_greedy_decoder_temperature_1.0</td>\n",
       "      <td>decoding_greedy_decoder_temperature_1.3</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>latency_False</td>\n",
       "      <td>latency_True_latency_0.05_latency_0.2_latency_...</td>\n",
       "      <td>latency_True_latency_0.2_latency_0.6_latency_F...</td>\n",
       "      <td>latency_True_latency_0.05_latency_0.2_latency_...</td>\n",
       "      <td>latency_True_latency_0.2_latency_0.6_latency_T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <td>April 08, 2025 at 04:31:33 PM</td>\n",
       "      <td>April 08, 2025 at 04:32:06 PM</td>\n",
       "      <td>April 08, 2025 at 04:32:41 PM</td>\n",
       "      <td>April 08, 2025 at 04:33:15 PM</td>\n",
       "      <td>April 08, 2025 at 04:34:12 PM</td>\n",
       "      <td>April 08, 2025 at 04:34:59 PM</td>\n",
       "      <td>April 08, 2025 at 04:35:43 PM</td>\n",
       "      <td>April 08, 2025 at 04:36:20 PM</td>\n",
       "      <td>April 08, 2025 at 04:36:58 PM</td>\n",
       "      <td>April 08, 2025 at 04:37:33 PM</td>\n",
       "      <td>April 08, 2025 at 04:38:19 PM</td>\n",
       "      <td>April 08, 2025 at 04:38:55 PM</td>\n",
       "      <td>April 08, 2025 at 04:39:28 PM</td>\n",
       "      <td>April 08, 2025 at 04:40:33 PM</td>\n",
       "      <td>April 08, 2025 at 04:41:10 PM</td>\n",
       "      <td>April 08, 2025 at 04:41:43 PM</td>\n",
       "      <td>April 08, 2025 at 04:42:19 PM</td>\n",
       "      <td>April 08, 2025 at 04:42:54 PM</td>\n",
       "      <td>April 08, 2025 at 04:43:29 PM</td>\n",
       "      <td>April 08, 2025 at 04:44:03 PM</td>\n",
       "      <td>April 08, 2025 at 04:44:38 PM</td>\n",
       "      <td>April 08, 2025 at 04:45:14 PM</td>\n",
       "      <td>April 08, 2025 at 04:45:49 PM</td>\n",
       "      <td>April 08, 2025 at 04:46:23 PM</td>\n",
       "      <td>April 08, 2025 at 04:47:02 PM</td>\n",
       "      <td>April 08, 2025 at 04:47:37 PM</td>\n",
       "      <td>April 08, 2025 at 04:48:15 PM</td>\n",
       "      <td>April 08, 2025 at 04:48:49 PM</td>\n",
       "      <td>April 08, 2025 at 04:49:27 PM</td>\n",
       "      <td>April 08, 2025 at 04:50:02 PM</td>\n",
       "      <td>April 08, 2025 at 04:50:37 PM</td>\n",
       "      <td>April 08, 2025 at 04:51:12 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_processes</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size___fixed_batching</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_temperature</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_k</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_p</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate_burst</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_size</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_interval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp_precision</th>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantization</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_8bit</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_4bit</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharding_strategy</th>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharding_config_fsdp_config_use_orig_params</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharding_config_fsdp_config_cpu_offload</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive_batching</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive_max_tokens</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_rate</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_input_tokens</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_encoder_decoder</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_type</th>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_gpu_count</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_model</th>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_cpu_count</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_model</th>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>os</th>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python_version</th>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distributed_type</th>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decode_token_to_text</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inference_type</th>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backend</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_params</th>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>615606272</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_arch</th>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_input_tokens</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_output_tokens</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_input_prompts</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh</th>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.00258</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>0.009953</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.002528</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.009094</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.00258</td>\n",
       "      <td>0.00262</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.00261</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.002472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules</th>\n",
       "      <td>1561.168622</td>\n",
       "      <td>4151.58235</td>\n",
       "      <td>6486.403256</td>\n",
       "      <td>9287.658482</td>\n",
       "      <td>57830.498773</td>\n",
       "      <td>35832.430964</td>\n",
       "      <td>22811.407515</td>\n",
       "      <td>15412.070402</td>\n",
       "      <td>9669.475684</td>\n",
       "      <td>9099.859349</td>\n",
       "      <td>9673.588298</td>\n",
       "      <td>10544.0582</td>\n",
       "      <td>6938.191835</td>\n",
       "      <td>32739.910723</td>\n",
       "      <td>9749.962662</td>\n",
       "      <td>7767.530628</td>\n",
       "      <td>8612.615549</td>\n",
       "      <td>9287.457917</td>\n",
       "      <td>9431.681788</td>\n",
       "      <td>8861.743317</td>\n",
       "      <td>9394.350592</td>\n",
       "      <td>9569.324332</td>\n",
       "      <td>9578.843492</td>\n",
       "      <td>10361.488063</td>\n",
       "      <td>9881.56245</td>\n",
       "      <td>9782.421027</td>\n",
       "      <td>9460.731311</td>\n",
       "      <td>11004.24041</td>\n",
       "      <td>9104.932397</td>\n",
       "      <td>10752.746732</td>\n",
       "      <td>8354.124101</td>\n",
       "      <td>8900.869755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops</th>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens_per_joule</th>\n",
       "      <td>0.640546</td>\n",
       "      <td>0.240872</td>\n",
       "      <td>0.154169</td>\n",
       "      <td>0.10767</td>\n",
       "      <td>0.017292</td>\n",
       "      <td>0.027908</td>\n",
       "      <td>0.043838</td>\n",
       "      <td>0.064884</td>\n",
       "      <td>0.103418</td>\n",
       "      <td>0.109892</td>\n",
       "      <td>0.103374</td>\n",
       "      <td>0.09484</td>\n",
       "      <td>0.14413</td>\n",
       "      <td>0.030544</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.128741</td>\n",
       "      <td>0.116109</td>\n",
       "      <td>0.107672</td>\n",
       "      <td>0.106026</td>\n",
       "      <td>0.112845</td>\n",
       "      <td>0.106447</td>\n",
       "      <td>0.104501</td>\n",
       "      <td>0.104397</td>\n",
       "      <td>0.096511</td>\n",
       "      <td>0.101199</td>\n",
       "      <td>0.102224</td>\n",
       "      <td>0.1057</td>\n",
       "      <td>0.090874</td>\n",
       "      <td>0.109831</td>\n",
       "      <td>0.092999</td>\n",
       "      <td>0.119701</td>\n",
       "      <td>0.112349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_token</th>\n",
       "      <td>1.561169</td>\n",
       "      <td>4.151582</td>\n",
       "      <td>6.486403</td>\n",
       "      <td>9.287658</td>\n",
       "      <td>57.830499</td>\n",
       "      <td>35.832431</td>\n",
       "      <td>22.811408</td>\n",
       "      <td>15.41207</td>\n",
       "      <td>9.669476</td>\n",
       "      <td>9.099859</td>\n",
       "      <td>9.673588</td>\n",
       "      <td>10.544058</td>\n",
       "      <td>6.938192</td>\n",
       "      <td>32.739911</td>\n",
       "      <td>9.749963</td>\n",
       "      <td>7.767531</td>\n",
       "      <td>8.612616</td>\n",
       "      <td>9.287458</td>\n",
       "      <td>9.431682</td>\n",
       "      <td>8.861743</td>\n",
       "      <td>9.394351</td>\n",
       "      <td>9.569324</td>\n",
       "      <td>9.578843</td>\n",
       "      <td>10.361488</td>\n",
       "      <td>9.881562</td>\n",
       "      <td>9.782421</td>\n",
       "      <td>9.460731</td>\n",
       "      <td>11.00424</td>\n",
       "      <td>9.104932</td>\n",
       "      <td>10.752747</td>\n",
       "      <td>8.354124</td>\n",
       "      <td>8.90087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops_per_joule</th>\n",
       "      <td>662672893.521465</td>\n",
       "      <td>249192727.209392</td>\n",
       "      <td>159494266.256535</td>\n",
       "      <td>111389122.454932</td>\n",
       "      <td>17889247.88724</td>\n",
       "      <td>28871725.980626</td>\n",
       "      <td>45352051.482635</td>\n",
       "      <td>67125577.616509</td>\n",
       "      <td>106990716.129887</td>\n",
       "      <td>113687925.088365</td>\n",
       "      <td>106945230.268081</td>\n",
       "      <td>98116314.268051</td>\n",
       "      <td>149108608.219022</td>\n",
       "      <td>31598868.327846</td>\n",
       "      <td>106107496.397334</td>\n",
       "      <td>133188290.785709</td>\n",
       "      <td>120119622.447774</td>\n",
       "      <td>111391527.936536</td>\n",
       "      <td>109688192.54092</td>\n",
       "      <td>116742732.320793</td>\n",
       "      <td>110124070.617504</td>\n",
       "      <td>108110467.588197</td>\n",
       "      <td>108003030.722911</td>\n",
       "      <td>99845130.52061</td>\n",
       "      <td>104694387.473973</td>\n",
       "      <td>105755428.550843</td>\n",
       "      <td>109351390.926845</td>\n",
       "      <td>94013224.855566</td>\n",
       "      <td>113624580.931623</td>\n",
       "      <td>96212079.926237</td>\n",
       "      <td>123836337.055097</td>\n",
       "      <td>116229554.686645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_flop</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_inference_time_sec</th>\n",
       "      <td>2.356892</td>\n",
       "      <td>2.401629</td>\n",
       "      <td>2.346066</td>\n",
       "      <td>2.372563</td>\n",
       "      <td>20.824448</td>\n",
       "      <td>10.598905</td>\n",
       "      <td>6.579609</td>\n",
       "      <td>4.488748</td>\n",
       "      <td>2.56615</td>\n",
       "      <td>2.408858</td>\n",
       "      <td>2.385437</td>\n",
       "      <td>2.286825</td>\n",
       "      <td>2.363797</td>\n",
       "      <td>7.218139</td>\n",
       "      <td>3.677875</td>\n",
       "      <td>2.272839</td>\n",
       "      <td>2.381273</td>\n",
       "      <td>2.350439</td>\n",
       "      <td>2.395863</td>\n",
       "      <td>2.303065</td>\n",
       "      <td>2.387908</td>\n",
       "      <td>2.412971</td>\n",
       "      <td>2.478181</td>\n",
       "      <td>3.440782</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.56474</td>\n",
       "      <td>2.419328</td>\n",
       "      <td>3.559638</td>\n",
       "      <td>2.453797</td>\n",
       "      <td>4.07742</td>\n",
       "      <td>2.509436</td>\n",
       "      <td>2.615047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_latency_ms_per_batch</th>\n",
       "      <td>2356.891729</td>\n",
       "      <td>2401.628917</td>\n",
       "      <td>2346.066005</td>\n",
       "      <td>2372.563443</td>\n",
       "      <td>2082.444752</td>\n",
       "      <td>2119.780987</td>\n",
       "      <td>2193.20311</td>\n",
       "      <td>2244.3741</td>\n",
       "      <td>2566.149628</td>\n",
       "      <td>2408.858126</td>\n",
       "      <td>2385.437419</td>\n",
       "      <td>2286.825385</td>\n",
       "      <td>2363.7969</td>\n",
       "      <td>7218.139077</td>\n",
       "      <td>3677.875369</td>\n",
       "      <td>2272.839022</td>\n",
       "      <td>2381.273368</td>\n",
       "      <td>2350.439308</td>\n",
       "      <td>2395.863263</td>\n",
       "      <td>2303.064523</td>\n",
       "      <td>2387.907913</td>\n",
       "      <td>2412.971</td>\n",
       "      <td>2478.180916</td>\n",
       "      <td>3440.782234</td>\n",
       "      <td>2714.285777</td>\n",
       "      <td>2564.739563</td>\n",
       "      <td>2419.327923</td>\n",
       "      <td>3559.637986</td>\n",
       "      <td>2453.797072</td>\n",
       "      <td>4077.420104</td>\n",
       "      <td>2509.436437</td>\n",
       "      <td>2615.046637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_queries_per_sec</th>\n",
       "      <td>4.242876</td>\n",
       "      <td>4.163841</td>\n",
       "      <td>4.262455</td>\n",
       "      <td>4.21485</td>\n",
       "      <td>0.480205</td>\n",
       "      <td>0.943494</td>\n",
       "      <td>1.519847</td>\n",
       "      <td>2.227793</td>\n",
       "      <td>3.896889</td>\n",
       "      <td>4.151345</td>\n",
       "      <td>4.192103</td>\n",
       "      <td>4.372874</td>\n",
       "      <td>4.230482</td>\n",
       "      <td>1.385399</td>\n",
       "      <td>2.718961</td>\n",
       "      <td>4.399784</td>\n",
       "      <td>4.199434</td>\n",
       "      <td>4.254524</td>\n",
       "      <td>4.173861</td>\n",
       "      <td>4.342041</td>\n",
       "      <td>4.187766</td>\n",
       "      <td>4.144269</td>\n",
       "      <td>4.035218</td>\n",
       "      <td>2.906316</td>\n",
       "      <td>3.68421</td>\n",
       "      <td>3.899031</td>\n",
       "      <td>4.133379</td>\n",
       "      <td>2.809274</td>\n",
       "      <td>4.075317</td>\n",
       "      <td>2.452531</td>\n",
       "      <td>3.984958</td>\n",
       "      <td>3.824024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_tokens_per_sec</th>\n",
       "      <td>424.287627</td>\n",
       "      <td>416.38406</td>\n",
       "      <td>426.245467</td>\n",
       "      <td>421.485041</td>\n",
       "      <td>48.020482</td>\n",
       "      <td>94.34937</td>\n",
       "      <td>151.984708</td>\n",
       "      <td>222.779259</td>\n",
       "      <td>389.68889</td>\n",
       "      <td>415.134453</td>\n",
       "      <td>419.210327</td>\n",
       "      <td>437.287432</td>\n",
       "      <td>423.04819</td>\n",
       "      <td>138.539863</td>\n",
       "      <td>271.896108</td>\n",
       "      <td>439.978366</td>\n",
       "      <td>419.943386</td>\n",
       "      <td>425.452381</td>\n",
       "      <td>417.38609</td>\n",
       "      <td>434.204075</td>\n",
       "      <td>418.776618</td>\n",
       "      <td>414.426862</td>\n",
       "      <td>403.52179</td>\n",
       "      <td>290.631587</td>\n",
       "      <td>368.421044</td>\n",
       "      <td>389.903137</td>\n",
       "      <td>413.337932</td>\n",
       "      <td>280.927444</td>\n",
       "      <td>407.531662</td>\n",
       "      <td>245.253119</td>\n",
       "      <td>398.495848</td>\n",
       "      <td>382.402358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_usage_percent</th>\n",
       "      <td>3.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>47.4</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>55.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>16.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>17.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_memory_usage_bytes</th>\n",
       "      <td>2050256896</td>\n",
       "      <td>2070810624</td>\n",
       "      <td>2068250624</td>\n",
       "      <td>2075455488</td>\n",
       "      <td>2015477760</td>\n",
       "      <td>2049409024</td>\n",
       "      <td>2057400320</td>\n",
       "      <td>2067193856</td>\n",
       "      <td>2073178112</td>\n",
       "      <td>2076033024</td>\n",
       "      <td>2071547904</td>\n",
       "      <td>2073534464</td>\n",
       "      <td>3161710592</td>\n",
       "      <td>2766688256</td>\n",
       "      <td>2705195008</td>\n",
       "      <td>2056642560</td>\n",
       "      <td>2073894912</td>\n",
       "      <td>2070286336</td>\n",
       "      <td>2072047616</td>\n",
       "      <td>2056028160</td>\n",
       "      <td>2075602944</td>\n",
       "      <td>2075750400</td>\n",
       "      <td>2077544448</td>\n",
       "      <td>2057662464</td>\n",
       "      <td>2070953984</td>\n",
       "      <td>2052939776</td>\n",
       "      <td>2072227840</td>\n",
       "      <td>2074927104</td>\n",
       "      <td>2070724608</td>\n",
       "      <td>2072039424</td>\n",
       "      <td>2073120768</td>\n",
       "      <td>2070740992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_current_memory_allocated_bytes</th>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817967616</td>\n",
       "      <td>8817965056</td>\n",
       "      <td>8817964032</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>4419607552</td>\n",
       "      <td>1576284160</td>\n",
       "      <td>1087442944</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_max_memory_allocated_bytes</th>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817967616</td>\n",
       "      <td>8817965056</td>\n",
       "      <td>8817964032</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>4419607552</td>\n",
       "      <td>1576284160</td>\n",
       "      <td>1087442944</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_current_memory_reserved_bytes</th>\n",
       "      <td>12008292352</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>6838812672</td>\n",
       "      <td>2885681152</td>\n",
       "      <td>1927282688</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_max_memory_reserved_bytes</th>\n",
       "      <td>12008292352</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>6838812672</td>\n",
       "      <td>2885681152</td>\n",
       "      <td>1927282688</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_0</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_0</th>\n",
       "      <td>414.856645</td>\n",
       "      <td>605.276451</td>\n",
       "      <td>560.689296</td>\n",
       "      <td>788.015735</td>\n",
       "      <td>1313.057996</td>\n",
       "      <td>641.064988</td>\n",
       "      <td>677.58912</td>\n",
       "      <td>623.64748</td>\n",
       "      <td>641.468533</td>\n",
       "      <td>705.181102</td>\n",
       "      <td>651.046027</td>\n",
       "      <td>619.770725</td>\n",
       "      <td>675.28713</td>\n",
       "      <td>444.462409</td>\n",
       "      <td>557.53898</td>\n",
       "      <td>612.704186</td>\n",
       "      <td>762.470124</td>\n",
       "      <td>795.129191</td>\n",
       "      <td>740.388</td>\n",
       "      <td>776.321292</td>\n",
       "      <td>809.680864</td>\n",
       "      <td>646.756882</td>\n",
       "      <td>652.001595</td>\n",
       "      <td>567.629617</td>\n",
       "      <td>727.260463</td>\n",
       "      <td>701.330117</td>\n",
       "      <td>756.244221</td>\n",
       "      <td>551.612807</td>\n",
       "      <td>716.271282</td>\n",
       "      <td>381.983252</td>\n",
       "      <td>615.725547</td>\n",
       "      <td>717.525238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>491.304513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>424.010995</td>\n",
       "      <td>466.001815</td>\n",
       "      <td>518.360923</td>\n",
       "      <td>369.103744</td>\n",
       "      <td>483.293236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>505.669169</td>\n",
       "      <td>1743.091048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.894599</td>\n",
       "      <td>374.736474</td>\n",
       "      <td>633.739616</td>\n",
       "      <td>556.747136</td>\n",
       "      <td>453.252145</td>\n",
       "      <td>18.628497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>495.301506</td>\n",
       "      <td>1679.540024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2219.419073</td>\n",
       "      <td>771.336972</td>\n",
       "      <td>555.824567</td>\n",
       "      <td>471.022131</td>\n",
       "      <td>413.266378</td>\n",
       "      <td>404.622742</td>\n",
       "      <td>468.725355</td>\n",
       "      <td>559.126046</td>\n",
       "      <td>310.173365</td>\n",
       "      <td>533.99169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>531.830444</td>\n",
       "      <td>708.880427</td>\n",
       "      <td>469.151347</td>\n",
       "      <td>629.644402</td>\n",
       "      <td>632.178172</td>\n",
       "      <td>561.420978</td>\n",
       "      <td>588.174565</td>\n",
       "      <td>683.577268</td>\n",
       "      <td>742.100489</td>\n",
       "      <td>667.109686</td>\n",
       "      <td>594.917177</td>\n",
       "      <td>518.21448</td>\n",
       "      <td>564.387603</td>\n",
       "      <td>660.52256</td>\n",
       "      <td>683.491168</td>\n",
       "      <td>688.585224</td>\n",
       "      <td>685.891048</td>\n",
       "      <td>759.717472</td>\n",
       "      <td>708.550319</td>\n",
       "      <td>731.480916</td>\n",
       "      <td>670.105119</td>\n",
       "      <td>615.131361</td>\n",
       "      <td>705.838975</td>\n",
       "      <td>718.217363</td>\n",
       "      <td>780.127003</td>\n",
       "      <td>516.23026</td>\n",
       "      <td>694.223236</td>\n",
       "      <td>611.717499</td>\n",
       "      <td>631.657895</td>\n",
       "      <td>734.177811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>533.950626</td>\n",
       "      <td>580.455824</td>\n",
       "      <td>658.01506</td>\n",
       "      <td>667.772397</td>\n",
       "      <td>545.313817</td>\n",
       "      <td>595.323068</td>\n",
       "      <td>598.674237</td>\n",
       "      <td>555.219656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>589.702252</td>\n",
       "      <td>480.250829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>627.405103</td>\n",
       "      <td>658.562704</td>\n",
       "      <td>610.801172</td>\n",
       "      <td>604.058121</td>\n",
       "      <td>574.829885</td>\n",
       "      <td>601.787839</td>\n",
       "      <td>1382.946973</td>\n",
       "      <td>708.385754</td>\n",
       "      <td>657.908802</td>\n",
       "      <td>944.800435</td>\n",
       "      <td>363.407429</td>\n",
       "      <td>250.763626</td>\n",
       "      <td>604.277492</td>\n",
       "      <td>618.121217</td>\n",
       "      <td>479.491748</td>\n",
       "      <td>796.653119</td>\n",
       "      <td>514.542529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_0</th>\n",
       "      <td>0.714289</td>\n",
       "      <td>0.721865</td>\n",
       "      <td>0.719776</td>\n",
       "      <td>0.722456</td>\n",
       "      <td>0.702599</td>\n",
       "      <td>0.71335</td>\n",
       "      <td>0.71698</td>\n",
       "      <td>0.720617</td>\n",
       "      <td>0.72172</td>\n",
       "      <td>0.722474</td>\n",
       "      <td>0.721355</td>\n",
       "      <td>0.721694</td>\n",
       "      <td>1.102643</td>\n",
       "      <td>0.965406</td>\n",
       "      <td>0.944375</td>\n",
       "      <td>0.716738</td>\n",
       "      <td>0.721763</td>\n",
       "      <td>0.721812</td>\n",
       "      <td>0.722298</td>\n",
       "      <td>0.716374</td>\n",
       "      <td>0.722797</td>\n",
       "      <td>0.723407</td>\n",
       "      <td>0.723691</td>\n",
       "      <td>0.716706</td>\n",
       "      <td>0.721634</td>\n",
       "      <td>0.714984</td>\n",
       "      <td>0.722484</td>\n",
       "      <td>0.722661</td>\n",
       "      <td>0.721959</td>\n",
       "      <td>0.722185</td>\n",
       "      <td>0.721872</td>\n",
       "      <td>0.720926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680336</td>\n",
       "      <td>0.678097</td>\n",
       "      <td>0.666578</td>\n",
       "      <td>0.659914</td>\n",
       "      <td>0.656784</td>\n",
       "      <td>0.662802</td>\n",
       "      <td>0.667093</td>\n",
       "      <td>0.667399</td>\n",
       "      <td>0.67005</td>\n",
       "      <td>0.670575</td>\n",
       "      <td>0.668138</td>\n",
       "      <td>0.871312</td>\n",
       "      <td>1.010028</td>\n",
       "      <td>1.002962</td>\n",
       "      <td>0.653096</td>\n",
       "      <td>0.666492</td>\n",
       "      <td>0.668358</td>\n",
       "      <td>0.672742</td>\n",
       "      <td>0.65193</td>\n",
       "      <td>0.681414</td>\n",
       "      <td>0.691215</td>\n",
       "      <td>0.681756</td>\n",
       "      <td>0.639193</td>\n",
       "      <td>0.662752</td>\n",
       "      <td>0.673425</td>\n",
       "      <td>0.663541</td>\n",
       "      <td>0.665721</td>\n",
       "      <td>0.678437</td>\n",
       "      <td>0.680659</td>\n",
       "      <td>0.673545</td>\n",
       "      <td>0.674317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670814</td>\n",
       "      <td>0.677396</td>\n",
       "      <td>0.652318</td>\n",
       "      <td>0.656422</td>\n",
       "      <td>0.671325</td>\n",
       "      <td>0.665362</td>\n",
       "      <td>0.666369</td>\n",
       "      <td>0.669521</td>\n",
       "      <td>0.680642</td>\n",
       "      <td>0.666388</td>\n",
       "      <td>0.913636</td>\n",
       "      <td>1.010149</td>\n",
       "      <td>0.979697</td>\n",
       "      <td>0.652359</td>\n",
       "      <td>0.667424</td>\n",
       "      <td>0.668231</td>\n",
       "      <td>0.678045</td>\n",
       "      <td>0.638948</td>\n",
       "      <td>0.686724</td>\n",
       "      <td>0.691328</td>\n",
       "      <td>0.684342</td>\n",
       "      <td>0.646367</td>\n",
       "      <td>0.667909</td>\n",
       "      <td>0.666428</td>\n",
       "      <td>0.666791</td>\n",
       "      <td>0.67092</td>\n",
       "      <td>0.669261</td>\n",
       "      <td>0.671914</td>\n",
       "      <td>0.667791</td>\n",
       "      <td>0.668052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.672838</td>\n",
       "      <td>0.650243</td>\n",
       "      <td>0.657912</td>\n",
       "      <td>0.66566</td>\n",
       "      <td>0.666917</td>\n",
       "      <td>0.666261</td>\n",
       "      <td>0.678216</td>\n",
       "      <td>0.676693</td>\n",
       "      <td>0.671143</td>\n",
       "      <td>0.893091</td>\n",
       "      <td>1.000088</td>\n",
       "      <td>0.9912</td>\n",
       "      <td>0.652561</td>\n",
       "      <td>0.668657</td>\n",
       "      <td>0.670784</td>\n",
       "      <td>0.669389</td>\n",
       "      <td>0.639038</td>\n",
       "      <td>0.688542</td>\n",
       "      <td>0.681649</td>\n",
       "      <td>0.689416</td>\n",
       "      <td>0.651056</td>\n",
       "      <td>0.675183</td>\n",
       "      <td>0.667291</td>\n",
       "      <td>0.67208</td>\n",
       "      <td>0.685136</td>\n",
       "      <td>0.67303</td>\n",
       "      <td>0.671625</td>\n",
       "      <td>0.667638</td>\n",
       "      <td>0.667927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_0</th>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.00021</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.00013</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.00013</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.00021</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_0</th>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.00038</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.00093</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.00046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.00064</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.000543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.00052</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.00053</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.00053</td>\n",
       "      <td>0.000619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_0</th>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.00046</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.00055</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.000547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.00085</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.000646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.00057</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.00054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.00073</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.00066</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_0</th>\n",
       "      <td>1561.168622</td>\n",
       "      <td>1655.254476</td>\n",
       "      <td>1785.737139</td>\n",
       "      <td>1967.774708</td>\n",
       "      <td>13298.517006</td>\n",
       "      <td>7821.340985</td>\n",
       "      <td>5062.259515</td>\n",
       "      <td>3433.921539</td>\n",
       "      <td>2099.764701</td>\n",
       "      <td>2024.987954</td>\n",
       "      <td>1956.394685</td>\n",
       "      <td>2222.158137</td>\n",
       "      <td>1542.311349</td>\n",
       "      <td>4171.360098</td>\n",
       "      <td>2298.536562</td>\n",
       "      <td>1833.577944</td>\n",
       "      <td>1935.222914</td>\n",
       "      <td>1999.907206</td>\n",
       "      <td>2033.157579</td>\n",
       "      <td>1980.873995</td>\n",
       "      <td>2036.742215</td>\n",
       "      <td>1985.841167</td>\n",
       "      <td>2041.046993</td>\n",
       "      <td>2654.411522</td>\n",
       "      <td>2218.098723</td>\n",
       "      <td>2130.240098</td>\n",
       "      <td>2031.708541</td>\n",
       "      <td>2753.201388</td>\n",
       "      <td>2030.512325</td>\n",
       "      <td>2877.54669</td>\n",
       "      <td>1905.424207</td>\n",
       "      <td>1968.818093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2496.327873</td>\n",
       "      <td>2892.296754</td>\n",
       "      <td>2786.096248</td>\n",
       "      <td>16527.902193</td>\n",
       "      <td>10826.222637</td>\n",
       "      <td>6735.872403</td>\n",
       "      <td>4427.86806</td>\n",
       "      <td>3150.834691</td>\n",
       "      <td>2912.954866</td>\n",
       "      <td>3038.993424</td>\n",
       "      <td>3386.549539</td>\n",
       "      <td>1989.664818</td>\n",
       "      <td>18084.969546</td>\n",
       "      <td>2527.941143</td>\n",
       "      <td>2092.726127</td>\n",
       "      <td>2539.553048</td>\n",
       "      <td>3109.550092</td>\n",
       "      <td>3121.067615</td>\n",
       "      <td>2774.728283</td>\n",
       "      <td>3003.487737</td>\n",
       "      <td>3054.210497</td>\n",
       "      <td>3047.636726</td>\n",
       "      <td>3041.883795</td>\n",
       "      <td>3042.360366</td>\n",
       "      <td>3028.890264</td>\n",
       "      <td>2890.460805</td>\n",
       "      <td>3061.352417</td>\n",
       "      <td>2805.720536</td>\n",
       "      <td>2856.492483</td>\n",
       "      <td>2287.806555</td>\n",
       "      <td>2326.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1808.369364</td>\n",
       "      <td>2018.489243</td>\n",
       "      <td>13131.137615</td>\n",
       "      <td>7769.089104</td>\n",
       "      <td>5047.998719</td>\n",
       "      <td>3381.365592</td>\n",
       "      <td>2120.050649</td>\n",
       "      <td>1989.456368</td>\n",
       "      <td>2051.496196</td>\n",
       "      <td>2259.662788</td>\n",
       "      <td>1606.976883</td>\n",
       "      <td>4179.91919</td>\n",
       "      <td>2320.70705</td>\n",
       "      <td>1832.894399</td>\n",
       "      <td>2010.031883</td>\n",
       "      <td>2003.210191</td>\n",
       "      <td>2055.629763</td>\n",
       "      <td>1960.037607</td>\n",
       "      <td>2068.396405</td>\n",
       "      <td>2070.639691</td>\n",
       "      <td>2044.85402</td>\n",
       "      <td>2205.460381</td>\n",
       "      <td>2245.070151</td>\n",
       "      <td>2189.903237</td>\n",
       "      <td>2059.903488</td>\n",
       "      <td>2440.732517</td>\n",
       "      <td>2019.285212</td>\n",
       "      <td>2363.976182</td>\n",
       "      <td>1887.933024</td>\n",
       "      <td>1944.850933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2515.298283</td>\n",
       "      <td>14872.94196</td>\n",
       "      <td>9415.778239</td>\n",
       "      <td>5965.276878</td>\n",
       "      <td>4168.915212</td>\n",
       "      <td>2298.825642</td>\n",
       "      <td>2172.460161</td>\n",
       "      <td>2626.703993</td>\n",
       "      <td>2675.687736</td>\n",
       "      <td>1799.238784</td>\n",
       "      <td>6303.66189</td>\n",
       "      <td>2602.777907</td>\n",
       "      <td>2008.332158</td>\n",
       "      <td>2127.807703</td>\n",
       "      <td>2174.790428</td>\n",
       "      <td>2221.826831</td>\n",
       "      <td>2146.103432</td>\n",
       "      <td>2285.724235</td>\n",
       "      <td>2458.632976</td>\n",
       "      <td>2445.305753</td>\n",
       "      <td>2459.732365</td>\n",
       "      <td>2376.033211</td>\n",
       "      <td>2433.387427</td>\n",
       "      <td>2478.658477</td>\n",
       "      <td>2748.954088</td>\n",
       "      <td>2249.414323</td>\n",
       "      <td>2654.731377</td>\n",
       "      <td>2272.960315</td>\n",
       "      <td>2661.04673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_avg</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_avg</th>\n",
       "      <td>414.856645</td>\n",
       "      <td>548.290482</td>\n",
       "      <td>364.173247</td>\n",
       "      <td>613.714446</td>\n",
       "      <td>707.166746</td>\n",
       "      <td>611.771343</td>\n",
       "      <td>586.660858</td>\n",
       "      <td>553.418878</td>\n",
       "      <td>456.241542</td>\n",
       "      <td>623.275444</td>\n",
       "      <td>922.864305</td>\n",
       "      <td>321.720103</td>\n",
       "      <td>494.950289</td>\n",
       "      <td>454.416048</td>\n",
       "      <td>438.91655</td>\n",
       "      <td>614.344746</td>\n",
       "      <td>639.444035</td>\n",
       "      <td>528.286021</td>\n",
       "      <td>507.584292</td>\n",
       "      <td>651.542539</td>\n",
       "      <td>949.889761</td>\n",
       "      <td>690.296192</td>\n",
       "      <td>1062.477885</td>\n",
       "      <td>653.001688</td>\n",
       "      <td>733.43111</td>\n",
       "      <td>563.49426</td>\n",
       "      <td>550.100307</td>\n",
       "      <td>519.185825</td>\n",
       "      <td>624.335273</td>\n",
       "      <td>508.079636</td>\n",
       "      <td>588.552482</td>\n",
       "      <td>625.059317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_avg</th>\n",
       "      <td>0.714289</td>\n",
       "      <td>0.7011</td>\n",
       "      <td>0.689562</td>\n",
       "      <td>0.684817</td>\n",
       "      <td>0.666268</td>\n",
       "      <td>0.671117</td>\n",
       "      <td>0.679191</td>\n",
       "      <td>0.679998</td>\n",
       "      <td>0.680437</td>\n",
       "      <td>0.685065</td>\n",
       "      <td>0.687316</td>\n",
       "      <td>0.681841</td>\n",
       "      <td>0.94517</td>\n",
       "      <td>0.996418</td>\n",
       "      <td>0.979558</td>\n",
       "      <td>0.668688</td>\n",
       "      <td>0.681084</td>\n",
       "      <td>0.682296</td>\n",
       "      <td>0.685619</td>\n",
       "      <td>0.661573</td>\n",
       "      <td>0.69487</td>\n",
       "      <td>0.696899</td>\n",
       "      <td>0.694802</td>\n",
       "      <td>0.66333</td>\n",
       "      <td>0.681869</td>\n",
       "      <td>0.680532</td>\n",
       "      <td>0.681224</td>\n",
       "      <td>0.68611</td>\n",
       "      <td>0.685672</td>\n",
       "      <td>0.686596</td>\n",
       "      <td>0.682712</td>\n",
       "      <td>0.682806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_total</th>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_total</th>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.00148</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.013203</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.002251</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.007272</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.00224</td>\n",
       "      <td>0.00258</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.002076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_total</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_0</th>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.001574</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.00019</td>\n",
       "      <td>0.000667</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.00026</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.00023</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.00021</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.001407</td>\n",
       "      <td>0.000996</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.00017</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000269</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.00021</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.000306</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.00139</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.00023</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.00026</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000202</td>\n",
       "      <td>0.000246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_generated_tokens</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_config_decoding_mode</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            0   \\\n",
       "config_name                                                                    num_processes_1   \n",
       "experiment_id                                                                                1   \n",
       "date_time                                                        April 08, 2025 at 04:31:33 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                1   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.000434   \n",
       "total_energy_joules                                                                1561.168622   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.640546   \n",
       "joules_per_token                                                                      1.561169   \n",
       "flops_per_joule                                                               662672893.521465   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.356892   \n",
       "average_latency_ms_per_batch                                                       2356.891729   \n",
       "throughput_queries_per_sec                                                            4.242876   \n",
       "throughput_tokens_per_sec                                                           424.287627   \n",
       "cpu_usage_percent                                                                          3.9   \n",
       "cpu_memory_usage_bytes                                                              2050256896   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                  0.0   \n",
       "gpu_utilization_percent_3                                                                 35.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  12008292352   \n",
       "gpu_max_memory_reserved_bytes                                                      12008292352   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                        NaN   \n",
       "cpu_power_process_2                                                                        NaN   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                 414.856645   \n",
       "gpu_power_process_1                                                                        NaN   \n",
       "gpu_power_process_2                                                                        NaN   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   0.714289   \n",
       "ram_power_process_1                                                                        NaN   \n",
       "ram_power_process_2                                                                        NaN   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                  0.000078   \n",
       "cpu_energy_process_1                                                                       NaN   \n",
       "cpu_energy_process_2                                                                       NaN   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                  0.000355   \n",
       "gpu_energy_process_1                                                                       NaN   \n",
       "gpu_energy_process_2                                                                       NaN   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                       NaN   \n",
       "ram_energy_process_2                                                                       NaN   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.000434   \n",
       "total_energy_kwh_process_1                                                                 NaN   \n",
       "total_energy_kwh_process_2                                                                 NaN   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                      1561.168622   \n",
       "total_energy_joules_process_1                                                              NaN   \n",
       "total_energy_joules_process_2                                                              NaN   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       414.856645   \n",
       "ram_power_avg                                                                         0.714289   \n",
       "cpu_energy_total                                                                      0.000078   \n",
       "gpu_energy_total                                                                      0.000355   \n",
       "ram_energy_total                                                                           0.0   \n",
       "per-process_emissions_0                                                               0.000165   \n",
       "per-process_emissions_1                                                                    NaN   \n",
       "per-process_emissions_2                                                                    NaN   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "\n",
       "                                                                                            1   \\\n",
       "config_name                                                                    num_processes_2   \n",
       "experiment_id                                                                                2   \n",
       "date_time                                                        April 08, 2025 at 04:32:06 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                2   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.001153   \n",
       "total_energy_joules                                                                 4151.58235   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.240872   \n",
       "joules_per_token                                                                      4.151582   \n",
       "flops_per_joule                                                               249192727.209392   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.401629   \n",
       "average_latency_ms_per_batch                                                       2401.628917   \n",
       "throughput_queries_per_sec                                                            4.163841   \n",
       "throughput_tokens_per_sec                                                            416.38406   \n",
       "cpu_usage_percent                                                                          2.8   \n",
       "cpu_memory_usage_bytes                                                              2070810624   \n",
       "gpu_utilization_percent_0                                                                 65.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                  0.0   \n",
       "gpu_utilization_percent_3                                                                 71.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                        NaN   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                 605.276451   \n",
       "gpu_power_process_1                                                                 491.304513   \n",
       "gpu_power_process_2                                                                        NaN   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   0.721865   \n",
       "ram_power_process_1                                                                   0.680336   \n",
       "ram_power_process_2                                                                        NaN   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                   0.00008   \n",
       "cpu_energy_process_1                                                                  0.000126   \n",
       "cpu_energy_process_2                                                                       NaN   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                   0.00038   \n",
       "gpu_energy_process_1                                                                  0.000567   \n",
       "gpu_energy_process_2                                                                       NaN   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       NaN   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                             0.00046   \n",
       "total_energy_kwh_process_1                                                            0.000693   \n",
       "total_energy_kwh_process_2                                                                 NaN   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                      1655.254476   \n",
       "total_energy_joules_process_1                                                      2496.327873   \n",
       "total_energy_joules_process_2                                                              NaN   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       548.290482   \n",
       "ram_power_avg                                                                           0.7011   \n",
       "cpu_energy_total                                                                      0.000205   \n",
       "gpu_energy_total                                                                      0.000947   \n",
       "ram_energy_total                                                                      0.000001   \n",
       "per-process_emissions_0                                                               0.000175   \n",
       "per-process_emissions_1                                                               0.000264   \n",
       "per-process_emissions_2                                                                    NaN   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "\n",
       "                                                                                            2   \\\n",
       "config_name                                                                    num_processes_3   \n",
       "experiment_id                                                                                3   \n",
       "date_time                                                        April 08, 2025 at 04:32:41 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                3   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.001802   \n",
       "total_energy_joules                                                                6486.403256   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.154169   \n",
       "joules_per_token                                                                      6.486403   \n",
       "flops_per_joule                                                               159494266.256535   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.346066   \n",
       "average_latency_ms_per_batch                                                       2346.066005   \n",
       "throughput_queries_per_sec                                                            4.262455   \n",
       "throughput_tokens_per_sec                                                           426.245467   \n",
       "cpu_usage_percent                                                                          4.9   \n",
       "cpu_memory_usage_bytes                                                              2068250624   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                 560.689296   \n",
       "gpu_power_process_1                                                                        0.0   \n",
       "gpu_power_process_2                                                                 531.830444   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   0.719776   \n",
       "ram_power_process_1                                                                   0.678097   \n",
       "ram_power_process_2                                                                   0.670814   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                  0.000078   \n",
       "cpu_energy_process_1                                                                  0.000162   \n",
       "cpu_energy_process_2                                                                   0.00008   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                  0.000417   \n",
       "gpu_energy_process_1                                                                   0.00064   \n",
       "gpu_energy_process_2                                                                  0.000422   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.000496   \n",
       "total_energy_kwh_process_1                                                            0.000803   \n",
       "total_energy_kwh_process_2                                                            0.000502   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                      1785.737139   \n",
       "total_energy_joules_process_1                                                      2892.296754   \n",
       "total_energy_joules_process_2                                                      1808.369364   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       364.173247   \n",
       "ram_power_avg                                                                         0.689562   \n",
       "cpu_energy_total                                                                      0.000321   \n",
       "gpu_energy_total                                                                       0.00148   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000191   \n",
       "per-process_emissions_1                                                               0.000306   \n",
       "per-process_emissions_2                                                               0.000189   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "\n",
       "                                                                                            3   \\\n",
       "config_name                                                                    num_processes_4   \n",
       "experiment_id                                                                                4   \n",
       "date_time                                                        April 08, 2025 at 04:33:15 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                       0.00258   \n",
       "total_energy_joules                                                                9287.658482   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                       0.10767   \n",
       "joules_per_token                                                                      9.287658   \n",
       "flops_per_joule                                                               111389122.454932   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.372563   \n",
       "average_latency_ms_per_batch                                                       2372.563443   \n",
       "throughput_queries_per_sec                                                             4.21485   \n",
       "throughput_tokens_per_sec                                                           421.485041   \n",
       "cpu_usage_percent                                                                          4.4   \n",
       "cpu_memory_usage_bytes                                                              2075455488   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 788.015735   \n",
       "gpu_power_process_1                                                                 424.010995   \n",
       "gpu_power_process_2                                                                 708.880427   \n",
       "gpu_power_process_3                                                                 533.950626   \n",
       "ram_power_process_0                                                                   0.722456   \n",
       "ram_power_process_1                                                                   0.666578   \n",
       "ram_power_process_2                                                                   0.677396   \n",
       "ram_power_process_3                                                                   0.672838   \n",
       "cpu_energy_process_0                                                                  0.000079   \n",
       "cpu_energy_process_1                                                                   0.00012   \n",
       "cpu_energy_process_2                                                                  0.000081   \n",
       "cpu_energy_process_3                                                                  0.000105   \n",
       "gpu_energy_process_0                                                                  0.000467   \n",
       "gpu_energy_process_1                                                                  0.000654   \n",
       "gpu_energy_process_2                                                                  0.000479   \n",
       "gpu_energy_process_3                                                                  0.000594   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                  0.000001   \n",
       "total_energy_kwh_process_0                                                            0.000547   \n",
       "total_energy_kwh_process_1                                                            0.000774   \n",
       "total_energy_kwh_process_2                                                            0.000561   \n",
       "total_energy_kwh_process_3                                                            0.000699   \n",
       "total_energy_joules_process_0                                                      1967.774708   \n",
       "total_energy_joules_process_1                                                      2786.096248   \n",
       "total_energy_joules_process_2                                                      2018.489243   \n",
       "total_energy_joules_process_3                                                      2515.298283   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       613.714446   \n",
       "ram_power_avg                                                                         0.684817   \n",
       "cpu_energy_total                                                                      0.000384   \n",
       "gpu_energy_total                                                                      0.002194   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000295   \n",
       "per-process_emissions_1                                                               0.000208   \n",
       "per-process_emissions_2                                                               0.000266   \n",
       "per-process_emissions_3                                                               0.000214   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "\n",
       "                                                                                            4   \\\n",
       "config_name                                                                         batching_1   \n",
       "experiment_id                                                                                5   \n",
       "date_time                                                        April 08, 2025 at 04:34:12 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                  1   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.016064   \n",
       "total_energy_joules                                                               57830.498773   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.017292   \n",
       "joules_per_token                                                                     57.830499   \n",
       "flops_per_joule                                                                 17889247.88724   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             20.824448   \n",
       "average_latency_ms_per_batch                                                       2082.444752   \n",
       "throughput_queries_per_sec                                                            0.480205   \n",
       "throughput_tokens_per_sec                                                            48.020482   \n",
       "cpu_usage_percent                                                                          5.0   \n",
       "cpu_memory_usage_bytes                                                              2015477760   \n",
       "gpu_utilization_percent_0                                                                 57.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817967616   \n",
       "gpu_max_memory_allocated_bytes                                                      8817967616   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1313.057996   \n",
       "gpu_power_process_1                                                                 466.001815   \n",
       "gpu_power_process_2                                                                 469.151347   \n",
       "gpu_power_process_3                                                                 580.455824   \n",
       "ram_power_process_0                                                                   0.702599   \n",
       "ram_power_process_1                                                                   0.659914   \n",
       "ram_power_process_2                                                                   0.652318   \n",
       "ram_power_process_3                                                                   0.650243   \n",
       "cpu_energy_process_0                                                                  0.000652   \n",
       "cpu_energy_process_1                                                                  0.000822   \n",
       "cpu_energy_process_2                                                                  0.000644   \n",
       "cpu_energy_process_3                                                                  0.000729   \n",
       "gpu_energy_process_0                                                                  0.003039   \n",
       "gpu_energy_process_1                                                                  0.003765   \n",
       "gpu_energy_process_2                                                                  0.003001   \n",
       "gpu_energy_process_3                                                                  0.003399   \n",
       "ram_energy_process_0                                                                  0.000003   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000003   \n",
       "ram_energy_process_3                                                                  0.000003   \n",
       "total_energy_kwh_process_0                                                            0.003694   \n",
       "total_energy_kwh_process_1                                                            0.004591   \n",
       "total_energy_kwh_process_2                                                            0.003648   \n",
       "total_energy_kwh_process_3                                                            0.004131   \n",
       "total_energy_joules_process_0                                                     13298.517006   \n",
       "total_energy_joules_process_1                                                     16527.902193   \n",
       "total_energy_joules_process_2                                                     13131.137615   \n",
       "total_energy_joules_process_3                                                      14872.94196   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       707.166746   \n",
       "ram_power_avg                                                                         0.666268   \n",
       "cpu_energy_total                                                                      0.002848   \n",
       "gpu_energy_total                                                                      0.013203   \n",
       "ram_energy_total                                                                      0.000014   \n",
       "per-process_emissions_0                                                               0.001574   \n",
       "per-process_emissions_1                                                               0.001749   \n",
       "per-process_emissions_2                                                               0.001407   \n",
       "per-process_emissions_3                                                                0.00139   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "\n",
       "                                                                                            5   \\\n",
       "config_name                                                                         batching_2   \n",
       "experiment_id                                                                                6   \n",
       "date_time                                                        April 08, 2025 at 04:34:59 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                  2   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.009953   \n",
       "total_energy_joules                                                               35832.430964   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.027908   \n",
       "joules_per_token                                                                     35.832431   \n",
       "flops_per_joule                                                                28871725.980626   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             10.598905   \n",
       "average_latency_ms_per_batch                                                       2119.780987   \n",
       "throughput_queries_per_sec                                                            0.943494   \n",
       "throughput_tokens_per_sec                                                             94.34937   \n",
       "cpu_usage_percent                                                                         17.6   \n",
       "cpu_memory_usage_bytes                                                              2049409024   \n",
       "gpu_utilization_percent_0                                                                 20.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817965056   \n",
       "gpu_max_memory_allocated_bytes                                                      8817965056   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 641.064988   \n",
       "gpu_power_process_1                                                                 518.360923   \n",
       "gpu_power_process_2                                                                 629.644402   \n",
       "gpu_power_process_3                                                                  658.01506   \n",
       "ram_power_process_0                                                                    0.71335   \n",
       "ram_power_process_1                                                                   0.656784   \n",
       "ram_power_process_2                                                                   0.656422   \n",
       "ram_power_process_3                                                                   0.657912   \n",
       "cpu_energy_process_0                                                                  0.000335   \n",
       "cpu_energy_process_1                                                                  0.000488   \n",
       "cpu_energy_process_2                                                                  0.000333   \n",
       "cpu_energy_process_3                                                                  0.000412   \n",
       "gpu_energy_process_0                                                                  0.001836   \n",
       "gpu_energy_process_1                                                                  0.002517   \n",
       "gpu_energy_process_2                                                                  0.001823   \n",
       "gpu_energy_process_3                                                                  0.002202   \n",
       "ram_energy_process_0                                                                  0.000002   \n",
       "ram_energy_process_1                                                                  0.000002   \n",
       "ram_energy_process_2                                                                  0.000002   \n",
       "ram_energy_process_3                                                                  0.000002   \n",
       "total_energy_kwh_process_0                                                            0.002173   \n",
       "total_energy_kwh_process_1                                                            0.003007   \n",
       "total_energy_kwh_process_2                                                            0.002158   \n",
       "total_energy_kwh_process_3                                                            0.002615   \n",
       "total_energy_joules_process_0                                                      7821.340985   \n",
       "total_energy_joules_process_1                                                     10826.222637   \n",
       "total_energy_joules_process_2                                                      7769.089104   \n",
       "total_energy_joules_process_3                                                      9415.778239   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       611.771343   \n",
       "ram_power_avg                                                                         0.671117   \n",
       "cpu_energy_total                                                                      0.001568   \n",
       "gpu_energy_total                                                                      0.008378   \n",
       "ram_energy_total                                                                      0.000008   \n",
       "per-process_emissions_0                                                               0.001146   \n",
       "per-process_emissions_1                                                               0.000828   \n",
       "per-process_emissions_2                                                               0.000996   \n",
       "per-process_emissions_3                                                               0.000822   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "\n",
       "                                                                                            6   \\\n",
       "config_name                                                                         batching_4   \n",
       "experiment_id                                                                                7   \n",
       "date_time                                                        April 08, 2025 at 04:35:43 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                  4   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.006337   \n",
       "total_energy_joules                                                               22811.407515   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.043838   \n",
       "joules_per_token                                                                     22.811408   \n",
       "flops_per_joule                                                                45352051.482635   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              6.579609   \n",
       "average_latency_ms_per_batch                                                        2193.20311   \n",
       "throughput_queries_per_sec                                                            1.519847   \n",
       "throughput_tokens_per_sec                                                           151.984708   \n",
       "cpu_usage_percent                                                                          4.0   \n",
       "cpu_memory_usage_bytes                                                              2057400320   \n",
       "gpu_utilization_percent_0                                                                 67.0   \n",
       "gpu_utilization_percent_1                                                                 73.0   \n",
       "gpu_utilization_percent_2                                                                 99.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817964032   \n",
       "gpu_max_memory_allocated_bytes                                                      8817964032   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  677.58912   \n",
       "gpu_power_process_1                                                                 369.103744   \n",
       "gpu_power_process_2                                                                 632.178172   \n",
       "gpu_power_process_3                                                                 667.772397   \n",
       "ram_power_process_0                                                                    0.71698   \n",
       "ram_power_process_1                                                                   0.662802   \n",
       "ram_power_process_2                                                                   0.671325   \n",
       "ram_power_process_3                                                                    0.66566   \n",
       "cpu_energy_process_0                                                                   0.00021   \n",
       "cpu_energy_process_1                                                                    0.0003   \n",
       "cpu_energy_process_2                                                                   0.00021   \n",
       "cpu_energy_process_3                                                                  0.000255   \n",
       "gpu_energy_process_0                                                                  0.001195   \n",
       "gpu_energy_process_1                                                                  0.001569   \n",
       "gpu_energy_process_2                                                                  0.001192   \n",
       "gpu_energy_process_3                                                                  0.001401   \n",
       "ram_energy_process_0                                                                  0.000001   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                  0.000001   \n",
       "ram_energy_process_3                                                                  0.000001   \n",
       "total_energy_kwh_process_0                                                            0.001406   \n",
       "total_energy_kwh_process_1                                                            0.001871   \n",
       "total_energy_kwh_process_2                                                            0.001402   \n",
       "total_energy_kwh_process_3                                                            0.001657   \n",
       "total_energy_joules_process_0                                                      5062.259515   \n",
       "total_energy_joules_process_1                                                      6735.872403   \n",
       "total_energy_joules_process_2                                                      5047.998719   \n",
       "total_energy_joules_process_3                                                      5965.276878   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       586.660858   \n",
       "ram_power_avg                                                                         0.679191   \n",
       "cpu_energy_total                                                                      0.000975   \n",
       "gpu_energy_total                                                                      0.005357   \n",
       "ram_energy_total                                                                      0.000005   \n",
       "per-process_emissions_0                                                               0.000631   \n",
       "per-process_emissions_1                                                               0.000534   \n",
       "per-process_emissions_2                                                               0.000713   \n",
       "per-process_emissions_3                                                               0.000536   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "\n",
       "                                                                                            7   \\\n",
       "config_name                                                                         batching_8   \n",
       "experiment_id                                                                                8   \n",
       "date_time                                                        April 08, 2025 at 04:36:20 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                  8   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.004281   \n",
       "total_energy_joules                                                               15412.070402   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.064884   \n",
       "joules_per_token                                                                      15.41207   \n",
       "flops_per_joule                                                                67125577.616509   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              4.488748   \n",
       "average_latency_ms_per_batch                                                         2244.3741   \n",
       "throughput_queries_per_sec                                                            2.227793   \n",
       "throughput_tokens_per_sec                                                           222.779259   \n",
       "cpu_usage_percent                                                                         16.3   \n",
       "cpu_memory_usage_bytes                                                              2067193856   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  623.64748   \n",
       "gpu_power_process_1                                                                 483.293236   \n",
       "gpu_power_process_2                                                                 561.420978   \n",
       "gpu_power_process_3                                                                 545.313817   \n",
       "ram_power_process_0                                                                   0.720617   \n",
       "ram_power_process_1                                                                   0.667093   \n",
       "ram_power_process_2                                                                   0.665362   \n",
       "ram_power_process_3                                                                   0.666917   \n",
       "cpu_energy_process_0                                                                  0.000145   \n",
       "cpu_energy_process_1                                                                  0.000195   \n",
       "cpu_energy_process_2                                                                  0.000145   \n",
       "cpu_energy_process_3                                                                   0.00018   \n",
       "gpu_energy_process_0                                                                  0.000808   \n",
       "gpu_energy_process_1                                                                  0.001034   \n",
       "gpu_energy_process_2                                                                  0.000794   \n",
       "gpu_energy_process_3                                                                  0.000977   \n",
       "ram_energy_process_0                                                                  0.000001   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                  0.000001   \n",
       "ram_energy_process_3                                                                  0.000001   \n",
       "total_energy_kwh_process_0                                                            0.000954   \n",
       "total_energy_kwh_process_1                                                             0.00123   \n",
       "total_energy_kwh_process_2                                                            0.000939   \n",
       "total_energy_kwh_process_3                                                            0.001158   \n",
       "total_energy_joules_process_0                                                      3433.921539   \n",
       "total_energy_joules_process_1                                                       4427.86806   \n",
       "total_energy_joules_process_2                                                      3381.365592   \n",
       "total_energy_joules_process_3                                                      4168.915212   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       553.418878   \n",
       "ram_power_avg                                                                         0.679998   \n",
       "cpu_energy_total                                                                      0.000665   \n",
       "gpu_energy_total                                                                      0.003613   \n",
       "ram_energy_total                                                                      0.000003   \n",
       "per-process_emissions_0                                                               0.000441   \n",
       "per-process_emissions_1                                                               0.000363   \n",
       "per-process_emissions_2                                                               0.000469   \n",
       "per-process_emissions_3                                                               0.000358   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "\n",
       "                                                                                            8   \\\n",
       "config_name                                                                        batching_16   \n",
       "experiment_id                                                                                9   \n",
       "date_time                                                        April 08, 2025 at 04:36:58 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.002686   \n",
       "total_energy_joules                                                                9669.475684   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.103418   \n",
       "joules_per_token                                                                      9.669476   \n",
       "flops_per_joule                                                               106990716.129887   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                               2.56615   \n",
       "average_latency_ms_per_batch                                                       2566.149628   \n",
       "throughput_queries_per_sec                                                            3.896889   \n",
       "throughput_tokens_per_sec                                                            389.68889   \n",
       "cpu_usage_percent                                                                         47.4   \n",
       "cpu_memory_usage_bytes                                                              2073178112   \n",
       "gpu_utilization_percent_0                                                                 69.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 641.468533   \n",
       "gpu_power_process_1                                                                        0.0   \n",
       "gpu_power_process_2                                                                 588.174565   \n",
       "gpu_power_process_3                                                                 595.323068   \n",
       "ram_power_process_0                                                                    0.72172   \n",
       "ram_power_process_1                                                                   0.667399   \n",
       "ram_power_process_2                                                                   0.666369   \n",
       "ram_power_process_3                                                                   0.666261   \n",
       "cpu_energy_process_0                                                                  0.000086   \n",
       "cpu_energy_process_1                                                                  0.000166   \n",
       "cpu_energy_process_2                                                                  0.000086   \n",
       "cpu_energy_process_3                                                                  0.000095   \n",
       "gpu_energy_process_0                                                                  0.000497   \n",
       "gpu_energy_process_1                                                                  0.000708   \n",
       "gpu_energy_process_2                                                                  0.000502   \n",
       "gpu_energy_process_3                                                                  0.000543   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                       0.0   \n",
       "total_energy_kwh_process_0                                                            0.000583   \n",
       "total_energy_kwh_process_1                                                            0.000875   \n",
       "total_energy_kwh_process_2                                                            0.000589   \n",
       "total_energy_kwh_process_3                                                            0.000639   \n",
       "total_energy_joules_process_0                                                      2099.764701   \n",
       "total_energy_joules_process_1                                                      3150.834691   \n",
       "total_energy_joules_process_2                                                      2120.050649   \n",
       "total_energy_joules_process_3                                                      2298.825642   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       456.241542   \n",
       "ram_power_avg                                                                         0.680437   \n",
       "cpu_energy_total                                                                      0.000433   \n",
       "gpu_energy_total                                                                      0.002251   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000222   \n",
       "per-process_emissions_1                                                               0.000243   \n",
       "per-process_emissions_2                                                               0.000333   \n",
       "per-process_emissions_3                                                               0.000224   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "\n",
       "                                                                                            9   \\\n",
       "config_name                                                                        batching_32   \n",
       "experiment_id                                                                               10   \n",
       "date_time                                                        April 08, 2025 at 04:37:33 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 32   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.002528   \n",
       "total_energy_joules                                                                9099.859349   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.109892   \n",
       "joules_per_token                                                                      9.099859   \n",
       "flops_per_joule                                                               113687925.088365   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.408858   \n",
       "average_latency_ms_per_batch                                                       2408.858126   \n",
       "throughput_queries_per_sec                                                            4.151345   \n",
       "throughput_tokens_per_sec                                                           415.134453   \n",
       "cpu_usage_percent                                                                          5.8   \n",
       "cpu_memory_usage_bytes                                                              2076033024   \n",
       "gpu_utilization_percent_0                                                                  4.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 705.181102   \n",
       "gpu_power_process_1                                                                 505.669169   \n",
       "gpu_power_process_2                                                                 683.577268   \n",
       "gpu_power_process_3                                                                 598.674237   \n",
       "ram_power_process_0                                                                   0.722474   \n",
       "ram_power_process_1                                                                    0.67005   \n",
       "ram_power_process_2                                                                   0.669521   \n",
       "ram_power_process_3                                                                   0.678216   \n",
       "cpu_energy_process_0                                                                   0.00008   \n",
       "cpu_energy_process_1                                                                  0.000125   \n",
       "cpu_energy_process_2                                                                  0.000079   \n",
       "cpu_energy_process_3                                                                   0.00009   \n",
       "gpu_energy_process_0                                                                  0.000482   \n",
       "gpu_energy_process_1                                                                  0.000683   \n",
       "gpu_energy_process_2                                                                  0.000473   \n",
       "gpu_energy_process_3                                                                  0.000513   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                       0.0   \n",
       "total_energy_kwh_process_0                                                            0.000562   \n",
       "total_energy_kwh_process_1                                                            0.000809   \n",
       "total_energy_kwh_process_2                                                            0.000553   \n",
       "total_energy_kwh_process_3                                                            0.000603   \n",
       "total_energy_joules_process_0                                                      2024.987954   \n",
       "total_energy_joules_process_1                                                      2912.954866   \n",
       "total_energy_joules_process_2                                                      1989.456368   \n",
       "total_energy_joules_process_3                                                      2172.460161   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       623.275444   \n",
       "ram_power_avg                                                                         0.685065   \n",
       "cpu_energy_total                                                                      0.000375   \n",
       "gpu_energy_total                                                                      0.002151   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000211   \n",
       "per-process_emissions_1                                                                0.00023   \n",
       "per-process_emissions_2                                                               0.000214   \n",
       "per-process_emissions_3                                                               0.000308   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "\n",
       "                                                                                            10  \\\n",
       "config_name                                                                        batching_64   \n",
       "experiment_id                                                                               11   \n",
       "date_time                                                        April 08, 2025 at 04:38:19 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 64   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.002687   \n",
       "total_energy_joules                                                                9673.588298   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.103374   \n",
       "joules_per_token                                                                      9.673588   \n",
       "flops_per_joule                                                               106945230.268081   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.385437   \n",
       "average_latency_ms_per_batch                                                       2385.437419   \n",
       "throughput_queries_per_sec                                                            4.192103   \n",
       "throughput_tokens_per_sec                                                           419.210327   \n",
       "cpu_usage_percent                                                                          5.0   \n",
       "cpu_memory_usage_bytes                                                              2071547904   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 651.046027   \n",
       "gpu_power_process_1                                                                1743.091048   \n",
       "gpu_power_process_2                                                                 742.100489   \n",
       "gpu_power_process_3                                                                 555.219656   \n",
       "ram_power_process_0                                                                   0.721355   \n",
       "ram_power_process_1                                                                   0.670575   \n",
       "ram_power_process_2                                                                   0.680642   \n",
       "ram_power_process_3                                                                   0.676693   \n",
       "cpu_energy_process_0                                                                  0.000078   \n",
       "cpu_energy_process_1                                                                  0.000131   \n",
       "cpu_energy_process_2                                                                  0.000081   \n",
       "cpu_energy_process_3                                                                  0.000107   \n",
       "gpu_energy_process_0                                                                  0.000465   \n",
       "gpu_energy_process_1                                                                  0.000713   \n",
       "gpu_energy_process_2                                                                  0.000489   \n",
       "gpu_energy_process_3                                                                  0.000622   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                  0.000001   \n",
       "total_energy_kwh_process_0                                                            0.000543   \n",
       "total_energy_kwh_process_1                                                            0.000844   \n",
       "total_energy_kwh_process_2                                                             0.00057   \n",
       "total_energy_kwh_process_3                                                             0.00073   \n",
       "total_energy_joules_process_0                                                      1956.394685   \n",
       "total_energy_joules_process_1                                                      3038.993424   \n",
       "total_energy_joules_process_2                                                      2051.496196   \n",
       "total_energy_joules_process_3                                                      2626.703993   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       922.864305   \n",
       "ram_power_avg                                                                         0.687316   \n",
       "cpu_energy_total                                                                      0.000397   \n",
       "gpu_energy_total                                                                      0.002288   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000322   \n",
       "per-process_emissions_1                                                               0.000278   \n",
       "per-process_emissions_2                                                               0.000207   \n",
       "per-process_emissions_3                                                               0.000217   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "\n",
       "                                                                                            11  \\\n",
       "config_name                                  precis_float32_quant_False_quant8_False_quant4...   \n",
       "experiment_id                                                                               12   \n",
       "date_time                                                        April 08, 2025 at 04:38:55 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.002929   \n",
       "total_energy_joules                                                                 10544.0582   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                       0.09484   \n",
       "joules_per_token                                                                     10.544058   \n",
       "flops_per_joule                                                                98116314.268051   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.286825   \n",
       "average_latency_ms_per_batch                                                       2286.825385   \n",
       "throughput_queries_per_sec                                                            4.372874   \n",
       "throughput_tokens_per_sec                                                           437.287432   \n",
       "cpu_usage_percent                                                                          8.0   \n",
       "cpu_memory_usage_bytes                                                              2073534464   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 619.770725   \n",
       "gpu_power_process_1                                                                        0.0   \n",
       "gpu_power_process_2                                                                 667.109686   \n",
       "gpu_power_process_3                                                                        0.0   \n",
       "ram_power_process_0                                                                   0.721694   \n",
       "ram_power_process_1                                                                   0.668138   \n",
       "ram_power_process_2                                                                   0.666388   \n",
       "ram_power_process_3                                                                   0.671143   \n",
       "cpu_energy_process_0                                                                  0.000109   \n",
       "cpu_energy_process_1                                                                  0.000196   \n",
       "cpu_energy_process_2                                                                  0.000111   \n",
       "cpu_energy_process_3                                                                  0.000157   \n",
       "gpu_energy_process_0                                                                  0.000507   \n",
       "gpu_energy_process_1                                                                  0.000744   \n",
       "gpu_energy_process_2                                                                  0.000516   \n",
       "gpu_energy_process_3                                                                  0.000586   \n",
       "ram_energy_process_0                                                                  0.000001   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                  0.000001   \n",
       "ram_energy_process_3                                                                  0.000001   \n",
       "total_energy_kwh_process_0                                                            0.000617   \n",
       "total_energy_kwh_process_1                                                            0.000941   \n",
       "total_energy_kwh_process_2                                                            0.000628   \n",
       "total_energy_kwh_process_3                                                            0.000743   \n",
       "total_energy_joules_process_0                                                      2222.158137   \n",
       "total_energy_joules_process_1                                                      3386.549539   \n",
       "total_energy_joules_process_2                                                      2259.662788   \n",
       "total_energy_joules_process_3                                                      2675.687736   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       321.720103   \n",
       "ram_power_avg                                                                         0.681841   \n",
       "cpu_energy_total                                                                      0.000572   \n",
       "gpu_energy_total                                                                      0.002353   \n",
       "ram_energy_total                                                                      0.000003   \n",
       "per-process_emissions_0                                                               0.000358   \n",
       "per-process_emissions_1                                                               0.000235   \n",
       "per-process_emissions_2                                                               0.000283   \n",
       "per-process_emissions_3                                                               0.000239   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "\n",
       "                                                                                            12  \\\n",
       "config_name                                  precis_float16_quant_False_quant8_False_quant4...   \n",
       "experiment_id                                                                               13   \n",
       "date_time                                                        April 08, 2025 at 04:39:28 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.001927   \n",
       "total_energy_joules                                                                6938.191835   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                       0.14413   \n",
       "joules_per_token                                                                      6.938192   \n",
       "flops_per_joule                                                               149108608.219022   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.363797   \n",
       "average_latency_ms_per_batch                                                         2363.7969   \n",
       "throughput_queries_per_sec                                                            4.230482   \n",
       "throughput_tokens_per_sec                                                            423.04819   \n",
       "cpu_usage_percent                                                                          5.1   \n",
       "cpu_memory_usage_bytes                                                              3161710592   \n",
       "gpu_utilization_percent_0                                                                  4.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  4419607552   \n",
       "gpu_max_memory_allocated_bytes                                                      4419607552   \n",
       "gpu_current_memory_reserved_bytes                                                   6838812672   \n",
       "gpu_max_memory_reserved_bytes                                                       6838812672   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  675.28713   \n",
       "gpu_power_process_1                                                                 119.894599   \n",
       "gpu_power_process_2                                                                 594.917177   \n",
       "gpu_power_process_3                                                                 589.702252   \n",
       "ram_power_process_0                                                                   1.102643   \n",
       "ram_power_process_1                                                                   0.871312   \n",
       "ram_power_process_2                                                                   0.913636   \n",
       "ram_power_process_3                                                                   0.893091   \n",
       "cpu_energy_process_0                                                                  0.000078   \n",
       "cpu_energy_process_1                                                                  0.000099   \n",
       "cpu_energy_process_2                                                                   0.00008   \n",
       "cpu_energy_process_3                                                                  0.000089   \n",
       "gpu_energy_process_0                                                                   0.00035   \n",
       "gpu_energy_process_1                                                                  0.000453   \n",
       "gpu_energy_process_2                                                                  0.000366   \n",
       "gpu_energy_process_3                                                                  0.000411   \n",
       "ram_energy_process_0                                                                  0.000001   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                  0.000001   \n",
       "ram_energy_process_3                                                                  0.000001   \n",
       "total_energy_kwh_process_0                                                            0.000428   \n",
       "total_energy_kwh_process_1                                                            0.000553   \n",
       "total_energy_kwh_process_2                                                            0.000446   \n",
       "total_energy_kwh_process_3                                                              0.0005   \n",
       "total_energy_joules_process_0                                                      1542.311349   \n",
       "total_energy_joules_process_1                                                      1989.664818   \n",
       "total_energy_joules_process_2                                                      1606.976883   \n",
       "total_energy_joules_process_3                                                      1799.238784   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       494.950289   \n",
       "ram_power_avg                                                                          0.94517   \n",
       "cpu_energy_total                                                                      0.000346   \n",
       "gpu_energy_total                                                                      0.001579   \n",
       "ram_energy_total                                                                      0.000003   \n",
       "per-process_emissions_0                                                                0.00019   \n",
       "per-process_emissions_1                                                               0.000163   \n",
       "per-process_emissions_2                                                                0.00017   \n",
       "per-process_emissions_3                                                               0.000211   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "\n",
       "                                                                                            13  \\\n",
       "config_name                                  precis_float16_quant_True_quant8_True_quant4_F...   \n",
       "experiment_id                                                                               14   \n",
       "date_time                                                        April 08, 2025 at 04:40:33 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                              True   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.009094   \n",
       "total_energy_joules                                                               32739.910723   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.030544   \n",
       "joules_per_token                                                                     32.739911   \n",
       "flops_per_joule                                                                31598868.327846   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              7.218139   \n",
       "average_latency_ms_per_batch                                                       7218.139077   \n",
       "throughput_queries_per_sec                                                            1.385399   \n",
       "throughput_tokens_per_sec                                                           138.539863   \n",
       "cpu_usage_percent                                                                          4.7   \n",
       "cpu_memory_usage_bytes                                                              2766688256   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                 96.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1576284160   \n",
       "gpu_max_memory_allocated_bytes                                                      1576284160   \n",
       "gpu_current_memory_reserved_bytes                                                   2885681152   \n",
       "gpu_max_memory_reserved_bytes                                                       2885681152   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 444.462409   \n",
       "gpu_power_process_1                                                                 374.736474   \n",
       "gpu_power_process_2                                                                  518.21448   \n",
       "gpu_power_process_3                                                                 480.250829   \n",
       "ram_power_process_0                                                                   0.965406   \n",
       "ram_power_process_1                                                                   1.010028   \n",
       "ram_power_process_2                                                                   1.010149   \n",
       "ram_power_process_3                                                                   1.000088   \n",
       "cpu_energy_process_0                                                                  0.000227   \n",
       "cpu_energy_process_1                                                                  0.001001   \n",
       "cpu_energy_process_2                                                                  0.000229   \n",
       "cpu_energy_process_3                                                                  0.000352   \n",
       "gpu_energy_process_0                                                                   0.00093   \n",
       "gpu_energy_process_1                                                                  0.004014   \n",
       "gpu_energy_process_2                                                                  0.000931   \n",
       "gpu_energy_process_3                                                                  0.001397   \n",
       "ram_energy_process_0                                                                  0.000001   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000002   \n",
       "ram_energy_process_3                                                                  0.000003   \n",
       "total_energy_kwh_process_0                                                            0.001159   \n",
       "total_energy_kwh_process_1                                                            0.005024   \n",
       "total_energy_kwh_process_2                                                            0.001161   \n",
       "total_energy_kwh_process_3                                                            0.001751   \n",
       "total_energy_joules_process_0                                                      4171.360098   \n",
       "total_energy_joules_process_1                                                     18084.969546   \n",
       "total_energy_joules_process_2                                                       4179.91919   \n",
       "total_energy_joules_process_3                                                       6303.66189   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       454.416048   \n",
       "ram_power_avg                                                                         0.996418   \n",
       "cpu_energy_total                                                                      0.001809   \n",
       "gpu_energy_total                                                                      0.007272   \n",
       "ram_energy_total                                                                      0.000014   \n",
       "per-process_emissions_0                                                               0.000667   \n",
       "per-process_emissions_1                                                               0.000441   \n",
       "per-process_emissions_2                                                               0.000442   \n",
       "per-process_emissions_3                                                               0.001914   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "\n",
       "                                                                                            14  \\\n",
       "config_name                                  precis_float16_quant_True_quant8_False_quant4_...   \n",
       "experiment_id                                                                               15   \n",
       "date_time                                                        April 08, 2025 at 04:41:10 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.002708   \n",
       "total_energy_joules                                                                9749.962662   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.102564   \n",
       "joules_per_token                                                                      9.749963   \n",
       "flops_per_joule                                                               106107496.397334   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              3.677875   \n",
       "average_latency_ms_per_batch                                                       3677.875369   \n",
       "throughput_queries_per_sec                                                            2.718961   \n",
       "throughput_tokens_per_sec                                                           271.896108   \n",
       "cpu_usage_percent                                                                          3.9   \n",
       "cpu_memory_usage_bytes                                                              2705195008   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087442944   \n",
       "gpu_max_memory_allocated_bytes                                                      1087442944   \n",
       "gpu_current_memory_reserved_bytes                                                   1927282688   \n",
       "gpu_max_memory_reserved_bytes                                                       1927282688   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  557.53898   \n",
       "gpu_power_process_1                                                                 633.739616   \n",
       "gpu_power_process_2                                                                 564.387603   \n",
       "gpu_power_process_3                                                                        0.0   \n",
       "ram_power_process_0                                                                   0.944375   \n",
       "ram_power_process_1                                                                   1.002962   \n",
       "ram_power_process_2                                                                   0.979697   \n",
       "ram_power_process_3                                                                     0.9912   \n",
       "cpu_energy_process_0                                                                   0.00012   \n",
       "cpu_energy_process_1                                                                  0.000133   \n",
       "cpu_energy_process_2                                                                  0.000122   \n",
       "cpu_energy_process_3                                                                  0.000163   \n",
       "gpu_energy_process_0                                                                  0.000518   \n",
       "gpu_energy_process_1                                                                  0.000568   \n",
       "gpu_energy_process_2                                                                  0.000522   \n",
       "gpu_energy_process_3                                                                  0.000559   \n",
       "ram_energy_process_0                                                                  0.000001   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                  0.000001   \n",
       "ram_energy_process_3                                                                  0.000001   \n",
       "total_energy_kwh_process_0                                                            0.000638   \n",
       "total_energy_kwh_process_1                                                            0.000702   \n",
       "total_energy_kwh_process_2                                                            0.000645   \n",
       "total_energy_kwh_process_3                                                            0.000723   \n",
       "total_energy_joules_process_0                                                      2298.536562   \n",
       "total_energy_joules_process_1                                                      2527.941143   \n",
       "total_energy_joules_process_2                                                       2320.70705   \n",
       "total_energy_joules_process_3                                                      2602.777907   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        438.91655   \n",
       "ram_power_avg                                                                         0.979558   \n",
       "cpu_energy_total                                                                      0.000538   \n",
       "gpu_energy_total                                                                      0.002166   \n",
       "ram_energy_total                                                                      0.000004   \n",
       "per-process_emissions_0                                                               0.000275   \n",
       "per-process_emissions_1                                                               0.000243   \n",
       "per-process_emissions_2                                                               0.000268   \n",
       "per-process_emissions_3                                                               0.000246   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "\n",
       "                                                                                            15  \\\n",
       "config_name                                              decoding_greedy_decoder_temperature_0   \n",
       "experiment_id                                                                               16   \n",
       "date_time                                                        April 08, 2025 at 04:41:43 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.002158   \n",
       "total_energy_joules                                                                7767.530628   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.128741   \n",
       "joules_per_token                                                                      7.767531   \n",
       "flops_per_joule                                                               133188290.785709   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.272839   \n",
       "average_latency_ms_per_batch                                                       2272.839022   \n",
       "throughput_queries_per_sec                                                            4.399784   \n",
       "throughput_tokens_per_sec                                                           439.978366   \n",
       "cpu_usage_percent                                                                          4.0   \n",
       "cpu_memory_usage_bytes                                                              2056642560   \n",
       "gpu_utilization_percent_0                                                                 18.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 612.704186   \n",
       "gpu_power_process_1                                                                 556.747136   \n",
       "gpu_power_process_2                                                                  660.52256   \n",
       "gpu_power_process_3                                                                 627.405103   \n",
       "ram_power_process_0                                                                   0.716738   \n",
       "ram_power_process_1                                                                   0.653096   \n",
       "ram_power_process_2                                                                   0.652359   \n",
       "ram_power_process_3                                                                   0.652561   \n",
       "cpu_energy_process_0                                                                  0.000076   \n",
       "cpu_energy_process_1                                                                   0.00009   \n",
       "cpu_energy_process_2                                                                  0.000076   \n",
       "cpu_energy_process_3                                                                  0.000085   \n",
       "gpu_energy_process_0                                                                  0.000433   \n",
       "gpu_energy_process_1                                                                  0.000491   \n",
       "gpu_energy_process_2                                                                  0.000433   \n",
       "gpu_energy_process_3                                                                  0.000473   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                       0.0   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                       0.0   \n",
       "total_energy_kwh_process_0                                                            0.000509   \n",
       "total_energy_kwh_process_1                                                            0.000581   \n",
       "total_energy_kwh_process_2                                                            0.000509   \n",
       "total_energy_kwh_process_3                                                            0.000558   \n",
       "total_energy_joules_process_0                                                      1833.577944   \n",
       "total_energy_joules_process_1                                                      2092.726127   \n",
       "total_energy_joules_process_2                                                      1832.894399   \n",
       "total_energy_joules_process_3                                                      2008.332158   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       614.344746   \n",
       "ram_power_avg                                                                         0.668688   \n",
       "cpu_energy_total                                                                      0.000328   \n",
       "gpu_energy_total                                                                      0.001828   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000194   \n",
       "per-process_emissions_1                                                               0.000221   \n",
       "per-process_emissions_2                                                               0.000194   \n",
       "per-process_emissions_3                                                               0.000213   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "\n",
       "                                                                                            16  \\\n",
       "config_name                                            decoding_greedy_decoder_temperature_0.7   \n",
       "experiment_id                                                                               17   \n",
       "date_time                                                        April 08, 2025 at 04:42:19 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.7   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.002392   \n",
       "total_energy_joules                                                                8612.615549   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.116109   \n",
       "joules_per_token                                                                      8.612616   \n",
       "flops_per_joule                                                               120119622.447774   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.381273   \n",
       "average_latency_ms_per_batch                                                       2381.273368   \n",
       "throughput_queries_per_sec                                                            4.199434   \n",
       "throughput_tokens_per_sec                                                           419.943386   \n",
       "cpu_usage_percent                                                                          4.7   \n",
       "cpu_memory_usage_bytes                                                              2073894912   \n",
       "gpu_utilization_percent_0                                                                  1.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 762.470124   \n",
       "gpu_power_process_1                                                                 453.252145   \n",
       "gpu_power_process_2                                                                 683.491168   \n",
       "gpu_power_process_3                                                                 658.562704   \n",
       "ram_power_process_0                                                                   0.721763   \n",
       "ram_power_process_1                                                                   0.666492   \n",
       "ram_power_process_2                                                                   0.667424   \n",
       "ram_power_process_3                                                                   0.668657   \n",
       "cpu_energy_process_0                                                                  0.000079   \n",
       "cpu_energy_process_1                                                                  0.000112   \n",
       "cpu_energy_process_2                                                                  0.000083   \n",
       "cpu_energy_process_3                                                                   0.00009   \n",
       "gpu_energy_process_0                                                                  0.000458   \n",
       "gpu_energy_process_1                                                                  0.000593   \n",
       "gpu_energy_process_2                                                                  0.000475   \n",
       "gpu_energy_process_3                                                                  0.000501   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                       0.0   \n",
       "total_energy_kwh_process_0                                                            0.000538   \n",
       "total_energy_kwh_process_1                                                            0.000705   \n",
       "total_energy_kwh_process_2                                                            0.000558   \n",
       "total_energy_kwh_process_3                                                            0.000591   \n",
       "total_energy_joules_process_0                                                      1935.222914   \n",
       "total_energy_joules_process_1                                                      2539.553048   \n",
       "total_energy_joules_process_2                                                      2010.031883   \n",
       "total_energy_joules_process_3                                                      2127.807703   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       639.444035   \n",
       "ram_power_avg                                                                         0.681084   \n",
       "cpu_energy_total                                                                      0.000364   \n",
       "gpu_energy_total                                                                      0.002027   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000205   \n",
       "per-process_emissions_1                                                               0.000225   \n",
       "per-process_emissions_2                                                               0.000269   \n",
       "per-process_emissions_3                                                               0.000213   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "\n",
       "                                                                                            17  \\\n",
       "config_name                                            decoding_greedy_decoder_temperature_1.0   \n",
       "experiment_id                                                                               18   \n",
       "date_time                                                        April 08, 2025 at 04:42:54 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                       0.00258   \n",
       "total_energy_joules                                                                9287.457917   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.107672   \n",
       "joules_per_token                                                                      9.287458   \n",
       "flops_per_joule                                                               111391527.936536   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.350439   \n",
       "average_latency_ms_per_batch                                                       2350.439308   \n",
       "throughput_queries_per_sec                                                            4.254524   \n",
       "throughput_tokens_per_sec                                                           425.452381   \n",
       "cpu_usage_percent                                                                          4.8   \n",
       "cpu_memory_usage_bytes                                                              2070286336   \n",
       "gpu_utilization_percent_0                                                                 20.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                 99.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 795.129191   \n",
       "gpu_power_process_1                                                                  18.628497   \n",
       "gpu_power_process_2                                                                 688.585224   \n",
       "gpu_power_process_3                                                                 610.801172   \n",
       "ram_power_process_0                                                                   0.721812   \n",
       "ram_power_process_1                                                                   0.668358   \n",
       "ram_power_process_2                                                                   0.668231   \n",
       "ram_power_process_3                                                                   0.670784   \n",
       "cpu_energy_process_0                                                                  0.000078   \n",
       "cpu_energy_process_1                                                                  0.000163   \n",
       "cpu_energy_process_2                                                                  0.000079   \n",
       "cpu_energy_process_3                                                                  0.000088   \n",
       "gpu_energy_process_0                                                                  0.000477   \n",
       "gpu_energy_process_1                                                                    0.0007   \n",
       "gpu_energy_process_2                                                                  0.000477   \n",
       "gpu_energy_process_3                                                                  0.000515   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                       0.0   \n",
       "total_energy_kwh_process_0                                                            0.000556   \n",
       "total_energy_kwh_process_1                                                            0.000864   \n",
       "total_energy_kwh_process_2                                                            0.000556   \n",
       "total_energy_kwh_process_3                                                            0.000604   \n",
       "total_energy_joules_process_0                                                      1999.907206   \n",
       "total_energy_joules_process_1                                                      3109.550092   \n",
       "total_energy_joules_process_2                                                      2003.210191   \n",
       "total_energy_joules_process_3                                                      2174.790428   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       528.286021   \n",
       "ram_power_avg                                                                         0.682296   \n",
       "cpu_energy_total                                                                      0.000409   \n",
       "gpu_energy_total                                                                      0.002169   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000329   \n",
       "per-process_emissions_1                                                               0.000212   \n",
       "per-process_emissions_2                                                               0.000212   \n",
       "per-process_emissions_3                                                                0.00023   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "\n",
       "                                                                                            18  \\\n",
       "config_name                                            decoding_greedy_decoder_temperature_1.3   \n",
       "experiment_id                                                                               19   \n",
       "date_time                                                        April 08, 2025 at 04:43:29 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.3   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                       0.00262   \n",
       "total_energy_joules                                                                9431.681788   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.106026   \n",
       "joules_per_token                                                                      9.431682   \n",
       "flops_per_joule                                                                109688192.54092   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.395863   \n",
       "average_latency_ms_per_batch                                                       2395.863263   \n",
       "throughput_queries_per_sec                                                            4.173861   \n",
       "throughput_tokens_per_sec                                                            417.38609   \n",
       "cpu_usage_percent                                                                          5.5   \n",
       "cpu_memory_usage_bytes                                                              2072047616   \n",
       "gpu_utilization_percent_0                                                                 36.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                    740.388   \n",
       "gpu_power_process_1                                                                        0.0   \n",
       "gpu_power_process_2                                                                 685.891048   \n",
       "gpu_power_process_3                                                                 604.058121   \n",
       "ram_power_process_0                                                                   0.722298   \n",
       "ram_power_process_1                                                                   0.672742   \n",
       "ram_power_process_2                                                                   0.678045   \n",
       "ram_power_process_3                                                                   0.669389   \n",
       "cpu_energy_process_0                                                                   0.00008   \n",
       "cpu_energy_process_1                                                                  0.000163   \n",
       "cpu_energy_process_2                                                                  0.000083   \n",
       "cpu_energy_process_3                                                                  0.000089   \n",
       "gpu_energy_process_0                                                                  0.000484   \n",
       "gpu_energy_process_1                                                                  0.000703   \n",
       "gpu_energy_process_2                                                                  0.000488   \n",
       "gpu_energy_process_3                                                                  0.000527   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                       0.0   \n",
       "total_energy_kwh_process_0                                                            0.000565   \n",
       "total_energy_kwh_process_1                                                            0.000867   \n",
       "total_energy_kwh_process_2                                                            0.000571   \n",
       "total_energy_kwh_process_3                                                            0.000617   \n",
       "total_energy_joules_process_0                                                      2033.157579   \n",
       "total_energy_joules_process_1                                                      3121.067615   \n",
       "total_energy_joules_process_2                                                      2055.629763   \n",
       "total_energy_joules_process_3                                                      2221.826831   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       507.584292   \n",
       "ram_power_avg                                                                         0.685619   \n",
       "cpu_energy_total                                                                      0.000415   \n",
       "gpu_energy_total                                                                      0.002203   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                                0.00033   \n",
       "per-process_emissions_1                                                               0.000235   \n",
       "per-process_emissions_2                                                               0.000218   \n",
       "per-process_emissions_3                                                               0.000215   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "\n",
       "                                                                                            19  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                               20   \n",
       "date_time                                                        April 08, 2025 at 04:44:03 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.002462   \n",
       "total_energy_joules                                                                8861.743317   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.112845   \n",
       "joules_per_token                                                                      8.861743   \n",
       "flops_per_joule                                                               116742732.320793   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.303065   \n",
       "average_latency_ms_per_batch                                                       2303.064523   \n",
       "throughput_queries_per_sec                                                            4.342041   \n",
       "throughput_tokens_per_sec                                                           434.204075   \n",
       "cpu_usage_percent                                                                          5.8   \n",
       "cpu_memory_usage_bytes                                                              2056028160   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 776.321292   \n",
       "gpu_power_process_1                                                                 495.301506   \n",
       "gpu_power_process_2                                                                 759.717472   \n",
       "gpu_power_process_3                                                                 574.829885   \n",
       "ram_power_process_0                                                                   0.716374   \n",
       "ram_power_process_1                                                                    0.65193   \n",
       "ram_power_process_2                                                                   0.638948   \n",
       "ram_power_process_3                                                                   0.639038   \n",
       "cpu_energy_process_0                                                                  0.000077   \n",
       "cpu_energy_process_1                                                                  0.000119   \n",
       "cpu_energy_process_2                                                                  0.000076   \n",
       "cpu_energy_process_3                                                                  0.000086   \n",
       "gpu_energy_process_0                                                                  0.000473   \n",
       "gpu_energy_process_1                                                                  0.000651   \n",
       "gpu_energy_process_2                                                                  0.000468   \n",
       "gpu_energy_process_3                                                                  0.000509   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                       0.0   \n",
       "total_energy_kwh_process_0                                                             0.00055   \n",
       "total_energy_kwh_process_1                                                            0.000771   \n",
       "total_energy_kwh_process_2                                                            0.000544   \n",
       "total_energy_kwh_process_3                                                            0.000596   \n",
       "total_energy_joules_process_0                                                      1980.873995   \n",
       "total_energy_joules_process_1                                                      2774.728283   \n",
       "total_energy_joules_process_2                                                      1960.037607   \n",
       "total_energy_joules_process_3                                                      2146.103432   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       651.542539   \n",
       "ram_power_avg                                                                         0.661573   \n",
       "cpu_energy_total                                                                      0.000359   \n",
       "gpu_energy_total                                                                      0.002101   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000227   \n",
       "per-process_emissions_1                                                                0.00021   \n",
       "per-process_emissions_2                                                               0.000294   \n",
       "per-process_emissions_3                                                               0.000207   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "\n",
       "                                                                                            20  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                               21   \n",
       "date_time                                                        April 08, 2025 at 04:44:38 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.7   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                       0.00261   \n",
       "total_energy_joules                                                                9394.350592   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.106447   \n",
       "joules_per_token                                                                      9.394351   \n",
       "flops_per_joule                                                               110124070.617504   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.387908   \n",
       "average_latency_ms_per_batch                                                       2387.907913   \n",
       "throughput_queries_per_sec                                                            4.187766   \n",
       "throughput_tokens_per_sec                                                           418.776618   \n",
       "cpu_usage_percent                                                                          5.5   \n",
       "cpu_memory_usage_bytes                                                              2075602944   \n",
       "gpu_utilization_percent_0                                                                 67.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 809.680864   \n",
       "gpu_power_process_1                                                                1679.540024   \n",
       "gpu_power_process_2                                                                 708.550319   \n",
       "gpu_power_process_3                                                                 601.787839   \n",
       "ram_power_process_0                                                                   0.722797   \n",
       "ram_power_process_1                                                                   0.681414   \n",
       "ram_power_process_2                                                                   0.686724   \n",
       "ram_power_process_3                                                                   0.688542   \n",
       "cpu_energy_process_0                                                                   0.00008   \n",
       "cpu_energy_process_1                                                                   0.00013   \n",
       "cpu_energy_process_2                                                                  0.000083   \n",
       "cpu_energy_process_3                                                                  0.000093   \n",
       "gpu_energy_process_0                                                                  0.000486   \n",
       "gpu_energy_process_1                                                                  0.000703   \n",
       "gpu_energy_process_2                                                                  0.000492   \n",
       "gpu_energy_process_3                                                                  0.000542   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                       0.0   \n",
       "total_energy_kwh_process_0                                                            0.000566   \n",
       "total_energy_kwh_process_1                                                            0.000834   \n",
       "total_energy_kwh_process_2                                                            0.000575   \n",
       "total_energy_kwh_process_3                                                            0.000635   \n",
       "total_energy_joules_process_0                                                      2036.742215   \n",
       "total_energy_joules_process_1                                                      3003.487737   \n",
       "total_energy_joules_process_2                                                      2068.396405   \n",
       "total_energy_joules_process_3                                                      2285.724235   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       949.889761   \n",
       "ram_power_avg                                                                          0.69487   \n",
       "cpu_energy_total                                                                      0.000386   \n",
       "gpu_energy_total                                                                      0.002222   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000219   \n",
       "per-process_emissions_1                                                               0.000242   \n",
       "per-process_emissions_2                                                               0.000216   \n",
       "per-process_emissions_3                                                               0.000318   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "\n",
       "                                                                                            21  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                               22   \n",
       "date_time                                                        April 08, 2025 at 04:45:14 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.002658   \n",
       "total_energy_joules                                                                9569.324332   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.104501   \n",
       "joules_per_token                                                                      9.569324   \n",
       "flops_per_joule                                                               108110467.588197   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.412971   \n",
       "average_latency_ms_per_batch                                                          2412.971   \n",
       "throughput_queries_per_sec                                                            4.144269   \n",
       "throughput_tokens_per_sec                                                           414.426862   \n",
       "cpu_usage_percent                                                                          4.0   \n",
       "cpu_memory_usage_bytes                                                              2075750400   \n",
       "gpu_utilization_percent_0                                                                  7.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 646.756882   \n",
       "gpu_power_process_1                                                                        0.0   \n",
       "gpu_power_process_2                                                                 731.480916   \n",
       "gpu_power_process_3                                                                1382.946973   \n",
       "ram_power_process_0                                                                   0.723407   \n",
       "ram_power_process_1                                                                   0.691215   \n",
       "ram_power_process_2                                                                   0.691328   \n",
       "ram_power_process_3                                                                   0.681649   \n",
       "cpu_energy_process_0                                                                   0.00008   \n",
       "cpu_energy_process_1                                                                  0.000131   \n",
       "cpu_energy_process_2                                                                  0.000082   \n",
       "cpu_energy_process_3                                                                  0.000099   \n",
       "gpu_energy_process_0                                                                  0.000471   \n",
       "gpu_energy_process_1                                                                  0.000717   \n",
       "gpu_energy_process_2                                                                  0.000492   \n",
       "gpu_energy_process_3                                                                  0.000583   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                  0.000001   \n",
       "total_energy_kwh_process_0                                                            0.000552   \n",
       "total_energy_kwh_process_1                                                            0.000848   \n",
       "total_energy_kwh_process_2                                                            0.000575   \n",
       "total_energy_kwh_process_3                                                            0.000683   \n",
       "total_energy_joules_process_0                                                      1985.841167   \n",
       "total_energy_joules_process_1                                                      3054.210497   \n",
       "total_energy_joules_process_2                                                      2070.639691   \n",
       "total_energy_joules_process_3                                                      2458.632976   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       690.296192   \n",
       "ram_power_avg                                                                         0.696899   \n",
       "cpu_energy_total                                                                      0.000393   \n",
       "gpu_energy_total                                                                      0.002263   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                                0.00026   \n",
       "per-process_emissions_1                                                               0.000323   \n",
       "per-process_emissions_2                                                                0.00021   \n",
       "per-process_emissions_3                                                               0.000219   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "\n",
       "                                                                                            22  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                               23   \n",
       "date_time                                                        April 08, 2025 at 04:45:49 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.3   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.002661   \n",
       "total_energy_joules                                                                9578.843492   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.104397   \n",
       "joules_per_token                                                                      9.578843   \n",
       "flops_per_joule                                                               108003030.722911   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.478181   \n",
       "average_latency_ms_per_batch                                                       2478.180916   \n",
       "throughput_queries_per_sec                                                            4.035218   \n",
       "throughput_tokens_per_sec                                                            403.52179   \n",
       "cpu_usage_percent                                                                          4.7   \n",
       "cpu_memory_usage_bytes                                                              2077544448   \n",
       "gpu_utilization_percent_0                                                                 51.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 652.001595   \n",
       "gpu_power_process_1                                                                2219.419073   \n",
       "gpu_power_process_2                                                                 670.105119   \n",
       "gpu_power_process_3                                                                 708.385754   \n",
       "ram_power_process_0                                                                   0.723691   \n",
       "ram_power_process_1                                                                   0.681756   \n",
       "ram_power_process_2                                                                   0.684342   \n",
       "ram_power_process_3                                                                   0.689416   \n",
       "cpu_energy_process_0                                                                  0.000082   \n",
       "cpu_energy_process_1                                                                   0.00013   \n",
       "cpu_energy_process_2                                                                  0.000081   \n",
       "cpu_energy_process_3                                                                  0.000099   \n",
       "gpu_energy_process_0                                                                  0.000484   \n",
       "gpu_energy_process_1                                                                  0.000716   \n",
       "gpu_energy_process_2                                                                  0.000486   \n",
       "gpu_energy_process_3                                                                  0.000579   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                  0.000001   \n",
       "total_energy_kwh_process_0                                                            0.000567   \n",
       "total_energy_kwh_process_1                                                            0.000847   \n",
       "total_energy_kwh_process_2                                                            0.000568   \n",
       "total_energy_kwh_process_3                                                            0.000679   \n",
       "total_energy_joules_process_0                                                      2041.046993   \n",
       "total_energy_joules_process_1                                                      3047.636726   \n",
       "total_energy_joules_process_2                                                       2044.85402   \n",
       "total_energy_joules_process_3                                                      2445.305753   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1062.477885   \n",
       "ram_power_avg                                                                         0.694802   \n",
       "cpu_energy_total                                                                      0.000393   \n",
       "gpu_energy_total                                                                      0.002265   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000259   \n",
       "per-process_emissions_1                                                               0.000322   \n",
       "per-process_emissions_2                                                               0.000216   \n",
       "per-process_emissions_3                                                               0.000216   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "\n",
       "                                                                                            23  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                               24   \n",
       "date_time                                                        April 08, 2025 at 04:46:23 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.002878   \n",
       "total_energy_joules                                                               10361.488063   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.096511   \n",
       "joules_per_token                                                                     10.361488   \n",
       "flops_per_joule                                                                 99845130.52061   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              3.440782   \n",
       "average_latency_ms_per_batch                                                       3440.782234   \n",
       "throughput_queries_per_sec                                                            2.906316   \n",
       "throughput_tokens_per_sec                                                           290.631587   \n",
       "cpu_usage_percent                                                                         55.3   \n",
       "cpu_memory_usage_bytes                                                              2057662464   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 567.629617   \n",
       "gpu_power_process_1                                                                 771.336972   \n",
       "gpu_power_process_2                                                                 615.131361   \n",
       "gpu_power_process_3                                                                 657.908802   \n",
       "ram_power_process_0                                                                   0.716706   \n",
       "ram_power_process_1                                                                   0.639193   \n",
       "ram_power_process_2                                                                   0.646367   \n",
       "ram_power_process_3                                                                   0.651056   \n",
       "cpu_energy_process_0                                                                  0.000114   \n",
       "cpu_energy_process_1                                                                  0.000133   \n",
       "cpu_energy_process_2                                                                  0.000092   \n",
       "cpu_energy_process_3                                                                  0.000105   \n",
       "gpu_energy_process_0                                                                  0.000623   \n",
       "gpu_energy_process_1                                                                  0.000711   \n",
       "gpu_energy_process_2                                                                   0.00052   \n",
       "gpu_energy_process_3                                                                  0.000578   \n",
       "ram_energy_process_0                                                                  0.000001   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                       0.0   \n",
       "total_energy_kwh_process_0                                                            0.000737   \n",
       "total_energy_kwh_process_1                                                            0.000845   \n",
       "total_energy_kwh_process_2                                                            0.000613   \n",
       "total_energy_kwh_process_3                                                            0.000683   \n",
       "total_energy_joules_process_0                                                      2654.411522   \n",
       "total_energy_joules_process_1                                                      3041.883795   \n",
       "total_energy_joules_process_2                                                      2205.460381   \n",
       "total_energy_joules_process_3                                                      2459.732365   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       653.001688   \n",
       "ram_power_avg                                                                          0.66333   \n",
       "cpu_energy_total                                                                      0.000443   \n",
       "gpu_energy_total                                                                      0.002433   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000233   \n",
       "per-process_emissions_1                                                               0.000281   \n",
       "per-process_emissions_2                                                               0.000322   \n",
       "per-process_emissions_3                                                                0.00026   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "\n",
       "                                                                                            24  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                               25   \n",
       "date_time                                                        April 08, 2025 at 04:47:02 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.7   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.002745   \n",
       "total_energy_joules                                                                 9881.56245   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.101199   \n",
       "joules_per_token                                                                      9.881562   \n",
       "flops_per_joule                                                               104694387.473973   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.714286   \n",
       "average_latency_ms_per_batch                                                       2714.285777   \n",
       "throughput_queries_per_sec                                                             3.68421   \n",
       "throughput_tokens_per_sec                                                           368.421044   \n",
       "cpu_usage_percent                                                                          5.5   \n",
       "cpu_memory_usage_bytes                                                              2070953984   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 727.260463   \n",
       "gpu_power_process_1                                                                 555.824567   \n",
       "gpu_power_process_2                                                                 705.838975   \n",
       "gpu_power_process_3                                                                 944.800435   \n",
       "ram_power_process_0                                                                   0.721634   \n",
       "ram_power_process_1                                                                   0.662752   \n",
       "ram_power_process_2                                                                   0.667909   \n",
       "ram_power_process_3                                                                   0.675183   \n",
       "cpu_energy_process_0                                                                  0.000092   \n",
       "cpu_energy_process_1                                                                  0.000132   \n",
       "cpu_energy_process_2                                                                  0.000093   \n",
       "cpu_energy_process_3                                                                    0.0001   \n",
       "gpu_energy_process_0                                                                  0.000524   \n",
       "gpu_energy_process_1                                                                  0.000712   \n",
       "gpu_energy_process_2                                                                  0.000531   \n",
       "gpu_energy_process_3                                                                  0.000559   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                  0.000001   \n",
       "total_energy_kwh_process_0                                                            0.000616   \n",
       "total_energy_kwh_process_1                                                            0.000845   \n",
       "total_energy_kwh_process_2                                                            0.000624   \n",
       "total_energy_kwh_process_3                                                             0.00066   \n",
       "total_energy_joules_process_0                                                      2218.098723   \n",
       "total_energy_joules_process_1                                                      3042.360366   \n",
       "total_energy_joules_process_2                                                      2245.070151   \n",
       "total_energy_joules_process_3                                                      2376.033211   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        733.43111   \n",
       "ram_power_avg                                                                         0.681869   \n",
       "cpu_energy_total                                                                      0.000417   \n",
       "gpu_energy_total                                                                      0.002326   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000238   \n",
       "per-process_emissions_1                                                               0.000251   \n",
       "per-process_emissions_2                                                               0.000322   \n",
       "per-process_emissions_3                                                               0.000235   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "\n",
       "                                                                                            25  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                               26   \n",
       "date_time                                                        April 08, 2025 at 04:47:37 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.002717   \n",
       "total_energy_joules                                                                9782.421027   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.102224   \n",
       "joules_per_token                                                                      9.782421   \n",
       "flops_per_joule                                                               105755428.550843   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                               2.56474   \n",
       "average_latency_ms_per_batch                                                       2564.739563   \n",
       "throughput_queries_per_sec                                                            3.899031   \n",
       "throughput_tokens_per_sec                                                           389.903137   \n",
       "cpu_usage_percent                                                                         16.2   \n",
       "cpu_memory_usage_bytes                                                              2052939776   \n",
       "gpu_utilization_percent_0                                                                 58.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 701.330117   \n",
       "gpu_power_process_1                                                                 471.022131   \n",
       "gpu_power_process_2                                                                 718.217363   \n",
       "gpu_power_process_3                                                                 363.407429   \n",
       "ram_power_process_0                                                                   0.714984   \n",
       "ram_power_process_1                                                                   0.673425   \n",
       "ram_power_process_2                                                                   0.666428   \n",
       "ram_power_process_3                                                                   0.667291   \n",
       "cpu_energy_process_0                                                                  0.000088   \n",
       "cpu_energy_process_1                                                                  0.000135   \n",
       "cpu_energy_process_2                                                                  0.000091   \n",
       "cpu_energy_process_3                                                                  0.000103   \n",
       "gpu_energy_process_0                                                                  0.000503   \n",
       "gpu_energy_process_1                                                                  0.000706   \n",
       "gpu_energy_process_2                                                                  0.000517   \n",
       "gpu_energy_process_3                                                                  0.000572   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                  0.000001   \n",
       "total_energy_kwh_process_0                                                            0.000592   \n",
       "total_energy_kwh_process_1                                                            0.000841   \n",
       "total_energy_kwh_process_2                                                            0.000608   \n",
       "total_energy_kwh_process_3                                                            0.000676   \n",
       "total_energy_joules_process_0                                                      2130.240098   \n",
       "total_energy_joules_process_1                                                      3028.890264   \n",
       "total_energy_joules_process_2                                                      2189.903237   \n",
       "total_energy_joules_process_3                                                      2433.387427   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        563.49426   \n",
       "ram_power_avg                                                                         0.680532   \n",
       "cpu_energy_total                                                                      0.000417   \n",
       "gpu_energy_total                                                                      0.002298   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000257   \n",
       "per-process_emissions_1                                                               0.000232   \n",
       "per-process_emissions_2                                                               0.000225   \n",
       "per-process_emissions_3                                                               0.000321   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "\n",
       "                                                                                            26  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                               27   \n",
       "date_time                                                        April 08, 2025 at 04:48:15 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.3   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.002628   \n",
       "total_energy_joules                                                                9460.731311   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                        0.1057   \n",
       "joules_per_token                                                                      9.460731   \n",
       "flops_per_joule                                                               109351390.926845   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.419328   \n",
       "average_latency_ms_per_batch                                                       2419.327923   \n",
       "throughput_queries_per_sec                                                            4.133379   \n",
       "throughput_tokens_per_sec                                                           413.337932   \n",
       "cpu_usage_percent                                                                          4.8   \n",
       "cpu_memory_usage_bytes                                                              2072227840   \n",
       "gpu_utilization_percent_0                                                                 68.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 756.244221   \n",
       "gpu_power_process_1                                                                 413.266378   \n",
       "gpu_power_process_2                                                                 780.127003   \n",
       "gpu_power_process_3                                                                 250.763626   \n",
       "ram_power_process_0                                                                   0.722484   \n",
       "ram_power_process_1                                                                   0.663541   \n",
       "ram_power_process_2                                                                   0.666791   \n",
       "ram_power_process_3                                                                    0.67208   \n",
       "cpu_energy_process_0                                                                   0.00008   \n",
       "cpu_energy_process_1                                                                  0.000125   \n",
       "cpu_energy_process_2                                                                   0.00008   \n",
       "cpu_energy_process_3                                                                  0.000101   \n",
       "gpu_energy_process_0                                                                  0.000484   \n",
       "gpu_energy_process_1                                                                  0.000678   \n",
       "gpu_energy_process_2                                                                  0.000492   \n",
       "gpu_energy_process_3                                                                  0.000587   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                       0.0   \n",
       "total_energy_kwh_process_0                                                            0.000564   \n",
       "total_energy_kwh_process_1                                                            0.000803   \n",
       "total_energy_kwh_process_2                                                            0.000572   \n",
       "total_energy_kwh_process_3                                                            0.000689   \n",
       "total_energy_joules_process_0                                                      2031.708541   \n",
       "total_energy_joules_process_1                                                      2890.460805   \n",
       "total_energy_joules_process_2                                                      2059.903488   \n",
       "total_energy_joules_process_3                                                      2478.658477   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       550.100307   \n",
       "ram_power_avg                                                                         0.681224   \n",
       "cpu_energy_total                                                                      0.000386   \n",
       "gpu_energy_total                                                                       0.00224   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000218   \n",
       "per-process_emissions_1                                                               0.000215   \n",
       "per-process_emissions_2                                                               0.000306   \n",
       "per-process_emissions_3                                                               0.000262   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "\n",
       "                                                                                            27  \\\n",
       "config_name                                                                      latency_False   \n",
       "experiment_id                                                                               28   \n",
       "date_time                                                        April 08, 2025 at 04:48:49 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.003057   \n",
       "total_energy_joules                                                                11004.24041   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.090874   \n",
       "joules_per_token                                                                      11.00424   \n",
       "flops_per_joule                                                                94013224.855566   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              3.559638   \n",
       "average_latency_ms_per_batch                                                       3559.637986   \n",
       "throughput_queries_per_sec                                                            2.809274   \n",
       "throughput_tokens_per_sec                                                           280.927444   \n",
       "cpu_usage_percent                                                                         54.0   \n",
       "cpu_memory_usage_bytes                                                              2074927104   \n",
       "gpu_utilization_percent_0                                                                 52.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 551.612807   \n",
       "gpu_power_process_1                                                                 404.622742   \n",
       "gpu_power_process_2                                                                  516.23026   \n",
       "gpu_power_process_3                                                                 604.277492   \n",
       "ram_power_process_0                                                                   0.722661   \n",
       "ram_power_process_1                                                                   0.665721   \n",
       "ram_power_process_2                                                                    0.67092   \n",
       "ram_power_process_3                                                                   0.685136   \n",
       "cpu_energy_process_0                                                                  0.000119   \n",
       "cpu_energy_process_1                                                                  0.000135   \n",
       "cpu_energy_process_2                                                                  0.000103   \n",
       "cpu_energy_process_3                                                                  0.000117   \n",
       "gpu_energy_process_0                                                                  0.000646   \n",
       "gpu_energy_process_1                                                                  0.000715   \n",
       "gpu_energy_process_2                                                                  0.000575   \n",
       "gpu_energy_process_3                                                                  0.000646   \n",
       "ram_energy_process_0                                                                  0.000001   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                  0.000001   \n",
       "total_energy_kwh_process_0                                                            0.000765   \n",
       "total_energy_kwh_process_1                                                             0.00085   \n",
       "total_energy_kwh_process_2                                                            0.000678   \n",
       "total_energy_kwh_process_3                                                            0.000764   \n",
       "total_energy_joules_process_0                                                      2753.201388   \n",
       "total_energy_joules_process_1                                                      3061.352417   \n",
       "total_energy_joules_process_2                                                      2440.732517   \n",
       "total_energy_joules_process_3                                                      2748.954088   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       519.185825   \n",
       "ram_power_avg                                                                          0.68611   \n",
       "cpu_energy_total                                                                      0.000474   \n",
       "gpu_energy_total                                                                       0.00258   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000258   \n",
       "per-process_emissions_1                                                               0.000324   \n",
       "per-process_emissions_2                                                               0.000291   \n",
       "per-process_emissions_3                                                               0.000291   \n",
       "latency_simulation_simulate                                                              False   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "\n",
       "                                                                                            28  \\\n",
       "config_name                                  latency_True_latency_0.05_latency_0.2_latency_...   \n",
       "experiment_id                                                                               29   \n",
       "date_time                                                        April 08, 2025 at 04:49:27 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                              0.05   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.002529   \n",
       "total_energy_joules                                                                9104.932397   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.109831   \n",
       "joules_per_token                                                                      9.104932   \n",
       "flops_per_joule                                                               113624580.931623   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.453797   \n",
       "average_latency_ms_per_batch                                                       2453.797072   \n",
       "throughput_queries_per_sec                                                            4.075317   \n",
       "throughput_tokens_per_sec                                                           407.531662   \n",
       "cpu_usage_percent                                                                          5.5   \n",
       "cpu_memory_usage_bytes                                                              2070724608   \n",
       "gpu_utilization_percent_0                                                                 20.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 716.271282   \n",
       "gpu_power_process_1                                                                 468.725355   \n",
       "gpu_power_process_2                                                                 694.223236   \n",
       "gpu_power_process_3                                                                 618.121217   \n",
       "ram_power_process_0                                                                   0.721959   \n",
       "ram_power_process_1                                                                   0.678437   \n",
       "ram_power_process_2                                                                   0.669261   \n",
       "ram_power_process_3                                                                    0.67303   \n",
       "cpu_energy_process_0                                                                  0.000083   \n",
       "cpu_energy_process_1                                                                  0.000124   \n",
       "cpu_energy_process_2                                                                  0.000083   \n",
       "cpu_energy_process_3                                                                  0.000094   \n",
       "gpu_energy_process_0                                                                  0.000481   \n",
       "gpu_energy_process_1                                                                  0.000654   \n",
       "gpu_energy_process_2                                                                  0.000477   \n",
       "gpu_energy_process_3                                                                   0.00053   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                       0.0   \n",
       "total_energy_kwh_process_0                                                            0.000564   \n",
       "total_energy_kwh_process_1                                                            0.000779   \n",
       "total_energy_kwh_process_2                                                            0.000561   \n",
       "total_energy_kwh_process_3                                                            0.000625   \n",
       "total_energy_joules_process_0                                                      2030.512325   \n",
       "total_energy_joules_process_1                                                      2805.720536   \n",
       "total_energy_joules_process_2                                                      2019.285212   \n",
       "total_energy_joules_process_3                                                      2249.414323   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       624.335273   \n",
       "ram_power_avg                                                                         0.685672   \n",
       "cpu_energy_total                                                                      0.000384   \n",
       "gpu_energy_total                                                                      0.002143   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000215   \n",
       "per-process_emissions_1                                                               0.000214   \n",
       "per-process_emissions_2                                                               0.000238   \n",
       "per-process_emissions_3                                                               0.000297   \n",
       "latency_simulation_simulate                                                               True   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.2   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "\n",
       "                                                                                            29  \\\n",
       "config_name                                  latency_True_latency_0.2_latency_0.6_latency_F...   \n",
       "experiment_id                                                                               30   \n",
       "date_time                                                        April 08, 2025 at 04:50:02 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.2   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.002987   \n",
       "total_energy_joules                                                               10752.746732   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.092999   \n",
       "joules_per_token                                                                     10.752747   \n",
       "flops_per_joule                                                                96212079.926237   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                               4.07742   \n",
       "average_latency_ms_per_batch                                                       4077.420104   \n",
       "throughput_queries_per_sec                                                            2.452531   \n",
       "throughput_tokens_per_sec                                                           245.253119   \n",
       "cpu_usage_percent                                                                         17.3   \n",
       "cpu_memory_usage_bytes                                                              2072039424   \n",
       "gpu_utilization_percent_0                                                                  7.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 381.983252   \n",
       "gpu_power_process_1                                                                 559.126046   \n",
       "gpu_power_process_2                                                                 611.717499   \n",
       "gpu_power_process_3                                                                 479.491748   \n",
       "ram_power_process_0                                                                   0.722185   \n",
       "ram_power_process_1                                                                   0.680659   \n",
       "ram_power_process_2                                                                   0.671914   \n",
       "ram_power_process_3                                                                   0.671625   \n",
       "cpu_energy_process_0                                                                  0.000135   \n",
       "cpu_energy_process_1                                                                  0.000134   \n",
       "cpu_energy_process_2                                                                  0.000109   \n",
       "cpu_energy_process_3                                                                  0.000123   \n",
       "gpu_energy_process_0                                                                  0.000664   \n",
       "gpu_energy_process_1                                                                  0.000658   \n",
       "gpu_energy_process_2                                                                  0.000547   \n",
       "gpu_energy_process_3                                                                  0.000614   \n",
       "ram_energy_process_0                                                                  0.000001   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                  0.000001   \n",
       "total_energy_kwh_process_0                                                            0.000799   \n",
       "total_energy_kwh_process_1                                                            0.000793   \n",
       "total_energy_kwh_process_2                                                            0.000657   \n",
       "total_energy_kwh_process_3                                                            0.000737   \n",
       "total_energy_joules_process_0                                                       2877.54669   \n",
       "total_energy_joules_process_1                                                      2856.492483   \n",
       "total_energy_joules_process_2                                                      2363.976182   \n",
       "total_energy_joules_process_3                                                      2654.731377   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       508.079636   \n",
       "ram_power_avg                                                                         0.686596   \n",
       "cpu_energy_total                                                                      0.000501   \n",
       "gpu_energy_total                                                                      0.002483   \n",
       "ram_energy_total                                                                      0.000003   \n",
       "per-process_emissions_0                                                               0.000302   \n",
       "per-process_emissions_1                                                               0.000305   \n",
       "per-process_emissions_2                                                                0.00025   \n",
       "per-process_emissions_3                                                               0.000281   \n",
       "latency_simulation_simulate                                                               True   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.6   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "\n",
       "                                                                                            30  \\\n",
       "config_name                                  latency_True_latency_0.05_latency_0.2_latency_...   \n",
       "experiment_id                                                                               31   \n",
       "date_time                                                        April 08, 2025 at 04:50:37 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                              0.05   \n",
       "latency_simulation_simulate_burst                                                         True   \n",
       "latency_simulation_burst_size                                                                5   \n",
       "latency_simulation_burst_interval                                                          4.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                        1000   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           100   \n",
       "max_output_tokens                                                                          100   \n",
       "number_input_prompts                                                                        10   \n",
       "total_energy_kwh                                                                      0.002321   \n",
       "total_energy_joules                                                                8354.124101   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.119701   \n",
       "joules_per_token                                                                      8.354124   \n",
       "flops_per_joule                                                               123836337.055097   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              2.509436   \n",
       "average_latency_ms_per_batch                                                       2509.436437   \n",
       "throughput_queries_per_sec                                                            3.984958   \n",
       "throughput_tokens_per_sec                                                           398.495848   \n",
       "cpu_usage_percent                                                                          4.8   \n",
       "cpu_memory_usage_bytes                                                              2073120768   \n",
       "gpu_utilization_percent_0                                                                 44.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 615.725547   \n",
       "gpu_power_process_1                                                                 310.173365   \n",
       "gpu_power_process_2                                                                 631.657895   \n",
       "gpu_power_process_3                                                                 796.653119   \n",
       "ram_power_process_0                                                                   0.721872   \n",
       "ram_power_process_1                                                                   0.673545   \n",
       "ram_power_process_2                                                                   0.667791   \n",
       "ram_power_process_3                                                                   0.667638   \n",
       "cpu_energy_process_0                                                                  0.000084   \n",
       "cpu_energy_process_1                                                                    0.0001   \n",
       "cpu_energy_process_2                                                                  0.000083   \n",
       "cpu_energy_process_3                                                                  0.000101   \n",
       "gpu_energy_process_0                                                                  0.000445   \n",
       "gpu_energy_process_1                                                                  0.000535   \n",
       "gpu_energy_process_2                                                                  0.000442   \n",
       "gpu_energy_process_3                                                                   0.00053   \n",
       "ram_energy_process_0                                                                       0.0   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       0.0   \n",
       "ram_energy_process_3                                                                  0.000001   \n",
       "total_energy_kwh_process_0                                                            0.000529   \n",
       "total_energy_kwh_process_1                                                            0.000636   \n",
       "total_energy_kwh_process_2                                                            0.000524   \n",
       "total_energy_kwh_process_3                                                            0.000631   \n",
       "total_energy_joules_process_0                                                      1905.424207   \n",
       "total_energy_joules_process_1                                                      2287.806555   \n",
       "total_energy_joules_process_2                                                      1887.933024   \n",
       "total_energy_joules_process_3                                                      2272.960315   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       588.552482   \n",
       "ram_power_avg                                                                         0.682712   \n",
       "cpu_energy_total                                                                      0.000368   \n",
       "gpu_energy_total                                                                      0.001951   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000242   \n",
       "per-process_emissions_1                                                               0.000241   \n",
       "per-process_emissions_2                                                                 0.0002   \n",
       "per-process_emissions_3                                                               0.000202   \n",
       "latency_simulation_simulate                                                               True   \n",
       "models                                                                           1034544128000   \n",
       "latency_simulation_delay_max                                                               0.2   \n",
       "total_generated_tokens                                                                    1000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "\n",
       "                                                                                            31  \n",
       "config_name                                  latency_True_latency_0.2_latency_0.6_latency_T...  \n",
       "experiment_id                                                                               32  \n",
       "date_time                                                        April 08, 2025 at 04:51:12 PM  \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0  \n",
       "num_processes                                                                                4  \n",
       "batch_size___fixed_batching                                                                 16  \n",
       "decoder_temperature                                                                        1.0  \n",
       "decoder_top_k                                                                                0  \n",
       "decoder_top_p                                                                              0.0  \n",
       "latency_simulation_delay_min                                                               0.2  \n",
       "latency_simulation_simulate_burst                                                         True  \n",
       "latency_simulation_burst_size                                                                8  \n",
       "latency_simulation_burst_interval                                                          5.0  \n",
       "fp_precision                                                                     torch.float32  \n",
       "quantization                                                                             False  \n",
       "load_in_8bit                                                                             False  \n",
       "load_in_4bit                                                                             False  \n",
       "sharding_strategy                                                                     NO_SHARD  \n",
       "sharding_config_fsdp_config_use_orig_params                                              False  \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False  \n",
       "adaptive_batching                                                                        False  \n",
       "adaptive_max_tokens                                                                          0  \n",
       "query_rate                                                                                 1.0  \n",
       "total_input_tokens                                                                        1000  \n",
       "is_encoder_decoder                                                                       False  \n",
       "task_type                                                                      text_generation  \n",
       "available_gpu_count                                                                          4  \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB  \n",
       "available_cpu_count                                                                        128  \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor  \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31  \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]  \n",
       "country                                                                                Germany  \n",
       "region                                                                                  saxony  \n",
       "distributed_type                                                     DistributedType.MULTI_GPU  \n",
       "decode_token_to_text                                                                      True  \n",
       "inference_type                                                                 pure_generative  \n",
       "backend                                                                                pytorch  \n",
       "total_params                                                                        1100048384  \n",
       "model_arch                                                       Unknown (no config attribute)  \n",
       "max_input_tokens                                                                           100  \n",
       "max_output_tokens                                                                          100  \n",
       "number_input_prompts                                                                        10  \n",
       "total_energy_kwh                                                                      0.002472  \n",
       "total_energy_joules                                                                8900.869755  \n",
       "flops                                                                            1034544128000  \n",
       "tokens_per_joule                                                                      0.112349  \n",
       "joules_per_token                                                                       8.90087  \n",
       "flops_per_joule                                                               116229554.686645  \n",
       "joules_per_flop                                                                            0.0  \n",
       "total_inference_time_sec                                                              2.615047  \n",
       "average_latency_ms_per_batch                                                       2615.046637  \n",
       "throughput_queries_per_sec                                                            3.824024  \n",
       "throughput_tokens_per_sec                                                           382.402358  \n",
       "cpu_usage_percent                                                                          4.0  \n",
       "cpu_memory_usage_bytes                                                              2070740992  \n",
       "gpu_utilization_percent_0                                                                 57.0  \n",
       "gpu_utilization_percent_1                                                                100.0  \n",
       "gpu_utilization_percent_2                                                                100.0  \n",
       "gpu_utilization_percent_3                                                                 94.0  \n",
       "gpu_current_memory_allocated_bytes                                                  8817963520  \n",
       "gpu_max_memory_allocated_bytes                                                      8817963520  \n",
       "gpu_current_memory_reserved_bytes                                                  13203668992  \n",
       "gpu_max_memory_reserved_bytes                                                      13203668992  \n",
       "cpu_power_process_0                                                                      112.5  \n",
       "cpu_power_process_1                                                                      112.5  \n",
       "cpu_power_process_2                                                                      112.5  \n",
       "cpu_power_process_3                                                                      112.5  \n",
       "gpu_power_process_0                                                                 717.525238  \n",
       "gpu_power_process_1                                                                  533.99169  \n",
       "gpu_power_process_2                                                                 734.177811  \n",
       "gpu_power_process_3                                                                 514.542529  \n",
       "ram_power_process_0                                                                   0.720926  \n",
       "ram_power_process_1                                                                   0.674317  \n",
       "ram_power_process_2                                                                   0.668052  \n",
       "ram_power_process_3                                                                   0.667927  \n",
       "cpu_energy_process_0                                                                  0.000086  \n",
       "cpu_energy_process_1                                                                  0.000102  \n",
       "cpu_energy_process_2                                                                  0.000086  \n",
       "cpu_energy_process_3                                                                  0.000119  \n",
       "gpu_energy_process_0                                                                   0.00046  \n",
       "gpu_energy_process_1                                                                  0.000543  \n",
       "gpu_energy_process_2                                                                  0.000454  \n",
       "gpu_energy_process_3                                                                  0.000619  \n",
       "ram_energy_process_0                                                                       0.0  \n",
       "ram_energy_process_1                                                                  0.000001  \n",
       "ram_energy_process_2                                                                       0.0  \n",
       "ram_energy_process_3                                                                  0.000001  \n",
       "total_energy_kwh_process_0                                                            0.000547  \n",
       "total_energy_kwh_process_1                                                            0.000646  \n",
       "total_energy_kwh_process_2                                                             0.00054  \n",
       "total_energy_kwh_process_3                                                            0.000739  \n",
       "total_energy_joules_process_0                                                      1968.818093  \n",
       "total_energy_joules_process_1                                                         2326.154  \n",
       "total_energy_joules_process_2                                                      1944.850933  \n",
       "total_energy_joules_process_3                                                       2661.04673  \n",
       "cpu_power_avg                                                                            112.5  \n",
       "gpu_power_avg                                                                       625.059317  \n",
       "ram_power_avg                                                                         0.682806  \n",
       "cpu_energy_total                                                                      0.000394  \n",
       "gpu_energy_total                                                                      0.002076  \n",
       "ram_energy_total                                                                      0.000002  \n",
       "per-process_emissions_0                                                               0.000282  \n",
       "per-process_emissions_1                                                               0.000208  \n",
       "per-process_emissions_2                                                               0.000206  \n",
       "per-process_emissions_3                                                               0.000246  \n",
       "latency_simulation_simulate                                                               True  \n",
       "models                                                                           1034544128000  \n",
       "latency_simulation_delay_max                                                               0.6  \n",
       "total_generated_tokens                                                                    1000  \n",
       "decoder_config_decoding_mode                                                               NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenarios did not exist: [Errno 2] No such file or directory: 'results/scenarios_results.csv'\n",
      "grid did not exist: [Errno 2] No such file or directory: 'results/grid_results.csv'\n",
      "text_generation did not exist: [Errno 2] No such file or directory: 'results/text_generation_results.csv'\n"
     ]
    }
   ],
   "source": [
    "def inspect_results(name, desired_order):\n",
    "    input_file = f\"results/{name}_results.csv\"\n",
    "    \n",
    "    df = pd.read_csv(input_file)\n",
    "    df_cleaned = clean_and_reorder_columns(df, desired_order)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "possible_files = [\"controlled\", \"scenarios\", \"grid\", \"text_generation\"]\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "for file in possible_files:\n",
    "    try:\n",
    "        var_name = f\"df_{file}_cleaned\"\n",
    "        globals()[var_name] = inspect_results(file, desired_order)  # dynamically create variable\n",
    "        print(f\"Found & inspecting: {var_name}\")\n",
    "        display(globals()[var_name].T)\n",
    "    except Exception as e:\n",
    "        print(f\"{file} did not exist: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second round ordering\n",
    "#existing_cols = [col for col in desired_order if col in df.columns]\n",
    "#df_controlled = df[existing_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found & inspecting dropped version: df_controlled_dropped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>config_name</th>\n",
       "      <td>num_processes_1</td>\n",
       "      <td>num_processes_2</td>\n",
       "      <td>num_processes_3</td>\n",
       "      <td>num_processes_4</td>\n",
       "      <td>batching_1</td>\n",
       "      <td>batching_2</td>\n",
       "      <td>batching_4</td>\n",
       "      <td>batching_8</td>\n",
       "      <td>batching_16</td>\n",
       "      <td>batching_32</td>\n",
       "      <td>batching_64</td>\n",
       "      <td>precis_float32_quant_False_quant8_False_quant4...</td>\n",
       "      <td>precis_float16_quant_False_quant8_False_quant4...</td>\n",
       "      <td>precis_float16_quant_True_quant8_True_quant4_F...</td>\n",
       "      <td>precis_float16_quant_True_quant8_False_quant4_...</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.7</td>\n",
       "      <td>decoding_greedy_decoder_temperature_1.0</td>\n",
       "      <td>decoding_greedy_decoder_temperature_1.3</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>latency_False</td>\n",
       "      <td>latency_True_latency_0.05_latency_0.2_latency_...</td>\n",
       "      <td>latency_True_latency_0.2_latency_0.6_latency_F...</td>\n",
       "      <td>latency_True_latency_0.05_latency_0.2_latency_...</td>\n",
       "      <td>latency_True_latency_0.2_latency_0.6_latency_T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <td>April 08, 2025 at 04:31:33 PM</td>\n",
       "      <td>April 08, 2025 at 04:32:06 PM</td>\n",
       "      <td>April 08, 2025 at 04:32:41 PM</td>\n",
       "      <td>April 08, 2025 at 04:33:15 PM</td>\n",
       "      <td>April 08, 2025 at 04:34:12 PM</td>\n",
       "      <td>April 08, 2025 at 04:34:59 PM</td>\n",
       "      <td>April 08, 2025 at 04:35:43 PM</td>\n",
       "      <td>April 08, 2025 at 04:36:20 PM</td>\n",
       "      <td>April 08, 2025 at 04:36:58 PM</td>\n",
       "      <td>April 08, 2025 at 04:37:33 PM</td>\n",
       "      <td>April 08, 2025 at 04:38:19 PM</td>\n",
       "      <td>April 08, 2025 at 04:38:55 PM</td>\n",
       "      <td>April 08, 2025 at 04:39:28 PM</td>\n",
       "      <td>April 08, 2025 at 04:40:33 PM</td>\n",
       "      <td>April 08, 2025 at 04:41:10 PM</td>\n",
       "      <td>April 08, 2025 at 04:41:43 PM</td>\n",
       "      <td>April 08, 2025 at 04:42:19 PM</td>\n",
       "      <td>April 08, 2025 at 04:42:54 PM</td>\n",
       "      <td>April 08, 2025 at 04:43:29 PM</td>\n",
       "      <td>April 08, 2025 at 04:44:03 PM</td>\n",
       "      <td>April 08, 2025 at 04:44:38 PM</td>\n",
       "      <td>April 08, 2025 at 04:45:14 PM</td>\n",
       "      <td>April 08, 2025 at 04:45:49 PM</td>\n",
       "      <td>April 08, 2025 at 04:46:23 PM</td>\n",
       "      <td>April 08, 2025 at 04:47:02 PM</td>\n",
       "      <td>April 08, 2025 at 04:47:37 PM</td>\n",
       "      <td>April 08, 2025 at 04:48:15 PM</td>\n",
       "      <td>April 08, 2025 at 04:48:49 PM</td>\n",
       "      <td>April 08, 2025 at 04:49:27 PM</td>\n",
       "      <td>April 08, 2025 at 04:50:02 PM</td>\n",
       "      <td>April 08, 2025 at 04:50:37 PM</td>\n",
       "      <td>April 08, 2025 at 04:51:12 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_processes</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size___fixed_batching</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_temperature</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_k</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_p</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate_burst</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_size</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_interval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp_precision</th>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantization</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_8bit</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_4bit</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_input_tokens</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_params</th>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>615606272</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_input_tokens</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_output_tokens</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_input_prompts</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh</th>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.001802</td>\n",
       "      <td>0.00258</td>\n",
       "      <td>0.016064</td>\n",
       "      <td>0.009953</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>0.004281</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.002528</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.009094</td>\n",
       "      <td>0.002708</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>0.002392</td>\n",
       "      <td>0.00258</td>\n",
       "      <td>0.00262</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.00261</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.002745</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.003057</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.002321</td>\n",
       "      <td>0.002472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules</th>\n",
       "      <td>1561.168622</td>\n",
       "      <td>4151.58235</td>\n",
       "      <td>6486.403256</td>\n",
       "      <td>9287.658482</td>\n",
       "      <td>57830.498773</td>\n",
       "      <td>35832.430964</td>\n",
       "      <td>22811.407515</td>\n",
       "      <td>15412.070402</td>\n",
       "      <td>9669.475684</td>\n",
       "      <td>9099.859349</td>\n",
       "      <td>9673.588298</td>\n",
       "      <td>10544.0582</td>\n",
       "      <td>6938.191835</td>\n",
       "      <td>32739.910723</td>\n",
       "      <td>9749.962662</td>\n",
       "      <td>7767.530628</td>\n",
       "      <td>8612.615549</td>\n",
       "      <td>9287.457917</td>\n",
       "      <td>9431.681788</td>\n",
       "      <td>8861.743317</td>\n",
       "      <td>9394.350592</td>\n",
       "      <td>9569.324332</td>\n",
       "      <td>9578.843492</td>\n",
       "      <td>10361.488063</td>\n",
       "      <td>9881.56245</td>\n",
       "      <td>9782.421027</td>\n",
       "      <td>9460.731311</td>\n",
       "      <td>11004.24041</td>\n",
       "      <td>9104.932397</td>\n",
       "      <td>10752.746732</td>\n",
       "      <td>8354.124101</td>\n",
       "      <td>8900.869755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops</th>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens_per_joule</th>\n",
       "      <td>0.640546</td>\n",
       "      <td>0.240872</td>\n",
       "      <td>0.154169</td>\n",
       "      <td>0.10767</td>\n",
       "      <td>0.017292</td>\n",
       "      <td>0.027908</td>\n",
       "      <td>0.043838</td>\n",
       "      <td>0.064884</td>\n",
       "      <td>0.103418</td>\n",
       "      <td>0.109892</td>\n",
       "      <td>0.103374</td>\n",
       "      <td>0.09484</td>\n",
       "      <td>0.14413</td>\n",
       "      <td>0.030544</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.128741</td>\n",
       "      <td>0.116109</td>\n",
       "      <td>0.107672</td>\n",
       "      <td>0.106026</td>\n",
       "      <td>0.112845</td>\n",
       "      <td>0.106447</td>\n",
       "      <td>0.104501</td>\n",
       "      <td>0.104397</td>\n",
       "      <td>0.096511</td>\n",
       "      <td>0.101199</td>\n",
       "      <td>0.102224</td>\n",
       "      <td>0.1057</td>\n",
       "      <td>0.090874</td>\n",
       "      <td>0.109831</td>\n",
       "      <td>0.092999</td>\n",
       "      <td>0.119701</td>\n",
       "      <td>0.112349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_token</th>\n",
       "      <td>1.561169</td>\n",
       "      <td>4.151582</td>\n",
       "      <td>6.486403</td>\n",
       "      <td>9.287658</td>\n",
       "      <td>57.830499</td>\n",
       "      <td>35.832431</td>\n",
       "      <td>22.811408</td>\n",
       "      <td>15.41207</td>\n",
       "      <td>9.669476</td>\n",
       "      <td>9.099859</td>\n",
       "      <td>9.673588</td>\n",
       "      <td>10.544058</td>\n",
       "      <td>6.938192</td>\n",
       "      <td>32.739911</td>\n",
       "      <td>9.749963</td>\n",
       "      <td>7.767531</td>\n",
       "      <td>8.612616</td>\n",
       "      <td>9.287458</td>\n",
       "      <td>9.431682</td>\n",
       "      <td>8.861743</td>\n",
       "      <td>9.394351</td>\n",
       "      <td>9.569324</td>\n",
       "      <td>9.578843</td>\n",
       "      <td>10.361488</td>\n",
       "      <td>9.881562</td>\n",
       "      <td>9.782421</td>\n",
       "      <td>9.460731</td>\n",
       "      <td>11.00424</td>\n",
       "      <td>9.104932</td>\n",
       "      <td>10.752747</td>\n",
       "      <td>8.354124</td>\n",
       "      <td>8.90087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops_per_joule</th>\n",
       "      <td>662672893.521465</td>\n",
       "      <td>249192727.209392</td>\n",
       "      <td>159494266.256535</td>\n",
       "      <td>111389122.454932</td>\n",
       "      <td>17889247.88724</td>\n",
       "      <td>28871725.980626</td>\n",
       "      <td>45352051.482635</td>\n",
       "      <td>67125577.616509</td>\n",
       "      <td>106990716.129887</td>\n",
       "      <td>113687925.088365</td>\n",
       "      <td>106945230.268081</td>\n",
       "      <td>98116314.268051</td>\n",
       "      <td>149108608.219022</td>\n",
       "      <td>31598868.327846</td>\n",
       "      <td>106107496.397334</td>\n",
       "      <td>133188290.785709</td>\n",
       "      <td>120119622.447774</td>\n",
       "      <td>111391527.936536</td>\n",
       "      <td>109688192.54092</td>\n",
       "      <td>116742732.320793</td>\n",
       "      <td>110124070.617504</td>\n",
       "      <td>108110467.588197</td>\n",
       "      <td>108003030.722911</td>\n",
       "      <td>99845130.52061</td>\n",
       "      <td>104694387.473973</td>\n",
       "      <td>105755428.550843</td>\n",
       "      <td>109351390.926845</td>\n",
       "      <td>94013224.855566</td>\n",
       "      <td>113624580.931623</td>\n",
       "      <td>96212079.926237</td>\n",
       "      <td>123836337.055097</td>\n",
       "      <td>116229554.686645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_flop</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_inference_time_sec</th>\n",
       "      <td>2.356892</td>\n",
       "      <td>2.401629</td>\n",
       "      <td>2.346066</td>\n",
       "      <td>2.372563</td>\n",
       "      <td>20.824448</td>\n",
       "      <td>10.598905</td>\n",
       "      <td>6.579609</td>\n",
       "      <td>4.488748</td>\n",
       "      <td>2.56615</td>\n",
       "      <td>2.408858</td>\n",
       "      <td>2.385437</td>\n",
       "      <td>2.286825</td>\n",
       "      <td>2.363797</td>\n",
       "      <td>7.218139</td>\n",
       "      <td>3.677875</td>\n",
       "      <td>2.272839</td>\n",
       "      <td>2.381273</td>\n",
       "      <td>2.350439</td>\n",
       "      <td>2.395863</td>\n",
       "      <td>2.303065</td>\n",
       "      <td>2.387908</td>\n",
       "      <td>2.412971</td>\n",
       "      <td>2.478181</td>\n",
       "      <td>3.440782</td>\n",
       "      <td>2.714286</td>\n",
       "      <td>2.56474</td>\n",
       "      <td>2.419328</td>\n",
       "      <td>3.559638</td>\n",
       "      <td>2.453797</td>\n",
       "      <td>4.07742</td>\n",
       "      <td>2.509436</td>\n",
       "      <td>2.615047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_latency_ms_per_batch</th>\n",
       "      <td>2356.891729</td>\n",
       "      <td>2401.628917</td>\n",
       "      <td>2346.066005</td>\n",
       "      <td>2372.563443</td>\n",
       "      <td>2082.444752</td>\n",
       "      <td>2119.780987</td>\n",
       "      <td>2193.20311</td>\n",
       "      <td>2244.3741</td>\n",
       "      <td>2566.149628</td>\n",
       "      <td>2408.858126</td>\n",
       "      <td>2385.437419</td>\n",
       "      <td>2286.825385</td>\n",
       "      <td>2363.7969</td>\n",
       "      <td>7218.139077</td>\n",
       "      <td>3677.875369</td>\n",
       "      <td>2272.839022</td>\n",
       "      <td>2381.273368</td>\n",
       "      <td>2350.439308</td>\n",
       "      <td>2395.863263</td>\n",
       "      <td>2303.064523</td>\n",
       "      <td>2387.907913</td>\n",
       "      <td>2412.971</td>\n",
       "      <td>2478.180916</td>\n",
       "      <td>3440.782234</td>\n",
       "      <td>2714.285777</td>\n",
       "      <td>2564.739563</td>\n",
       "      <td>2419.327923</td>\n",
       "      <td>3559.637986</td>\n",
       "      <td>2453.797072</td>\n",
       "      <td>4077.420104</td>\n",
       "      <td>2509.436437</td>\n",
       "      <td>2615.046637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_queries_per_sec</th>\n",
       "      <td>4.242876</td>\n",
       "      <td>4.163841</td>\n",
       "      <td>4.262455</td>\n",
       "      <td>4.21485</td>\n",
       "      <td>0.480205</td>\n",
       "      <td>0.943494</td>\n",
       "      <td>1.519847</td>\n",
       "      <td>2.227793</td>\n",
       "      <td>3.896889</td>\n",
       "      <td>4.151345</td>\n",
       "      <td>4.192103</td>\n",
       "      <td>4.372874</td>\n",
       "      <td>4.230482</td>\n",
       "      <td>1.385399</td>\n",
       "      <td>2.718961</td>\n",
       "      <td>4.399784</td>\n",
       "      <td>4.199434</td>\n",
       "      <td>4.254524</td>\n",
       "      <td>4.173861</td>\n",
       "      <td>4.342041</td>\n",
       "      <td>4.187766</td>\n",
       "      <td>4.144269</td>\n",
       "      <td>4.035218</td>\n",
       "      <td>2.906316</td>\n",
       "      <td>3.68421</td>\n",
       "      <td>3.899031</td>\n",
       "      <td>4.133379</td>\n",
       "      <td>2.809274</td>\n",
       "      <td>4.075317</td>\n",
       "      <td>2.452531</td>\n",
       "      <td>3.984958</td>\n",
       "      <td>3.824024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_tokens_per_sec</th>\n",
       "      <td>424.287627</td>\n",
       "      <td>416.38406</td>\n",
       "      <td>426.245467</td>\n",
       "      <td>421.485041</td>\n",
       "      <td>48.020482</td>\n",
       "      <td>94.34937</td>\n",
       "      <td>151.984708</td>\n",
       "      <td>222.779259</td>\n",
       "      <td>389.68889</td>\n",
       "      <td>415.134453</td>\n",
       "      <td>419.210327</td>\n",
       "      <td>437.287432</td>\n",
       "      <td>423.04819</td>\n",
       "      <td>138.539863</td>\n",
       "      <td>271.896108</td>\n",
       "      <td>439.978366</td>\n",
       "      <td>419.943386</td>\n",
       "      <td>425.452381</td>\n",
       "      <td>417.38609</td>\n",
       "      <td>434.204075</td>\n",
       "      <td>418.776618</td>\n",
       "      <td>414.426862</td>\n",
       "      <td>403.52179</td>\n",
       "      <td>290.631587</td>\n",
       "      <td>368.421044</td>\n",
       "      <td>389.903137</td>\n",
       "      <td>413.337932</td>\n",
       "      <td>280.927444</td>\n",
       "      <td>407.531662</td>\n",
       "      <td>245.253119</td>\n",
       "      <td>398.495848</td>\n",
       "      <td>382.402358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_usage_percent</th>\n",
       "      <td>3.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>47.4</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.7</td>\n",
       "      <td>55.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>16.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>17.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_memory_usage_bytes</th>\n",
       "      <td>2050256896</td>\n",
       "      <td>2070810624</td>\n",
       "      <td>2068250624</td>\n",
       "      <td>2075455488</td>\n",
       "      <td>2015477760</td>\n",
       "      <td>2049409024</td>\n",
       "      <td>2057400320</td>\n",
       "      <td>2067193856</td>\n",
       "      <td>2073178112</td>\n",
       "      <td>2076033024</td>\n",
       "      <td>2071547904</td>\n",
       "      <td>2073534464</td>\n",
       "      <td>3161710592</td>\n",
       "      <td>2766688256</td>\n",
       "      <td>2705195008</td>\n",
       "      <td>2056642560</td>\n",
       "      <td>2073894912</td>\n",
       "      <td>2070286336</td>\n",
       "      <td>2072047616</td>\n",
       "      <td>2056028160</td>\n",
       "      <td>2075602944</td>\n",
       "      <td>2075750400</td>\n",
       "      <td>2077544448</td>\n",
       "      <td>2057662464</td>\n",
       "      <td>2070953984</td>\n",
       "      <td>2052939776</td>\n",
       "      <td>2072227840</td>\n",
       "      <td>2074927104</td>\n",
       "      <td>2070724608</td>\n",
       "      <td>2072039424</td>\n",
       "      <td>2073120768</td>\n",
       "      <td>2070740992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_0</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_0</th>\n",
       "      <td>414.856645</td>\n",
       "      <td>605.276451</td>\n",
       "      <td>560.689296</td>\n",
       "      <td>788.015735</td>\n",
       "      <td>1313.057996</td>\n",
       "      <td>641.064988</td>\n",
       "      <td>677.58912</td>\n",
       "      <td>623.64748</td>\n",
       "      <td>641.468533</td>\n",
       "      <td>705.181102</td>\n",
       "      <td>651.046027</td>\n",
       "      <td>619.770725</td>\n",
       "      <td>675.28713</td>\n",
       "      <td>444.462409</td>\n",
       "      <td>557.53898</td>\n",
       "      <td>612.704186</td>\n",
       "      <td>762.470124</td>\n",
       "      <td>795.129191</td>\n",
       "      <td>740.388</td>\n",
       "      <td>776.321292</td>\n",
       "      <td>809.680864</td>\n",
       "      <td>646.756882</td>\n",
       "      <td>652.001595</td>\n",
       "      <td>567.629617</td>\n",
       "      <td>727.260463</td>\n",
       "      <td>701.330117</td>\n",
       "      <td>756.244221</td>\n",
       "      <td>551.612807</td>\n",
       "      <td>716.271282</td>\n",
       "      <td>381.983252</td>\n",
       "      <td>615.725547</td>\n",
       "      <td>717.525238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>491.304513</td>\n",
       "      <td>0.0</td>\n",
       "      <td>424.010995</td>\n",
       "      <td>466.001815</td>\n",
       "      <td>518.360923</td>\n",
       "      <td>369.103744</td>\n",
       "      <td>483.293236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>505.669169</td>\n",
       "      <td>1743.091048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>119.894599</td>\n",
       "      <td>374.736474</td>\n",
       "      <td>633.739616</td>\n",
       "      <td>556.747136</td>\n",
       "      <td>453.252145</td>\n",
       "      <td>18.628497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>495.301506</td>\n",
       "      <td>1679.540024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2219.419073</td>\n",
       "      <td>771.336972</td>\n",
       "      <td>555.824567</td>\n",
       "      <td>471.022131</td>\n",
       "      <td>413.266378</td>\n",
       "      <td>404.622742</td>\n",
       "      <td>468.725355</td>\n",
       "      <td>559.126046</td>\n",
       "      <td>310.173365</td>\n",
       "      <td>533.99169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>531.830444</td>\n",
       "      <td>708.880427</td>\n",
       "      <td>469.151347</td>\n",
       "      <td>629.644402</td>\n",
       "      <td>632.178172</td>\n",
       "      <td>561.420978</td>\n",
       "      <td>588.174565</td>\n",
       "      <td>683.577268</td>\n",
       "      <td>742.100489</td>\n",
       "      <td>667.109686</td>\n",
       "      <td>594.917177</td>\n",
       "      <td>518.21448</td>\n",
       "      <td>564.387603</td>\n",
       "      <td>660.52256</td>\n",
       "      <td>683.491168</td>\n",
       "      <td>688.585224</td>\n",
       "      <td>685.891048</td>\n",
       "      <td>759.717472</td>\n",
       "      <td>708.550319</td>\n",
       "      <td>731.480916</td>\n",
       "      <td>670.105119</td>\n",
       "      <td>615.131361</td>\n",
       "      <td>705.838975</td>\n",
       "      <td>718.217363</td>\n",
       "      <td>780.127003</td>\n",
       "      <td>516.23026</td>\n",
       "      <td>694.223236</td>\n",
       "      <td>611.717499</td>\n",
       "      <td>631.657895</td>\n",
       "      <td>734.177811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>533.950626</td>\n",
       "      <td>580.455824</td>\n",
       "      <td>658.01506</td>\n",
       "      <td>667.772397</td>\n",
       "      <td>545.313817</td>\n",
       "      <td>595.323068</td>\n",
       "      <td>598.674237</td>\n",
       "      <td>555.219656</td>\n",
       "      <td>0.0</td>\n",
       "      <td>589.702252</td>\n",
       "      <td>480.250829</td>\n",
       "      <td>0.0</td>\n",
       "      <td>627.405103</td>\n",
       "      <td>658.562704</td>\n",
       "      <td>610.801172</td>\n",
       "      <td>604.058121</td>\n",
       "      <td>574.829885</td>\n",
       "      <td>601.787839</td>\n",
       "      <td>1382.946973</td>\n",
       "      <td>708.385754</td>\n",
       "      <td>657.908802</td>\n",
       "      <td>944.800435</td>\n",
       "      <td>363.407429</td>\n",
       "      <td>250.763626</td>\n",
       "      <td>604.277492</td>\n",
       "      <td>618.121217</td>\n",
       "      <td>479.491748</td>\n",
       "      <td>796.653119</td>\n",
       "      <td>514.542529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_0</th>\n",
       "      <td>0.714289</td>\n",
       "      <td>0.721865</td>\n",
       "      <td>0.719776</td>\n",
       "      <td>0.722456</td>\n",
       "      <td>0.702599</td>\n",
       "      <td>0.71335</td>\n",
       "      <td>0.71698</td>\n",
       "      <td>0.720617</td>\n",
       "      <td>0.72172</td>\n",
       "      <td>0.722474</td>\n",
       "      <td>0.721355</td>\n",
       "      <td>0.721694</td>\n",
       "      <td>1.102643</td>\n",
       "      <td>0.965406</td>\n",
       "      <td>0.944375</td>\n",
       "      <td>0.716738</td>\n",
       "      <td>0.721763</td>\n",
       "      <td>0.721812</td>\n",
       "      <td>0.722298</td>\n",
       "      <td>0.716374</td>\n",
       "      <td>0.722797</td>\n",
       "      <td>0.723407</td>\n",
       "      <td>0.723691</td>\n",
       "      <td>0.716706</td>\n",
       "      <td>0.721634</td>\n",
       "      <td>0.714984</td>\n",
       "      <td>0.722484</td>\n",
       "      <td>0.722661</td>\n",
       "      <td>0.721959</td>\n",
       "      <td>0.722185</td>\n",
       "      <td>0.721872</td>\n",
       "      <td>0.720926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680336</td>\n",
       "      <td>0.678097</td>\n",
       "      <td>0.666578</td>\n",
       "      <td>0.659914</td>\n",
       "      <td>0.656784</td>\n",
       "      <td>0.662802</td>\n",
       "      <td>0.667093</td>\n",
       "      <td>0.667399</td>\n",
       "      <td>0.67005</td>\n",
       "      <td>0.670575</td>\n",
       "      <td>0.668138</td>\n",
       "      <td>0.871312</td>\n",
       "      <td>1.010028</td>\n",
       "      <td>1.002962</td>\n",
       "      <td>0.653096</td>\n",
       "      <td>0.666492</td>\n",
       "      <td>0.668358</td>\n",
       "      <td>0.672742</td>\n",
       "      <td>0.65193</td>\n",
       "      <td>0.681414</td>\n",
       "      <td>0.691215</td>\n",
       "      <td>0.681756</td>\n",
       "      <td>0.639193</td>\n",
       "      <td>0.662752</td>\n",
       "      <td>0.673425</td>\n",
       "      <td>0.663541</td>\n",
       "      <td>0.665721</td>\n",
       "      <td>0.678437</td>\n",
       "      <td>0.680659</td>\n",
       "      <td>0.673545</td>\n",
       "      <td>0.674317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.670814</td>\n",
       "      <td>0.677396</td>\n",
       "      <td>0.652318</td>\n",
       "      <td>0.656422</td>\n",
       "      <td>0.671325</td>\n",
       "      <td>0.665362</td>\n",
       "      <td>0.666369</td>\n",
       "      <td>0.669521</td>\n",
       "      <td>0.680642</td>\n",
       "      <td>0.666388</td>\n",
       "      <td>0.913636</td>\n",
       "      <td>1.010149</td>\n",
       "      <td>0.979697</td>\n",
       "      <td>0.652359</td>\n",
       "      <td>0.667424</td>\n",
       "      <td>0.668231</td>\n",
       "      <td>0.678045</td>\n",
       "      <td>0.638948</td>\n",
       "      <td>0.686724</td>\n",
       "      <td>0.691328</td>\n",
       "      <td>0.684342</td>\n",
       "      <td>0.646367</td>\n",
       "      <td>0.667909</td>\n",
       "      <td>0.666428</td>\n",
       "      <td>0.666791</td>\n",
       "      <td>0.67092</td>\n",
       "      <td>0.669261</td>\n",
       "      <td>0.671914</td>\n",
       "      <td>0.667791</td>\n",
       "      <td>0.668052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.672838</td>\n",
       "      <td>0.650243</td>\n",
       "      <td>0.657912</td>\n",
       "      <td>0.66566</td>\n",
       "      <td>0.666917</td>\n",
       "      <td>0.666261</td>\n",
       "      <td>0.678216</td>\n",
       "      <td>0.676693</td>\n",
       "      <td>0.671143</td>\n",
       "      <td>0.893091</td>\n",
       "      <td>1.000088</td>\n",
       "      <td>0.9912</td>\n",
       "      <td>0.652561</td>\n",
       "      <td>0.668657</td>\n",
       "      <td>0.670784</td>\n",
       "      <td>0.669389</td>\n",
       "      <td>0.639038</td>\n",
       "      <td>0.688542</td>\n",
       "      <td>0.681649</td>\n",
       "      <td>0.689416</td>\n",
       "      <td>0.651056</td>\n",
       "      <td>0.675183</td>\n",
       "      <td>0.667291</td>\n",
       "      <td>0.67208</td>\n",
       "      <td>0.685136</td>\n",
       "      <td>0.67303</td>\n",
       "      <td>0.671625</td>\n",
       "      <td>0.667638</td>\n",
       "      <td>0.667927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_0</th>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.00021</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.00013</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.00013</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000124</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.00021</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.00008</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.00018</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.00009</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_0</th>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.00038</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.00035</td>\n",
       "      <td>0.00093</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.000664</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.00046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.00064</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.003765</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000491</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.000712</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.000543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000422</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.003001</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.00052</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000442</td>\n",
       "      <td>0.000454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.003399</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.000977</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>0.001397</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000559</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.00053</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.00053</td>\n",
       "      <td>0.000619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_0</th>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.00046</td>\n",
       "      <td>0.000496</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.003694</td>\n",
       "      <td>0.002173</td>\n",
       "      <td>0.001406</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.00055</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.000547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000693</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.00123</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000844</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.005024</td>\n",
       "      <td>0.000702</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000864</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.000848</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000845</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.00085</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.000793</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.000646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000502</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.002158</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.000589</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.00057</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.001161</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000608</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.00054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.002615</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>0.00073</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.00066</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.000739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_0</th>\n",
       "      <td>1561.168622</td>\n",
       "      <td>1655.254476</td>\n",
       "      <td>1785.737139</td>\n",
       "      <td>1967.774708</td>\n",
       "      <td>13298.517006</td>\n",
       "      <td>7821.340985</td>\n",
       "      <td>5062.259515</td>\n",
       "      <td>3433.921539</td>\n",
       "      <td>2099.764701</td>\n",
       "      <td>2024.987954</td>\n",
       "      <td>1956.394685</td>\n",
       "      <td>2222.158137</td>\n",
       "      <td>1542.311349</td>\n",
       "      <td>4171.360098</td>\n",
       "      <td>2298.536562</td>\n",
       "      <td>1833.577944</td>\n",
       "      <td>1935.222914</td>\n",
       "      <td>1999.907206</td>\n",
       "      <td>2033.157579</td>\n",
       "      <td>1980.873995</td>\n",
       "      <td>2036.742215</td>\n",
       "      <td>1985.841167</td>\n",
       "      <td>2041.046993</td>\n",
       "      <td>2654.411522</td>\n",
       "      <td>2218.098723</td>\n",
       "      <td>2130.240098</td>\n",
       "      <td>2031.708541</td>\n",
       "      <td>2753.201388</td>\n",
       "      <td>2030.512325</td>\n",
       "      <td>2877.54669</td>\n",
       "      <td>1905.424207</td>\n",
       "      <td>1968.818093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2496.327873</td>\n",
       "      <td>2892.296754</td>\n",
       "      <td>2786.096248</td>\n",
       "      <td>16527.902193</td>\n",
       "      <td>10826.222637</td>\n",
       "      <td>6735.872403</td>\n",
       "      <td>4427.86806</td>\n",
       "      <td>3150.834691</td>\n",
       "      <td>2912.954866</td>\n",
       "      <td>3038.993424</td>\n",
       "      <td>3386.549539</td>\n",
       "      <td>1989.664818</td>\n",
       "      <td>18084.969546</td>\n",
       "      <td>2527.941143</td>\n",
       "      <td>2092.726127</td>\n",
       "      <td>2539.553048</td>\n",
       "      <td>3109.550092</td>\n",
       "      <td>3121.067615</td>\n",
       "      <td>2774.728283</td>\n",
       "      <td>3003.487737</td>\n",
       "      <td>3054.210497</td>\n",
       "      <td>3047.636726</td>\n",
       "      <td>3041.883795</td>\n",
       "      <td>3042.360366</td>\n",
       "      <td>3028.890264</td>\n",
       "      <td>2890.460805</td>\n",
       "      <td>3061.352417</td>\n",
       "      <td>2805.720536</td>\n",
       "      <td>2856.492483</td>\n",
       "      <td>2287.806555</td>\n",
       "      <td>2326.154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1808.369364</td>\n",
       "      <td>2018.489243</td>\n",
       "      <td>13131.137615</td>\n",
       "      <td>7769.089104</td>\n",
       "      <td>5047.998719</td>\n",
       "      <td>3381.365592</td>\n",
       "      <td>2120.050649</td>\n",
       "      <td>1989.456368</td>\n",
       "      <td>2051.496196</td>\n",
       "      <td>2259.662788</td>\n",
       "      <td>1606.976883</td>\n",
       "      <td>4179.91919</td>\n",
       "      <td>2320.70705</td>\n",
       "      <td>1832.894399</td>\n",
       "      <td>2010.031883</td>\n",
       "      <td>2003.210191</td>\n",
       "      <td>2055.629763</td>\n",
       "      <td>1960.037607</td>\n",
       "      <td>2068.396405</td>\n",
       "      <td>2070.639691</td>\n",
       "      <td>2044.85402</td>\n",
       "      <td>2205.460381</td>\n",
       "      <td>2245.070151</td>\n",
       "      <td>2189.903237</td>\n",
       "      <td>2059.903488</td>\n",
       "      <td>2440.732517</td>\n",
       "      <td>2019.285212</td>\n",
       "      <td>2363.976182</td>\n",
       "      <td>1887.933024</td>\n",
       "      <td>1944.850933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2515.298283</td>\n",
       "      <td>14872.94196</td>\n",
       "      <td>9415.778239</td>\n",
       "      <td>5965.276878</td>\n",
       "      <td>4168.915212</td>\n",
       "      <td>2298.825642</td>\n",
       "      <td>2172.460161</td>\n",
       "      <td>2626.703993</td>\n",
       "      <td>2675.687736</td>\n",
       "      <td>1799.238784</td>\n",
       "      <td>6303.66189</td>\n",
       "      <td>2602.777907</td>\n",
       "      <td>2008.332158</td>\n",
       "      <td>2127.807703</td>\n",
       "      <td>2174.790428</td>\n",
       "      <td>2221.826831</td>\n",
       "      <td>2146.103432</td>\n",
       "      <td>2285.724235</td>\n",
       "      <td>2458.632976</td>\n",
       "      <td>2445.305753</td>\n",
       "      <td>2459.732365</td>\n",
       "      <td>2376.033211</td>\n",
       "      <td>2433.387427</td>\n",
       "      <td>2478.658477</td>\n",
       "      <td>2748.954088</td>\n",
       "      <td>2249.414323</td>\n",
       "      <td>2654.731377</td>\n",
       "      <td>2272.960315</td>\n",
       "      <td>2661.04673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_avg</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_avg</th>\n",
       "      <td>414.856645</td>\n",
       "      <td>548.290482</td>\n",
       "      <td>364.173247</td>\n",
       "      <td>613.714446</td>\n",
       "      <td>707.166746</td>\n",
       "      <td>611.771343</td>\n",
       "      <td>586.660858</td>\n",
       "      <td>553.418878</td>\n",
       "      <td>456.241542</td>\n",
       "      <td>623.275444</td>\n",
       "      <td>922.864305</td>\n",
       "      <td>321.720103</td>\n",
       "      <td>494.950289</td>\n",
       "      <td>454.416048</td>\n",
       "      <td>438.91655</td>\n",
       "      <td>614.344746</td>\n",
       "      <td>639.444035</td>\n",
       "      <td>528.286021</td>\n",
       "      <td>507.584292</td>\n",
       "      <td>651.542539</td>\n",
       "      <td>949.889761</td>\n",
       "      <td>690.296192</td>\n",
       "      <td>1062.477885</td>\n",
       "      <td>653.001688</td>\n",
       "      <td>733.43111</td>\n",
       "      <td>563.49426</td>\n",
       "      <td>550.100307</td>\n",
       "      <td>519.185825</td>\n",
       "      <td>624.335273</td>\n",
       "      <td>508.079636</td>\n",
       "      <td>588.552482</td>\n",
       "      <td>625.059317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_avg</th>\n",
       "      <td>0.714289</td>\n",
       "      <td>0.7011</td>\n",
       "      <td>0.689562</td>\n",
       "      <td>0.684817</td>\n",
       "      <td>0.666268</td>\n",
       "      <td>0.671117</td>\n",
       "      <td>0.679191</td>\n",
       "      <td>0.679998</td>\n",
       "      <td>0.680437</td>\n",
       "      <td>0.685065</td>\n",
       "      <td>0.687316</td>\n",
       "      <td>0.681841</td>\n",
       "      <td>0.94517</td>\n",
       "      <td>0.996418</td>\n",
       "      <td>0.979558</td>\n",
       "      <td>0.668688</td>\n",
       "      <td>0.681084</td>\n",
       "      <td>0.682296</td>\n",
       "      <td>0.685619</td>\n",
       "      <td>0.661573</td>\n",
       "      <td>0.69487</td>\n",
       "      <td>0.696899</td>\n",
       "      <td>0.694802</td>\n",
       "      <td>0.66333</td>\n",
       "      <td>0.681869</td>\n",
       "      <td>0.680532</td>\n",
       "      <td>0.681224</td>\n",
       "      <td>0.68611</td>\n",
       "      <td>0.685672</td>\n",
       "      <td>0.686596</td>\n",
       "      <td>0.682712</td>\n",
       "      <td>0.682806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_total</th>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.002848</td>\n",
       "      <td>0.001568</td>\n",
       "      <td>0.000975</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>0.000364</td>\n",
       "      <td>0.000409</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.000394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_total</th>\n",
       "      <td>0.000355</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.00148</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.013203</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.003613</td>\n",
       "      <td>0.002251</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.001579</td>\n",
       "      <td>0.007272</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>0.001828</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.002169</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.002433</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>0.002298</td>\n",
       "      <td>0.00224</td>\n",
       "      <td>0.00258</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.002076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_total</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_generated_tokens</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_config_decoding_mode</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   0   \\\n",
       "config_name                                           num_processes_1   \n",
       "experiment_id                                                       1   \n",
       "date_time                               April 08, 2025 at 04:31:33 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       1   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                               1000   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  100   \n",
       "max_output_tokens                                                 100   \n",
       "number_input_prompts                                               10   \n",
       "total_energy_kwh                                             0.000434   \n",
       "total_energy_joules                                       1561.168622   \n",
       "flops                                                   1034544128000   \n",
       "tokens_per_joule                                             0.640546   \n",
       "joules_per_token                                             1.561169   \n",
       "flops_per_joule                                      662672893.521465   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     2.356892   \n",
       "average_latency_ms_per_batch                              2356.891729   \n",
       "throughput_queries_per_sec                                   4.242876   \n",
       "throughput_tokens_per_sec                                  424.287627   \n",
       "cpu_usage_percent                                                 3.9   \n",
       "cpu_memory_usage_bytes                                     2050256896   \n",
       "gpu_utilization_percent_0                                        11.0   \n",
       "gpu_utilization_percent_1                                       100.0   \n",
       "gpu_utilization_percent_2                                         0.0   \n",
       "gpu_utilization_percent_3                                        35.0   \n",
       "cpu_power_process_0                                             112.5   \n",
       "cpu_power_process_1                                               NaN   \n",
       "cpu_power_process_2                                               NaN   \n",
       "cpu_power_process_3                                               NaN   \n",
       "gpu_power_process_0                                        414.856645   \n",
       "gpu_power_process_1                                               NaN   \n",
       "gpu_power_process_2                                               NaN   \n",
       "gpu_power_process_3                                               NaN   \n",
       "ram_power_process_0                                          0.714289   \n",
       "ram_power_process_1                                               NaN   \n",
       "ram_power_process_2                                               NaN   \n",
       "ram_power_process_3                                               NaN   \n",
       "cpu_energy_process_0                                         0.000078   \n",
       "cpu_energy_process_1                                              NaN   \n",
       "cpu_energy_process_2                                              NaN   \n",
       "cpu_energy_process_3                                              NaN   \n",
       "gpu_energy_process_0                                         0.000355   \n",
       "gpu_energy_process_1                                              NaN   \n",
       "gpu_energy_process_2                                              NaN   \n",
       "gpu_energy_process_3                                              NaN   \n",
       "ram_energy_process_0                                              0.0   \n",
       "ram_energy_process_1                                              NaN   \n",
       "ram_energy_process_2                                              NaN   \n",
       "ram_energy_process_3                                              NaN   \n",
       "total_energy_kwh_process_0                                   0.000434   \n",
       "total_energy_kwh_process_1                                        NaN   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "total_energy_joules_process_0                             1561.168622   \n",
       "total_energy_joules_process_1                                     NaN   \n",
       "total_energy_joules_process_2                                     NaN   \n",
       "total_energy_joules_process_3                                     NaN   \n",
       "cpu_power_avg                                                   112.5   \n",
       "gpu_power_avg                                              414.856645   \n",
       "ram_power_avg                                                0.714289   \n",
       "cpu_energy_total                                             0.000078   \n",
       "gpu_energy_total                                             0.000355   \n",
       "ram_energy_total                                                  0.0   \n",
       "latency_simulation_simulate                                     False   \n",
       "models                                                  1034544128000   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                           1000   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   1   \\\n",
       "config_name                                           num_processes_2   \n",
       "experiment_id                                                       2   \n",
       "date_time                               April 08, 2025 at 04:32:06 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       2   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                               1000   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  100   \n",
       "max_output_tokens                                                 100   \n",
       "number_input_prompts                                               10   \n",
       "total_energy_kwh                                             0.001153   \n",
       "total_energy_joules                                        4151.58235   \n",
       "flops                                                   1034544128000   \n",
       "tokens_per_joule                                             0.240872   \n",
       "joules_per_token                                             4.151582   \n",
       "flops_per_joule                                      249192727.209392   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     2.401629   \n",
       "average_latency_ms_per_batch                              2401.628917   \n",
       "throughput_queries_per_sec                                   4.163841   \n",
       "throughput_tokens_per_sec                                   416.38406   \n",
       "cpu_usage_percent                                                 2.8   \n",
       "cpu_memory_usage_bytes                                     2070810624   \n",
       "gpu_utilization_percent_0                                        65.0   \n",
       "gpu_utilization_percent_1                                       100.0   \n",
       "gpu_utilization_percent_2                                         0.0   \n",
       "gpu_utilization_percent_3                                        71.0   \n",
       "cpu_power_process_0                                             112.5   \n",
       "cpu_power_process_1                                             112.5   \n",
       "cpu_power_process_2                                               NaN   \n",
       "cpu_power_process_3                                               NaN   \n",
       "gpu_power_process_0                                        605.276451   \n",
       "gpu_power_process_1                                        491.304513   \n",
       "gpu_power_process_2                                               NaN   \n",
       "gpu_power_process_3                                               NaN   \n",
       "ram_power_process_0                                          0.721865   \n",
       "ram_power_process_1                                          0.680336   \n",
       "ram_power_process_2                                               NaN   \n",
       "ram_power_process_3                                               NaN   \n",
       "cpu_energy_process_0                                          0.00008   \n",
       "cpu_energy_process_1                                         0.000126   \n",
       "cpu_energy_process_2                                              NaN   \n",
       "cpu_energy_process_3                                              NaN   \n",
       "gpu_energy_process_0                                          0.00038   \n",
       "gpu_energy_process_1                                         0.000567   \n",
       "gpu_energy_process_2                                              NaN   \n",
       "gpu_energy_process_3                                              NaN   \n",
       "ram_energy_process_0                                              0.0   \n",
       "ram_energy_process_1                                         0.000001   \n",
       "ram_energy_process_2                                              NaN   \n",
       "ram_energy_process_3                                              NaN   \n",
       "total_energy_kwh_process_0                                    0.00046   \n",
       "total_energy_kwh_process_1                                   0.000693   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "total_energy_joules_process_0                             1655.254476   \n",
       "total_energy_joules_process_1                             2496.327873   \n",
       "total_energy_joules_process_2                                     NaN   \n",
       "total_energy_joules_process_3                                     NaN   \n",
       "cpu_power_avg                                                   112.5   \n",
       "gpu_power_avg                                              548.290482   \n",
       "ram_power_avg                                                  0.7011   \n",
       "cpu_energy_total                                             0.000205   \n",
       "gpu_energy_total                                             0.000947   \n",
       "ram_energy_total                                             0.000001   \n",
       "latency_simulation_simulate                                     False   \n",
       "models                                                  1034544128000   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                           1000   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   2   \\\n",
       "config_name                                           num_processes_3   \n",
       "experiment_id                                                       3   \n",
       "date_time                               April 08, 2025 at 04:32:41 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       3   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                               1000   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  100   \n",
       "max_output_tokens                                                 100   \n",
       "number_input_prompts                                               10   \n",
       "total_energy_kwh                                             0.001802   \n",
       "total_energy_joules                                       6486.403256   \n",
       "flops                                                   1034544128000   \n",
       "tokens_per_joule                                             0.154169   \n",
       "joules_per_token                                             6.486403   \n",
       "flops_per_joule                                      159494266.256535   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     2.346066   \n",
       "average_latency_ms_per_batch                              2346.066005   \n",
       "throughput_queries_per_sec                                   4.262455   \n",
       "throughput_tokens_per_sec                                  426.245467   \n",
       "cpu_usage_percent                                                 4.9   \n",
       "cpu_memory_usage_bytes                                     2068250624   \n",
       "gpu_utilization_percent_0                                        11.0   \n",
       "gpu_utilization_percent_1                                       100.0   \n",
       "gpu_utilization_percent_2                                       100.0   \n",
       "gpu_utilization_percent_3                                       100.0   \n",
       "cpu_power_process_0                                             112.5   \n",
       "cpu_power_process_1                                             112.5   \n",
       "cpu_power_process_2                                             112.5   \n",
       "cpu_power_process_3                                               NaN   \n",
       "gpu_power_process_0                                        560.689296   \n",
       "gpu_power_process_1                                               0.0   \n",
       "gpu_power_process_2                                        531.830444   \n",
       "gpu_power_process_3                                               NaN   \n",
       "ram_power_process_0                                          0.719776   \n",
       "ram_power_process_1                                          0.678097   \n",
       "ram_power_process_2                                          0.670814   \n",
       "ram_power_process_3                                               NaN   \n",
       "cpu_energy_process_0                                         0.000078   \n",
       "cpu_energy_process_1                                         0.000162   \n",
       "cpu_energy_process_2                                          0.00008   \n",
       "cpu_energy_process_3                                              NaN   \n",
       "gpu_energy_process_0                                         0.000417   \n",
       "gpu_energy_process_1                                          0.00064   \n",
       "gpu_energy_process_2                                         0.000422   \n",
       "gpu_energy_process_3                                              NaN   \n",
       "ram_energy_process_0                                              0.0   \n",
       "ram_energy_process_1                                         0.000001   \n",
       "ram_energy_process_2                                              0.0   \n",
       "ram_energy_process_3                                              NaN   \n",
       "total_energy_kwh_process_0                                   0.000496   \n",
       "total_energy_kwh_process_1                                   0.000803   \n",
       "total_energy_kwh_process_2                                   0.000502   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "total_energy_joules_process_0                             1785.737139   \n",
       "total_energy_joules_process_1                             2892.296754   \n",
       "total_energy_joules_process_2                             1808.369364   \n",
       "total_energy_joules_process_3                                     NaN   \n",
       "cpu_power_avg                                                   112.5   \n",
       "gpu_power_avg                                              364.173247   \n",
       "ram_power_avg                                                0.689562   \n",
       "cpu_energy_total                                             0.000321   \n",
       "gpu_energy_total                                              0.00148   \n",
       "ram_energy_total                                             0.000002   \n",
       "latency_simulation_simulate                                     False   \n",
       "models                                                  1034544128000   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                           1000   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   3   \\\n",
       "config_name                                           num_processes_4   \n",
       "experiment_id                                                       4   \n",
       "date_time                               April 08, 2025 at 04:33:15 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                               1000   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  100   \n",
       "max_output_tokens                                                 100   \n",
       "number_input_prompts                                               10   \n",
       "total_energy_kwh                                              0.00258   \n",
       "total_energy_joules                                       9287.658482   \n",
       "flops                                                   1034544128000   \n",
       "tokens_per_joule                                              0.10767   \n",
       "joules_per_token                                             9.287658   \n",
       "flops_per_joule                                      111389122.454932   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     2.372563   \n",
       "average_latency_ms_per_batch                              2372.563443   \n",
       "throughput_queries_per_sec                                    4.21485   \n",
       "throughput_tokens_per_sec                                  421.485041   \n",
       "cpu_usage_percent                                                 4.4   \n",
       "cpu_memory_usage_bytes                                     2075455488   \n",
       "gpu_utilization_percent_0                                        11.0   \n",
       "gpu_utilization_percent_1                                       100.0   \n",
       "gpu_utilization_percent_2                                       100.0   \n",
       "gpu_utilization_percent_3                                       100.0   \n",
       "cpu_power_process_0                                             112.5   \n",
       "cpu_power_process_1                                             112.5   \n",
       "cpu_power_process_2                                             112.5   \n",
       "cpu_power_process_3                                             112.5   \n",
       "gpu_power_process_0                                        788.015735   \n",
       "gpu_power_process_1                                        424.010995   \n",
       "gpu_power_process_2                                        708.880427   \n",
       "gpu_power_process_3                                        533.950626   \n",
       "ram_power_process_0                                          0.722456   \n",
       "ram_power_process_1                                          0.666578   \n",
       "ram_power_process_2                                          0.677396   \n",
       "ram_power_process_3                                          0.672838   \n",
       "cpu_energy_process_0                                         0.000079   \n",
       "cpu_energy_process_1                                          0.00012   \n",
       "cpu_energy_process_2                                         0.000081   \n",
       "cpu_energy_process_3                                         0.000105   \n",
       "gpu_energy_process_0                                         0.000467   \n",
       "gpu_energy_process_1                                         0.000654   \n",
       "gpu_energy_process_2                                         0.000479   \n",
       "gpu_energy_process_3                                         0.000594   \n",
       "ram_energy_process_0                                              0.0   \n",
       "ram_energy_process_1                                         0.000001   \n",
       "ram_energy_process_2                                              0.0   \n",
       "ram_energy_process_3                                         0.000001   \n",
       "total_energy_kwh_process_0                                   0.000547   \n",
       "total_energy_kwh_process_1                                   0.000774   \n",
       "total_energy_kwh_process_2                                   0.000561   \n",
       "total_energy_kwh_process_3                                   0.000699   \n",
       "total_energy_joules_process_0                             1967.774708   \n",
       "total_energy_joules_process_1                             2786.096248   \n",
       "total_energy_joules_process_2                             2018.489243   \n",
       "total_energy_joules_process_3                             2515.298283   \n",
       "cpu_power_avg                                                   112.5   \n",
       "gpu_power_avg                                              613.714446   \n",
       "ram_power_avg                                                0.684817   \n",
       "cpu_energy_total                                             0.000384   \n",
       "gpu_energy_total                                             0.002194   \n",
       "ram_energy_total                                             0.000002   \n",
       "latency_simulation_simulate                                     False   \n",
       "models                                                  1034544128000   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                           1000   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   4   \\\n",
       "config_name                                                batching_1   \n",
       "experiment_id                                                       5   \n",
       "date_time                               April 08, 2025 at 04:34:12 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                         1   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                               1000   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  100   \n",
       "max_output_tokens                                                 100   \n",
       "number_input_prompts                                               10   \n",
       "total_energy_kwh                                             0.016064   \n",
       "total_energy_joules                                      57830.498773   \n",
       "flops                                                   1034544128000   \n",
       "tokens_per_joule                                             0.017292   \n",
       "joules_per_token                                            57.830499   \n",
       "flops_per_joule                                        17889247.88724   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    20.824448   \n",
       "average_latency_ms_per_batch                              2082.444752   \n",
       "throughput_queries_per_sec                                   0.480205   \n",
       "throughput_tokens_per_sec                                   48.020482   \n",
       "cpu_usage_percent                                                 5.0   \n",
       "cpu_memory_usage_bytes                                     2015477760   \n",
       "gpu_utilization_percent_0                                        57.0   \n",
       "gpu_utilization_percent_1                                       100.0   \n",
       "gpu_utilization_percent_2                                       100.0   \n",
       "gpu_utilization_percent_3                                       100.0   \n",
       "cpu_power_process_0                                             112.5   \n",
       "cpu_power_process_1                                             112.5   \n",
       "cpu_power_process_2                                             112.5   \n",
       "cpu_power_process_3                                             112.5   \n",
       "gpu_power_process_0                                       1313.057996   \n",
       "gpu_power_process_1                                        466.001815   \n",
       "gpu_power_process_2                                        469.151347   \n",
       "gpu_power_process_3                                        580.455824   \n",
       "ram_power_process_0                                          0.702599   \n",
       "ram_power_process_1                                          0.659914   \n",
       "ram_power_process_2                                          0.652318   \n",
       "ram_power_process_3                                          0.650243   \n",
       "cpu_energy_process_0                                         0.000652   \n",
       "cpu_energy_process_1                                         0.000822   \n",
       "cpu_energy_process_2                                         0.000644   \n",
       "cpu_energy_process_3                                         0.000729   \n",
       "gpu_energy_process_0                                         0.003039   \n",
       "gpu_energy_process_1                                         0.003765   \n",
       "gpu_energy_process_2                                         0.003001   \n",
       "gpu_energy_process_3                                         0.003399   \n",
       "ram_energy_process_0                                         0.000003   \n",
       "ram_energy_process_1                                         0.000004   \n",
       "ram_energy_process_2                                         0.000003   \n",
       "ram_energy_process_3                                         0.000003   \n",
       "total_energy_kwh_process_0                                   0.003694   \n",
       "total_energy_kwh_process_1                                   0.004591   \n",
       "total_energy_kwh_process_2                                   0.003648   \n",
       "total_energy_kwh_process_3                                   0.004131   \n",
       "total_energy_joules_process_0                            13298.517006   \n",
       "total_energy_joules_process_1                            16527.902193   \n",
       "total_energy_joules_process_2                            13131.137615   \n",
       "total_energy_joules_process_3                             14872.94196   \n",
       "cpu_power_avg                                                   112.5   \n",
       "gpu_power_avg                                              707.166746   \n",
       "ram_power_avg                                                0.666268   \n",
       "cpu_energy_total                                             0.002848   \n",
       "gpu_energy_total                                             0.013203   \n",
       "ram_energy_total                                             0.000014   \n",
       "latency_simulation_simulate                                     False   \n",
       "models                                                  1034544128000   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                           1000   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   5   \\\n",
       "config_name                                                batching_2   \n",
       "experiment_id                                                       6   \n",
       "date_time                               April 08, 2025 at 04:34:59 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                         2   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                               1000   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  100   \n",
       "max_output_tokens                                                 100   \n",
       "number_input_prompts                                               10   \n",
       "total_energy_kwh                                             0.009953   \n",
       "total_energy_joules                                      35832.430964   \n",
       "flops                                                   1034544128000   \n",
       "tokens_per_joule                                             0.027908   \n",
       "joules_per_token                                            35.832431   \n",
       "flops_per_joule                                       28871725.980626   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    10.598905   \n",
       "average_latency_ms_per_batch                              2119.780987   \n",
       "throughput_queries_per_sec                                   0.943494   \n",
       "throughput_tokens_per_sec                                    94.34937   \n",
       "cpu_usage_percent                                                17.6   \n",
       "cpu_memory_usage_bytes                                     2049409024   \n",
       "gpu_utilization_percent_0                                        20.0   \n",
       "gpu_utilization_percent_1                                       100.0   \n",
       "gpu_utilization_percent_2                                       100.0   \n",
       "gpu_utilization_percent_3                                       100.0   \n",
       "cpu_power_process_0                                             112.5   \n",
       "cpu_power_process_1                                             112.5   \n",
       "cpu_power_process_2                                             112.5   \n",
       "cpu_power_process_3                                             112.5   \n",
       "gpu_power_process_0                                        641.064988   \n",
       "gpu_power_process_1                                        518.360923   \n",
       "gpu_power_process_2                                        629.644402   \n",
       "gpu_power_process_3                                         658.01506   \n",
       "ram_power_process_0                                           0.71335   \n",
       "ram_power_process_1                                          0.656784   \n",
       "ram_power_process_2                                          0.656422   \n",
       "ram_power_process_3                                          0.657912   \n",
       "cpu_energy_process_0                                         0.000335   \n",
       "cpu_energy_process_1                                         0.000488   \n",
       "cpu_energy_process_2                                         0.000333   \n",
       "cpu_energy_process_3                                         0.000412   \n",
       "gpu_energy_process_0                                         0.001836   \n",
       "gpu_energy_process_1                                         0.002517   \n",
       "gpu_energy_process_2                                         0.001823   \n",
       "gpu_energy_process_3                                         0.002202   \n",
       "ram_energy_process_0                                         0.000002   \n",
       "ram_energy_process_1                                         0.000002   \n",
       "ram_energy_process_2                                         0.000002   \n",
       "ram_energy_process_3                                         0.000002   \n",
       "total_energy_kwh_process_0                                   0.002173   \n",
       "total_energy_kwh_process_1                                   0.003007   \n",
       "total_energy_kwh_process_2                                   0.002158   \n",
       "total_energy_kwh_process_3                                   0.002615   \n",
       "total_energy_joules_process_0                             7821.340985   \n",
       "total_energy_joules_process_1                            10826.222637   \n",
       "total_energy_joules_process_2                             7769.089104   \n",
       "total_energy_joules_process_3                             9415.778239   \n",
       "cpu_power_avg                                                   112.5   \n",
       "gpu_power_avg                                              611.771343   \n",
       "ram_power_avg                                                0.671117   \n",
       "cpu_energy_total                                             0.001568   \n",
       "gpu_energy_total                                             0.008378   \n",
       "ram_energy_total                                             0.000008   \n",
       "latency_simulation_simulate                                     False   \n",
       "models                                                  1034544128000   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                           1000   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   6   \\\n",
       "config_name                                                batching_4   \n",
       "experiment_id                                                       7   \n",
       "date_time                               April 08, 2025 at 04:35:43 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                         4   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                               1000   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  100   \n",
       "max_output_tokens                                                 100   \n",
       "number_input_prompts                                               10   \n",
       "total_energy_kwh                                             0.006337   \n",
       "total_energy_joules                                      22811.407515   \n",
       "flops                                                   1034544128000   \n",
       "tokens_per_joule                                             0.043838   \n",
       "joules_per_token                                            22.811408   \n",
       "flops_per_joule                                       45352051.482635   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     6.579609   \n",
       "average_latency_ms_per_batch                               2193.20311   \n",
       "throughput_queries_per_sec                                   1.519847   \n",
       "throughput_tokens_per_sec                                  151.984708   \n",
       "cpu_usage_percent                                                 4.0   \n",
       "cpu_memory_usage_bytes                                     2057400320   \n",
       "gpu_utilization_percent_0                                        67.0   \n",
       "gpu_utilization_percent_1                                        73.0   \n",
       "gpu_utilization_percent_2                                        99.0   \n",
       "gpu_utilization_percent_3                                       100.0   \n",
       "cpu_power_process_0                                             112.5   \n",
       "cpu_power_process_1                                             112.5   \n",
       "cpu_power_process_2                                             112.5   \n",
       "cpu_power_process_3                                             112.5   \n",
       "gpu_power_process_0                                         677.58912   \n",
       "gpu_power_process_1                                        369.103744   \n",
       "gpu_power_process_2                                        632.178172   \n",
       "gpu_power_process_3                                        667.772397   \n",
       "ram_power_process_0                                           0.71698   \n",
       "ram_power_process_1                                          0.662802   \n",
       "ram_power_process_2                                          0.671325   \n",
       "ram_power_process_3                                           0.66566   \n",
       "cpu_energy_process_0                                          0.00021   \n",
       "cpu_energy_process_1                                           0.0003   \n",
       "cpu_energy_process_2                                          0.00021   \n",
       "cpu_energy_process_3                                         0.000255   \n",
       "gpu_energy_process_0                                         0.001195   \n",
       "gpu_energy_process_1                                         0.001569   \n",
       "gpu_energy_process_2                                         0.001192   \n",
       "gpu_energy_process_3                                         0.001401   \n",
       "ram_energy_process_0                                         0.000001   \n",
       "ram_energy_process_1                                         0.000001   \n",
       "ram_energy_process_2                                         0.000001   \n",
       "ram_energy_process_3                                         0.000001   \n",
       "total_energy_kwh_process_0                                   0.001406   \n",
       "total_energy_kwh_process_1                                   0.001871   \n",
       "total_energy_kwh_process_2                                   0.001402   \n",
       "total_energy_kwh_process_3                                   0.001657   \n",
       "total_energy_joules_process_0                             5062.259515   \n",
       "total_energy_joules_process_1                             6735.872403   \n",
       "total_energy_joules_process_2                             5047.998719   \n",
       "total_energy_joules_process_3                             5965.276878   \n",
       "cpu_power_avg                                                   112.5   \n",
       "gpu_power_avg                                              586.660858   \n",
       "ram_power_avg                                                0.679191   \n",
       "cpu_energy_total                                             0.000975   \n",
       "gpu_energy_total                                             0.005357   \n",
       "ram_energy_total                                             0.000005   \n",
       "latency_simulation_simulate                                     False   \n",
       "models                                                  1034544128000   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                           1000   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   7   \\\n",
       "config_name                                                batching_8   \n",
       "experiment_id                                                       8   \n",
       "date_time                               April 08, 2025 at 04:36:20 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                         8   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                               1000   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  100   \n",
       "max_output_tokens                                                 100   \n",
       "number_input_prompts                                               10   \n",
       "total_energy_kwh                                             0.004281   \n",
       "total_energy_joules                                      15412.070402   \n",
       "flops                                                   1034544128000   \n",
       "tokens_per_joule                                             0.064884   \n",
       "joules_per_token                                             15.41207   \n",
       "flops_per_joule                                       67125577.616509   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     4.488748   \n",
       "average_latency_ms_per_batch                                2244.3741   \n",
       "throughput_queries_per_sec                                   2.227793   \n",
       "throughput_tokens_per_sec                                  222.779259   \n",
       "cpu_usage_percent                                                16.3   \n",
       "cpu_memory_usage_bytes                                     2067193856   \n",
       "gpu_utilization_percent_0                                        11.0   \n",
       "gpu_utilization_percent_1                                       100.0   \n",
       "gpu_utilization_percent_2                                       100.0   \n",
       "gpu_utilization_percent_3                                       100.0   \n",
       "cpu_power_process_0                                             112.5   \n",
       "cpu_power_process_1                                             112.5   \n",
       "cpu_power_process_2                                             112.5   \n",
       "cpu_power_process_3                                             112.5   \n",
       "gpu_power_process_0                                         623.64748   \n",
       "gpu_power_process_1                                        483.293236   \n",
       "gpu_power_process_2                                        561.420978   \n",
       "gpu_power_process_3                                        545.313817   \n",
       "ram_power_process_0                                          0.720617   \n",
       "ram_power_process_1                                          0.667093   \n",
       "ram_power_process_2                                          0.665362   \n",
       "ram_power_process_3                                          0.666917   \n",
       "cpu_energy_process_0                                         0.000145   \n",
       "cpu_energy_process_1                                         0.000195   \n",
       "cpu_energy_process_2                                         0.000145   \n",
       "cpu_energy_process_3                                          0.00018   \n",
       "gpu_energy_process_0                                         0.000808   \n",
       "gpu_energy_process_1                                         0.001034   \n",
       "gpu_energy_process_2                                         0.000794   \n",
       "gpu_energy_process_3                                         0.000977   \n",
       "ram_energy_process_0                                         0.000001   \n",
       "ram_energy_process_1                                         0.000001   \n",
       "ram_energy_process_2                                         0.000001   \n",
       "ram_energy_process_3                                         0.000001   \n",
       "total_energy_kwh_process_0                                   0.000954   \n",
       "total_energy_kwh_process_1                                    0.00123   \n",
       "total_energy_kwh_process_2                                   0.000939   \n",
       "total_energy_kwh_process_3                                   0.001158   \n",
       "total_energy_joules_process_0                             3433.921539   \n",
       "total_energy_joules_process_1                              4427.86806   \n",
       "total_energy_joules_process_2                             3381.365592   \n",
       "total_energy_joules_process_3                             4168.915212   \n",
       "cpu_power_avg                                                   112.5   \n",
       "gpu_power_avg                                              553.418878   \n",
       "ram_power_avg                                                0.679998   \n",
       "cpu_energy_total                                             0.000665   \n",
       "gpu_energy_total                                             0.003613   \n",
       "ram_energy_total                                             0.000003   \n",
       "latency_simulation_simulate                                     False   \n",
       "models                                                  1034544128000   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                           1000   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   8   \\\n",
       "config_name                                               batching_16   \n",
       "experiment_id                                                       9   \n",
       "date_time                               April 08, 2025 at 04:36:58 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                               1000   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  100   \n",
       "max_output_tokens                                                 100   \n",
       "number_input_prompts                                               10   \n",
       "total_energy_kwh                                             0.002686   \n",
       "total_energy_joules                                       9669.475684   \n",
       "flops                                                   1034544128000   \n",
       "tokens_per_joule                                             0.103418   \n",
       "joules_per_token                                             9.669476   \n",
       "flops_per_joule                                      106990716.129887   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                      2.56615   \n",
       "average_latency_ms_per_batch                              2566.149628   \n",
       "throughput_queries_per_sec                                   3.896889   \n",
       "throughput_tokens_per_sec                                   389.68889   \n",
       "cpu_usage_percent                                                47.4   \n",
       "cpu_memory_usage_bytes                                     2073178112   \n",
       "gpu_utilization_percent_0                                        69.0   \n",
       "gpu_utilization_percent_1                                       100.0   \n",
       "gpu_utilization_percent_2                                       100.0   \n",
       "gpu_utilization_percent_3                                       100.0   \n",
       "cpu_power_process_0                                             112.5   \n",
       "cpu_power_process_1                                             112.5   \n",
       "cpu_power_process_2                                             112.5   \n",
       "cpu_power_process_3                                             112.5   \n",
       "gpu_power_process_0                                        641.468533   \n",
       "gpu_power_process_1                                               0.0   \n",
       "gpu_power_process_2                                        588.174565   \n",
       "gpu_power_process_3                                        595.323068   \n",
       "ram_power_process_0                                           0.72172   \n",
       "ram_power_process_1                                          0.667399   \n",
       "ram_power_process_2                                          0.666369   \n",
       "ram_power_process_3                                          0.666261   \n",
       "cpu_energy_process_0                                         0.000086   \n",
       "cpu_energy_process_1                                         0.000166   \n",
       "cpu_energy_process_2                                         0.000086   \n",
       "cpu_energy_process_3                                         0.000095   \n",
       "gpu_energy_process_0                                         0.000497   \n",
       "gpu_energy_process_1                                         0.000708   \n",
       "gpu_energy_process_2                                         0.000502   \n",
       "gpu_energy_process_3                                         0.000543   \n",
       "ram_energy_process_0                                              0.0   \n",
       "ram_energy_process_1                                         0.000001   \n",
       "ram_energy_process_2                                              0.0   \n",
       "ram_energy_process_3                                              0.0   \n",
       "total_energy_kwh_process_0                                   0.000583   \n",
       "total_energy_kwh_process_1                                   0.000875   \n",
       "total_energy_kwh_process_2                                   0.000589   \n",
       "total_energy_kwh_process_3                                   0.000639   \n",
       "total_energy_joules_process_0                             2099.764701   \n",
       "total_energy_joules_process_1                             3150.834691   \n",
       "total_energy_joules_process_2                             2120.050649   \n",
       "total_energy_joules_process_3                             2298.825642   \n",
       "cpu_power_avg                                                   112.5   \n",
       "gpu_power_avg                                              456.241542   \n",
       "ram_power_avg                                                0.680437   \n",
       "cpu_energy_total                                             0.000433   \n",
       "gpu_energy_total                                             0.002251   \n",
       "ram_energy_total                                             0.000002   \n",
       "latency_simulation_simulate                                     False   \n",
       "models                                                  1034544128000   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                           1000   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   9   \\\n",
       "config_name                                               batching_32   \n",
       "experiment_id                                                      10   \n",
       "date_time                               April 08, 2025 at 04:37:33 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        32   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                               1000   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  100   \n",
       "max_output_tokens                                                 100   \n",
       "number_input_prompts                                               10   \n",
       "total_energy_kwh                                             0.002528   \n",
       "total_energy_joules                                       9099.859349   \n",
       "flops                                                   1034544128000   \n",
       "tokens_per_joule                                             0.109892   \n",
       "joules_per_token                                             9.099859   \n",
       "flops_per_joule                                      113687925.088365   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     2.408858   \n",
       "average_latency_ms_per_batch                              2408.858126   \n",
       "throughput_queries_per_sec                                   4.151345   \n",
       "throughput_tokens_per_sec                                  415.134453   \n",
       "cpu_usage_percent                                                 5.8   \n",
       "cpu_memory_usage_bytes                                     2076033024   \n",
       "gpu_utilization_percent_0                                         4.0   \n",
       "gpu_utilization_percent_1                                       100.0   \n",
       "gpu_utilization_percent_2                                       100.0   \n",
       "gpu_utilization_percent_3                                       100.0   \n",
       "cpu_power_process_0                                             112.5   \n",
       "cpu_power_process_1                                             112.5   \n",
       "cpu_power_process_2                                             112.5   \n",
       "cpu_power_process_3                                             112.5   \n",
       "gpu_power_process_0                                        705.181102   \n",
       "gpu_power_process_1                                        505.669169   \n",
       "gpu_power_process_2                                        683.577268   \n",
       "gpu_power_process_3                                        598.674237   \n",
       "ram_power_process_0                                          0.722474   \n",
       "ram_power_process_1                                           0.67005   \n",
       "ram_power_process_2                                          0.669521   \n",
       "ram_power_process_3                                          0.678216   \n",
       "cpu_energy_process_0                                          0.00008   \n",
       "cpu_energy_process_1                                         0.000125   \n",
       "cpu_energy_process_2                                         0.000079   \n",
       "cpu_energy_process_3                                          0.00009   \n",
       "gpu_energy_process_0                                         0.000482   \n",
       "gpu_energy_process_1                                         0.000683   \n",
       "gpu_energy_process_2                                         0.000473   \n",
       "gpu_energy_process_3                                         0.000513   \n",
       "ram_energy_process_0                                              0.0   \n",
       "ram_energy_process_1                                         0.000001   \n",
       "ram_energy_process_2                                              0.0   \n",
       "ram_energy_process_3                                              0.0   \n",
       "total_energy_kwh_process_0                                   0.000562   \n",
       "total_energy_kwh_process_1                                   0.000809   \n",
       "total_energy_kwh_process_2                                   0.000553   \n",
       "total_energy_kwh_process_3                                   0.000603   \n",
       "total_energy_joules_process_0                             2024.987954   \n",
       "total_energy_joules_process_1                             2912.954866   \n",
       "total_energy_joules_process_2                             1989.456368   \n",
       "total_energy_joules_process_3                             2172.460161   \n",
       "cpu_power_avg                                                   112.5   \n",
       "gpu_power_avg                                              623.275444   \n",
       "ram_power_avg                                                0.685065   \n",
       "cpu_energy_total                                             0.000375   \n",
       "gpu_energy_total                                             0.002151   \n",
       "ram_energy_total                                             0.000002   \n",
       "latency_simulation_simulate                                     False   \n",
       "models                                                  1034544128000   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                           1000   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   10  \\\n",
       "config_name                                               batching_64   \n",
       "experiment_id                                                      11   \n",
       "date_time                               April 08, 2025 at 04:38:19 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        64   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                               1000   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  100   \n",
       "max_output_tokens                                                 100   \n",
       "number_input_prompts                                               10   \n",
       "total_energy_kwh                                             0.002687   \n",
       "total_energy_joules                                       9673.588298   \n",
       "flops                                                   1034544128000   \n",
       "tokens_per_joule                                             0.103374   \n",
       "joules_per_token                                             9.673588   \n",
       "flops_per_joule                                      106945230.268081   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     2.385437   \n",
       "average_latency_ms_per_batch                              2385.437419   \n",
       "throughput_queries_per_sec                                   4.192103   \n",
       "throughput_tokens_per_sec                                  419.210327   \n",
       "cpu_usage_percent                                                 5.0   \n",
       "cpu_memory_usage_bytes                                     2071547904   \n",
       "gpu_utilization_percent_0                                        11.0   \n",
       "gpu_utilization_percent_1                                       100.0   \n",
       "gpu_utilization_percent_2                                       100.0   \n",
       "gpu_utilization_percent_3                                       100.0   \n",
       "cpu_power_process_0                                             112.5   \n",
       "cpu_power_process_1                                             112.5   \n",
       "cpu_power_process_2                                             112.5   \n",
       "cpu_power_process_3                                             112.5   \n",
       "gpu_power_process_0                                        651.046027   \n",
       "gpu_power_process_1                                       1743.091048   \n",
       "gpu_power_process_2                                        742.100489   \n",
       "gpu_power_process_3                                        555.219656   \n",
       "ram_power_process_0                                          0.721355   \n",
       "ram_power_process_1                                          0.670575   \n",
       "ram_power_process_2                                          0.680642   \n",
       "ram_power_process_3                                          0.676693   \n",
       "cpu_energy_process_0                                         0.000078   \n",
       "cpu_energy_process_1                                         0.000131   \n",
       "cpu_energy_process_2                                         0.000081   \n",
       "cpu_energy_process_3                                         0.000107   \n",
       "gpu_energy_process_0                                         0.000465   \n",
       "gpu_energy_process_1                                         0.000713   \n",
       "gpu_energy_process_2                                         0.000489   \n",
       "gpu_energy_process_3                                         0.000622   \n",
       "ram_energy_process_0                                              0.0   \n",
       "ram_energy_process_1                                         0.000001   \n",
       "ram_energy_process_2                                              0.0   \n",
       "ram_energy_process_3                                         0.000001   \n",
       "total_energy_kwh_process_0                                   0.000543   \n",
       "total_energy_kwh_process_1                                   0.000844   \n",
       "total_energy_kwh_process_2                                    0.00057   \n",
       "total_energy_kwh_process_3                                    0.00073   \n",
       "total_energy_joules_process_0                             1956.394685   \n",
       "total_energy_joules_process_1                             3038.993424   \n",
       "total_energy_joules_process_2                             2051.496196   \n",
       "total_energy_joules_process_3                             2626.703993   \n",
       "cpu_power_avg                                                   112.5   \n",
       "gpu_power_avg                                              922.864305   \n",
       "ram_power_avg                                                0.687316   \n",
       "cpu_energy_total                                             0.000397   \n",
       "gpu_energy_total                                             0.002288   \n",
       "ram_energy_total                                             0.000002   \n",
       "latency_simulation_simulate                                     False   \n",
       "models                                                  1034544128000   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                           1000   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                                  11  \\\n",
       "config_name                        precis_float32_quant_False_quant8_False_quant4...   \n",
       "experiment_id                                                                     12   \n",
       "date_time                                              April 08, 2025 at 04:38:55 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                              1000   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 100   \n",
       "max_output_tokens                                                                100   \n",
       "number_input_prompts                                                              10   \n",
       "total_energy_kwh                                                            0.002929   \n",
       "total_energy_joules                                                       10544.0582   \n",
       "flops                                                                  1034544128000   \n",
       "tokens_per_joule                                                             0.09484   \n",
       "joules_per_token                                                           10.544058   \n",
       "flops_per_joule                                                      98116314.268051   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    2.286825   \n",
       "average_latency_ms_per_batch                                             2286.825385   \n",
       "throughput_queries_per_sec                                                  4.372874   \n",
       "throughput_tokens_per_sec                                                 437.287432   \n",
       "cpu_usage_percent                                                                8.0   \n",
       "cpu_memory_usage_bytes                                                    2073534464   \n",
       "gpu_utilization_percent_0                                                       11.0   \n",
       "gpu_utilization_percent_1                                                      100.0   \n",
       "gpu_utilization_percent_2                                                      100.0   \n",
       "gpu_utilization_percent_3                                                      100.0   \n",
       "cpu_power_process_0                                                            112.5   \n",
       "cpu_power_process_1                                                            112.5   \n",
       "cpu_power_process_2                                                            112.5   \n",
       "cpu_power_process_3                                                            112.5   \n",
       "gpu_power_process_0                                                       619.770725   \n",
       "gpu_power_process_1                                                              0.0   \n",
       "gpu_power_process_2                                                       667.109686   \n",
       "gpu_power_process_3                                                              0.0   \n",
       "ram_power_process_0                                                         0.721694   \n",
       "ram_power_process_1                                                         0.668138   \n",
       "ram_power_process_2                                                         0.666388   \n",
       "ram_power_process_3                                                         0.671143   \n",
       "cpu_energy_process_0                                                        0.000109   \n",
       "cpu_energy_process_1                                                        0.000196   \n",
       "cpu_energy_process_2                                                        0.000111   \n",
       "cpu_energy_process_3                                                        0.000157   \n",
       "gpu_energy_process_0                                                        0.000507   \n",
       "gpu_energy_process_1                                                        0.000744   \n",
       "gpu_energy_process_2                                                        0.000516   \n",
       "gpu_energy_process_3                                                        0.000586   \n",
       "ram_energy_process_0                                                        0.000001   \n",
       "ram_energy_process_1                                                        0.000001   \n",
       "ram_energy_process_2                                                        0.000001   \n",
       "ram_energy_process_3                                                        0.000001   \n",
       "total_energy_kwh_process_0                                                  0.000617   \n",
       "total_energy_kwh_process_1                                                  0.000941   \n",
       "total_energy_kwh_process_2                                                  0.000628   \n",
       "total_energy_kwh_process_3                                                  0.000743   \n",
       "total_energy_joules_process_0                                            2222.158137   \n",
       "total_energy_joules_process_1                                            3386.549539   \n",
       "total_energy_joules_process_2                                            2259.662788   \n",
       "total_energy_joules_process_3                                            2675.687736   \n",
       "cpu_power_avg                                                                  112.5   \n",
       "gpu_power_avg                                                             321.720103   \n",
       "ram_power_avg                                                               0.681841   \n",
       "cpu_energy_total                                                            0.000572   \n",
       "gpu_energy_total                                                            0.002353   \n",
       "ram_energy_total                                                            0.000003   \n",
       "latency_simulation_simulate                                                    False   \n",
       "models                                                                 1034544128000   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                          1000   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "\n",
       "                                                                                  12  \\\n",
       "config_name                        precis_float16_quant_False_quant8_False_quant4...   \n",
       "experiment_id                                                                     13   \n",
       "date_time                                              April 08, 2025 at 04:39:28 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                              1000   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 100   \n",
       "max_output_tokens                                                                100   \n",
       "number_input_prompts                                                              10   \n",
       "total_energy_kwh                                                            0.001927   \n",
       "total_energy_joules                                                      6938.191835   \n",
       "flops                                                                  1034544128000   \n",
       "tokens_per_joule                                                             0.14413   \n",
       "joules_per_token                                                            6.938192   \n",
       "flops_per_joule                                                     149108608.219022   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    2.363797   \n",
       "average_latency_ms_per_batch                                               2363.7969   \n",
       "throughput_queries_per_sec                                                  4.230482   \n",
       "throughput_tokens_per_sec                                                  423.04819   \n",
       "cpu_usage_percent                                                                5.1   \n",
       "cpu_memory_usage_bytes                                                    3161710592   \n",
       "gpu_utilization_percent_0                                                        4.0   \n",
       "gpu_utilization_percent_1                                                      100.0   \n",
       "gpu_utilization_percent_2                                                      100.0   \n",
       "gpu_utilization_percent_3                                                      100.0   \n",
       "cpu_power_process_0                                                            112.5   \n",
       "cpu_power_process_1                                                            112.5   \n",
       "cpu_power_process_2                                                            112.5   \n",
       "cpu_power_process_3                                                            112.5   \n",
       "gpu_power_process_0                                                        675.28713   \n",
       "gpu_power_process_1                                                       119.894599   \n",
       "gpu_power_process_2                                                       594.917177   \n",
       "gpu_power_process_3                                                       589.702252   \n",
       "ram_power_process_0                                                         1.102643   \n",
       "ram_power_process_1                                                         0.871312   \n",
       "ram_power_process_2                                                         0.913636   \n",
       "ram_power_process_3                                                         0.893091   \n",
       "cpu_energy_process_0                                                        0.000078   \n",
       "cpu_energy_process_1                                                        0.000099   \n",
       "cpu_energy_process_2                                                         0.00008   \n",
       "cpu_energy_process_3                                                        0.000089   \n",
       "gpu_energy_process_0                                                         0.00035   \n",
       "gpu_energy_process_1                                                        0.000453   \n",
       "gpu_energy_process_2                                                        0.000366   \n",
       "gpu_energy_process_3                                                        0.000411   \n",
       "ram_energy_process_0                                                        0.000001   \n",
       "ram_energy_process_1                                                        0.000001   \n",
       "ram_energy_process_2                                                        0.000001   \n",
       "ram_energy_process_3                                                        0.000001   \n",
       "total_energy_kwh_process_0                                                  0.000428   \n",
       "total_energy_kwh_process_1                                                  0.000553   \n",
       "total_energy_kwh_process_2                                                  0.000446   \n",
       "total_energy_kwh_process_3                                                    0.0005   \n",
       "total_energy_joules_process_0                                            1542.311349   \n",
       "total_energy_joules_process_1                                            1989.664818   \n",
       "total_energy_joules_process_2                                            1606.976883   \n",
       "total_energy_joules_process_3                                            1799.238784   \n",
       "cpu_power_avg                                                                  112.5   \n",
       "gpu_power_avg                                                             494.950289   \n",
       "ram_power_avg                                                                0.94517   \n",
       "cpu_energy_total                                                            0.000346   \n",
       "gpu_energy_total                                                            0.001579   \n",
       "ram_energy_total                                                            0.000003   \n",
       "latency_simulation_simulate                                                    False   \n",
       "models                                                                 1034544128000   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                          1000   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "\n",
       "                                                                                  13  \\\n",
       "config_name                        precis_float16_quant_True_quant8_True_quant4_F...   \n",
       "experiment_id                                                                     14   \n",
       "date_time                                              April 08, 2025 at 04:40:33 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                    True   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                              1000   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 100   \n",
       "max_output_tokens                                                                100   \n",
       "number_input_prompts                                                              10   \n",
       "total_energy_kwh                                                            0.009094   \n",
       "total_energy_joules                                                     32739.910723   \n",
       "flops                                                                  1034544128000   \n",
       "tokens_per_joule                                                            0.030544   \n",
       "joules_per_token                                                           32.739911   \n",
       "flops_per_joule                                                      31598868.327846   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    7.218139   \n",
       "average_latency_ms_per_batch                                             7218.139077   \n",
       "throughput_queries_per_sec                                                  1.385399   \n",
       "throughput_tokens_per_sec                                                 138.539863   \n",
       "cpu_usage_percent                                                                4.7   \n",
       "cpu_memory_usage_bytes                                                    2766688256   \n",
       "gpu_utilization_percent_0                                                        0.0   \n",
       "gpu_utilization_percent_1                                                       96.0   \n",
       "gpu_utilization_percent_2                                                      100.0   \n",
       "gpu_utilization_percent_3                                                      100.0   \n",
       "cpu_power_process_0                                                            112.5   \n",
       "cpu_power_process_1                                                            112.5   \n",
       "cpu_power_process_2                                                            112.5   \n",
       "cpu_power_process_3                                                            112.5   \n",
       "gpu_power_process_0                                                       444.462409   \n",
       "gpu_power_process_1                                                       374.736474   \n",
       "gpu_power_process_2                                                        518.21448   \n",
       "gpu_power_process_3                                                       480.250829   \n",
       "ram_power_process_0                                                         0.965406   \n",
       "ram_power_process_1                                                         1.010028   \n",
       "ram_power_process_2                                                         1.010149   \n",
       "ram_power_process_3                                                         1.000088   \n",
       "cpu_energy_process_0                                                        0.000227   \n",
       "cpu_energy_process_1                                                        0.001001   \n",
       "cpu_energy_process_2                                                        0.000229   \n",
       "cpu_energy_process_3                                                        0.000352   \n",
       "gpu_energy_process_0                                                         0.00093   \n",
       "gpu_energy_process_1                                                        0.004014   \n",
       "gpu_energy_process_2                                                        0.000931   \n",
       "gpu_energy_process_3                                                        0.001397   \n",
       "ram_energy_process_0                                                        0.000001   \n",
       "ram_energy_process_1                                                        0.000008   \n",
       "ram_energy_process_2                                                        0.000002   \n",
       "ram_energy_process_3                                                        0.000003   \n",
       "total_energy_kwh_process_0                                                  0.001159   \n",
       "total_energy_kwh_process_1                                                  0.005024   \n",
       "total_energy_kwh_process_2                                                  0.001161   \n",
       "total_energy_kwh_process_3                                                  0.001751   \n",
       "total_energy_joules_process_0                                            4171.360098   \n",
       "total_energy_joules_process_1                                           18084.969546   \n",
       "total_energy_joules_process_2                                             4179.91919   \n",
       "total_energy_joules_process_3                                             6303.66189   \n",
       "cpu_power_avg                                                                  112.5   \n",
       "gpu_power_avg                                                             454.416048   \n",
       "ram_power_avg                                                               0.996418   \n",
       "cpu_energy_total                                                            0.001809   \n",
       "gpu_energy_total                                                            0.007272   \n",
       "ram_energy_total                                                            0.000014   \n",
       "latency_simulation_simulate                                                    False   \n",
       "models                                                                 1034544128000   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                          1000   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "\n",
       "                                                                                  14  \\\n",
       "config_name                        precis_float16_quant_True_quant8_False_quant4_...   \n",
       "experiment_id                                                                     15   \n",
       "date_time                                              April 08, 2025 at 04:41:10 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                              1000   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 100   \n",
       "max_output_tokens                                                                100   \n",
       "number_input_prompts                                                              10   \n",
       "total_energy_kwh                                                            0.002708   \n",
       "total_energy_joules                                                      9749.962662   \n",
       "flops                                                                  1034544128000   \n",
       "tokens_per_joule                                                            0.102564   \n",
       "joules_per_token                                                            9.749963   \n",
       "flops_per_joule                                                     106107496.397334   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    3.677875   \n",
       "average_latency_ms_per_batch                                             3677.875369   \n",
       "throughput_queries_per_sec                                                  2.718961   \n",
       "throughput_tokens_per_sec                                                 271.896108   \n",
       "cpu_usage_percent                                                                3.9   \n",
       "cpu_memory_usage_bytes                                                    2705195008   \n",
       "gpu_utilization_percent_0                                                        0.0   \n",
       "gpu_utilization_percent_1                                                      100.0   \n",
       "gpu_utilization_percent_2                                                      100.0   \n",
       "gpu_utilization_percent_3                                                      100.0   \n",
       "cpu_power_process_0                                                            112.5   \n",
       "cpu_power_process_1                                                            112.5   \n",
       "cpu_power_process_2                                                            112.5   \n",
       "cpu_power_process_3                                                            112.5   \n",
       "gpu_power_process_0                                                        557.53898   \n",
       "gpu_power_process_1                                                       633.739616   \n",
       "gpu_power_process_2                                                       564.387603   \n",
       "gpu_power_process_3                                                              0.0   \n",
       "ram_power_process_0                                                         0.944375   \n",
       "ram_power_process_1                                                         1.002962   \n",
       "ram_power_process_2                                                         0.979697   \n",
       "ram_power_process_3                                                           0.9912   \n",
       "cpu_energy_process_0                                                         0.00012   \n",
       "cpu_energy_process_1                                                        0.000133   \n",
       "cpu_energy_process_2                                                        0.000122   \n",
       "cpu_energy_process_3                                                        0.000163   \n",
       "gpu_energy_process_0                                                        0.000518   \n",
       "gpu_energy_process_1                                                        0.000568   \n",
       "gpu_energy_process_2                                                        0.000522   \n",
       "gpu_energy_process_3                                                        0.000559   \n",
       "ram_energy_process_0                                                        0.000001   \n",
       "ram_energy_process_1                                                        0.000001   \n",
       "ram_energy_process_2                                                        0.000001   \n",
       "ram_energy_process_3                                                        0.000001   \n",
       "total_energy_kwh_process_0                                                  0.000638   \n",
       "total_energy_kwh_process_1                                                  0.000702   \n",
       "total_energy_kwh_process_2                                                  0.000645   \n",
       "total_energy_kwh_process_3                                                  0.000723   \n",
       "total_energy_joules_process_0                                            2298.536562   \n",
       "total_energy_joules_process_1                                            2527.941143   \n",
       "total_energy_joules_process_2                                             2320.70705   \n",
       "total_energy_joules_process_3                                            2602.777907   \n",
       "cpu_power_avg                                                                  112.5   \n",
       "gpu_power_avg                                                              438.91655   \n",
       "ram_power_avg                                                               0.979558   \n",
       "cpu_energy_total                                                            0.000538   \n",
       "gpu_energy_total                                                            0.002166   \n",
       "ram_energy_total                                                            0.000004   \n",
       "latency_simulation_simulate                                                    False   \n",
       "models                                                                 1034544128000   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                          1000   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "\n",
       "                                                                      15  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_0   \n",
       "experiment_id                                                         16   \n",
       "date_time                                  April 08, 2025 at 04:41:43 PM   \n",
       "model                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                          4   \n",
       "batch_size___fixed_batching                                           16   \n",
       "decoder_temperature                                                  0.0   \n",
       "decoder_top_k                                                          0   \n",
       "decoder_top_p                                                        0.0   \n",
       "latency_simulation_delay_min                                         0.0   \n",
       "latency_simulation_simulate_burst                                  False   \n",
       "latency_simulation_burst_size                                          0   \n",
       "latency_simulation_burst_interval                                    0.0   \n",
       "fp_precision                                               torch.float32   \n",
       "quantization                                                       False   \n",
       "load_in_8bit                                                       False   \n",
       "load_in_4bit                                                       False   \n",
       "total_input_tokens                                                  1000   \n",
       "total_params                                                  1100048384   \n",
       "max_input_tokens                                                     100   \n",
       "max_output_tokens                                                    100   \n",
       "number_input_prompts                                                  10   \n",
       "total_energy_kwh                                                0.002158   \n",
       "total_energy_joules                                          7767.530628   \n",
       "flops                                                      1034544128000   \n",
       "tokens_per_joule                                                0.128741   \n",
       "joules_per_token                                                7.767531   \n",
       "flops_per_joule                                         133188290.785709   \n",
       "joules_per_flop                                                      0.0   \n",
       "total_inference_time_sec                                        2.272839   \n",
       "average_latency_ms_per_batch                                 2272.839022   \n",
       "throughput_queries_per_sec                                      4.399784   \n",
       "throughput_tokens_per_sec                                     439.978366   \n",
       "cpu_usage_percent                                                    4.0   \n",
       "cpu_memory_usage_bytes                                        2056642560   \n",
       "gpu_utilization_percent_0                                           18.0   \n",
       "gpu_utilization_percent_1                                          100.0   \n",
       "gpu_utilization_percent_2                                          100.0   \n",
       "gpu_utilization_percent_3                                          100.0   \n",
       "cpu_power_process_0                                                112.5   \n",
       "cpu_power_process_1                                                112.5   \n",
       "cpu_power_process_2                                                112.5   \n",
       "cpu_power_process_3                                                112.5   \n",
       "gpu_power_process_0                                           612.704186   \n",
       "gpu_power_process_1                                           556.747136   \n",
       "gpu_power_process_2                                            660.52256   \n",
       "gpu_power_process_3                                           627.405103   \n",
       "ram_power_process_0                                             0.716738   \n",
       "ram_power_process_1                                             0.653096   \n",
       "ram_power_process_2                                             0.652359   \n",
       "ram_power_process_3                                             0.652561   \n",
       "cpu_energy_process_0                                            0.000076   \n",
       "cpu_energy_process_1                                             0.00009   \n",
       "cpu_energy_process_2                                            0.000076   \n",
       "cpu_energy_process_3                                            0.000085   \n",
       "gpu_energy_process_0                                            0.000433   \n",
       "gpu_energy_process_1                                            0.000491   \n",
       "gpu_energy_process_2                                            0.000433   \n",
       "gpu_energy_process_3                                            0.000473   \n",
       "ram_energy_process_0                                                 0.0   \n",
       "ram_energy_process_1                                                 0.0   \n",
       "ram_energy_process_2                                                 0.0   \n",
       "ram_energy_process_3                                                 0.0   \n",
       "total_energy_kwh_process_0                                      0.000509   \n",
       "total_energy_kwh_process_1                                      0.000581   \n",
       "total_energy_kwh_process_2                                      0.000509   \n",
       "total_energy_kwh_process_3                                      0.000558   \n",
       "total_energy_joules_process_0                                1833.577944   \n",
       "total_energy_joules_process_1                                2092.726127   \n",
       "total_energy_joules_process_2                                1832.894399   \n",
       "total_energy_joules_process_3                                2008.332158   \n",
       "cpu_power_avg                                                      112.5   \n",
       "gpu_power_avg                                                 614.344746   \n",
       "ram_power_avg                                                   0.668688   \n",
       "cpu_energy_total                                                0.000328   \n",
       "gpu_energy_total                                                0.001828   \n",
       "ram_energy_total                                                0.000002   \n",
       "latency_simulation_simulate                                        False   \n",
       "models                                                     1034544128000   \n",
       "latency_simulation_delay_max                                         0.0   \n",
       "total_generated_tokens                                              1000   \n",
       "decoder_config_decoding_mode                                      greedy   \n",
       "\n",
       "                                                                        16  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_0.7   \n",
       "experiment_id                                                           17   \n",
       "date_time                                    April 08, 2025 at 04:42:19 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    0.7   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float32   \n",
       "quantization                                                         False   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                         False   \n",
       "total_input_tokens                                                    1000   \n",
       "total_params                                                    1100048384   \n",
       "max_input_tokens                                                       100   \n",
       "max_output_tokens                                                      100   \n",
       "number_input_prompts                                                    10   \n",
       "total_energy_kwh                                                  0.002392   \n",
       "total_energy_joules                                            8612.615549   \n",
       "flops                                                        1034544128000   \n",
       "tokens_per_joule                                                  0.116109   \n",
       "joules_per_token                                                  8.612616   \n",
       "flops_per_joule                                           120119622.447774   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                          2.381273   \n",
       "average_latency_ms_per_batch                                   2381.273368   \n",
       "throughput_queries_per_sec                                        4.199434   \n",
       "throughput_tokens_per_sec                                       419.943386   \n",
       "cpu_usage_percent                                                      4.7   \n",
       "cpu_memory_usage_bytes                                          2073894912   \n",
       "gpu_utilization_percent_0                                              1.0   \n",
       "gpu_utilization_percent_1                                            100.0   \n",
       "gpu_utilization_percent_2                                            100.0   \n",
       "gpu_utilization_percent_3                                            100.0   \n",
       "cpu_power_process_0                                                  112.5   \n",
       "cpu_power_process_1                                                  112.5   \n",
       "cpu_power_process_2                                                  112.5   \n",
       "cpu_power_process_3                                                  112.5   \n",
       "gpu_power_process_0                                             762.470124   \n",
       "gpu_power_process_1                                             453.252145   \n",
       "gpu_power_process_2                                             683.491168   \n",
       "gpu_power_process_3                                             658.562704   \n",
       "ram_power_process_0                                               0.721763   \n",
       "ram_power_process_1                                               0.666492   \n",
       "ram_power_process_2                                               0.667424   \n",
       "ram_power_process_3                                               0.668657   \n",
       "cpu_energy_process_0                                              0.000079   \n",
       "cpu_energy_process_1                                              0.000112   \n",
       "cpu_energy_process_2                                              0.000083   \n",
       "cpu_energy_process_3                                               0.00009   \n",
       "gpu_energy_process_0                                              0.000458   \n",
       "gpu_energy_process_1                                              0.000593   \n",
       "gpu_energy_process_2                                              0.000475   \n",
       "gpu_energy_process_3                                              0.000501   \n",
       "ram_energy_process_0                                                   0.0   \n",
       "ram_energy_process_1                                              0.000001   \n",
       "ram_energy_process_2                                                   0.0   \n",
       "ram_energy_process_3                                                   0.0   \n",
       "total_energy_kwh_process_0                                        0.000538   \n",
       "total_energy_kwh_process_1                                        0.000705   \n",
       "total_energy_kwh_process_2                                        0.000558   \n",
       "total_energy_kwh_process_3                                        0.000591   \n",
       "total_energy_joules_process_0                                  1935.222914   \n",
       "total_energy_joules_process_1                                  2539.553048   \n",
       "total_energy_joules_process_2                                  2010.031883   \n",
       "total_energy_joules_process_3                                  2127.807703   \n",
       "cpu_power_avg                                                        112.5   \n",
       "gpu_power_avg                                                   639.444035   \n",
       "ram_power_avg                                                     0.681084   \n",
       "cpu_energy_total                                                  0.000364   \n",
       "gpu_energy_total                                                  0.002027   \n",
       "ram_energy_total                                                  0.000002   \n",
       "latency_simulation_simulate                                          False   \n",
       "models                                                       1034544128000   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "total_generated_tokens                                                1000   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "\n",
       "                                                                        17  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_1.0   \n",
       "experiment_id                                                           18   \n",
       "date_time                                    April 08, 2025 at 04:42:54 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    1.0   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float32   \n",
       "quantization                                                         False   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                         False   \n",
       "total_input_tokens                                                    1000   \n",
       "total_params                                                    1100048384   \n",
       "max_input_tokens                                                       100   \n",
       "max_output_tokens                                                      100   \n",
       "number_input_prompts                                                    10   \n",
       "total_energy_kwh                                                   0.00258   \n",
       "total_energy_joules                                            9287.457917   \n",
       "flops                                                        1034544128000   \n",
       "tokens_per_joule                                                  0.107672   \n",
       "joules_per_token                                                  9.287458   \n",
       "flops_per_joule                                           111391527.936536   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                          2.350439   \n",
       "average_latency_ms_per_batch                                   2350.439308   \n",
       "throughput_queries_per_sec                                        4.254524   \n",
       "throughput_tokens_per_sec                                       425.452381   \n",
       "cpu_usage_percent                                                      4.8   \n",
       "cpu_memory_usage_bytes                                          2070286336   \n",
       "gpu_utilization_percent_0                                             20.0   \n",
       "gpu_utilization_percent_1                                            100.0   \n",
       "gpu_utilization_percent_2                                             99.0   \n",
       "gpu_utilization_percent_3                                            100.0   \n",
       "cpu_power_process_0                                                  112.5   \n",
       "cpu_power_process_1                                                  112.5   \n",
       "cpu_power_process_2                                                  112.5   \n",
       "cpu_power_process_3                                                  112.5   \n",
       "gpu_power_process_0                                             795.129191   \n",
       "gpu_power_process_1                                              18.628497   \n",
       "gpu_power_process_2                                             688.585224   \n",
       "gpu_power_process_3                                             610.801172   \n",
       "ram_power_process_0                                               0.721812   \n",
       "ram_power_process_1                                               0.668358   \n",
       "ram_power_process_2                                               0.668231   \n",
       "ram_power_process_3                                               0.670784   \n",
       "cpu_energy_process_0                                              0.000078   \n",
       "cpu_energy_process_1                                              0.000163   \n",
       "cpu_energy_process_2                                              0.000079   \n",
       "cpu_energy_process_3                                              0.000088   \n",
       "gpu_energy_process_0                                              0.000477   \n",
       "gpu_energy_process_1                                                0.0007   \n",
       "gpu_energy_process_2                                              0.000477   \n",
       "gpu_energy_process_3                                              0.000515   \n",
       "ram_energy_process_0                                                   0.0   \n",
       "ram_energy_process_1                                              0.000001   \n",
       "ram_energy_process_2                                                   0.0   \n",
       "ram_energy_process_3                                                   0.0   \n",
       "total_energy_kwh_process_0                                        0.000556   \n",
       "total_energy_kwh_process_1                                        0.000864   \n",
       "total_energy_kwh_process_2                                        0.000556   \n",
       "total_energy_kwh_process_3                                        0.000604   \n",
       "total_energy_joules_process_0                                  1999.907206   \n",
       "total_energy_joules_process_1                                  3109.550092   \n",
       "total_energy_joules_process_2                                  2003.210191   \n",
       "total_energy_joules_process_3                                  2174.790428   \n",
       "cpu_power_avg                                                        112.5   \n",
       "gpu_power_avg                                                   528.286021   \n",
       "ram_power_avg                                                     0.682296   \n",
       "cpu_energy_total                                                  0.000409   \n",
       "gpu_energy_total                                                  0.002169   \n",
       "ram_energy_total                                                  0.000002   \n",
       "latency_simulation_simulate                                          False   \n",
       "models                                                       1034544128000   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "total_generated_tokens                                                1000   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "\n",
       "                                                                        18  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_1.3   \n",
       "experiment_id                                                           19   \n",
       "date_time                                    April 08, 2025 at 04:43:29 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    1.3   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float32   \n",
       "quantization                                                         False   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                         False   \n",
       "total_input_tokens                                                    1000   \n",
       "total_params                                                    1100048384   \n",
       "max_input_tokens                                                       100   \n",
       "max_output_tokens                                                      100   \n",
       "number_input_prompts                                                    10   \n",
       "total_energy_kwh                                                   0.00262   \n",
       "total_energy_joules                                            9431.681788   \n",
       "flops                                                        1034544128000   \n",
       "tokens_per_joule                                                  0.106026   \n",
       "joules_per_token                                                  9.431682   \n",
       "flops_per_joule                                            109688192.54092   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                          2.395863   \n",
       "average_latency_ms_per_batch                                   2395.863263   \n",
       "throughput_queries_per_sec                                        4.173861   \n",
       "throughput_tokens_per_sec                                        417.38609   \n",
       "cpu_usage_percent                                                      5.5   \n",
       "cpu_memory_usage_bytes                                          2072047616   \n",
       "gpu_utilization_percent_0                                             36.0   \n",
       "gpu_utilization_percent_1                                            100.0   \n",
       "gpu_utilization_percent_2                                            100.0   \n",
       "gpu_utilization_percent_3                                            100.0   \n",
       "cpu_power_process_0                                                  112.5   \n",
       "cpu_power_process_1                                                  112.5   \n",
       "cpu_power_process_2                                                  112.5   \n",
       "cpu_power_process_3                                                  112.5   \n",
       "gpu_power_process_0                                                740.388   \n",
       "gpu_power_process_1                                                    0.0   \n",
       "gpu_power_process_2                                             685.891048   \n",
       "gpu_power_process_3                                             604.058121   \n",
       "ram_power_process_0                                               0.722298   \n",
       "ram_power_process_1                                               0.672742   \n",
       "ram_power_process_2                                               0.678045   \n",
       "ram_power_process_3                                               0.669389   \n",
       "cpu_energy_process_0                                               0.00008   \n",
       "cpu_energy_process_1                                              0.000163   \n",
       "cpu_energy_process_2                                              0.000083   \n",
       "cpu_energy_process_3                                              0.000089   \n",
       "gpu_energy_process_0                                              0.000484   \n",
       "gpu_energy_process_1                                              0.000703   \n",
       "gpu_energy_process_2                                              0.000488   \n",
       "gpu_energy_process_3                                              0.000527   \n",
       "ram_energy_process_0                                                   0.0   \n",
       "ram_energy_process_1                                              0.000001   \n",
       "ram_energy_process_2                                                   0.0   \n",
       "ram_energy_process_3                                                   0.0   \n",
       "total_energy_kwh_process_0                                        0.000565   \n",
       "total_energy_kwh_process_1                                        0.000867   \n",
       "total_energy_kwh_process_2                                        0.000571   \n",
       "total_energy_kwh_process_3                                        0.000617   \n",
       "total_energy_joules_process_0                                  2033.157579   \n",
       "total_energy_joules_process_1                                  3121.067615   \n",
       "total_energy_joules_process_2                                  2055.629763   \n",
       "total_energy_joules_process_3                                  2221.826831   \n",
       "cpu_power_avg                                                        112.5   \n",
       "gpu_power_avg                                                   507.584292   \n",
       "ram_power_avg                                                     0.685619   \n",
       "cpu_energy_total                                                  0.000415   \n",
       "gpu_energy_total                                                  0.002203   \n",
       "ram_energy_total                                                  0.000002   \n",
       "latency_simulation_simulate                                          False   \n",
       "models                                                       1034544128000   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "total_generated_tokens                                                1000   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "\n",
       "                                                                                  19  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                     20   \n",
       "date_time                                              April 08, 2025 at 04:44:03 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                              1000   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 100   \n",
       "max_output_tokens                                                                100   \n",
       "number_input_prompts                                                              10   \n",
       "total_energy_kwh                                                            0.002462   \n",
       "total_energy_joules                                                      8861.743317   \n",
       "flops                                                                  1034544128000   \n",
       "tokens_per_joule                                                            0.112845   \n",
       "joules_per_token                                                            8.861743   \n",
       "flops_per_joule                                                     116742732.320793   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    2.303065   \n",
       "average_latency_ms_per_batch                                             2303.064523   \n",
       "throughput_queries_per_sec                                                  4.342041   \n",
       "throughput_tokens_per_sec                                                 434.204075   \n",
       "cpu_usage_percent                                                                5.8   \n",
       "cpu_memory_usage_bytes                                                    2056028160   \n",
       "gpu_utilization_percent_0                                                       11.0   \n",
       "gpu_utilization_percent_1                                                      100.0   \n",
       "gpu_utilization_percent_2                                                      100.0   \n",
       "gpu_utilization_percent_3                                                      100.0   \n",
       "cpu_power_process_0                                                            112.5   \n",
       "cpu_power_process_1                                                            112.5   \n",
       "cpu_power_process_2                                                            112.5   \n",
       "cpu_power_process_3                                                            112.5   \n",
       "gpu_power_process_0                                                       776.321292   \n",
       "gpu_power_process_1                                                       495.301506   \n",
       "gpu_power_process_2                                                       759.717472   \n",
       "gpu_power_process_3                                                       574.829885   \n",
       "ram_power_process_0                                                         0.716374   \n",
       "ram_power_process_1                                                          0.65193   \n",
       "ram_power_process_2                                                         0.638948   \n",
       "ram_power_process_3                                                         0.639038   \n",
       "cpu_energy_process_0                                                        0.000077   \n",
       "cpu_energy_process_1                                                        0.000119   \n",
       "cpu_energy_process_2                                                        0.000076   \n",
       "cpu_energy_process_3                                                        0.000086   \n",
       "gpu_energy_process_0                                                        0.000473   \n",
       "gpu_energy_process_1                                                        0.000651   \n",
       "gpu_energy_process_2                                                        0.000468   \n",
       "gpu_energy_process_3                                                        0.000509   \n",
       "ram_energy_process_0                                                             0.0   \n",
       "ram_energy_process_1                                                        0.000001   \n",
       "ram_energy_process_2                                                             0.0   \n",
       "ram_energy_process_3                                                             0.0   \n",
       "total_energy_kwh_process_0                                                   0.00055   \n",
       "total_energy_kwh_process_1                                                  0.000771   \n",
       "total_energy_kwh_process_2                                                  0.000544   \n",
       "total_energy_kwh_process_3                                                  0.000596   \n",
       "total_energy_joules_process_0                                            1980.873995   \n",
       "total_energy_joules_process_1                                            2774.728283   \n",
       "total_energy_joules_process_2                                            1960.037607   \n",
       "total_energy_joules_process_3                                            2146.103432   \n",
       "cpu_power_avg                                                                  112.5   \n",
       "gpu_power_avg                                                             651.542539   \n",
       "ram_power_avg                                                               0.661573   \n",
       "cpu_energy_total                                                            0.000359   \n",
       "gpu_energy_total                                                            0.002101   \n",
       "ram_energy_total                                                            0.000002   \n",
       "latency_simulation_simulate                                                    False   \n",
       "models                                                                 1034544128000   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                          1000   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  20  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                     21   \n",
       "date_time                                              April 08, 2025 at 04:44:38 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.7   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                              1000   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 100   \n",
       "max_output_tokens                                                                100   \n",
       "number_input_prompts                                                              10   \n",
       "total_energy_kwh                                                             0.00261   \n",
       "total_energy_joules                                                      9394.350592   \n",
       "flops                                                                  1034544128000   \n",
       "tokens_per_joule                                                            0.106447   \n",
       "joules_per_token                                                            9.394351   \n",
       "flops_per_joule                                                     110124070.617504   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    2.387908   \n",
       "average_latency_ms_per_batch                                             2387.907913   \n",
       "throughput_queries_per_sec                                                  4.187766   \n",
       "throughput_tokens_per_sec                                                 418.776618   \n",
       "cpu_usage_percent                                                                5.5   \n",
       "cpu_memory_usage_bytes                                                    2075602944   \n",
       "gpu_utilization_percent_0                                                       67.0   \n",
       "gpu_utilization_percent_1                                                      100.0   \n",
       "gpu_utilization_percent_2                                                      100.0   \n",
       "gpu_utilization_percent_3                                                      100.0   \n",
       "cpu_power_process_0                                                            112.5   \n",
       "cpu_power_process_1                                                            112.5   \n",
       "cpu_power_process_2                                                            112.5   \n",
       "cpu_power_process_3                                                            112.5   \n",
       "gpu_power_process_0                                                       809.680864   \n",
       "gpu_power_process_1                                                      1679.540024   \n",
       "gpu_power_process_2                                                       708.550319   \n",
       "gpu_power_process_3                                                       601.787839   \n",
       "ram_power_process_0                                                         0.722797   \n",
       "ram_power_process_1                                                         0.681414   \n",
       "ram_power_process_2                                                         0.686724   \n",
       "ram_power_process_3                                                         0.688542   \n",
       "cpu_energy_process_0                                                         0.00008   \n",
       "cpu_energy_process_1                                                         0.00013   \n",
       "cpu_energy_process_2                                                        0.000083   \n",
       "cpu_energy_process_3                                                        0.000093   \n",
       "gpu_energy_process_0                                                        0.000486   \n",
       "gpu_energy_process_1                                                        0.000703   \n",
       "gpu_energy_process_2                                                        0.000492   \n",
       "gpu_energy_process_3                                                        0.000542   \n",
       "ram_energy_process_0                                                             0.0   \n",
       "ram_energy_process_1                                                        0.000001   \n",
       "ram_energy_process_2                                                             0.0   \n",
       "ram_energy_process_3                                                             0.0   \n",
       "total_energy_kwh_process_0                                                  0.000566   \n",
       "total_energy_kwh_process_1                                                  0.000834   \n",
       "total_energy_kwh_process_2                                                  0.000575   \n",
       "total_energy_kwh_process_3                                                  0.000635   \n",
       "total_energy_joules_process_0                                            2036.742215   \n",
       "total_energy_joules_process_1                                            3003.487737   \n",
       "total_energy_joules_process_2                                            2068.396405   \n",
       "total_energy_joules_process_3                                            2285.724235   \n",
       "cpu_power_avg                                                                  112.5   \n",
       "gpu_power_avg                                                             949.889761   \n",
       "ram_power_avg                                                                0.69487   \n",
       "cpu_energy_total                                                            0.000386   \n",
       "gpu_energy_total                                                            0.002222   \n",
       "ram_energy_total                                                            0.000002   \n",
       "latency_simulation_simulate                                                    False   \n",
       "models                                                                 1034544128000   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                          1000   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  21  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                     22   \n",
       "date_time                                              April 08, 2025 at 04:45:14 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                              1000   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 100   \n",
       "max_output_tokens                                                                100   \n",
       "number_input_prompts                                                              10   \n",
       "total_energy_kwh                                                            0.002658   \n",
       "total_energy_joules                                                      9569.324332   \n",
       "flops                                                                  1034544128000   \n",
       "tokens_per_joule                                                            0.104501   \n",
       "joules_per_token                                                            9.569324   \n",
       "flops_per_joule                                                     108110467.588197   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    2.412971   \n",
       "average_latency_ms_per_batch                                                2412.971   \n",
       "throughput_queries_per_sec                                                  4.144269   \n",
       "throughput_tokens_per_sec                                                 414.426862   \n",
       "cpu_usage_percent                                                                4.0   \n",
       "cpu_memory_usage_bytes                                                    2075750400   \n",
       "gpu_utilization_percent_0                                                        7.0   \n",
       "gpu_utilization_percent_1                                                      100.0   \n",
       "gpu_utilization_percent_2                                                      100.0   \n",
       "gpu_utilization_percent_3                                                      100.0   \n",
       "cpu_power_process_0                                                            112.5   \n",
       "cpu_power_process_1                                                            112.5   \n",
       "cpu_power_process_2                                                            112.5   \n",
       "cpu_power_process_3                                                            112.5   \n",
       "gpu_power_process_0                                                       646.756882   \n",
       "gpu_power_process_1                                                              0.0   \n",
       "gpu_power_process_2                                                       731.480916   \n",
       "gpu_power_process_3                                                      1382.946973   \n",
       "ram_power_process_0                                                         0.723407   \n",
       "ram_power_process_1                                                         0.691215   \n",
       "ram_power_process_2                                                         0.691328   \n",
       "ram_power_process_3                                                         0.681649   \n",
       "cpu_energy_process_0                                                         0.00008   \n",
       "cpu_energy_process_1                                                        0.000131   \n",
       "cpu_energy_process_2                                                        0.000082   \n",
       "cpu_energy_process_3                                                        0.000099   \n",
       "gpu_energy_process_0                                                        0.000471   \n",
       "gpu_energy_process_1                                                        0.000717   \n",
       "gpu_energy_process_2                                                        0.000492   \n",
       "gpu_energy_process_3                                                        0.000583   \n",
       "ram_energy_process_0                                                             0.0   \n",
       "ram_energy_process_1                                                        0.000001   \n",
       "ram_energy_process_2                                                             0.0   \n",
       "ram_energy_process_3                                                        0.000001   \n",
       "total_energy_kwh_process_0                                                  0.000552   \n",
       "total_energy_kwh_process_1                                                  0.000848   \n",
       "total_energy_kwh_process_2                                                  0.000575   \n",
       "total_energy_kwh_process_3                                                  0.000683   \n",
       "total_energy_joules_process_0                                            1985.841167   \n",
       "total_energy_joules_process_1                                            3054.210497   \n",
       "total_energy_joules_process_2                                            2070.639691   \n",
       "total_energy_joules_process_3                                            2458.632976   \n",
       "cpu_power_avg                                                                  112.5   \n",
       "gpu_power_avg                                                             690.296192   \n",
       "ram_power_avg                                                               0.696899   \n",
       "cpu_energy_total                                                            0.000393   \n",
       "gpu_energy_total                                                            0.002263   \n",
       "ram_energy_total                                                            0.000002   \n",
       "latency_simulation_simulate                                                    False   \n",
       "models                                                                 1034544128000   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                          1000   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  22  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                     23   \n",
       "date_time                                              April 08, 2025 at 04:45:49 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.3   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                              1000   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 100   \n",
       "max_output_tokens                                                                100   \n",
       "number_input_prompts                                                              10   \n",
       "total_energy_kwh                                                            0.002661   \n",
       "total_energy_joules                                                      9578.843492   \n",
       "flops                                                                  1034544128000   \n",
       "tokens_per_joule                                                            0.104397   \n",
       "joules_per_token                                                            9.578843   \n",
       "flops_per_joule                                                     108003030.722911   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    2.478181   \n",
       "average_latency_ms_per_batch                                             2478.180916   \n",
       "throughput_queries_per_sec                                                  4.035218   \n",
       "throughput_tokens_per_sec                                                  403.52179   \n",
       "cpu_usage_percent                                                                4.7   \n",
       "cpu_memory_usage_bytes                                                    2077544448   \n",
       "gpu_utilization_percent_0                                                       51.0   \n",
       "gpu_utilization_percent_1                                                      100.0   \n",
       "gpu_utilization_percent_2                                                      100.0   \n",
       "gpu_utilization_percent_3                                                      100.0   \n",
       "cpu_power_process_0                                                            112.5   \n",
       "cpu_power_process_1                                                            112.5   \n",
       "cpu_power_process_2                                                            112.5   \n",
       "cpu_power_process_3                                                            112.5   \n",
       "gpu_power_process_0                                                       652.001595   \n",
       "gpu_power_process_1                                                      2219.419073   \n",
       "gpu_power_process_2                                                       670.105119   \n",
       "gpu_power_process_3                                                       708.385754   \n",
       "ram_power_process_0                                                         0.723691   \n",
       "ram_power_process_1                                                         0.681756   \n",
       "ram_power_process_2                                                         0.684342   \n",
       "ram_power_process_3                                                         0.689416   \n",
       "cpu_energy_process_0                                                        0.000082   \n",
       "cpu_energy_process_1                                                         0.00013   \n",
       "cpu_energy_process_2                                                        0.000081   \n",
       "cpu_energy_process_3                                                        0.000099   \n",
       "gpu_energy_process_0                                                        0.000484   \n",
       "gpu_energy_process_1                                                        0.000716   \n",
       "gpu_energy_process_2                                                        0.000486   \n",
       "gpu_energy_process_3                                                        0.000579   \n",
       "ram_energy_process_0                                                             0.0   \n",
       "ram_energy_process_1                                                        0.000001   \n",
       "ram_energy_process_2                                                             0.0   \n",
       "ram_energy_process_3                                                        0.000001   \n",
       "total_energy_kwh_process_0                                                  0.000567   \n",
       "total_energy_kwh_process_1                                                  0.000847   \n",
       "total_energy_kwh_process_2                                                  0.000568   \n",
       "total_energy_kwh_process_3                                                  0.000679   \n",
       "total_energy_joules_process_0                                            2041.046993   \n",
       "total_energy_joules_process_1                                            3047.636726   \n",
       "total_energy_joules_process_2                                             2044.85402   \n",
       "total_energy_joules_process_3                                            2445.305753   \n",
       "cpu_power_avg                                                                  112.5   \n",
       "gpu_power_avg                                                            1062.477885   \n",
       "ram_power_avg                                                               0.694802   \n",
       "cpu_energy_total                                                            0.000393   \n",
       "gpu_energy_total                                                            0.002265   \n",
       "ram_energy_total                                                            0.000002   \n",
       "latency_simulation_simulate                                                    False   \n",
       "models                                                                 1034544128000   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                          1000   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  23  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                     24   \n",
       "date_time                                              April 08, 2025 at 04:46:23 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                              1000   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 100   \n",
       "max_output_tokens                                                                100   \n",
       "number_input_prompts                                                              10   \n",
       "total_energy_kwh                                                            0.002878   \n",
       "total_energy_joules                                                     10361.488063   \n",
       "flops                                                                  1034544128000   \n",
       "tokens_per_joule                                                            0.096511   \n",
       "joules_per_token                                                           10.361488   \n",
       "flops_per_joule                                                       99845130.52061   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    3.440782   \n",
       "average_latency_ms_per_batch                                             3440.782234   \n",
       "throughput_queries_per_sec                                                  2.906316   \n",
       "throughput_tokens_per_sec                                                 290.631587   \n",
       "cpu_usage_percent                                                               55.3   \n",
       "cpu_memory_usage_bytes                                                    2057662464   \n",
       "gpu_utilization_percent_0                                                       11.0   \n",
       "gpu_utilization_percent_1                                                      100.0   \n",
       "gpu_utilization_percent_2                                                      100.0   \n",
       "gpu_utilization_percent_3                                                      100.0   \n",
       "cpu_power_process_0                                                            112.5   \n",
       "cpu_power_process_1                                                            112.5   \n",
       "cpu_power_process_2                                                            112.5   \n",
       "cpu_power_process_3                                                            112.5   \n",
       "gpu_power_process_0                                                       567.629617   \n",
       "gpu_power_process_1                                                       771.336972   \n",
       "gpu_power_process_2                                                       615.131361   \n",
       "gpu_power_process_3                                                       657.908802   \n",
       "ram_power_process_0                                                         0.716706   \n",
       "ram_power_process_1                                                         0.639193   \n",
       "ram_power_process_2                                                         0.646367   \n",
       "ram_power_process_3                                                         0.651056   \n",
       "cpu_energy_process_0                                                        0.000114   \n",
       "cpu_energy_process_1                                                        0.000133   \n",
       "cpu_energy_process_2                                                        0.000092   \n",
       "cpu_energy_process_3                                                        0.000105   \n",
       "gpu_energy_process_0                                                        0.000623   \n",
       "gpu_energy_process_1                                                        0.000711   \n",
       "gpu_energy_process_2                                                         0.00052   \n",
       "gpu_energy_process_3                                                        0.000578   \n",
       "ram_energy_process_0                                                        0.000001   \n",
       "ram_energy_process_1                                                        0.000001   \n",
       "ram_energy_process_2                                                             0.0   \n",
       "ram_energy_process_3                                                             0.0   \n",
       "total_energy_kwh_process_0                                                  0.000737   \n",
       "total_energy_kwh_process_1                                                  0.000845   \n",
       "total_energy_kwh_process_2                                                  0.000613   \n",
       "total_energy_kwh_process_3                                                  0.000683   \n",
       "total_energy_joules_process_0                                            2654.411522   \n",
       "total_energy_joules_process_1                                            3041.883795   \n",
       "total_energy_joules_process_2                                            2205.460381   \n",
       "total_energy_joules_process_3                                            2459.732365   \n",
       "cpu_power_avg                                                                  112.5   \n",
       "gpu_power_avg                                                             653.001688   \n",
       "ram_power_avg                                                                0.66333   \n",
       "cpu_energy_total                                                            0.000443   \n",
       "gpu_energy_total                                                            0.002433   \n",
       "ram_energy_total                                                            0.000002   \n",
       "latency_simulation_simulate                                                    False   \n",
       "models                                                                 1034544128000   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                          1000   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  24  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                     25   \n",
       "date_time                                              April 08, 2025 at 04:47:02 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.7   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                              1000   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 100   \n",
       "max_output_tokens                                                                100   \n",
       "number_input_prompts                                                              10   \n",
       "total_energy_kwh                                                            0.002745   \n",
       "total_energy_joules                                                       9881.56245   \n",
       "flops                                                                  1034544128000   \n",
       "tokens_per_joule                                                            0.101199   \n",
       "joules_per_token                                                            9.881562   \n",
       "flops_per_joule                                                     104694387.473973   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    2.714286   \n",
       "average_latency_ms_per_batch                                             2714.285777   \n",
       "throughput_queries_per_sec                                                   3.68421   \n",
       "throughput_tokens_per_sec                                                 368.421044   \n",
       "cpu_usage_percent                                                                5.5   \n",
       "cpu_memory_usage_bytes                                                    2070953984   \n",
       "gpu_utilization_percent_0                                                       11.0   \n",
       "gpu_utilization_percent_1                                                      100.0   \n",
       "gpu_utilization_percent_2                                                      100.0   \n",
       "gpu_utilization_percent_3                                                      100.0   \n",
       "cpu_power_process_0                                                            112.5   \n",
       "cpu_power_process_1                                                            112.5   \n",
       "cpu_power_process_2                                                            112.5   \n",
       "cpu_power_process_3                                                            112.5   \n",
       "gpu_power_process_0                                                       727.260463   \n",
       "gpu_power_process_1                                                       555.824567   \n",
       "gpu_power_process_2                                                       705.838975   \n",
       "gpu_power_process_3                                                       944.800435   \n",
       "ram_power_process_0                                                         0.721634   \n",
       "ram_power_process_1                                                         0.662752   \n",
       "ram_power_process_2                                                         0.667909   \n",
       "ram_power_process_3                                                         0.675183   \n",
       "cpu_energy_process_0                                                        0.000092   \n",
       "cpu_energy_process_1                                                        0.000132   \n",
       "cpu_energy_process_2                                                        0.000093   \n",
       "cpu_energy_process_3                                                          0.0001   \n",
       "gpu_energy_process_0                                                        0.000524   \n",
       "gpu_energy_process_1                                                        0.000712   \n",
       "gpu_energy_process_2                                                        0.000531   \n",
       "gpu_energy_process_3                                                        0.000559   \n",
       "ram_energy_process_0                                                             0.0   \n",
       "ram_energy_process_1                                                        0.000001   \n",
       "ram_energy_process_2                                                             0.0   \n",
       "ram_energy_process_3                                                        0.000001   \n",
       "total_energy_kwh_process_0                                                  0.000616   \n",
       "total_energy_kwh_process_1                                                  0.000845   \n",
       "total_energy_kwh_process_2                                                  0.000624   \n",
       "total_energy_kwh_process_3                                                   0.00066   \n",
       "total_energy_joules_process_0                                            2218.098723   \n",
       "total_energy_joules_process_1                                            3042.360366   \n",
       "total_energy_joules_process_2                                            2245.070151   \n",
       "total_energy_joules_process_3                                            2376.033211   \n",
       "cpu_power_avg                                                                  112.5   \n",
       "gpu_power_avg                                                              733.43111   \n",
       "ram_power_avg                                                               0.681869   \n",
       "cpu_energy_total                                                            0.000417   \n",
       "gpu_energy_total                                                            0.002326   \n",
       "ram_energy_total                                                            0.000002   \n",
       "latency_simulation_simulate                                                    False   \n",
       "models                                                                 1034544128000   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                          1000   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  25  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                     26   \n",
       "date_time                                              April 08, 2025 at 04:47:37 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                              1000   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 100   \n",
       "max_output_tokens                                                                100   \n",
       "number_input_prompts                                                              10   \n",
       "total_energy_kwh                                                            0.002717   \n",
       "total_energy_joules                                                      9782.421027   \n",
       "flops                                                                  1034544128000   \n",
       "tokens_per_joule                                                            0.102224   \n",
       "joules_per_token                                                            9.782421   \n",
       "flops_per_joule                                                     105755428.550843   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                     2.56474   \n",
       "average_latency_ms_per_batch                                             2564.739563   \n",
       "throughput_queries_per_sec                                                  3.899031   \n",
       "throughput_tokens_per_sec                                                 389.903137   \n",
       "cpu_usage_percent                                                               16.2   \n",
       "cpu_memory_usage_bytes                                                    2052939776   \n",
       "gpu_utilization_percent_0                                                       58.0   \n",
       "gpu_utilization_percent_1                                                      100.0   \n",
       "gpu_utilization_percent_2                                                      100.0   \n",
       "gpu_utilization_percent_3                                                      100.0   \n",
       "cpu_power_process_0                                                            112.5   \n",
       "cpu_power_process_1                                                            112.5   \n",
       "cpu_power_process_2                                                            112.5   \n",
       "cpu_power_process_3                                                            112.5   \n",
       "gpu_power_process_0                                                       701.330117   \n",
       "gpu_power_process_1                                                       471.022131   \n",
       "gpu_power_process_2                                                       718.217363   \n",
       "gpu_power_process_3                                                       363.407429   \n",
       "ram_power_process_0                                                         0.714984   \n",
       "ram_power_process_1                                                         0.673425   \n",
       "ram_power_process_2                                                         0.666428   \n",
       "ram_power_process_3                                                         0.667291   \n",
       "cpu_energy_process_0                                                        0.000088   \n",
       "cpu_energy_process_1                                                        0.000135   \n",
       "cpu_energy_process_2                                                        0.000091   \n",
       "cpu_energy_process_3                                                        0.000103   \n",
       "gpu_energy_process_0                                                        0.000503   \n",
       "gpu_energy_process_1                                                        0.000706   \n",
       "gpu_energy_process_2                                                        0.000517   \n",
       "gpu_energy_process_3                                                        0.000572   \n",
       "ram_energy_process_0                                                             0.0   \n",
       "ram_energy_process_1                                                        0.000001   \n",
       "ram_energy_process_2                                                             0.0   \n",
       "ram_energy_process_3                                                        0.000001   \n",
       "total_energy_kwh_process_0                                                  0.000592   \n",
       "total_energy_kwh_process_1                                                  0.000841   \n",
       "total_energy_kwh_process_2                                                  0.000608   \n",
       "total_energy_kwh_process_3                                                  0.000676   \n",
       "total_energy_joules_process_0                                            2130.240098   \n",
       "total_energy_joules_process_1                                            3028.890264   \n",
       "total_energy_joules_process_2                                            2189.903237   \n",
       "total_energy_joules_process_3                                            2433.387427   \n",
       "cpu_power_avg                                                                  112.5   \n",
       "gpu_power_avg                                                              563.49426   \n",
       "ram_power_avg                                                               0.680532   \n",
       "cpu_energy_total                                                            0.000417   \n",
       "gpu_energy_total                                                            0.002298   \n",
       "ram_energy_total                                                            0.000002   \n",
       "latency_simulation_simulate                                                    False   \n",
       "models                                                                 1034544128000   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                          1000   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  26  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                     27   \n",
       "date_time                                              April 08, 2025 at 04:48:15 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.3   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                              1000   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 100   \n",
       "max_output_tokens                                                                100   \n",
       "number_input_prompts                                                              10   \n",
       "total_energy_kwh                                                            0.002628   \n",
       "total_energy_joules                                                      9460.731311   \n",
       "flops                                                                  1034544128000   \n",
       "tokens_per_joule                                                              0.1057   \n",
       "joules_per_token                                                            9.460731   \n",
       "flops_per_joule                                                     109351390.926845   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    2.419328   \n",
       "average_latency_ms_per_batch                                             2419.327923   \n",
       "throughput_queries_per_sec                                                  4.133379   \n",
       "throughput_tokens_per_sec                                                 413.337932   \n",
       "cpu_usage_percent                                                                4.8   \n",
       "cpu_memory_usage_bytes                                                    2072227840   \n",
       "gpu_utilization_percent_0                                                       68.0   \n",
       "gpu_utilization_percent_1                                                      100.0   \n",
       "gpu_utilization_percent_2                                                      100.0   \n",
       "gpu_utilization_percent_3                                                      100.0   \n",
       "cpu_power_process_0                                                            112.5   \n",
       "cpu_power_process_1                                                            112.5   \n",
       "cpu_power_process_2                                                            112.5   \n",
       "cpu_power_process_3                                                            112.5   \n",
       "gpu_power_process_0                                                       756.244221   \n",
       "gpu_power_process_1                                                       413.266378   \n",
       "gpu_power_process_2                                                       780.127003   \n",
       "gpu_power_process_3                                                       250.763626   \n",
       "ram_power_process_0                                                         0.722484   \n",
       "ram_power_process_1                                                         0.663541   \n",
       "ram_power_process_2                                                         0.666791   \n",
       "ram_power_process_3                                                          0.67208   \n",
       "cpu_energy_process_0                                                         0.00008   \n",
       "cpu_energy_process_1                                                        0.000125   \n",
       "cpu_energy_process_2                                                         0.00008   \n",
       "cpu_energy_process_3                                                        0.000101   \n",
       "gpu_energy_process_0                                                        0.000484   \n",
       "gpu_energy_process_1                                                        0.000678   \n",
       "gpu_energy_process_2                                                        0.000492   \n",
       "gpu_energy_process_3                                                        0.000587   \n",
       "ram_energy_process_0                                                             0.0   \n",
       "ram_energy_process_1                                                        0.000001   \n",
       "ram_energy_process_2                                                             0.0   \n",
       "ram_energy_process_3                                                             0.0   \n",
       "total_energy_kwh_process_0                                                  0.000564   \n",
       "total_energy_kwh_process_1                                                  0.000803   \n",
       "total_energy_kwh_process_2                                                  0.000572   \n",
       "total_energy_kwh_process_3                                                  0.000689   \n",
       "total_energy_joules_process_0                                            2031.708541   \n",
       "total_energy_joules_process_1                                            2890.460805   \n",
       "total_energy_joules_process_2                                            2059.903488   \n",
       "total_energy_joules_process_3                                            2478.658477   \n",
       "cpu_power_avg                                                                  112.5   \n",
       "gpu_power_avg                                                             550.100307   \n",
       "ram_power_avg                                                               0.681224   \n",
       "cpu_energy_total                                                            0.000386   \n",
       "gpu_energy_total                                                             0.00224   \n",
       "ram_energy_total                                                            0.000002   \n",
       "latency_simulation_simulate                                                    False   \n",
       "models                                                                 1034544128000   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                          1000   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                   27  \\\n",
       "config_name                                             latency_False   \n",
       "experiment_id                                                      28   \n",
       "date_time                               April 08, 2025 at 04:48:49 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                               1000   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  100   \n",
       "max_output_tokens                                                 100   \n",
       "number_input_prompts                                               10   \n",
       "total_energy_kwh                                             0.003057   \n",
       "total_energy_joules                                       11004.24041   \n",
       "flops                                                   1034544128000   \n",
       "tokens_per_joule                                             0.090874   \n",
       "joules_per_token                                             11.00424   \n",
       "flops_per_joule                                       94013224.855566   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     3.559638   \n",
       "average_latency_ms_per_batch                              3559.637986   \n",
       "throughput_queries_per_sec                                   2.809274   \n",
       "throughput_tokens_per_sec                                  280.927444   \n",
       "cpu_usage_percent                                                54.0   \n",
       "cpu_memory_usage_bytes                                     2074927104   \n",
       "gpu_utilization_percent_0                                        52.0   \n",
       "gpu_utilization_percent_1                                       100.0   \n",
       "gpu_utilization_percent_2                                       100.0   \n",
       "gpu_utilization_percent_3                                       100.0   \n",
       "cpu_power_process_0                                             112.5   \n",
       "cpu_power_process_1                                             112.5   \n",
       "cpu_power_process_2                                             112.5   \n",
       "cpu_power_process_3                                             112.5   \n",
       "gpu_power_process_0                                        551.612807   \n",
       "gpu_power_process_1                                        404.622742   \n",
       "gpu_power_process_2                                         516.23026   \n",
       "gpu_power_process_3                                        604.277492   \n",
       "ram_power_process_0                                          0.722661   \n",
       "ram_power_process_1                                          0.665721   \n",
       "ram_power_process_2                                           0.67092   \n",
       "ram_power_process_3                                          0.685136   \n",
       "cpu_energy_process_0                                         0.000119   \n",
       "cpu_energy_process_1                                         0.000135   \n",
       "cpu_energy_process_2                                         0.000103   \n",
       "cpu_energy_process_3                                         0.000117   \n",
       "gpu_energy_process_0                                         0.000646   \n",
       "gpu_energy_process_1                                         0.000715   \n",
       "gpu_energy_process_2                                         0.000575   \n",
       "gpu_energy_process_3                                         0.000646   \n",
       "ram_energy_process_0                                         0.000001   \n",
       "ram_energy_process_1                                         0.000001   \n",
       "ram_energy_process_2                                              0.0   \n",
       "ram_energy_process_3                                         0.000001   \n",
       "total_energy_kwh_process_0                                   0.000765   \n",
       "total_energy_kwh_process_1                                    0.00085   \n",
       "total_energy_kwh_process_2                                   0.000678   \n",
       "total_energy_kwh_process_3                                   0.000764   \n",
       "total_energy_joules_process_0                             2753.201388   \n",
       "total_energy_joules_process_1                             3061.352417   \n",
       "total_energy_joules_process_2                             2440.732517   \n",
       "total_energy_joules_process_3                             2748.954088   \n",
       "cpu_power_avg                                                   112.5   \n",
       "gpu_power_avg                                              519.185825   \n",
       "ram_power_avg                                                 0.68611   \n",
       "cpu_energy_total                                             0.000474   \n",
       "gpu_energy_total                                              0.00258   \n",
       "ram_energy_total                                             0.000002   \n",
       "latency_simulation_simulate                                     False   \n",
       "models                                                  1034544128000   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                           1000   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                                  28  \\\n",
       "config_name                        latency_True_latency_0.05_latency_0.2_latency_...   \n",
       "experiment_id                                                                     29   \n",
       "date_time                                              April 08, 2025 at 04:49:27 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                    0.05   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                              1000   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 100   \n",
       "max_output_tokens                                                                100   \n",
       "number_input_prompts                                                              10   \n",
       "total_energy_kwh                                                            0.002529   \n",
       "total_energy_joules                                                      9104.932397   \n",
       "flops                                                                  1034544128000   \n",
       "tokens_per_joule                                                            0.109831   \n",
       "joules_per_token                                                            9.104932   \n",
       "flops_per_joule                                                     113624580.931623   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    2.453797   \n",
       "average_latency_ms_per_batch                                             2453.797072   \n",
       "throughput_queries_per_sec                                                  4.075317   \n",
       "throughput_tokens_per_sec                                                 407.531662   \n",
       "cpu_usage_percent                                                                5.5   \n",
       "cpu_memory_usage_bytes                                                    2070724608   \n",
       "gpu_utilization_percent_0                                                       20.0   \n",
       "gpu_utilization_percent_1                                                      100.0   \n",
       "gpu_utilization_percent_2                                                      100.0   \n",
       "gpu_utilization_percent_3                                                      100.0   \n",
       "cpu_power_process_0                                                            112.5   \n",
       "cpu_power_process_1                                                            112.5   \n",
       "cpu_power_process_2                                                            112.5   \n",
       "cpu_power_process_3                                                            112.5   \n",
       "gpu_power_process_0                                                       716.271282   \n",
       "gpu_power_process_1                                                       468.725355   \n",
       "gpu_power_process_2                                                       694.223236   \n",
       "gpu_power_process_3                                                       618.121217   \n",
       "ram_power_process_0                                                         0.721959   \n",
       "ram_power_process_1                                                         0.678437   \n",
       "ram_power_process_2                                                         0.669261   \n",
       "ram_power_process_3                                                          0.67303   \n",
       "cpu_energy_process_0                                                        0.000083   \n",
       "cpu_energy_process_1                                                        0.000124   \n",
       "cpu_energy_process_2                                                        0.000083   \n",
       "cpu_energy_process_3                                                        0.000094   \n",
       "gpu_energy_process_0                                                        0.000481   \n",
       "gpu_energy_process_1                                                        0.000654   \n",
       "gpu_energy_process_2                                                        0.000477   \n",
       "gpu_energy_process_3                                                         0.00053   \n",
       "ram_energy_process_0                                                             0.0   \n",
       "ram_energy_process_1                                                        0.000001   \n",
       "ram_energy_process_2                                                             0.0   \n",
       "ram_energy_process_3                                                             0.0   \n",
       "total_energy_kwh_process_0                                                  0.000564   \n",
       "total_energy_kwh_process_1                                                  0.000779   \n",
       "total_energy_kwh_process_2                                                  0.000561   \n",
       "total_energy_kwh_process_3                                                  0.000625   \n",
       "total_energy_joules_process_0                                            2030.512325   \n",
       "total_energy_joules_process_1                                            2805.720536   \n",
       "total_energy_joules_process_2                                            2019.285212   \n",
       "total_energy_joules_process_3                                            2249.414323   \n",
       "cpu_power_avg                                                                  112.5   \n",
       "gpu_power_avg                                                             624.335273   \n",
       "ram_power_avg                                                               0.685672   \n",
       "cpu_energy_total                                                            0.000384   \n",
       "gpu_energy_total                                                            0.002143   \n",
       "ram_energy_total                                                            0.000002   \n",
       "latency_simulation_simulate                                                     True   \n",
       "models                                                                 1034544128000   \n",
       "latency_simulation_delay_max                                                     0.2   \n",
       "total_generated_tokens                                                          1000   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "\n",
       "                                                                                  29  \\\n",
       "config_name                        latency_True_latency_0.2_latency_0.6_latency_F...   \n",
       "experiment_id                                                                     30   \n",
       "date_time                                              April 08, 2025 at 04:50:02 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.2   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                              1000   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 100   \n",
       "max_output_tokens                                                                100   \n",
       "number_input_prompts                                                              10   \n",
       "total_energy_kwh                                                            0.002987   \n",
       "total_energy_joules                                                     10752.746732   \n",
       "flops                                                                  1034544128000   \n",
       "tokens_per_joule                                                            0.092999   \n",
       "joules_per_token                                                           10.752747   \n",
       "flops_per_joule                                                      96212079.926237   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                     4.07742   \n",
       "average_latency_ms_per_batch                                             4077.420104   \n",
       "throughput_queries_per_sec                                                  2.452531   \n",
       "throughput_tokens_per_sec                                                 245.253119   \n",
       "cpu_usage_percent                                                               17.3   \n",
       "cpu_memory_usage_bytes                                                    2072039424   \n",
       "gpu_utilization_percent_0                                                        7.0   \n",
       "gpu_utilization_percent_1                                                      100.0   \n",
       "gpu_utilization_percent_2                                                      100.0   \n",
       "gpu_utilization_percent_3                                                      100.0   \n",
       "cpu_power_process_0                                                            112.5   \n",
       "cpu_power_process_1                                                            112.5   \n",
       "cpu_power_process_2                                                            112.5   \n",
       "cpu_power_process_3                                                            112.5   \n",
       "gpu_power_process_0                                                       381.983252   \n",
       "gpu_power_process_1                                                       559.126046   \n",
       "gpu_power_process_2                                                       611.717499   \n",
       "gpu_power_process_3                                                       479.491748   \n",
       "ram_power_process_0                                                         0.722185   \n",
       "ram_power_process_1                                                         0.680659   \n",
       "ram_power_process_2                                                         0.671914   \n",
       "ram_power_process_3                                                         0.671625   \n",
       "cpu_energy_process_0                                                        0.000135   \n",
       "cpu_energy_process_1                                                        0.000134   \n",
       "cpu_energy_process_2                                                        0.000109   \n",
       "cpu_energy_process_3                                                        0.000123   \n",
       "gpu_energy_process_0                                                        0.000664   \n",
       "gpu_energy_process_1                                                        0.000658   \n",
       "gpu_energy_process_2                                                        0.000547   \n",
       "gpu_energy_process_3                                                        0.000614   \n",
       "ram_energy_process_0                                                        0.000001   \n",
       "ram_energy_process_1                                                        0.000001   \n",
       "ram_energy_process_2                                                             0.0   \n",
       "ram_energy_process_3                                                        0.000001   \n",
       "total_energy_kwh_process_0                                                  0.000799   \n",
       "total_energy_kwh_process_1                                                  0.000793   \n",
       "total_energy_kwh_process_2                                                  0.000657   \n",
       "total_energy_kwh_process_3                                                  0.000737   \n",
       "total_energy_joules_process_0                                             2877.54669   \n",
       "total_energy_joules_process_1                                            2856.492483   \n",
       "total_energy_joules_process_2                                            2363.976182   \n",
       "total_energy_joules_process_3                                            2654.731377   \n",
       "cpu_power_avg                                                                  112.5   \n",
       "gpu_power_avg                                                             508.079636   \n",
       "ram_power_avg                                                               0.686596   \n",
       "cpu_energy_total                                                            0.000501   \n",
       "gpu_energy_total                                                            0.002483   \n",
       "ram_energy_total                                                            0.000003   \n",
       "latency_simulation_simulate                                                     True   \n",
       "models                                                                 1034544128000   \n",
       "latency_simulation_delay_max                                                     0.6   \n",
       "total_generated_tokens                                                          1000   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "\n",
       "                                                                                  30  \\\n",
       "config_name                        latency_True_latency_0.05_latency_0.2_latency_...   \n",
       "experiment_id                                                                     31   \n",
       "date_time                                              April 08, 2025 at 04:50:37 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                    0.05   \n",
       "latency_simulation_simulate_burst                                               True   \n",
       "latency_simulation_burst_size                                                      5   \n",
       "latency_simulation_burst_interval                                                4.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                              1000   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 100   \n",
       "max_output_tokens                                                                100   \n",
       "number_input_prompts                                                              10   \n",
       "total_energy_kwh                                                            0.002321   \n",
       "total_energy_joules                                                      8354.124101   \n",
       "flops                                                                  1034544128000   \n",
       "tokens_per_joule                                                            0.119701   \n",
       "joules_per_token                                                            8.354124   \n",
       "flops_per_joule                                                     123836337.055097   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    2.509436   \n",
       "average_latency_ms_per_batch                                             2509.436437   \n",
       "throughput_queries_per_sec                                                  3.984958   \n",
       "throughput_tokens_per_sec                                                 398.495848   \n",
       "cpu_usage_percent                                                                4.8   \n",
       "cpu_memory_usage_bytes                                                    2073120768   \n",
       "gpu_utilization_percent_0                                                       44.0   \n",
       "gpu_utilization_percent_1                                                      100.0   \n",
       "gpu_utilization_percent_2                                                      100.0   \n",
       "gpu_utilization_percent_3                                                      100.0   \n",
       "cpu_power_process_0                                                            112.5   \n",
       "cpu_power_process_1                                                            112.5   \n",
       "cpu_power_process_2                                                            112.5   \n",
       "cpu_power_process_3                                                            112.5   \n",
       "gpu_power_process_0                                                       615.725547   \n",
       "gpu_power_process_1                                                       310.173365   \n",
       "gpu_power_process_2                                                       631.657895   \n",
       "gpu_power_process_3                                                       796.653119   \n",
       "ram_power_process_0                                                         0.721872   \n",
       "ram_power_process_1                                                         0.673545   \n",
       "ram_power_process_2                                                         0.667791   \n",
       "ram_power_process_3                                                         0.667638   \n",
       "cpu_energy_process_0                                                        0.000084   \n",
       "cpu_energy_process_1                                                          0.0001   \n",
       "cpu_energy_process_2                                                        0.000083   \n",
       "cpu_energy_process_3                                                        0.000101   \n",
       "gpu_energy_process_0                                                        0.000445   \n",
       "gpu_energy_process_1                                                        0.000535   \n",
       "gpu_energy_process_2                                                        0.000442   \n",
       "gpu_energy_process_3                                                         0.00053   \n",
       "ram_energy_process_0                                                             0.0   \n",
       "ram_energy_process_1                                                        0.000001   \n",
       "ram_energy_process_2                                                             0.0   \n",
       "ram_energy_process_3                                                        0.000001   \n",
       "total_energy_kwh_process_0                                                  0.000529   \n",
       "total_energy_kwh_process_1                                                  0.000636   \n",
       "total_energy_kwh_process_2                                                  0.000524   \n",
       "total_energy_kwh_process_3                                                  0.000631   \n",
       "total_energy_joules_process_0                                            1905.424207   \n",
       "total_energy_joules_process_1                                            2287.806555   \n",
       "total_energy_joules_process_2                                            1887.933024   \n",
       "total_energy_joules_process_3                                            2272.960315   \n",
       "cpu_power_avg                                                                  112.5   \n",
       "gpu_power_avg                                                             588.552482   \n",
       "ram_power_avg                                                               0.682712   \n",
       "cpu_energy_total                                                            0.000368   \n",
       "gpu_energy_total                                                            0.001951   \n",
       "ram_energy_total                                                            0.000002   \n",
       "latency_simulation_simulate                                                     True   \n",
       "models                                                                 1034544128000   \n",
       "latency_simulation_delay_max                                                     0.2   \n",
       "total_generated_tokens                                                          1000   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "\n",
       "                                                                                  31  \n",
       "config_name                        latency_True_latency_0.2_latency_0.6_latency_T...  \n",
       "experiment_id                                                                     32  \n",
       "date_time                                              April 08, 2025 at 04:51:12 PM  \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0  \n",
       "num_processes                                                                      4  \n",
       "batch_size___fixed_batching                                                       16  \n",
       "decoder_temperature                                                              1.0  \n",
       "decoder_top_k                                                                      0  \n",
       "decoder_top_p                                                                    0.0  \n",
       "latency_simulation_delay_min                                                     0.2  \n",
       "latency_simulation_simulate_burst                                               True  \n",
       "latency_simulation_burst_size                                                      8  \n",
       "latency_simulation_burst_interval                                                5.0  \n",
       "fp_precision                                                           torch.float32  \n",
       "quantization                                                                   False  \n",
       "load_in_8bit                                                                   False  \n",
       "load_in_4bit                                                                   False  \n",
       "total_input_tokens                                                              1000  \n",
       "total_params                                                              1100048384  \n",
       "max_input_tokens                                                                 100  \n",
       "max_output_tokens                                                                100  \n",
       "number_input_prompts                                                              10  \n",
       "total_energy_kwh                                                            0.002472  \n",
       "total_energy_joules                                                      8900.869755  \n",
       "flops                                                                  1034544128000  \n",
       "tokens_per_joule                                                            0.112349  \n",
       "joules_per_token                                                             8.90087  \n",
       "flops_per_joule                                                     116229554.686645  \n",
       "joules_per_flop                                                                  0.0  \n",
       "total_inference_time_sec                                                    2.615047  \n",
       "average_latency_ms_per_batch                                             2615.046637  \n",
       "throughput_queries_per_sec                                                  3.824024  \n",
       "throughput_tokens_per_sec                                                 382.402358  \n",
       "cpu_usage_percent                                                                4.0  \n",
       "cpu_memory_usage_bytes                                                    2070740992  \n",
       "gpu_utilization_percent_0                                                       57.0  \n",
       "gpu_utilization_percent_1                                                      100.0  \n",
       "gpu_utilization_percent_2                                                      100.0  \n",
       "gpu_utilization_percent_3                                                       94.0  \n",
       "cpu_power_process_0                                                            112.5  \n",
       "cpu_power_process_1                                                            112.5  \n",
       "cpu_power_process_2                                                            112.5  \n",
       "cpu_power_process_3                                                            112.5  \n",
       "gpu_power_process_0                                                       717.525238  \n",
       "gpu_power_process_1                                                        533.99169  \n",
       "gpu_power_process_2                                                       734.177811  \n",
       "gpu_power_process_3                                                       514.542529  \n",
       "ram_power_process_0                                                         0.720926  \n",
       "ram_power_process_1                                                         0.674317  \n",
       "ram_power_process_2                                                         0.668052  \n",
       "ram_power_process_3                                                         0.667927  \n",
       "cpu_energy_process_0                                                        0.000086  \n",
       "cpu_energy_process_1                                                        0.000102  \n",
       "cpu_energy_process_2                                                        0.000086  \n",
       "cpu_energy_process_3                                                        0.000119  \n",
       "gpu_energy_process_0                                                         0.00046  \n",
       "gpu_energy_process_1                                                        0.000543  \n",
       "gpu_energy_process_2                                                        0.000454  \n",
       "gpu_energy_process_3                                                        0.000619  \n",
       "ram_energy_process_0                                                             0.0  \n",
       "ram_energy_process_1                                                        0.000001  \n",
       "ram_energy_process_2                                                             0.0  \n",
       "ram_energy_process_3                                                        0.000001  \n",
       "total_energy_kwh_process_0                                                  0.000547  \n",
       "total_energy_kwh_process_1                                                  0.000646  \n",
       "total_energy_kwh_process_2                                                   0.00054  \n",
       "total_energy_kwh_process_3                                                  0.000739  \n",
       "total_energy_joules_process_0                                            1968.818093  \n",
       "total_energy_joules_process_1                                               2326.154  \n",
       "total_energy_joules_process_2                                            1944.850933  \n",
       "total_energy_joules_process_3                                             2661.04673  \n",
       "cpu_power_avg                                                                  112.5  \n",
       "gpu_power_avg                                                             625.059317  \n",
       "ram_power_avg                                                               0.682806  \n",
       "cpu_energy_total                                                            0.000394  \n",
       "gpu_energy_total                                                            0.002076  \n",
       "ram_energy_total                                                            0.000002  \n",
       "latency_simulation_simulate                                                     True  \n",
       "models                                                                 1034544128000  \n",
       "latency_simulation_delay_max                                                     0.6  \n",
       "total_generated_tokens                                                          1000  \n",
       "decoder_config_decoding_mode                                                     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing scenarios: 'df_scenarios_cleaned'\n",
      "Error processing grid: 'df_grid_cleaned'\n",
      "Error processing text_generation: 'df_text_generation_cleaned'\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [\n",
    "    \"sharding_strategy\",\n",
    "    \"sharding_config_fsdp_config_use_orig_params\",\n",
    "    \"sharding_config_fsdp_config_cpu_offload\",\n",
    "    \"adaptive_batching\",\n",
    "    \"adaptive_max_tokens\",\n",
    "    \"query_rate\",\n",
    "    \"is_encoder_decoder\",\n",
    "    \"task_type\",\n",
    "    \"available_gpu_count\",\n",
    "    \"gpu_model\",\n",
    "    \"available_cpu_count\",\n",
    "    \"cpu_model\",\n",
    "    \"os\",\n",
    "    \"python_version\",\n",
    "    \"country\",\n",
    "    \"region\",\n",
    "    \"distributed_type\",\n",
    "    \"decode_token_to_text\",\n",
    "    \"inference_type\",\n",
    "    \"backend\",\n",
    "    \"model_arch\",\n",
    "    \"gpu_current_memory_allocated_bytes\",\n",
    "    \"gpu_max_memory_allocated_bytes\",\n",
    "    \"gpu_current_memory_reserved_bytes\",\n",
    "    \"gpu_max_memory_reserved_bytes\",\n",
    "    \"per-process_emissions_0\", \"per-process_emissions_1\", \"per-process_emissions_2\",\"per-process_emissions_3\" # OR IS THIS NICE TO HAVE?\n",
    "]\n",
    "\n",
    "for file in possible_files:\n",
    "    try:\n",
    "        cleaned_var = f\"df_{file}_cleaned\"   # e.g., df_controlled_cleaned\n",
    "        dropped_var = f\"df_{file}_dropped\"     # e.g., df_controlled_dropped\n",
    "        \n",
    "        # Drop the specified columns from the cleaned DataFrame.\n",
    "        globals()[dropped_var] = globals()[cleaned_var].drop(columns=columns_to_drop)\n",
    "        print(f\"Found & inspecting dropped version: {dropped_var}\")\n",
    "        display(globals()[dropped_var].T)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1034544128000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check all flops are constant\n",
    "df_controlled_dropped['flops'].unique()\n",
    "# TO DO: MAKE THIS DYANMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVE THIS CALCULATION INTO THE RESULTS GENERATED \n",
    "df_controlled_dropped['flops_per_token'] = df_controlled_dropped['flops'] / df_controlled_dropped['total_generated_tokens']\n",
    "df_controlled_dropped['energy_per_token_kwh'] = df_controlled_dropped['total_energy_kwh'] / df_controlled_dropped['total_generated_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['config_name', 'experiment_id', 'date_time', 'model', 'num_processes',\n",
       "       'batch_size___fixed_batching', 'decoder_temperature', 'decoder_top_k',\n",
       "       'decoder_top_p', 'latency_simulation_delay_min',\n",
       "       'latency_simulation_simulate_burst', 'latency_simulation_burst_size',\n",
       "       'latency_simulation_burst_interval', 'fp_precision', 'quantization',\n",
       "       'load_in_8bit', 'load_in_4bit', 'total_input_tokens', 'total_params',\n",
       "       'max_input_tokens', 'max_output_tokens', 'number_input_prompts',\n",
       "       'total_energy_kwh', 'total_energy_joules', 'flops', 'tokens_per_joule',\n",
       "       'joules_per_token', 'flops_per_joule', 'joules_per_flop',\n",
       "       'total_inference_time_sec', 'average_latency_ms_per_batch',\n",
       "       'throughput_queries_per_sec', 'throughput_tokens_per_sec',\n",
       "       'cpu_usage_percent', 'cpu_memory_usage_bytes',\n",
       "       'gpu_utilization_percent_0', 'gpu_utilization_percent_1',\n",
       "       'gpu_utilization_percent_2', 'gpu_utilization_percent_3',\n",
       "       'cpu_power_process_0', 'cpu_power_process_1', 'cpu_power_process_2',\n",
       "       'cpu_power_process_3', 'gpu_power_process_0', 'gpu_power_process_1',\n",
       "       'gpu_power_process_2', 'gpu_power_process_3', 'ram_power_process_0',\n",
       "       'ram_power_process_1', 'ram_power_process_2', 'ram_power_process_3',\n",
       "       'cpu_energy_process_0', 'cpu_energy_process_1', 'cpu_energy_process_2',\n",
       "       'cpu_energy_process_3', 'gpu_energy_process_0', 'gpu_energy_process_1',\n",
       "       'gpu_energy_process_2', 'gpu_energy_process_3', 'ram_energy_process_0',\n",
       "       'ram_energy_process_1', 'ram_energy_process_2', 'ram_energy_process_3',\n",
       "       'total_energy_kwh_process_0', 'total_energy_kwh_process_1',\n",
       "       'total_energy_kwh_process_2', 'total_energy_kwh_process_3',\n",
       "       'total_energy_joules_process_0', 'total_energy_joules_process_1',\n",
       "       'total_energy_joules_process_2', 'total_energy_joules_process_3',\n",
       "       'cpu_power_avg', 'gpu_power_avg', 'ram_power_avg', 'cpu_energy_total',\n",
       "       'gpu_energy_total', 'ram_energy_total', 'latency_simulation_simulate',\n",
       "       'models', 'latency_simulation_delay_max', 'total_generated_tokens',\n",
       "       'decoder_config_decoding_mode', 'flops_per_token',\n",
       "       'energy_per_token_kwh'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_controlled_dropped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['num_processes_1', 'num_processes_2', 'num_processes_3',\n",
       "       'num_processes_4', 'batching_1', 'batching_2', 'batching_4',\n",
       "       'batching_8', 'batching_16', 'batching_32', 'batching_64',\n",
       "       'precis_float32_quant_False_quant8_False_quant4_False',\n",
       "       'precis_float16_quant_False_quant8_False_quant4_False',\n",
       "       'precis_float16_quant_True_quant8_True_quant4_False',\n",
       "       'precis_float16_quant_True_quant8_False_quant4_True',\n",
       "       'decoding_greedy_decoder_temperature_0',\n",
       "       'decoding_greedy_decoder_temperature_0.7',\n",
       "       'decoding_greedy_decoder_temperature_1.0',\n",
       "       'decoding_greedy_decoder_temperature_1.3',\n",
       "       'decoding_top_k_decoder_top_k_50_decoder_temperature_0',\n",
       "       'decoding_top_k_decoder_top_k_50_decoder_temperature_0.7',\n",
       "       'decoding_top_k_decoder_top_k_50_decoder_temperature_1.0',\n",
       "       'decoding_top_k_decoder_top_k_50_decoder_temperature_1.3',\n",
       "       'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0',\n",
       "       'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.7',\n",
       "       'decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.0',\n",
       "       'decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.3',\n",
       "       'latency_False',\n",
       "       'latency_True_latency_0.05_latency_0.2_latency_False',\n",
       "       'latency_True_latency_0.2_latency_0.6_latency_False',\n",
       "       'latency_True_latency_0.05_latency_0.2_latency_True_latency_4.0_latency_5',\n",
       "       'latency_True_latency_0.2_latency_0.6_latency_True_latency_5.0_latency_8'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_controlled_dropped['config_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAHpCAYAAAAf5apCAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAArqZJREFUeJzs3XdYk9fbB/BvQFmyRGSJCooLwYUL90CpRavVumqL4rbuvepeVeveo4Jat9bxc4+Ktu6FdW8FBzhRAQGB8/5xXiKRFcII4/u5rlzynJyc3IlPxp2zFEIIASIiIiIionTQ0XYARERERESU8zGxICIiIiKidGNiQURERERE6cbEgoiIiIiI0o2JBRERERERpRsTCyIiIiIiSjcmFkRERERElG5MLIiIiIiIKN2YWBARERERUboxsSDSotmzZ6NEiRLQ1dVFpUqVAAAODg7o0qWLVuPKqxQKBfr166ftMLKUv78/FAoF/P39tR1Kqh4/fgyFQgE/Pz9th5IjOTg4oHnz5pnS9sSJE6FQKPD69etMaT+rdOnSBQ4ODtoOQ205Jd4GDRqgQYMG2g6DsgATCyItOXz4MEaMGIHatWvD19cX06dP13ZIOdr+/fsxceJEbYeRa50+fRoTJ05EaGioxm0sXbqUSQHlKBEREZg4cWKOSLyzSnKv45s3b2LixIl4/PhxlsdE2QcTCyIt+fvvv6Gjo4M//vgD3t7e+Pbbb7UdUo62f/9+TJo0Sdth5FqnT5/GpEmTmFhQnhIREYFJkyYxsUggpcRi0qRJSSYWhw8fxuHDhzM/ONI6JhaULuHh4doOIcd6+fIlDA0Noaenp+1Qsi0hBD59+qTtMIgyTGRkJOLi4rQdBmlZXvvs1NPT42ddHsHEIgPFjzG9f/8+unTpAnNzc5iZmcHHxwcRERHKeimNE1YoFCrDOeLbvHv3Ln766SeYmZmhcOHCGDduHIQQCAoKQsuWLWFqagobGxvMmTMnzXHHj7s9fPgwKlWqBAMDAzg7O+Ovv/5Sqefn5weFQoETJ07gl19+gZWVFezt7ZXXL126FOXLl4e+vj7s7OzQt2/fJH/dPHfuHL799lsULFgQBQoUQIUKFbBgwQKVOrdv38YPP/wACwsLGBgYoGrVqtizZ49Knc+fP2PSpEkoVaoUDAwMUKhQIdSpUwdHjhxR1gkODoaPjw/s7e2hr68PW1tbtGzZMtEvKgcOHEDdunVRoEABmJiYwMvLCzdu3FCpo05b79+/x+3bt/H+/fsUn3OFQgFfX1+Eh4dDoVCkOm784cOHaNu2LSwsLGBkZISaNWti3759KnXix8pv2bIFY8aMgY2NDQoUKIDvvvsOQUFBKnXv3buHNm3awMbGBgYGBrC3t0eHDh1SjTuhLl26wNjYGA8fPoSnpycKFCgAOzs7TJ48GUIIlbpxcXGYP38+ypcvDwMDA1hbW6NXr1549+6dSr34c/HQoUOoWrUqDA0NsWLFCrViWbJkCQAon0+FQqG8Pjw8HEOHDkXRokWhr6+PMmXK4Pfff08UZ1KmTp0KHR0dLFq0SFmmzvkS//w8e/YMrVq1grGxMQoXLoxhw4YhNjY21fvdvXs3vLy8YGdnB319fZQsWRJTpkxJdNsGDRrAxcUFN2/eRMOGDWFkZIQiRYpg1qxZidp8+vQpWrVqhQIFCsDKygqDBw9GVFRUqrFMnDgRw4cPBwA4Ojoqn9/4cz8mJgZTpkxByZIloa+vDwcHB4wZM0albQcHB9y4cQMnTpxQ3j5+zPXbt28xbNgwuLq6wtjYGKampmjWrBmuXr2aamzqiIqKwoQJE+Dk5AR9fX0ULVoUI0aMSPTY4+fY7Nq1Cy4uLtDX10f58uVx8ODBRG0+e/YMXbt2hbW1tbLemjVrVOrEvyY3b96MX3/9FUWKFIGRkRE+fPgAANi2bRucnZ1hYGAAFxcX7Ny5U2XMvBACDg4OaNmyZaL7j4yMhJmZGXr16pWu52bt2rXIly+f8v+3SpUqaN26tUodV1dXKBQK/Pfff8qyLVu2QKFQ4NatWyp1Q0NDU/z8S0q/fv1gbGycZL2OHTvCxsZGed5fvHgRnp6esLS0hKGhIRwdHdG1a9dUH6e6r6eEHj9+jMKFCwMAJk2apDxvE35Gq/NZldpnpzrvJwCU52XC80Vd6jxv6rxPJ/c69vPzQ9u2bQEADRs2VF4X39Pz9RyL+NfG1q1bMW3aNNjb28PAwACNGzfG/fv3E8W/ZMkSlChRAoaGhqhevTr++ecfztvIrgRlmAkTJggAonLlyqJ169Zi6dKlonv37gKAGDFihLLeo0ePBADh6+ubqA0AYsKECYnarFSpkujYsaNYunSp8PLyEgDE3LlzRZkyZUSfPn3E0qVLRe3atQUAceLEiTTFXbx4cVG6dGlhbm4uRo0aJebOnStcXV2Fjo6OOHz4sLKer6+vACCcnZ1F/fr1xaJFi8Rvv/2mEqeHh4dYtGiR6Nevn9DV1RXVqlUT0dHRyjYOHz4s9PT0RPHixcWECRPEsmXLxIABA4SHh4eyzvXr14WZmZlwdnYWM2fOFIsXLxb16tUTCoVC/PXXX8p6Y8aMEQqFQvTo0UOsWrVKzJkzR3Ts2FEZkxBC1KpVS5iZmYlff/1VrF69WkyfPl00bNhQ5Tlat26dUCgU4ptvvhGLFi0SM2fOFA4ODsLc3Fw8evQoTW3FP0dJ/d8mtH79elG3bl2hr68v1q9fL9avXy8ePHig/P/o3Lmzsm5wcLCwtrYWJiYmYuzYsWLu3LmiYsWKQkdHR+X5OH78uAAgXF1dRYUKFcTcuXPFqFGjhIGBgShdurSIiIgQQggRFRUlHB0dhZ2dnZg6dapYvXq1mDRpkqhWrZp4/PhxinEn1LlzZ2FgYCBKlSolfv75Z7F48WLRvHlzAUCMGzdOpW737t1Fvnz5RI8ePcTy5cvFyJEjRYECBRKdH8WLFxdOTk6iYMGCYtSoUWL58uXi+PHjqcZy+vRp0aRJEwFA+XyuX79eCCFEXFycaNSokVAoFKJ79+5i8eLFokWLFgKAGDRokEo7AETfvn2Vx2PHjhUKhUKsXLlSWabu+RL//JQvX1507dpVLFu2TLRp00YAEEuXLk31MbVq1Uq0a9dOzJ49Wyxbtky0bdtWABDDhg1TqVe/fn1hZ2cnihYtKgYOHCiWLl0qGjVqJACI/fv3K+tFRESI0qVLCwMDAzFixAgxf/584ebmJipUqCAApPg8X716VXTs2FEAEPPmzVM+v2FhYcrHCkD88MMPYsmSJcLb21sAEK1atVK2sXPnTmFvby/Kli2rvH38+8uFCxdEyZIlxahRo8SKFSvE5MmTRZEiRYSZmZl49uyZso2U3juTExsbK5o2bSqMjIzEoEGDxIoVK0S/fv1Evnz5RMuWLVXqAhAVK1YUtra2YsqUKWL+/PmiRIkSwsjISLx+/VpZLzg4WNjb24uiRYuKyZMni2XLlonvvvtO+fzEi39NOjs7i0qVKom5c+eKGTNmiPDwcLF3716hUCiUr9Vx48aJggULChcXF1G8eHFlG2PHjhX58+cXb968UYl169atAoA4efKk2s9F8eLFhZeXl/J4xYoVQqFQiLFjxyrLBgwYIAoXLqw8fvPmjVAoFEJHR0csXrxYWd63b1+Veup+/iXl5MmTAoDYunWrSnl4eLgoUKCA8jUZEhIiChYsKEqXLi1mz54tVq1aJcaOHSvKlSuX6mNX9/XUuXNn5fMfFhYmli1bJgCI77//XnneXr16VQih/mdVSp+d6r6fHDp0SOjo6AgXFxcxd+5cMXbsWGFmZibKly+vcr4kRd3nTZ336eRexw8ePBADBgwQAMSYMWOU1wUHBwsh5PtU/fr1lfcV/9qoXLmycHNzE/PmzRMTJ04URkZGonr16ipxLV26VAAQdevWFQsXLhRDhgwRFhYWomTJkiptUvbAxCIDxb+xdu3aVaX8+++/F4UKFVIea5JY9OzZU1kWExMj7O3thUKhUPkS/e7dO2FoaKjypVQdxYsXFwDEjh07lGXv378Xtra2onLlysqy+DfHOnXqiJiYGGX5y5cvhZ6enmjatKmIjY1Vli9evFgAEGvWrFHG7ejoKIoXLy7evXunEkNcXJzy78aNGwtXV1cRGRmpcn2tWrVEqVKllGUVK1ZU+ZD82rt37wQAMXv27GTrfPz4UZibm4sePXqolAcHBwszMzNluTptCaF+YiGE/AArUKBAovKvE4tBgwYJAOKff/5RidvR0VE4ODgon/P4N+oiRYqIDx8+KOvGfwFZsGCBEEKIK1euCABi27ZtqcaYWvwARP/+/ZVlcXFxwsvLS+jp6YlXr14JIYT4559/BACxYcMGldsfPHgwUXn8uXjw4ME0x9O3b1+R1G8lu3btEgDE1KlTVcp/+OEHoVAoxP3795VlCROLoUOHCh0dHeHn56e8Xt3zRYgvz8/kyZNV6sZ/kKYmPhFMqFevXsLIyEjltVG/fn0BQKxbt05ZFhUVJWxsbESbNm2UZfPnz0/05S08PFw4OTmlmlgIIcTs2bMFAJUvO0IIERAQIACI7t27q5QPGzZMABB///23sqx8+fJJfhGIjIxUee8QQr5P6uvrqzx/miQW69evFzo6OiqvHyGEWL58uQAgTp06pSwDIPT09FTOiatXrwoAYtGiRcqybt26CVtbW5VkQwghOnToIMzMzJT/d/GvyRIlSiT6/3R1dRX29vbi48ePyjJ/f38BQOWL4p07dwQAsWzZMpXbf/fdd8LBwUHlvTM1CROLBQsWCIVCIaZMmaJSZ9u2bQKAuHnzphBCiD179gh9fX3x3Xffifbt2yvrVahQQXz//ffKY3U//5ISFxcnihQponK+CpE4edq5c6cAIC5cuKD2Y46n7uspYWIhhBCvXr1K9LkcT93PquQ+O9PyflKpUiVha2srQkNDlWWHDx9OdL4kRZ3nLS3v08m9juPPnaTeS5JLLMqVKyeioqKU5QsWLBAAxLVr14QQ8r2sUKFColq1auLz58/Ken5+fgIAE4tsiEOhMkHv3r1VjuvWrYs3b94ou7810b17d+Xfurq6qFq1KoQQ6Natm7Lc3NwcZcqUwcOHD9Pcvp2dHb7//nvlsampKby9vXHlyhUEBwer1O3Rowd0dXWVx0ePHkV0dDQGDRoEHR0dlXqmpqbKITtXrlzBo0ePMGjQIJibm6u0GT9s5e3bt/j777/Rrl07fPz4Ea9fv8br16/x5s0beHp64t69e3j27Jny8d64cQP37t1L8jHFz1/w9/dPNOQm3pEjRxAaGoqOHTsq7+v169fQ1dVFjRo1cPz4cbXbAuTwFyFEhi4Xu3//flSvXh116tRRlhkbG6Nnz554/Pgxbt68qVLf29sbJiYmyuMffvgBtra22L9/PwDAzMwMAHDo0KFUhyioI+HyrPFDSaKjo3H06FEAcriHmZkZmjRpovIcu7m5wdjYWPkcx3N0dISnp2e644q3f/9+6OrqYsCAASrlQ4cOhRACBw4cUCkXQqBfv35YsGAB/vzzT3Tu3Fl5nbrnS0JJvR+o8xo1NDRU/h3/Wqhbty4iIiJw+/ZtlbrGxsb46aeflMd6enqoXr26yv3s378ftra2+OGHH5RlRkZG6NmzZ6qxpCT+vBoyZIhK+dChQwEg0ZC9pOjr6yvfO2JjY/HmzRsYGxujTJkyuHz5crri27ZtG8qVK4eyZcuq/J81atQIABL9n3l4eKBkyZLK4woVKsDU1FT5XAohsGPHDrRo0QJCCJU2PT098f79+0Qxd+7cWeX/8/nz57h27Rq8vb1hbGysLK9fvz5cXV1Vblu6dGnUqFEDGzZsUJa9ffsWBw4cQKdOnVSG/Klr1qxZGDhwIGbOnIlff/1V5bq6desCAE6ePAkA+Oeff1CtWjU0adIE//zzDwA53On69evKuglp8vmnUCjQtm1b7N+/H2FhYcryLVu2oEiRIsr3vvjPjb179+Lz589pesxpeT2pIy2fVfG+/uxU9/3kxYsXCAgIQOfOnZXv3wDQpEkTODs7pxqrOs9bWt+nM4qPj4/K3Iv4cyr+9Xbx4kW8efMGPXr0QL58+ZT1OnXqhIIFC2ZKTJQ+TCwyQbFixVSO40/+lL6QprVNMzMzGBgYwNLSMlG5Jvfj5OSU6AOqdOnSAJBoPoKjo6PK8ZMnTwAAZcqUUSnX09NDiRIllNc/ePAAAODi4pJsHPfv34cQAuPGjUPhwoVVLhMmTAAgJz0DwOTJkxEaGorSpUvD1dUVw4cPVxkDrK+vj5kzZ+LAgQOwtrZGvXr1MGvWLJVEKT4padSoUaL7O3z4sPK+1Gkrszx58iTRcwsA5cqVU16fUKlSpVSOFQoFnJyclP+Pjo6OGDJkCFavXg1LS0t4enpiyZIlaZpfEU9HRwclSpRQKfv6vLl37x7ev38PKyurRM9xWFiY8jmO9/X5lV5PnjyBnZ2dSrIFJP/8rVu3DkuWLMGiRYvQsWNHlevUPV/iGRgYKMdoxytYsKBar9EbN27g+++/h5mZGUxNTVG4cGFl8vD1/5W9vX2i1+/X9/PkyZMkX+dJnVtp8eTJE+jo6MDJyUml3MbGBubm5ome36TExcVh3rx5KFWqFPT19WFpaYnChQvjv//+0+i8TOjevXu4ceNGov+v+PP06/+zr99rAdXn8tWrVwgNDcXKlSsTtenj45Nkm8m9Z379nCVX5u3tjVOnTilvt23bNnz+/Bk///yzWs9BQidOnMDIkSMxcuRI5byKhKytrVGqVCllEvHPP/+gbt26qFevHp4/f46HDx/i1KlTiIuLSzKx0PTzr3379vj06ZNyfkJYWBj279+Ptm3bKs/Z+vXro02bNpg0aRIsLS3RsmVL+Pr6qjVPKC2vJ3Wk5bMq3tfngbrvJ/H/71+/twPqvX7Ved7S+j6dUVI7X5J7reTLly9H7N+RF+VLvQqlVcJfJBIS/z9RNLlfmFKaRJZUm6ndT2ZJ+MtPRotfLWXYsGHJ/mod/wZTr149PHjwALt378bhw4exevVqzJs3D8uXL1f28AwaNAgtWrTArl27cOjQIYwbNw4zZszA33//jcqVKyvvb/369bCxsUl0Xwl/IUmtrZxkzpw56NKli/K5GzBgAGbMmIGzZ8+qTCrMCHFxcbCyslL5xTWhr794Z+b5pY7atWsjICAAixcvRrt27WBhYaG8Li3nC5D8azQ1oaGhqF+/PkxNTTF58mSULFkSBgYGuHz5MkaOHJloVSFtvRckpMkv5/GmT5+OcePGoWvXrpgyZQosLCygo6ODQYMGpXsFpbi4OLi6umLu3LlJXl+0aFGV49Sey/h4fvrpJ5XerIQqVKigcpzec7pDhw4YPHgwNmzYgDFjxuDPP/9E1apVNUoKy5cvj9DQUKxfvx69evVKMpGvU6cOjh07hk+fPuHSpUsYP348XFxcYG5ujn/++Qe3bt2CsbFxku97mp6LNWvWhIODA7Zu3Yoff/wR//vf//Dp0ye0b99eWUehUGD79u04e/Ys/ve//+HQoUPo2rUr5syZg7Nnz6r0/iSU1teTOtLyWRXv6/Mgre8nmlLneUvr+3RGyQ7vXZSxmFhoQXxG/vWKSer8spdZ4n99Sfjl4O7duwCQ6q8CxYsXBwDcuXNH5dfr6OhoPHr0CB4eHgCgHF5w/fp1ZdnX4m+fP3/+ZOskZGFhAR8fH/j4+CAsLAz16tXDxIkTVYaOlSxZEkOHDsXQoUNx7949VKpUCXPmzMGff/6pjMnKykqt+0uprcxSvHhx3LlzJ1F5fPd9/PMf7+uhYUII3L9/P9GXHVdXV7i6uuLXX3/F6dOnUbt2bSxfvhxTp05VO7a4uDg8fPhQ+esvkPi8KVmyJI4ePYratWtnatKQ3Bfb4sWL4+jRo/j48aNKr0Vyz5+TkxNmzZqFBg0a4JtvvsGxY8eUt0vr+aIpf39/vHnzBn/99Rfq1aunLH/06JHGbRYvXhzXr19P9DpP6txKSkrPb1xcHO7du6fsBQKAkJAQhIaGqjy/ybWxfft2NGzYEH/88YdKeWhoaKJe2bQqWbIkrl69isaNG6cr+YlXuHBhmJiYIDY2VuNzIP45SWr1m6TKLCws4OXlhQ0bNqBTp044deoU5s+fr9F9W1paYvv27ahTpw4aN26Mf//9F3Z2dip16tatC19fX2zevBmxsbGoVasWdHR0UKdOHWViUatWLY0T5+S0a9cOCxYswIcPH7BlyxY4ODigZs2aierVrFkTNWvWxLRp07Bx40Z06tQJmzdvVnnfTyg9r6fkzpm0flYlRd33k/jzJalhv+q+foGUn7e0vE8n95xkxOvrawlfKw0bNlSWx8TE4PHjx4k+10j7OBRKC0xNTWFpaakcwxpv6dKlWopIjvlNuHTdhw8fsG7dOlSqVCnJX1IS8vDwgJ6eHhYuXKjyK8Mff/yB9+/fw8vLC4BcxtDR0RHz589PlFTF387KygoNGjTAihUr8OLFi0T39erVK+Xfb968UbnO2NgYTk5Oyu7diIgIREZGqtQpWbIkTExMlHU8PT1hamqK6dOnJzn2NP7+1GkLUH+52bT49ttvcf78eZw5c0ZZFh4ejpUrV8LBwSHRGNt169bh48ePyuPt27fjxYsXaNasGQD5fxsTE6NyG1dXV+jo6Kg1pOBrixcvVv4thMDixYuRP39+NG7cGID8shAbG4spU6Ykum1MTEy6NlxLqECBAgASJ+zffvstYmNjVeIEgHnz5kGhUCifl4QqVKiA/fv349atW2jRooVyLw11z5f0iv/ClvD1FB0dna73iG+//RbPnz/H9u3blWURERFYuXKlWrdP6fkFkOiLbnwPQfzrP76NpP6/dXV1E/1CuW3btkRj1DXRrl07PHv2DKtWrUp03adPn9K8n4Curi7atGmDHTt24Pr164muV+ccsLOzg4uLC9atW6cyp+DEiRO4du1akrf5+eefcfPmTQwfPhy6urro0KFDmuJOyN7eHkePHsWnT5/QpEmTRO+l8UOcZs6ciQoVKijH9detWxfHjh3DxYsXkxwGlV7t27dHVFQU1q5di4MHD6Jdu3Yq17979y7ReVKpUiUASPG9Kz2vJyMjIwCJz/u0fFYlR933E1tbW1SqVAlr165V+Ww5cuRIojl2SVHneUvL+3Ryr+Pk3iPSo2rVqihUqBBWrVql8rm1YcOGdA0vp8zDHgst6d69O3777Td0794dVatWxcmTJ5W/9GpD6dKl0a1bN1y4cAHW1tZYs2YNQkJC4Ovrm+ptCxcujNGjR2PSpEn45ptv8N133+HOnTtYunQpqlWrphzHqqOjg2XLlqFFixaoVKkSfHx8YGtri9u3b+PGjRs4dOgQALledZ06deDq6ooePXqgRIkSCAkJwZkzZ/D06VPl2vbOzs5o0KAB3NzcYGFhgYsXL2L79u3KycR3795F48aN0a5dOzg7OyNfvnzYuXMnQkJClB/KpqamWLZsGX7++WdUqVIFHTp0QOHChREYGIh9+/ahdu3aWLx4sVptAcDOnTvh4+MDX1/fDJvAPWrUKGzatAnNmjXDgAEDYGFhgbVr1+LRo0fYsWOHyoR5QP66WadOHfj4+CAkJATz58+Hk5MTevToAUDu+N2vXz+0bdsWpUuXRkxMDNavX6/8wpQWBgYGOHjwIDp37owaNWrgwIED2LdvH8aMGaPsOq9fvz569eqFGTNmICAgAE2bNkX+/Plx7949bNu2DQsWLFCZUKwpNzc3AMCAAQPg6emp/PLVokULNGzYEGPHjsXjx49RsWJFHD58GLt378agQYNUJuomVLNmTezevRvffvstfvjhB+zatUvt8yW9atWqhYIFC6Jz584YMGAAFAoF1q9fn67hAT169MDixYvh7e2NS5cuwdbWFuvXr1d+cUpN/PM7duxYdOjQAfnz50eLFi1QsWJFdO7cGStXrlQOOTl//jzWrl2LVq1aqfzK6ObmhmXLlmHq1KlwcnKClZUVGjVqhObNm2Py5Mnw8fFBrVq1cO3aNWzYsCHR/B1N/Pzzz9i6dSt69+6N48ePo3bt2oiNjcXt27exdetW5Z4pafHbb7/h+PHjqFGjBnr06AFnZ2e8ffsWly9fxtGjR/H27dtU25g+fTpatmyJ2rVrw8fHB+/evcPixYvh4uKikmzE8/LyQqFChbBt2zY0a9YMVlZWaYr5a05OTjh8+DAaNGgAT09P/P333zA1NVVeZ2Njgzt37qB///7K29SrVw8jR44EgExJLKpUqQInJyeMHTsWUVFRKsOgALnnxtKlS/H999+jZMmS+PjxI1atWgVTU1NlgpuU9LyeDA0N4ezsjC1btqB06dKwsLCAi4sLXFxc1P6sSk5a3k9mzJgBLy8v1KlTB127dsXbt2+xaNEilC9fPsnzJa3PW1rep5N7HVeqVAm6urqYOXMm3r9/D319fTRq1Chd56qenh4mTpyI/v37o1GjRmjXrh0eP34MPz8/lCxZMlN6SSidsmj1qTwhfrm9+GU248UvNZdwmcaIiAjRrVs3YWZmJkxMTES7du3Ey5cvk11u9us2k1uqtH79+qJ8+fJpijt+CcJDhw6JChUqCH19fVG2bNlEy5HGP47klqxbvHixKFu2rMifP7+wtrYWffr0SbSsrBBC/Pvvv6JJkybCxMREFChQQFSoUEFlKUchhHjw4IHw9vYWNjY2In/+/KJIkSKiefPmYvv27co6U6dOFdWrVxfm5ubC0NBQlC1bVkybNk253vbr169F3759RdmyZUWBAgWEmZmZqFGjRqK10oWQS995enoKMzMzYWBgIEqWLCm6dOkiLl68mKa2MmO52fjn44cffhDm5ubCwMBAVK9eXezduzfRYwAgNm3aJEaPHi2srKyEoaGh8PLyEk+ePFHWe/jwoejatasoWbKkMDAwEBYWFqJhw4bi6NGjqcacVPwPHjxQ7hNgbW0tJkyYkGjpUCGEWLlypXBzcxOGhobCxMREuLq6ihEjRojnz5+rPPaUlhBOSUxMjOjfv78oXLiwUCgUKkvPfvz4UQwePFjY2dmJ/Pnzi1KlSonZs2cnWqoTX+1jIYQQu3fvFvny5RPt27dXWdo3pfMl4fPztfjXdGpOnTolatasKQwNDYWdnZ0YMWKEOHToUKLlHJN7zX+9bKYQQjx58kR89913wsjISFhaWoqBAwcql5NUZ7+QKVOmiCJFiggdHR2V97TPnz+LSZMmCUdHR5E/f35RtGhRMXr0aJVlOIWQy2h6eXkJExMTlaUiIyMjxdChQ4Wtra0wNDQUtWvXFmfOnEm0RKUmy80KIUR0dLSYOXOmKF++vNDX1xcFCxYUbm5uYtKkSeL9+/fKekn9/wuR9GsyJCRE9O3bVxQtWlTkz59f2NjYiMaNG6vseRL/mkxuaefNmzeLsmXLCn19feHi4iL27Nkj2rRpI8qWLZtk/V9++UUAEBs3bkzT40/4OL5+fZ07d06YmJiIevXqqSzJGr/Pw5YtW5Rl0dHRwsjISOjp6YlPnz6ptJOWz7+UjB07VgAQTk5Oia67fPmy6NixoyhWrJjQ19cXVlZWonnz5iqvu+So+3pK6nVz+vRp4ebmJvT09BJ9RqvzWZXaZ6c67ydCCLFjxw5Rrlw5oa+vL5ydncVff/2VZLzped7UeZ9O7nUshBCrVq0SJUqUELq6uirPbXLLzX792kjuNb5w4UJRvHhxoa+vL6pXry5OnTol3NzcxDfffJPiY6espxCCM2TyOgcHB7i4uGDv3r3aDoXSwd/fHw0bNsS2bdsypAcgNV26dMH27dtT/bWMiNRXqVIlFC5cGEeOHEl03eDBg/HHH38gODhY7Z4motwoLi4OhQsXRuvWrZMc5kjawzkWREREWezz58+J5jr5+/vj6tWraNCgQaL6kZGR+PPPP9GmTRsmFZSnREZGJhq2tm7dOrx9+zbJ1wppF+dY5GKvXr1KcQlbPT09laU0iQA5AT1+snJyUpvQn5GyWzyUPURHR6c6l8HMzEzryxcn59mzZ/Dw8MBPP/0EOzs73L59G8uXL4eNjY3KJnMvX77E0aNHsX37drx58wYDBw5M1Bbf6yk3O3v2LAYPHoy2bduiUKFCuHz5Mv744w+4uLigbdu22g6PvsLEIherVq1aikvY1q9fH/7+/lkXEOUIAwcOxNq1a1Osk5UjKLNbPJQ9nD59WmVieFIychGFjFawYEG4ublh9erVePXqFQoUKAAvLy/89ttvKFSokLLezZs30alTJ1hZWWHhwoXK1XwS4ns95WYODg4oWrQoFi5ciLdv38LCwgLe3t747bffVHbtpuyBcyxysVOnTqX4S2/8BxtRQjdv3sTz589TrJOZezh8LbvFQ9nDu3fvcOnSpRTrlC9fHra2tlkUkfbwvZ6IsgsmFkRERERElG6cvE1EREREROnGxIKIiIiIiNKNiQUREREREaUbE4tUnDx5Ei1atICdnR0UCgV27dqV5ja2bt2KSpUqwcjICMWLF8fs2bMzPlAiIiIiIi1iYpGK8PBwVKxYEUuWLNHo9gcOHECnTp3Qu3dvXL9+HUuXLsW8efOwePHiDI6UiIiIiEh7uCpUGigUCuzcuROtWrVSlkVFRWHs2LHYtGkTQkND4eLigpkzZyp3g/zxxx/x+fNnbNu2TXmbRYsWYdasWQgMDIRCocjiR0FERERElPHYY5FO/fr1w5kzZ7B582b8999/aNu2Lb755hvcu3cPgEw8DAwMVG5jaGiIp0+fprihERERERFRTsLEIh0CAwPh6+uLbdu2oW7duihZsiSGDRuGOnXqwNfXFwDg6emJv/76C8eOHUNcXBzu3r2LOXPmAABevHihzfCJiIiIiDJMPm0HkJNdu3YNsbGxKF26tEp5VFQUChUqBADo0aMHHjx4gObNm+Pz588wNTXFwIEDMXHiROjoMK8jIiIiotyBiUU6hIWFQVdXF5cuXYKurq7KdcbGxgDkvIyZM2di+vTpCA4ORuHChXHs2DEAQIkSJbI8ZiIiIiKizMDEIh0qV66M2NhYvHz5EnXr1k2xrq6uLooUKQIA2LRpE9zd3VG4cOGsCJOIiIiIKNMxsUhFWFgY7t+/rzx+9OgRAgICYGFhgdKlS6NTp07w9vbGnDlzULlyZbx69QrHjh1DhQoV4OXlhdevX2P79u1o0KABIiMjlXMyTpw4ocVHRURERESUsbjcbCr8/f3RsGHDROWdO3eGn58fPn/+jKlTp2LdunV49uwZLC0tUbNmTUyaNAmurq54/fo1WrRogWvXrkEIAXd3d0ybNg01atTQwqMhIiIiIsocTCyIiIiIiCjduCwRERERERGlGxMLIiIiIiJKN07eTkJMTAyuXLkCa2tr7jVBRERElAvExcUhJCQElStXRr58/AqcGfisJuHKlSuoXr26tsMgIiIiogx2/vx5VKtWTdth5EpMLJJgbW0NQJ54tra2Wo6GiIiIiNLrxYsXqF69uvJ7HmU8JhZJiB/+ZGtrC3t7ey1HQ0REREQZhcPcMw+fWSIiIiIiSjcmFkRERERElG4cCkVERERqiY2NxefPn7UdBlGy9PT0ONRJi5hYEBERUYqEEAgODkZoaKi2QyFKkY6ODhwdHaGnp6ftUPIkJhZERESUovikwsrKCkZGRlAoFNoOiSiRuLg4PH/+HC9evECxYsV4nmoBEwsiIiJKVmxsrDKpKFSokLbDIUpR4cKF8fz5c8TExCB//vzaDifP4SA0IiIiSlb8nAojIyMtR0KUuvghULGxsVqOJG9iYkFERESp4rASygl4nmoXEwsiIiIiIko3zrEgIiIioqwRGAi8fp389ZaWQLFiWRcPZSj2WBAREVGmi40F/P2BTZvkv1kxBF4IgZ49e8LCwgIKhQLm5uYYNGhQ5t9xLuTv7w+FQpG+JYcDA4EyZQA3t+QvZcrIepQjMbEgIiKiTPXXX4CDA9CwIfDjj/JfBwdZnpkOHjwIPz8/7N27Fy9evICLi0vm3mEOkCEJgqZevwYiI1OuExmZco8GZWtMLIiIiCjT/PUX8MMPwNOnquXPnsnyzEwuHjx4AFtbW9SqVQs2NjbIly/3jwDnzuikTUwsiIiISG1CAOHh6l0+fAAGDJC3SaodABg4UNZTp72k2klOly5d0L9/fwQGBkKhUMDBwSFRnXfv3sHb2xsFCxaEkZERmjVrhnv37imv9/Pzg7m5OXbt2oVSpUrBwMAAnp6eCAoKUta5evUqGjZsCBMTE5iamsLNzQ0XL15MNT512gaA3bt3o0qVKjAwMECJEiUwadIkxMTEKK9XKBRYtmwZvvvuOxQoUADTpk1L9j4fP36Mhg0bAgAKFiwIhUKBLl26AACioqIwYMAAWFlZwcDAAHXq1MGFCxeSbSsiIgLNmjVD7dq1lb0fq1evRrly5WBgYICyZcti6dKlKvddxc0t1eeFcjYmFkRERKS2iAjA2Fi9i5mZ7JlIjhCyJ8PMTL32IiLUj3PBggWYPHky7O3t8eLFiyS/JHfp0gUXL17Enj17cObMGQgh8O2336r86h8REYFp06Zh3bp1OHXqFEJDQ9GhQwfl9Z06dYK9vT0uXLiAS5cuYdSoUWpvzJZa2//88w+8vb0xcOBA3Lx5EytWrICfn1+i5GHixIn4/vvvce3aNXTt2jXZ+ytatCh27NgBALhz5w5evHiBBQsWAABGjBiBHTt2YO3atbh8+TKcnJzg6emJt2/fJmonNDQUTZo0QVxcHI4cOQJzc3Ns2LAB48ePx7Rp03Dr1i1Mnz4d48aNw9q1a9V6LiiXEJRIUFCQACCCgoK0HQoREZFWffr0Sdy8eVN8+vRJCCFEWJgQMiXI+ktYWNpinzdvnihevLjyuH79+mLgwIFCCCHu3r0rAIhTp04pr3/9+rUwNDQUW7duFUII4evrKwCIs2fPKuvcunVLABDnzp0TQghhYmIi/Pz80vy8qtN248aNxfTp01Vut379emFra6s8BiAGDRqk9v0eP35cABDv3r1TloWFhYn8+fOLDRs2KMuio6OFnZ2dmDVrlsrtbt26JSpUqCDatGkjoqKilPVLliwpNm7cqHJfU6ZMEe7u7kIIIR49eiSGqvsffemS2o/na1+frwnx+13my/2DDYmIiCjDGBkBYWHq1T15Evj229Tr7d8P1Kun3n1nlFu3biFfvnyoUaOGsqxQoUIoU6YMbt26pSzLly8fqlWrpjwuW7YszM3NcevWLVSvXh1DhgxB9+7dsX79enh4eKBt27YoWbKkWjGk1vbVq1dx6tQplR6K2NhYREZGIiIiQrkbetWqVTV+HgA5F+Xz58+oXbu2six//vyoXr26ynMBAE2aNEH16tWxZcsW6OrqAgDCw8Px4MEDdOvWDT169FDWjYmJgZmZGfD6NQr374/f0xUl5QRMLIiIiEhtCgVQoIB6dZs2Bezt5XCopOZHKBTy+qZNgf//jprjTJw4ET/++CP27duHAwcOYMKECdi8eTO+//77dLcdFhaGSZMmoXXr1omuMzAwUP5dQN3/kAzg5eWFHTt24ObNm3B1dVXGCQCrVq1SSdQAwOToUaB8eRR4+RIx4BfP3I5zLIiIiChT6OoC/z+EHwqF6nXxx/PnayepKFeuHGJiYnDu3Dll2Zs3b3Dnzh04Ozsry2JiYlQmY9+5cwehoaEoV66csqx06dIYPHgwDh8+jNatW8PX11etGFJru0qVKrhz5w6cnJwSXXR0NPsKp6enB0D2fMQrWbIk9PT0cOrUKWXZ58+fceHCBZXnAgB+++03dO7cGY0bN8bNmzcBANbW1rCzs8PDhw+/xFiwIJzGj4d1nz7Ay5eILlUKLQHE/f/9J8vAQG6SRzkSE0ciIiLKNK1bA9u3y9WfEi45a28vk4okfozPEqVKlULLli3Ro0cPrFixAiYmJhg1ahSKFCmCli1bKuvlz58f/fv3x8KFC5EvXz7069cPNWvWRPXq1fHp0ycMHz4cP/zwAxwdHfH06VNcuHABbdq0USuGlNoGgPHjx6N58+YoVqwYfvjhB+jo6ODq1au4fv06pk6dqtHjLl68OBQKBfbu3Ytvv/0WhoaGMDY2Rp8+fTB8+HBYWFigWLFimDVrFiIiItCtW7dEbfz++++IjY1Fo0aN4O/vj7Jly2LSpEkYMGAAzMzM0CZfPliNH4/8b94gTqGAzqhReN65M/aXLYtbu3ahvLU1AODjx4+o36ABVq5Y8WU4F3feztGYWBAREVGmat0aaNkS+Ocf4MULwNYWqFtX+8OffH19MXDgQDRv3hzR0dGoV68e9u/fr7Kqk5GREUaOHIkff/wRz549Q926dfHHH38AAHR1dfHmzRt4e3sjJCQElpaWaN26NSZNmqTW/afUNgB4enpi7969mDx5MmbOnIn8+fOjbNmy6N69u8aPuUiRIpg0aRJGjRoFHx8feHt7w8/PD7/99hvi4uLw888/4+PHj6hatSoOHTqEggULJtnOvHnzVJKL7t27wzwuDgajRqHIu3cAgMdGRng8YQIajBgBPH4MAPhsawtUqgQAiA0NxRUAYaVLA1WqaPyYKPtQCJGWVaHzhqdPn6Jo0aIICgqCvb29tsMhIiLSmsjISDx69AiOjo4q4/rzAj8/PwwaNChTdqnOzLa14n//A3r2BIKDAR0dYPhwYOJEObQpC6V0vvL7XeZjjwURERERaebdO2DQIGDdOnlctizg5wd8NYmb8gZO3iYiIiLKYM2aNYOxsXGSl+nTp2fa/fbu3TvZ++3du3fG3tm+fYCLi0wqFArZS3H5MpOKPIyJBREREVESunTpovFQpdWrVyMgICDJS+/evdPVdkomT56c7P1Onjw5Y+4kNBTw8QGaNweePwdKlwZOnQJmzQIMDTPmPrKRJUuWwMHBAQYGBqhRowbOnz+fYv1t27ahbNmyMDAwgKurK/bv369yvRAC48ePh62tLQwNDeHh4YF79+4pr3/8+DG6desGR0dHGBoaomTJkpgwYQKio6NV6igUikSXs2fPZuyDTyMOhSIiIiLKYEWKFNHK/VpZWcHKyirz7uDAAaBHD7k5iUIBDBkCTJmSKxMKANiyZQuGDBmC5cuXo0aNGpg/fz48PT1x586dJJ/n06dPo2PHjpgxYwaaN2+OjRs3olWrVrh8+TJcXFwAALNmzcLChQuxdu1aODo6Yty4cfD09MTNmzdhYGCA27dvIy4uDitWrICTkxOuX7+OHj16IDw8HL//rrrN4NGjR1G+fHnlcaFChTL3CUkFJ28ngZN7iIiIpLw8eZsSeP9eJhFr1shjJyc5lyLBbt3ZgTqTt2/evKmS+Onr60NfXz/J9mrUqIFq1aph8eLFAIC4uDgULVoU/fv3x6hRoxLVb9++PcLDw7F3715lWc2aNVGpUiUsX74cQgjY2dlh6NChGDZsGADg/fv3sLa2hp+fHzp06JBkHLNnz8ayZcvw8OFDALLHwtHREVeuXEGl/19lKzvgUCgiIiIiSt7hw3IuxZo1spdi0CDg6tVsl1Soy9nZGWZmZsrLjBkzkqwXHR2NS5cuwcPDQ1mmo6MDDw8PnDlzJsnbnDlzRqU+IJcNjq//6NEjBAcHq9QxMzNDjRo1km0TkMmHhYVFovLvvvsOVlZWqFOnDvbs2ZP8g84iHApFRERERIl9+AAMHQqsXi2PS5YEfH3lJiQ5WFI9Fkl5/fo1YmNjYf3/G/rFs7a2xu3bt5O8TXBwcJL1g4ODldfHlyVX52v379/HokWLVIZBGRsbY86cOahduzZ0dHSwY8cOtGrVCrt27cJ3332XZDtZgYkFEREREak6cgTo1g0ICpLHAwYA06cDBQpoN64MYGJiAlNTU22HoZZnz57hm2++Qdu2bdGjRw9luaWlJYYMGaI8rlatGp4/f47Zs2drNbHgUCgiIiIikj5+BHr3Bpo2lUlFiRKAvz+wYEGuSCrSwtLSErq6uggJCVEpDwkJgY2NTZK3sbGxSbF+/L/qtPn8+XM0bNgQtWrVwsqVK1ONt0aNGrh//36q9TITEwsiIiLKPIGBcm+D5C6BgdqOMEN06dIFrVq10nYY6XPsGODqCqxYIY/79QP++w+oX1/tJvz8/GBubp5hITk4OGD+/PkZ1l5a6Onpwc3NDceOHVOWxcXF4dixY3B3d0/yNu7u7ir1AeDIkSPK+o6OjrCxsVGp8+HDB5w7d06lzWfPnqFBgwZwc3ODr68vdHRS/8oeEBAAW1vbND3GjKbVxOLkyZNo0aIF7OzsoFAosGvXrlRv4+/vjypVqkBfXx9OTk7w8/NTuT42Nhbjxo1TWft3ypQp4OJXREREWSwwEChTBnBzS/5SpkymJRcNGjTAoEGDMv02OV5YGPDLL4CHB/DkCeDgAPz9N7BoUZ7rpfjakCFDsGrVKqxduxa3bt1Cnz59EB4eDh8fHwCAt7c3Ro8eraw/cOBAHDx4EHPmzMHt27cxceJEXLx4Ef369QMAKBQKDBo0CFOnTsWePXtw7do1eHt7w87OTpmYxicVxYoVw++//45Xr14hODhYZQ7G2rVrsWnTJty+fRu3b9/G9OnTsWbNGvTv3z/rnpwkaHWORXh4OCpWrIiuXbuidevWqdZ/9OgRvLy80Lt3b2zYsAHHjh1D9+7dYWtrC09PTwDAzJkzsWzZMqxduxbly5fHxYsX4ePjAzMzMwwYMCCzHxIRERHFe/0aiIxMuU5kpKxXrFjWxJSHff78Gfnz51ctPH4c6NoVePxYHvfpIze6MzbO8viyo/bt2+PVq1cYP348goODUalSJRw8eFA5+TowMFClN6FWrVrYuHEjfv31V4wZMwalSpXCrl27lHtYAMCIESMQHh6Onj17IjQ0FHXq1MHBgweVy+MeOXIE9+/fx/379xNte5Dwh/IpU6bgyZMnyJcvH8qWLYstW7bghx9+yMynI3UimwAgdu7cmWKdESNGiPLly6uUtW/fXnh6eiqPvby8RNeuXVXqtG7dWnTq1EntWIKCggQAERQUpPZtiIiIcqNPnz6Jmzdvik+fPsmCuDghwsLUu/z7rxBA6pd//1Wvvbg4tePu3LmzAKByefTokfD39xfVqlUTenp6wsbGRowcOVJ8/vw5xdvExMSIrl27CgcHB2FgYCBKly4t5s+fn+j+WrZsqVZssbGxYvr06cr2KlSoILZt26a8/vjx4wKAOHr0qHBzcxOGhobC3d1d3L59W6WdXbt2icqVKwt9fX3h6OgoJk6cqHwsQsjvVkuXLhUtWrQQRkZGYsKECUIIIaZMmSIcLC3F8vz5lf8Hz/LnF+LYMXHixAmRL18+8eLFC5X7GjhwoKhTp06qj83X11eYmZkpj1++fCnc3NxEq1atRGRkpHBzcxOzZ89WXt+yZUuRL18+8fHjRyHEl+9g9+7dE0IIUbx4cTFt2jTh4+MjjI2NRdGiRcWKFSuSvf9E52sC/H6X+XJUYlG3bl0xcOBAlbI1a9YIU1NT5fG0adNE8eLFxZ07d4QQQgQEBAgrKyvx559/JttuZGSkeP/+vfJy8+ZNnnhEREQiiS9qYWHqJQuZcQkLUzvu0NBQ4e7uLnr06CFevHghXrx4IZ4+fSqMjIzEL7/8Im7duiV27twpLC0tlV+4k7pNTEyMiI6OFuPHjxcXLlwQDx8+FH/++acwMjISW7ZsUd5fWhKLqVOnirJly4qDBw+KBw8eCF9fX6Gvry/8/f2FEF8Sixo1agh/f39x48YNUbduXVGrVi1lGydPnhSmpqbCz89PPHjwQBw+fFg4ODiIiRMnKusAEFZWVmLNmjXiwYMH4smTJ+LPP/8UHnp64oOlpfJ5/SN/fuHu4qK8XenSpcWsWbOUx9HR0cLS0lKsWbMm1ceWMLEIDAwUZcqUEZ07dxYxMTFCCCGGDBkivLy8hBBCxMXFCQsLC2FpaSkOHDgghBDizz//FEWKFFG2V7x4cWFhYSGWLFki7t27J2bMmCF0dHQSJVnxmFhoV45KLEqVKiWmT5+uUrZv3z4BQERERAgh5K8AI0eOFAqFQuTLl08oFIpEt/nahAkTEv1CwROPiIgo5yYWQghRv359lR8kx4wZI8qUKSPiEvR8LFmyRBgbG4vY2Ngkb5Ocvn37ijZt2iiP1U0sIiMjhZGRkTh9+rRKebdu3UTHjh2FEKo9FvHiv+/E/z80btw40feb9evXC1tbW+UxADFo0KAvFcLCxGZr6y/PZ9GiQhw+LGrXri0qVqyorDZz5kxRrlw55fGOHTuEsbGxCFPj+Y9PLG7fvi2KFi0qBgwYoPJ879mzR5iZmYmYmBgREBAgbGxsxMCBA8XIkSOFEEJ0795d/Pjjj8r6xYsXFz/99JPyOC4uTlhZWYlly5Ylef9MLLQr160KtXXrVmzYsAEbN27E5cuXsXbtWvz+++9Yu3ZtsrcZPXo03r9/r7zcvHkzCyMmIiLKQYyM5GRfdS7//qtem//+q157RkbpCv3WrVtwd3eHQqFQltWuXRthYWF4+vRpirddsmQJ3NzcULhwYRgbG2PlypUI1GDS+f379xEREYEmTZrA2NhYeVm3bh0ePHigUrdChQrKv+NX+3n58iUA4OrVq5g8ebJKGz169MCLFy8QERGhvF3VqlXlH//8A1SsiPbxy5z26AFcvw40aYLq1aur3G+XLl1w//59nD17FoBc6aldu3YooOZE7k+fPqFu3bpo3bo1FixYoPJ8161bFx8/fsSVK1dw4sQJ1K9fHw0aNIC/vz8A4MSJE2jQoEGyz4NCoYCNjY3yeaDsJUdtkJfc2sCmpqYwNDQEAAwfPhyjRo1Chw4dAACurq548uQJZsyYgc6dOyfZrr6+vsquix8+fMikR0BERJTDKRTqrxT0/5/NatXLxqsPbd68GcOGDcOcOXPg7u4OExMTzJ49G+fOnUtzW2FhYQCAffv2qez+DCTeATrhROv4L+dxcXHKdiZNmpTk4jfxk4ABwDRfPmDwYLkPhRB4plDg1tCh8Jg9O9kYrays0KJFC/j6+sLR0REHDhxQfvFXh76+Pjw8PLB3714MHz5c5XGam5ujYsWK8Pf3x5kzZ9CkSRPUq1cP7du3x927d3Hv3j3U/2p5268nnCsUCuXzQNlLjkos3N3dsX//fpWyhGsDA0BERESitX51dXV5AhIREeUxenp6iI2NVR6XK1cOO3bsgBBC+UX91KlTMDExUa6+8/Vt4uvUqlULv/zyi7Ls694FdTk7O0NfXx+BgYGJvkCnRZUqVXDnzh04OTklW6cWgIaDBwMvXsiCbt3gHRAA58hIeCSod+HChUS37d69Ozp27Ah7e3uULFkStWvXVjs2HR0drF+/Hj/++CMaNmwIf39/2NnZKa+vX78+jh8/jvPnz2PatGmwsLBAuXLlMG3aNNja2qJ06dJq3xdlL1odChUWFoaAgAAEBAQAkMvJBgQEKLsWR48eDW9vb2X93r174+HDhxgxYgRu376NpUuXYuvWrRg8eLCyTosWLTBt2jTs27cPjx8/xs6dOzF37lx8//33WfrYiIiI8jxLSyDBr+dJMjCQ9TKBg4MDzp07h8ePH+P169f45ZdfEBQUhP79++P27dvYvXs3JkyYgCFDhih/lPz6NnFxcShVqhQuXryIQ4cO4e7duxg3blySX8bVYWJigmHDhmHw4MFYu3YtHjx4gMuXL2PRokUpDtv+2vjx47Fu3TpMmjQJN27cwK1bt7B582b8+uuvwKdPwNCh+AeA8YsXQJEiwP79wOrV6Dp4MP744w+sXbsW9+7dw9SpU/Hff/+pDFcCAE9PT5iammLq1KnKPRvSQldXFxs2bEDFihXRqFEjlT0YGjRogEOHDimXSY0v27BhQ7qSLcoGtDnBI35y0teXzp07CyHkRKj69esnuk2lSpWEnp6eKFGihPD19VW5/sOHD2LgwIGiWLFiwsDAQJQoUUKMHTtWREVFqR0XJ/cQERFJKU2GVcuTJ0JcupT85cmTjA04gTt37oiaNWsKQ0NDtZabTe42kZGRokuXLsLMzEyYm5uLPn36iFGjRqlMeE7LqlBxcXFi/vz5okyZMiJ//vyicOHCwtPTU5w4cUII8eX70bt375S3uXLlijKeeAcPHhS1atUShoaGwtTUVFSvXl3sGjlSiNKllRO0HzdqJESCdoQQYvLkycLS0lIYGxuLrl27igEDBoiaNWsminPcuHFCV1dXPH/+XK3HJUTi5WY/f/4sWrduLcqVKydCQkKEEEK8efNGKBQK0b59e2W9nTt3CgBi+fLlKu0VL15czJs3T6WsYsWKypW8vsbJ29qlEIJbUn/t6dOnKFq0KIKCghJtTEJERJSXREZG4tGjR3B0dFQZu0/ZzKdPwPjxwNy5QFwcYGcHrFwJeHmletMmTZrAxsYG69evVynv1q0bXr16hT179mRW1BkupfOV3+8yX46aY0FEREREXzl7FvDxAW7flsfe3sD8+UDBgomqRkREYPny5fD09ISuri42bdqEo0eP4siRI8o679+/x7Vr17Bx48YclVSQ9uW65WaJiIiItCUwMFBlCdivL5osUZusyEhg5Eigdm2ZVNjYAHv2AGvXJplUAHJFpf3796NevXpwc3PD//73P+zYsQMeHl+mc7ds2RJNmzZF79690aRJE5XbN2vWLNnHNn369Ix7bJQjsceCiIiIKIPY2dkpF6VJ7voMceEC0LkzcOuWPP7pJ7mkrIVFijczNDTE0aNHU6yT0tKyq1evxqdPn5K8ziKV+6bcj4kFERERUQbJly9fikvApltUFDBxIjBrlpxLYW0NrFgBtGyZefeZwNd7bxAlxMSCiIiIUsW1XrKBixeBLl2AGzfk8Y8/AgsXAoUKaTWs7ITnqXZxjgURERElK37X44iICC1HkodFRQG//grUrCmTCisr4K+/gA0bmFR8JTo6GoDcR4OyHnssiIiIKFm6urowNzfHy5cvAQBGRkaJNlOjzKO4cgX5e/SAzv/3UsS2bYvPc+fKTQUjI7UcXfYSFxeHV69ewcjICPny8SuuNvBZJyIiohTZ2NgAgDK5oCwQHQ3LFStguXIlFLGxiLGwQPD48fjYtCnw8aO8UCI6OjooVqwYk18tYWJBREREKVIoFLC1tYWVlRU+f/6s7XByPcXVq7KX4to1AEBs69aImT8floULw1LLsWV3enp60NHhSH9tYWJBREREatHV1eXY9cwUHQ1Mnw5MmwbExMjhTkuXQrdtW/BZp5yAiQURERGRtl29Kld8it8Do00bYOlSOVGbKIdgXxERERGRtnz+DEyZAlStKpOKQoWATZuAbduYVFCOwx4LIiIiIm24dk32Uly+LI+//x5YtkxuekeUA7HHgoiIiCgrxcTIeRRubjKpsLCQe1Ls2MGkgnI09lgQERERZZXr12UvxaVL8rhlS2D5cuD/l/QlysnYY0FERESU2WJigBkzZC/FpUtAwYLA+vXAzp1MKijXYI8FERERUWa6eVP2Uly4II9btABWrABsbbUaFlFGY48FERERUWaIiQFmzgQqV5ZJhbk5sHYtsHs3kwrKldhjQURERJTRbt2SvRTnz8vjb78FVq4EihTRalhEmYk9FkREREQZJTYWmD1b9lKcPw+YmQG+vsDevUwqKNdjjwURERFRRrhzB/DxAc6ckcfffAOsWgXY22s3LqIswh4LIiIiovSIjQXmzAEqVZJJhakp8McfwP79TCooT2GPBREREZGm7t6VvRSnT8vjpk2B1auBokW1GxeRFrDHgoiIiCitYmOBefOAihVlUmFiIoc9HTzIpILyLPZYEBEREaXF/fuyl+Lff+Wxh4cc+lSsmHbjItIy9lgQERERqSMuDli4EKhQQSYVxsbA8uXA4cNMKojAHgsiIiKi1D14AHTtCpw8KY8bNZK9FA4OWg2LKDthjwURERFRcuLigMWLZS/FyZNAgQLA0qXAkSNMKoi+wh4LIiIioqQ8eiR7Kfz95XGDBsCaNYCjozajIsq22GNBRERElFBcnOyVcHWVSYWRkey1OHaMSQVRCthjQURERBTv8WOgWzfg77/lcb16speiZEmthkWUE7DHgoiIiEgIYMUK2Uvx99+AoSGwYAFw/DiTCiI1sceCiIiI8rYnT4Du3YGjR+VxnTqAry/g5KTduIhyGPZYEBERUd4khNwt29VVJhWGhnI37RMnmFQQaYA9FkRERJT3BAXJXorDh+Vx7dqyl6JUKe3GRZSDsceCiIiI8g4h5MZ2Li4yqTAwAObMkb0UTCqI0oU9FkRERJQ3PH0K9OgBHDwoj2vWBPz8gDJltBoWUW7BHgsiIiLK3YSQw5xcXGRSoa8PzJ4N/PsvkwqiDMQeCyIiIsq9nj0DevYE9u+XxzVqyF6KsmW1GhZRbsQeCyIiIsp9hADWrgXKl5dJhZ4eMHOm7KVgUkGUKdhjQURERLnL8+dAr17A3r3yuFo12Uvh7KzVsIhyO/ZYEBERUe4gBLB+veyl2LtX9lLMmAGcPs2kgigLsMeCiIiIcr7gYNlLsWePPHZzk70ULi5aDYsoL2GPBREREeVcQgAbN8peij17gPz5galTgTNnmFQQZTH2WBAREVHOFBIC9O4N7Nolj6tUkb0Urq7ajIooz2KPBREREeUsQgCbN8teil27ZC/F5MnA2bNMKoi0iD0WRERElHO8fAn88guwY4c8rlRJLitboYJWwyIi9lgQERFRTrF1q+yl2LEDyJcPmDgROH+eSQVRNsEeCyIiIsreXr0C+vYFtm2TxxUqyF6KSpW0GhYRqWKPBREREWVfO3bIXopt2wBdXWD8eODCBSYVRNkQeyyIiIgo+3n9GujXD9iyRR67usoVn6pU0WpYRJQ89lgQERFR9rJzp+yl2LJF9lKMHSt7KZhUEGVr7LEgIiKi7OHNG6B/f2DTJnlcvrzspahaVathEZF62GNBRERE2rd7t0wkNm0CdHSA0aOBS5eYVBDlIOyxICIiIu15+xYYMADYsEEelysneymqV9dqWESUduyxICIiIu343/9kL8WGDbKXYuRI4PJlJhVEORR7LIiIiChrvXsHDBwIrF8vj8uWlb0UNWpoNSwiSh/2WBAREVHW2bcPcHGRSYWODjB8uOylYFJBlONpNbE4efIkWrRoATs7OygUCuzatSvV2/j7+6NKlSrQ19eHk5MT/Pz8EtV59uwZfvrpJxQqVAiGhoZwdXXFxYsXM/4BEBERkXpCQwEfH6B5c+D5c6B0aeDff4FZswBDQ21HR0QZQKuJRXh4OCpWrIglS5aoVf/Ro0fw8vJCw4YNERAQgEGDBqF79+44dOiQss67d+9Qu3Zt5M+fHwcOHMDNmzcxZ84cFCxYMLMeBhEREaXkwAHZS+HnBygUwNChQEAA4O6u7ciIKANpdY5Fs2bN0KxZM7XrL1++HI6OjpgzZw4AoFy5cvj3338xb948eHp6AgBmzpyJokWLwtfXV3k7R0fHFNuNiopCVFSU8vjjx49peRhERESUlPfvgSFDgDVr5HGpUoCvL1C7tnbjIqJMkaPmWJw5cwYeHh4qZZ6enjhz5ozyeM+ePahatSratm0LKysrVK5cGatWrUqx3RkzZsDMzEx5cXZ2zpT4iYiI8oxDh2QvxZo1spdi8GDZS8GkgijXylGJRXBwMKytrVXKrK2t8eHDB3z69AkA8PDhQyxbtgylSpXCoUOH0KdPHwwYMABr165Ntt3Ro0fj/fv3ysvNmzcz9XEQERHlWh8+AD16AN98Azx9CpQsCZw4AcydCxgZaTs6IspEOSqxUEdcXByqVKmC6dOno3LlyujZsyd69OiB5cuXJ3sbfX19mJqaKi8mJiZZGDEREVEuceSI7KVYvVoeDxgAXL0K1K2r3biI0mHJkiVwcHCAgYEBatSogfPnz6dYf9u2bShbtiwMDAzg6uqK/fv3q1wvhMD48eNha2sLQ0NDeHh44N69e8rrHz9+jG7dusHR0RGGhoYoWbIkJkyYgOjoaJV2/vvvP9StWxcGBgYoWrQoZs2alXEPWkM5KrGwsbFBSEiISllISAhMTU1h+P8rStja2iYaylSuXDkEBgZmWZxERER5ysePQK9eQNOmQFAQUKIE4O8PLFgAFCig7eiINLZlyxYMGTIEEyZMwOXLl1GxYkV4enri5cuXSdY/ffo0OnbsiG7duuHKlSto1aoVWrVqhevXryvrzJo1CwsXLsTy5ctx7tw5FChQAJ6enoiMjAQA3L59G3FxcVixYgVu3LiBefPmYfny5RgzZoyyjQ8fPqBp06YoXrw4Ll26hNmzZ2PixIlYuXJl5j4hqRHZBACxc+fOFOuMGDFCuLi4qJR17NhReHp6qhzXqVNHpc6gQYOEu7u72rEEBQUJACIoKEjt2xAREeVJR48KUby4EIC89OsnRFiYtqMiSkST73fVq1cXffv2VR7HxsYKOzs7MWPGjCTrt2vXTnh5eamU1ahRQ/Tq1UsIIURcXJywsbERs2fPVl4fGhoq9PX1xaZNm5KNY9asWcLR0VF5vHTpUlGwYEERFRWlLBs5cqQoU6aM2o8tM2i1xyIsLAwBAQEICAgAIJeTDQgIUPYujB49Gt7e3sr6vXv3xsOHDzFixAjcvn0bS5cuxdatWzF48GBlncGDB+Ps2bOYPn067t+/j40bN2LlypXo27dvlj42IiKiXC0sDPjlF8DDA3jyBHBwAP7+G1i0iL0UlK19/PgRHz58UF4SrgyaUHR0NC5duqSycJCOjg48PDxUFg5KKLWFhh49eoTg4GCVOmZmZqhRo0aybQLA+/fvYWFhoXI/9erVg56ensr93LlzB+/evUvh0WcurSYWFy9eROXKlVG5cmUAwJAhQ1C5cmWMHz8eAPDixQuVIUyOjo7Yt28fjhw5gooVK2LOnDlYvXq1cqlZAKhWrRp27tyJTZs2wcXFBVOmTMH8+fPRqVOnrH1wREREudXx44CrK7BsmTz+5Rfg2jWgYUPtxkWkBmdnZ5XVQGfMmJFkvdevXyM2NjbJhYOCg4OTvE1yCw3F14//Ny1t3r9/H4sWLUKvXr1SvZ+E96ENWt3HokGDBhBCJHt9UrtqN2jQAFeuXEmx3ebNm6N58+bpDY+IiIgSCgsDRo0C4je2LV5cLifbqJF24yJKg5s3b6JIkSLKY319fS1Gk7Jnz57hm2++Qdu2bdGjRw9th5OqHDV5m4iIiLTkxAmgQoUvSUWvXrKXgkkF5TAmJiYqq4Eml1hYWlpCV1c3yYWDbGxskrxNcgsNxdeP/1edNp8/f46GDRuiVq1aiSZlJ3c/Ce9DG5hYEBERUfLCw+WysQ0aAI8eAcWKyWVlly8HuDw75WJ6enpwc3PDsWPHlGVxcXE4duwY3N3dk7yNu7u7Sn0AOHLkiLK+o6MjbGxsVOp8+PAB586dU2nz2bNnaNCgAdzc3ODr6wsdHdWv7O7u7jh58iQ+f/6scj9lypRBwYIFNX/Q6cTEgoiIiJL2zz9AxYpyQjYgN767dk1O2CbKA4YMGYJVq1Zh7dq1uHXrFvr06YPw8HD4+PgAALy9vTF69Ghl/YEDB+LgwYOYM2cObt++jYkTJ+LixYvo168fAEChUGDQoEGYOnUq9uzZg2vXrsHb2xt2dnZo1aoVgC9JRbFixfD777/j1atXCA4OVpk78eOPP0JPTw/dunXDjRs3sGXLFixYsABDhgzJuicnCVqdY0FERETZUEQEMHas3IdCCMDeXm56l2CxFKK8oH379nj16hXGjx+P4OBgVKpUCQcPHlROlA4MDFTpTahVqxY2btyIX3/9FWPGjEGpUqWwa9cuuLi4KOuMGDEC4eHh6NmzJ0JDQ1GnTh0cPHgQBgYGAGTPw/3793H//n3Y29urxBM/N9nMzAyHDx9G37594ebmBktLS4wfPx49e/bM7KckRQqR0uzpPOrp06coWrQogoKCEv2HEhER5WqnTgE+PkD8TsDdugFz5gBmZtqNiyid+P0u83EoFBEREQGfPgFDhwJ168qkokgRYP9+2VPBpIKI1MChUERERHndmTNAly7A3bvy2McHmDsXMDfXZlRElMOwx4KIiCiv+vQJGD4cqFNHJhV2dsC+fXJvCiYVRJRG7LEgIiLKi86elb0Ud+7IY29vYP58QItLVRJRzsYeCyIiorwkMhIYORKoXVsmFba2wJ49wNq1TCqIKF3YY0FERJRXnD8veylu3ZLHP/0kl5S1sNBqWESUO7DHgoiIKLeLigJGjwbc3WVSYWMD7N4NrF/PpIKIMgx7LIiIiHKzixdlL8WNG/L4xx+BhQuBQoW0GhYR5T7ssSAiIsqNoqLk7tk1a8qkwsoK+OsvYMMGJhVElCnYY0FERJTbXL4MdO4MXL8ujzt0ABYtAiwttRsXEeVq7LEgIiLKLaKjgfHjgerVZVJRuDCwfTuwaROTCiLKdOyxICIiyg2uXJFzKf77Tx63awcsXiyTCyKiLMAeCyIiopwsOhqYOFH2Uvz3n+yZ2LoV2LKFSQURZSn2WBAREeVUV6/KXoqAAHncpg2wdKmcqE1ElMXYY0FERJTTfP4MTJ4MVK0qk4pChYDNm4Ft25hUEJHWsMeCiIgoJ7l2Ta74dOWKPP7+e2DZMsDaWrtxEVGex8SCiIgoJ4iJAWbOBCZNkj0WFhZycnaHDoBCoe3oiCinuXcPOH4cePkSiItTvW78eI2aZGJBRESU3V2/LudSXLokj1u2BJYvB2xstBoWEeVQq1YBffrIxR5sbFR/nFAomFgQERHlOjExwOzZctWn6GigYEFg4UKgUyf2UhCR5qZOBaZNA0aOzNBmmVgQERFlRzdvyl6KCxfkcYsWwIoVgK2tVsMiolzg3TugbdsMb5aJBRERUVYKDARev07+enNzubrT+PGyl8LcHFiwAPj5Z/ZSEFHGaNsWOHwY6N07Q5tlYkFERJRVAgOBMmWAyMjk6ygUgBDyby8v2UtRpEjWxEdEudfChV/+dnICxo0Dzp4FXF2B/PlV6w4YoNFdMLEgIiLKKq9fp5xUADKpMDYGFi2Sy8qyl4KIMsK8earHxsbAiRPykpBCkfWJRVwccP9+0itU1aunaatERESErVuBZs20HQUR5SaPHmX6XWiUWJw9C/z4I/DkyZfe2ngKBRAbmxGhERER5VHc7I6IMtPDh0CJEhnerEaJRe/eQNWqwL59cnEK9tISEREREeUQTk6AvT1Qvz7QoIH818kp3c1qlFjcuwds354h909ERJR3/PeftiMgIgKCggB/fzm/YtYsoEcPwM5OJhgNGwLdu2vUrI4mN6pRQ86vICIiIjU8fAi0bw/4+Gg7EiIiudJcp07AypXAnTvy4uEh53f16qVxsxr1WPTvDwwdCgQHJ71CVYUKGsdDRESUe7x7J3e3XbRI7klBRJQdREQA//4rey38/YErV4CyZYF+/eTQKA1plFi0aSP/7dr1S1n8stucvE1ERHne58/AsmXApEnA27eyrEkT+atcq1YpLzlrYABYWmZJmESUR5mbAwULyl6LUaOAunXlcTpplFhkwWpVREREOY8QwO7dwIgRckIiADg7A7//Dnzzjfz17c6dlHfetrQEihXLmniJKG/69lvZY7F5sxyCFBwseypKl05XsxolFsWLp+s+iYiIcp+LF2WPxMmT8tjKCpg8GejWDciX4OO2WDEmDkSkXbt2yX//+09O4D58WO7EnS+fTDA2bNCoWY0mbwPA+vVA7dpyAvmTJ7Js/nz5Qw0REVGeERgI/PQTUK2aTCoMDIAxY2SPRa9eqkkFEVF24uoqv9C7u8v3sJcvgS1bNG5Oo8Ri2TJgyBDZixIa+mVOhbm5TC6IiIhyvQ8fZAJRpsyXX/d+/hm4e1dO2DY11W58RETJmTsX+O47oFAhudzrpk1yGNSOHcCrVxo3q9HPKIsWAatWyflnv/32pbxqVWDYMI1jISIiyv5iYoDVq4EJE+Sve4Bc+33OHMDNTbuxERGpY9Mm+b7Vs6ecuG1mliHNajx5u3LlxOX6+kB4eHpDIiIiyoaEAPbvB4YPB27dkmWlS8vNpb77Tk7MJiLKCU6dAvT0kr7u9WuNV6bTaCiUoyMQEJC4/OBBoFw5jeIgIiLKvq5elcvFNm8uk4pChYCFC4Hr14GWLZlUEFHO0rGj/LHkayEhWb+PxZAhQN++chluIYDz52WPyowZsneYiIgoV3j+HPj1V8DPT37g6ekBAwfKuRXm5tqOjohIM4GBQPfuwB9/fCkLDgYaNgTKl9e4WY0Si+7dAUND+V4bEQH8+KNcHWrBAqBDB41jISIiyh7Cw4HZs+UlIkKWtW8vf0FzdNRubERE6bV/P1CvnuwtmDtX/ojSsCFQsaLc20JDGiUWHz7Ijfo6dZLvt2FhcrluALh/H3By0jgeIiIi7YmNBdaulb+cvXghy9zd5QdvzZrajY2IKKMULiz3rqhTRx7v3QtUqSJXuNPReDcKzeZYeHkBUVHybyOjL0nFnTvpGpZFRESkPUeOyA/Wbt1kUuHoCGzdKic5MqkgotymaFH5vrdhA1C9upzXoKubriY16rEwNga+/x7Ys+fLvj+3bgGNGgHt2qUrHiIioqx144Zc6enAAXlsbi53oO3bVy53SESUGxQsmPRCExERwP/+JxeliPf2rUZ3oVFi8ddfgIeHHAq1ebN8T27cWB7PnatRHERERFkrJETuRbFqFRAXJ38p69tXJhUJP2CJiHKDLNjFWqPEwtAQ2LdPDntq1w44eRLw9pZz3IiIiLK1T5+AefPkROywMFn2/ffAzJlAqVLajY2IKLN07pz22/z2G9C7t9qr4Kk9x+LDB9WLjg6wZQtw7hzQpo38gSf+OiIiomwnLg5Yv15uajd2rEwqqlYFTpyQXfFMKoiIVE2fnqZhUWr3WJibJz0sSwhg+XJgxQr5t0IhF9UgIiLKNk6cAIYOBS5dksfFiskeiw4d0rUCChFRrpbUJnopUDuxOH48zaEQERFp1927wIgRwO7d8tjERG5uN3CgHNdLREQZRu3Eon79zAyDiIgoA71+DUyeDCxbBsTEyCUUe/YEJk78skY6ERFlKI0mbwNAaKjcBfzWLXlcvjzQtStgZpZBkREREaVVVBSwcCEwbRrw/r0sa94cmDULKFdOu7EREeVyGg0svXgRKFlSLqrx9q28zJ0ryy5fzugQiYiIUiGEXFGkbFk59On9e6BSJeDoUbk+O5MKIqJMp1GPxeDBwHffyaW/4zfIi4kBuncHBg2Sy88SERFlidOn5cTss2flsZ2d7LH4+ed07yJLRJSn1a2bpvloGvdYjBz5JakA5N8jRsjriIiIMt2DB3Izpdq1ZVJRoAAwaZKcsN2lC5MKIqLk1K8PrFsn9/VJyf79gK2t2s1qlFiYmgKBgYnLg4LkghvqOnnyJFq0aAE7OzsoFArs2rUr1dv4+/ujSpUq0NfXh5OTE/z8/JKt+9tvv0GhUGDQoEHqB0VERNnbu3eyh6JcOWDbNrlcbPfuwL17wPjxMsEgIqLkVa4MDBsG2NgAPXp86fFNJ40Si/btgW7d5HDWoCB52bxZvq937Kh+O+Hh4ahYsSKWLFmiVv1Hjx7By8sLDRs2REBAAAYNGoTu3bvj0KFDiepeuHABK1asQIUKFdQPiIiIsq/oaGDBAsDJSU7s+/wZaNIEuHJFjs1Nw69qRER52vz5wPPngK8v8PIlUK8e4OwM/P47EBKicbMazbH4/Xe5EZ63t5xbAQD58wN9+sidv9XVrFkzNGvWTO36y5cvh6OjI+bMmQMAKFeuHP7991/MmzcPnp6eynphYWHo1KkTVq1ahalTp6bablRUFKKiopTHHz9+VP9BEBFR5hIC2LVLjre9f1+WlS8vP4w8PZPevZWIiFKWLx/QurW8vHwJrFwJjBsn9/r59ltgwACgUaM0NalRj4WenvzR6N07ICBAXt6+latE6etr0qJ6zpw5Aw8PD5UyT09PnDlzRqWsb9++8PLySlQ3OTNmzICZmZny4uzsnGExExFROly8KMcCt24tkworK2DFCvnB8803TCqIiNLr/HlgwgRgzhz5Hjt6NGBpKZfqHjYsTU1plFh07Qp8/AgYGQGurvJiZASEh8vrMktwcDCsra1VyqytrfHhwwd8+v/JJ5s3b8bly5cxY8YMtdsdPXo03r9/r7zcvHkzQ+MmIqI0CgwEfvoJqFYN+OcfwMAAGDtWJhc9e6quHkJERGnz8qVMJFxc5MpPr14BmzYBjx/LRTBWrwYOHwaWL09Tsxq9M69dK4c8fT1R+9MnOcF8zRpNWk2/oKAgDBw4EEeOHIGBgYHat9PX14d+gq6WDx8+ZEZ4RESUmg8fgBkzZBd4/BBVb2+5fKy9vXZjIyLKLezt5QZ0XbvKVfQKF05cp0IF+eNOGqQpsfjwQQ51FUL2WCT87h4bK1eksrJK0/2niY2NDUK+mlASEhICU1NTGBoa4tKlS3j58iWqVKmSIK5YnDx5EosXL0ZUVBR0ufwgEVH2ExMjJ2BPmCB/OQOABg3kL2oJ3tOJiCgDHDsmeypSYmoKHD+epmbTlFiYm8vhrAoFULp04usVCtl7klnc3d2xf/9+lbIjR47A3d0dANC4cWNcu3ZN5XofHx+ULVsWI0eOZFJBRJTdCCF/lRo+HLh1S5aVLg3Mng20aME5FEREmSG1pEJDaUosjh+XnwGNGgE7dgAWFl+u09MDiheXG56qKywsDPfjV/iAXE42ICAAFhYWKFasGEaPHo1nz55h3bp1AIDevXtj8eLFGDFiBLp27Yq///4bW7duxb59+wAAJiYmcHFxUbmPAgUKoFChQonKiYhIywIC5MTAY8fkcaFCwMSJQK9ecqlBIiLKHJUrJ/3DjUIhhyQ5OckhUg0bpqnZNCUW9evLfx89AooVS/2HpF9+ASZPlhPLk3Lx4kU0TBDwkCFDAACdO3eGn58fXrx4gcAEO/E5Ojpi3759GDx4MBYsWAB7e3usXr1aZalZIiLK5p49A379VU7YE0L+MjVwoFzi0Nxc29EREeV+33wDLFsmV2CqXl2WXbgA/PefTChu3gQ8PIC//gJatlS7WYUQQmROxHJoVkAAUKJEZt1D5nj69CmKFi2KoKAg2HOyIBFRxggLk0Ocfv8diIiQZR06yMnaDg5aDY2Icj9+v0ugRw/ZSzBunGr51KnAkydf5rzt2yeX/VaTRsvNqivzUhYiIsoxYmOBP/4ASpWS3dgREUCtWsDZs3J5QyYVRERZa+tWoGPHxOUdOsjrAHn9nTtpajZTEwsiIsrjjhyRqzp17w4EB8su7G3bgH//BWrU0HZ0RER5k4EBcPp04vLTp78s+xoXp7oErBq4wxAREWW8GzfkxOyDB+Wxubnscu/bF0iwbxAREWlB//5A797ApUtf9qq4cEFujDdmjDw+dAioVClNzTKxICKijBMSAowfLz+c4uLk6k59+8qkIuFSgkREpD2//go4OgKLFwPr18uyMmXk3Ioff5THvXsDffqkqVkmFkRElH4REXK37N9+k5O0AaB1a2DmTLlsIRERZQ8xMcD06XLX7U6dkq9naJjmptM8xyImRs69e/o09bo//SRXhiIiolwqLk7+2lWmjPwFLCxMdqufPCk3PGJSQUSUveTLB8yaJb/UZ3TTmsQyezbg7Z163WXLNAkp74mNBf75B3jxArC1lZshcpNwyit4/udg/v7A0KHA5cvyuFgxuXRshw6ADtcGSQ3PfcrLeP5rWePGwIkTGb4qn0ZDoRo1ypRY8qS//pL7QiXsAbK3BxYskKMIiHIznv851J07wIgRwJ498tjUVE72GzgwzSuI5FU89ykv4/mfDTRrBowaBVy7Bri5AQUKqF7/3XcaNavRBnnLlwOTJslhWRkYS7aRVRuo/PUX8MMPiff7iN/RfPt2vsAo9+L5nwO9fi3f/Jcvl13ourpAr17AxIlA4cLaji7H4LlPeZk2z39ukJdASr3KCoXsUtKARolFJsWSbWTFiRcbK3t8kpurolAARYrIFRvZNUi5TWws4OwMPHuW9PU8/7OZyEjkX74I+WdPg+L9ewBATLPmiJ4yC6JsOS0Hl7Pw3Ke8TJ3z394eePQoc85/Tb/fLVmyBLNnz0ZwcDAqVqyIRYsWoXr16snW37ZtG8aNG4fHjx+jVKlSmDlzJr799lvl9UIITJgwAatWrUJoaChq166NZcuWoVSpUso606ZNw759+xAQEAA9PT2EhoYmuh9FfDaWwKZNm9ChQwe1H1uGE5RIUFCQACCCgoIy7T6OHxdC5uu88MILL9n1EifaY5N4CAdl4WVUEg1xLBvExgsvvOTWy/HjmfPdS5Pvd5s3bxZ6enpizZo14saNG6JHjx7C3NxchISEJFn/1KlTQldXV8yaNUvcvHlT/PrrryJ//vzi2rVryjq//fabMDMzE7t27RJXr14V3333nXB0dBSfPn1S1hk/fryYO3euGDJkiDAzM0vyvgAIX19f8eLFC+UlYRtq0+Q2yUB6G8jAWLKNrEgsNm7U/guXF1544SW5iztOiTOooSwIQhHhDT+hQKzWY+OFF15y92Xjxsz57hX//e7mzZvi/fv3yktkZGSyt6levbro27ev8jg2NlbY2dmJGTNmJFm/Xbt2wsvLS6WsRo0aolevXkIIIeLi4oSNjY2YPXu28vrQ0FChr68vNm3alKg9X1/fFBOLnTt3Jht7imJihJg8WQg7OyF0dYV48ECW//qrEKtXa9amEEKjyduxsXL52+XL5V5Id+8CJUrI/Y8cHIBu3TKsQyXXsrVVr97+/UC9epkbC1FWO3kSSNArnCye/1lP8fAB9MaPQr5d2wEAokABfB48EgUHDMVSIyMs1XJ8OR3PfcrL1D3/1f2OpClnZ2eV4wkTJmDixImJ6kVHR+PSpUsYPXq0skxHRwceHh44c+ZMkm2fOXMGQ4YMUSnz9PTErl27AACPHj1CcHAwPDw8lNebmZmhRo0aOHPmTJqHMfXt2xfdu3dHiRIl0Lt3b/j4+CQ5RCqRadOAtWvlsrM9enwpd3EB5s/X+Mu8RolFJsWSp9StK8cRPnsm8/OvxY8zbNqU42wp92nalOd/tvPuHTB1KrBoEfD5s5xM17UrFJMnQ8/WFnraji+X4LlPeZm653/dupkbx82bN1GkSBHlsb6+fpL1Xr9+jdjYWFhbW6uUW1tb4/bt20neJjg4OMn6wcHByuvjy5Kro67JkyejUaNGMDIywuHDh/HLL78gLCwMAwYMSP3G69YBK1fKZWd79/5SXrEikMxjU4dGC43Hx9Kpk+obXzpjyVN0deWyasCXlRDixR/Pn88PFsqdeP5nI9HR8skuWRKYO1cmFU2bAgEBwKpVmf/TYR7Dc5/ysuxy/puYmMDU1FR5SS6xyO7GjRuH2rVro3Llyhg5ciRGjBiB2bNnq3fjZ8+S3sA0Lk5+DmhIo8Qik2LJc1q3lsuqJUiaAchsncsNUm7H81/LhJDrPpYvDwweLHssypcHDhwADh0CXF21HWGuxXOf8rKcdP5bWlpCV1cXISEhKuUhISGwsbFJ8jY2NjYp1o//Ny1tqqtGjRp4+vQpoqKiUq/s7Cx3KPza9u1A5coax6DRUKj4WIoXz9BY8qTWrYGWLbn7JOVNPP+15MIFuWN2/IeKtTUwZQrg4wPk0+hjgdKI5z7lZTnl/NfT04ObmxuOHTuGVq1aAQDi4uJw7Ngx9OvXL8nbuLu749ixYxg0aJCy7MiRI3B3dwcAODo6wsbGBseOHUOlSpUAAB8+fMC5c+fQp0+fdMUbEBCAggULqtcDM3480Lmz7C2Ii5M/NN25I4cl7d2rcQwafYJkUix5lq4u0KCBtqMg0g6e/1noyRO5Q/bGjfLY0FAmGCNGACYm2o0tD+K5T3lZTjn/hwwZgs6dO6Nq1aqoXr065s+fj/DwcPj4+AAAvL29UaRIEcyYMQMAMHDgQNSvXx9z5syBl5cXNm/ejIsXL2LlypUA5N4TgwYNwtSpU1GqVCk4Ojpi3LhxsLOzUyYvABAYGIi3b98iMDAQsbGxCAgIAAA4OTnB2NgY//vf/xASEoKaNWvCwMAAR44cwfTp0zFs2DD1HljLlsD//gdMnix3uh4/HqhSRZY1aaL5E6bpclInTwrh4SFE4cJCGBoKUbu2EIcOabw6VbaSFcvNEhFlmdBQIUaOFEJfX67lqFAI4e0tBN/jiCgP0fT73aJFi0SxYsWEnp6eqF69ujh79qzyuvr164vOnTur1N+6dasoXbq00NPTE+XLlxf79u1TuT4uLk6MGzdOWFtbC319fdG4cWNx584dlTqdO3cWABJdjv//Jh8HDhwQlSpVEsbGxqJAgQKiYsWKYvny5SI2NjZNjy2jabTzdm7HLd+JKFeIiZErbUycCLx6JcsaNADmzJG/TBER5SH8fpeE6Gjg5Us5BCmhYsU0ai5dg2kvXgRu3ZJ/OzsDbm7paY2IiDKEEMC+fcDw4V+W6itTBpg9G2jePPFyLERElLfcuwd07QqcPq1aLoT8jIiN1ahZjRKLp0+Bjh2BU6cAc3NZFhoK1KoFbN4sZ/YTEZEWXLkCDBsG/P23PLa0lD0WPXsC+fNrNTQiIsomunSRi3Xs3Stnz2fQD04aJRbdu8tlZW/dkj+CAXLyto+PvO7gwQyJjYiI1PXsGTB2rFxFQwhAXx8YOFBO1jYz03Z0RESUnQQEAJcuAWXLZmizGiUWJ07InpP4pAKQfy9alPm7JRIRUQJhYcCsWcDvvwOfPsmyDh2AGTMABwethkZERNmUszPw+nWGN6vRBnlFiya9EV5sLGBnl96QiIgoVbGxwOrVQKlScg+KT5+A2rWBs2eBTZuYVBARUfJmzpRLjfv7A2/eAB8+qF40pFGPxezZQP/+wJIlQNWqsuziRdnr/vvvGsdCRETqOHRIzqO4fl0elywpPyRat+bEbCIiSp2Hh/y3cWPVcm1M3u7SBYiIAGrU+LJJa0yM/LtrV3mJ9/atRnEREdHXrl+XCcWhQ/K4YEFg3Digb19AT0+7sRERUc5x/HimNKtRYjF/fgZHQUREyQsOlrui/vGHXGs8f36ZTIwbB1hYaDs6IiLKaerXz5RmNUosOndWr95vv8llaOOXpCUiojSIiADmzpXDnMLCZFmbNvLN1clJu7EREVHO9s8/wIoVwMOHwLZtQJEiwPr1gKMjUKeORk1qNHlbXdOncygUEVGaxcUBa9cCpUvLXomwMKB6dfkhsH07kwoiIkqfHTsAT0/A0BC4fBmIipLl79/LL/AaytTEQojMbJ2IKBc6flyuitGli9ybonhxYONG4MwZjX9BIiIiUjF1KrB8ObBqlermqbVry0RDQxoNhSIiogx2+7Zc+u9//5PHpqZyc7uBAwEDA+3GRkREucudO0C9eonLzczkPAYNZWqPBRERpeLVK6BfP8DFRSYVurpyYvb9+8DIkUwqiIgo49nYyM+Zr/37L1CihMbNsseCiEgbIiOBhQuBadO+bEbUooXcRbtsWe3GRkREuVuPHrJHfM0auW/F8+dyyO2wYXJun4aYWBARZSUhgC1bgFGjgCdPZFnlynJ30UaNtBsbERHlDaNGyYVCGjeWKxDWqwfo68vEon9/jZvN1MSibl052ZyIiACcOgUMGQKcPy+PixSRPRY//wzocGQqERFlEYUCGDsWGD5cDokKCwOcnQFjY9V6T58CdnZqf0Zp9El2+TJw7dqX4927gVat5DzD6Ogv5fv3A7a2mtwDEVEu8uAB8MMPclWn8+eBAgWAKVOAu3flxkBMKoiISBv09GRCUb164qQCkNc9fqx2cxp9mvXqJT8PAbmnRocOgJGR3FtjxAhNWiQiyoXevpU9FOXKyTXDdXTkuNb794Fff5VvnERERNlVGveO0CixuHsXqFRJ/r1tmxyWtXEj4OcnPzuJiPK06Ghg/ny5kd28ecDnz3IjooAAYOVKuRoHERFRLqPRHAsh5HwPADh6FGjeXP5dtCjw+nVGhUZElMMIAfz1l1wm9sEDWebiIidme3pqNzYiIqJMplGPRdWqcsO+9euBEycALy9Z/ugRYG2dkeEREeUQ58/L7tsffpBJhY2N3NE0IIBJBRER5Qka9VjMnw906gTs2iUnlDs5yfLt24FatTIuOCKibO/JE2D0aGDTJnlsaCiX6xsxIumJcERERDmFQpGm6holFhUqqK4KFW/2bLlpLBFRrvf+PTBjhvylJSpKvvl6e8vuXHt7bUdHRESUfmmcvJ2ufSwuXgRu3ZJ/lysnh0gREeVqnz/LCdgTJ36ZVNawITBnjtzojoiIKLe4eVPuY6EmjRKLp0+Bjh3lXk/m5rIsNFQOg9q8mT/WEVEuJASwd6/cTOjOHVlWpozsqm3ePM3dxURERFmqdWv16/71l/y3aNE03YVGk7e7d5c/2t26JZdpf/tW/h0XJ68jIspVrlwBGjcGvvtOJhWWlsCSJXJMaIsWTCqIiCj7MzNT/6IhjXosTpwATp+WP9bFK1MGWLQIqFtX41iIiLKXp0/lRnbr1skeC319YNAgOVk7HW+8REREWc7XN9PvQqPEomhR2WPxtdjYNA3DIiLKnj5+BGbNkvMmPn2SZR07AtOnAw4OWg2NiIgou9IosZg9G+jfX44EiJ+wffEiMHCg3AeKiChHio0F1qwBxo0DQkJkWe3awNy5QPXq2o2NiIgoI23fDmzdCgQGAtHRqtddvqxRkxrNsejSRe75VKOGHBmgry//vnwZ6NoVsLD4ciEiyhEOHQIqVQJ69pRJRcmSwI4dwD//MKkgIqLcZeFCwMdH7mx95Yr8nCtUCHj4EGjWTONmNd4gj4goV7h2Ta70dOiQPC5YEBg/HvjlF0BPT7uxERERZYalS+XS6R07An5+clPXEiXk59/btxo3q1Fi0bmzxvdHRJQ9BAfLIU9r1sgl7fLnB/r1k5O12d1KRES5WWCg3CcCAAwN5dxCAPj5Z6BmTWDxYo2a1XiDvNhYYNeuLxvklS8vV2LkzttElK1FRMhJ2TNnAuHhsqxNG3lcsqR2YyMiIsoKNjayZ6J4caBYMeDsWaBiReDRozTvtp2QRonF/fvAt98Cz559WXJ2xgy5WtS+ffxsJqJsKC4OWL8eGDtWvnkBcnLYnDlygjYREVFe0agRsGcPULmynGsxeLCczH3xYto20vuKRonFgAEyeTh79suIgTdvgJ9+ktft26dxPEREGe/vv4GhQ+WqE4D8hea334D27bm5HRER5T0rV8of3ACgb185cfv0aTn8qFcvjZvVeIO8hEkFIOP57Tf+8EdE2cjt23Ji9t698tjUVPZYDBgAGBhoNzYiIiJtefpUDjWK16GDvAgBBAXJ4VEa0Gi5WX39L3M8EgoL4yIqRJQNvHolf4FxcZFJha6uPL5/X658waSCiIjyMkdH+Vn5tbdv5XUa0iixaN5cLvV+7pxMbISQPRi9e8seFHWdPHkSLVq0gJ2dHRQKBXbt2pXqbfz9/VGlShXo6+vDyckJfn5+KtfPmDED1apVg4mJCaysrNCqVSvcuXMnbQ+QiHKmyEg5CdvJSS6lFxsr35Ru3JArXBQurO0IiYiItE+IpIcCh4Wl68c3jYZCLVwol5x1d5crNAJATIz8/F6wQP12wsPDUbFiRXTt2hWt1Zgo8ujRI3h5eaF3797YsGEDjh07hu7du8PW1haenp4AgBMnTqBv376oVq0aYmJiMGbMGDRt2hQ3b95EgQIFNHm4RJTdxcUBmzcDo0fLJfQAoEoV4PffgYYNtRsbERFRdjFkiPxXoZBLrhsZfbkuNlb2GlSqpHHzCiE0X1Pq3j05hBkAypWTPxJqHIhCgZ07d6JVq1bJ1hk5ciT27duH69evK8s6dOiA0NBQHDx4MMnbvHr1ClZWVjhx4gTq1aunVixPnz5F0aJFERQUBHt7+zQ9DiLKYv/+K98oL1yQx0WKANOny9UkdDTqlCUiolyI3+/w5ce2EydkD0HCOQx6eoCDAzBsGFCqlEbNa7yPBSDvU8P71ciZM2fg4eGhUubp6YlBgwYle5v3798DACxS2PAqKioKUVFRyuOPSU0gIaLs5f59YORI4K+/5HGBAsCoUTLJSPgLDBEREUnHj8t/fXzkMCNT0wxtXu3EIr7nRB1z52oSSuqCg4NhbW2tUmZtbY0PHz7g06dPMDQ0VLkuLi4OgwYNQu3ateHi4pJsuzNmzMCkSZMyJWYiymBv3wJTpgBLlgCfP8teie7dgUmT5IY/RERElDJf3y9/P30q/82AXhy1EwtfX7nASr58clhWcgOostOS8H379sX169fx77//plhv9OjRGJIgc3r27BmcnZ0zOzwiSouoKJlMTJkChIbKsm++AWbPlm9OREREpJ64OGDqVLlJbFiYLDMxkXs+jR2r8VBitROL9++BHTsAKyugRAk5nLlQIY3uU2M2NjYICQlRKQsJCYGpqWmi3op+/fph7969OHnyZKrj6PT19aGvr688/vDhQ8YFTUTpI4R88xk5Enj4UJa5usqJ2U2bajc2IiKinGjsWOCPP1Q3ofv3X2DiRLnC4rRpGjWrdmJRsCDw6JFMLB4//rJZX1Zyd3fH/v37VcqOHDkCd3d35bEQAv3798fOnTvh7+8Px3SsxUtEmSgwEHj9OvnrLS2BFy/kryenTskyGxvZY+HjI/emICIiorRbuxZYvVp1n4gKFeQCKL/8kvmJRZs2QL16gJ2dHO5UtWryn+vxPyqmJiwsDPfv31ceP3r0CAEBAbCwsECxYsUwevRoPHv2DOvWrQMA9O7dG4sXL8aIESPQtWtX/P3339i6dSv27dunbKNv377YuHEjdu/eDRMTEwQHBwMAzMzMEvVqEJGWBAYCZcrIX0WSo6Pz5RcMQ0O5g/bw4YCxcdbESERElFu9fQuULZu4vGxZeZ2G1E4sVq4EWreWC7EMGAD06CGHYqXHxYsX0TDBGvPx8xw6d+4MPz8/vHjxAoHxa9IDcHR0xL59+zB48GAsWLAA9vb2WL16tXIPCwBYtmwZAKBBgwYq9+Xr64suXbqkL2AiyhivX6ecVABfkoouXeQ40CJFMj0sIiKiPKFiRblx7MKFquWLF8vrNKTRPhY+PjKO9CYW2RXXOSbKZJcvA25uqdfbsAH48cfMj4eIiHI9fr9L4MQJwMsLKFZM7mcBAGfOAEFBwP79QN26GjWr0ZRvX9/cm1QQUTaSVDctERERpY+jI3D3LvD993KlxdBQOTTpzh2geHGNm03XBnlERERERJTDODrKBVK+nqT95g1QtCgQG6tRs5otUktEpKnYWGDrVm1HQURElHclNxMiLAwwMNC4WfZYEFHWuXIF6N0bOH9e25EQERHlPfEbQisUwPjxgJHRl+tiY4Fz54BKlTRunokFEWW+jx/lG9jChXK1JyMjICJC21ERERHlLVeuyH+FAK5dA/T0vlynpydXhBo2TOPmmVgQUeYRAti5U65R/eyZLGvfXm56V69eykvOGhjITfKIiIgoYxw/Lv/18QEWLABMTTO0eSYWRJQ5Hj8G+vcH9u6VxyVKAEuWAN98I4/v3El95+1ixTI9TCIiojzH1zdTmmViQUQZ6/NnYN48YNIkOdwpf35gxAhg7Fi5g3a8YsWYOBAREeUiTCyIKOOcOiUnZ1+/Lo/r1QOWLwfKldNuXERERJTpuNwsEaXf27dAjx5AnToyqShUCPDzA/z9mVQQERHlEeyxICLNCQH8+aecjP3qlSzr2hWYNUsmF0RERJRnMLEgIs3cuQP06fNlhQlnZznsqW5d7cZFREREWsGhUESUNp8+yT0pKlSQSYWhITBjhlwbm0kFERFRnsUeCyJS35EjspfiwQN53KyZXELW0VG7cREREZHWsceCiFIXHAz8+CPQtKlMKuzsgG3bgH37mFQQERERACYWRJSS2Fhg6VKgbFlg0yZAR0fuon3rFvDDD4BCoe0IiYiIKJvgUCgiStqVK3JPivPn5XHVqnJytpubduMiIiKibIk9FkSk6uNHYMgQmUicPw+YmACLFgFnzzKpICIiomSxx4KIJCGAXbvkUKenT2VZu3bAvHlyTgURERFRCphYEBHw5AnQvz/wv//JY0dHObfim2+0GxcRERHlGBwKRZSXff4MzJ4tN7f73/+A/PmBMWOA69eZVBAREVGasMeCKK86fVpOzr52TR7XqwcsWyaTDCIiIqI0Yo8FUV7z9i3QsydQu7ZMKgoVAnx9AX9/JhVERESkMSYWRHmFEMD69XJPilWrZFnXrsDt20CXLtyTgoiIKAlLliyBg4MDDAwMUKNGDZyPX4Y9Gdu2bUPZsmVhYGAAV1dX7N+/X+V6IQTGjx8PW1tbGBoawsPDA/fu3VOpM23aNNSqVQtGRkYwNzdP8n4CAwPh5eUFIyMjWFlZYfjw4YiJiUnXY00vJhZEecGdO0DjxoC3N/DqleyZOHEC+OMPwNJS29ERERFlS1u2bMGQIUMwYcIEXL58GRUrVoSnpydevnyZZP3Tp0+jY8eO6NatG65cuYJWrVqhVatWuH79urLOrFmzsHDhQixfvhznzp1DgQIF4OnpicjISGWd6OhotG3bFn369EnyfmJjY+Hl5YXo6GicPn0aa9euhZ+fH8aPH5+xT0BaCUokKChIABBBQUHaDoUofT59EmL8eCH09IQAhDAwEGL6dCGiorQdGRERUZbS5Ptd9erVRd++fZXHsbGxws7OTsyYMSPJ+u3atRNeXl4qZTVq1BC9evUSQggRFxcnbGxsxOzZs5XXh4aGCn19fbFp06ZE7fn6+gozM7NE5fv37xc6OjoiODhYWbZs2TJhamoqorT4Gc8eC6Lc6sgRwNUVmDwZiI4GmjUDbtwARo8G9PS0HR0REZFWfPz4ER8+fFBeoqKikqwXHR2NS5cuwcPDQ1mmo6MDDw8PnDlzJsnbnDlzRqU+AHh6eirrP3r0CMHBwSp1zMzMUKNGjWTbTO5+XF1dYW1trXI/Hz58wI0bN9RuJ6MxsSDKbYKDgR9/BJo2Be7fl5vbbdsG7NsHlCih7eiIiIi0ytnZGWZmZsrLjBkzkqz3+vVrxMbGqnx5BwBra2sEBwcneZvg4OAU68f/m5Y203I/Ce9DG7jcLFFuERcHrFgheyTevwd0dIB+/YApUwBTU21HR0RElC3cvHkTRYoUUR7r6+trMZrchT0WRLlBQABQqxbwyy8yqXBzA86fBxYsYFJBRESUgImJCUxNTZWX5BILS0tL6OrqIiQkRKU8JCQENjY2Sd7GxsYmxfrx/6alzbTcT8L70AYmFkQ5WVgYMHQoULUqcO4cYGICLFok/3Zz03Z0REREOZaenh7c3Nxw7NgxZVlcXByOHTsGd3f3JG/j7u6uUh8Ajhw5oqzv6OgIGxsblTofPnzAuXPnkm0zufu5du2ayupUR44cgampKZy1uCcVh0IR5VS7dgH9+wNPn8rjtm2B+fPlnAoiIiJKtyFDhqBz586oWrUqqlevjvnz5yM8PBw+Pj4AAG9vbxQpUkQ5T2PgwIGoX78+5syZAy8vL2zevBkXL17EypUrAQAKhQKDBg3C1KlTUapUKTg6OmLcuHGws7NDq1atlPcbGBiIt2/fIjAwELGxsQgICAAAODk5wdjYGE2bNoWzszN+/vlnzJo1C8HBwfj111/Rt29frQ7tYmJBlNM8eQIMGADs2SOPHR2BJUvkqk9ERESUYdq3b49Xr15h/PjxCA4ORqVKlXDw4EHlROnAwEDo6HwZAFSrVi1s3LgRv/76K8aMGYNSpUph165dcHFxUdYZMWIEwsPD0bNnT4SGhqJOnTo4ePAgDAwMlHXGjx+PtWvXKo8rV64MADh+/DgaNGgAXV1d7N27F3369IG7uzsKFCiAzp07Y/LkyZn9lKRIIYQQWo0gG3r69CmKFi2KoKAg2NvbazscIunzZ9kjMXEiEBEB5M8PDB8OjB0LGBlpOzoiIqJsjd/vMh97LIhygtOngd69gWvX5HHdusDy5XIHbSIiIqJsgJO3ibKzt2+BXr2A2rVlUlGoELBmDXDiBJMKIiIiylbYY0GUHQkBbNgADBkCvHoly3x8gFmzAEtL7cZGRERElAQmFkTZzZ07cj+Kv/+Wx+XKyWFP9eppNy4iIiKiFHAoFFF2ERkJTJgAVKggkwoDA2D6dLn5HZMKIiIiyubYY0GUHRw9Knsp7t2Tx998I5eQLVFCu3ERERERqYk9FkTaFBICdOoENGkikwpbW2DrVmD/fiYVRERElKMwsSDShrg4OW+iTBlg40ZAR0fuon37ttxBW6HQdoREREREacKhUERZ7epVuYTsuXPy2M1NJhlVq2o3LiIiIqJ0YI8FUVYJCwOGDZOJxLlzgIkJsHCh/JtJBREREeVw7LEgygq7dsmhTk+fyuO2bYF584AiRbQaFhEREVFGYWJBlJmePAEGDAD27JHHjo7A4sXAt99qNy4iIiKiDMahUESZ4fNn4PffAWdnmVTkyweMHg1cv86kgoiIiHIl9lgQZbQzZ4DevYH//pPHdesCy5YB5ctrNy4iIiKiTMQeC6KM8u6dXO2pVi2ZVBQqBKxZA5w4waSCiIiIcj32WBCllxByL4ohQ4CXL2VZly7A7NmApaVWQyMiIiLKKkwsiNLj7l3gl1+AY8fkcblycthT/frajYuIiIgoi3EoFJEmIiOBiRMBV1eZVBgYANOmAQEBTCqIiIgoT2KPBVFaHT0qeynu3ZPH33wDLFkClCih3biIiIiItIg9FkTqCgkBfvoJaNJEJhW2tsDWrcD+/UwqiIiIKM9jYkGUmrg4YMUKoGxZYMMGQKGQu2jfuiV30FYotB0hERERkdZxKBRRSq5elXtSnD0rj6tUkUlG1arajYuIiIgom2GPBVFSwsKAYcMANzeZVJiYAAsWAOfPM6kgIiIiSgJ7LIi+tnu3HOoUFCSPf/gBmD8fKFJEq2ERERERZWda7bE4efIkWrRoATs7OygUCuzatSvV2/j7+6NKlSrQ19eHk5MT/Pz8EtVZsmQJHBwcYGBggBo1auD8+fMZHzzlPoGBQKtW8hIUBDg4APv2Adu2MakgIiIiSoVWE4vw8HBUrFgRS5YsUav+o0eP4OXlhYYNGyIgIACDBg1C9+7dcejQIWWdLVu2YMiQIZgwYQIuX76MihUrwtPTEy/jd0Qm+trnz8Dvv8vN7XbvBvLlA0aPBm7cAL79VtvREREREeUICiGE0HYQAKBQKLBz5060atUq2TojR47Evn37cP36dWVZhw4dEBoaioMHDwIAatSogWrVqmHx4sUAgLi4OBQtWhT9+/fHqFGjkmw3KioKUVFRyuNnz57B2dkZQUFBsLe3z4BHR9nW2bNAr17Af//J4zp1gOXLgfLltRsXERERZainT5+iaNGi/H6XiXLU5O0zZ87Aw8NDpczT0xNnzpwBAERHR+PSpUsqdXR0dODh4aGsk5QZM2bAzMxMeXF2ds6cB0DZx7t3crWnWrVkUmFhAfzxB3DiBJMKIiIiIg3kqMQiODgY1tbWKmXW1tb48OEDPn36hNevXyM2NjbJOsHBwcm2O3r0aLx//155uXnzZqbET9mAEHIvirJl5bKxQgBdugB37gBduwI6OeolQURERJRtcFUoAPr6+tDX11cef/jwQYvRUKa5exf45Rfg2DF5XK4csGwZUL++duMiIiIiygVyVGJhY2ODkJAQlbKQkBCYmprC0NAQurq60NXVTbKOjY1NVoZK2UlkJDBzJjB9OhAdDRgYAOPGyX0q9PS0HR0RERFRrpCjxn24u7vjWPyvzf/vyJEjcHd3BwDo6enBzc1NpU5cXByOHTumrEN5zLFjQMWKwMSJMqnw9ASuXwfGjGFSQURERJSBtJpYhIWFISAgAAEBAQDkcrIBAQEIDAwEIOc+eHt7K+v37t0bDx8+xIgRI3D79m0sXboUW7duxeDBg5V1hgwZglWrVmHt2rW4desW+vTpg/DwcPj4+GTpYyMtCwkBfvoJ8PCQQ6BsbIAtW4ADB4CSJbUdHREREVGuo9WhUBcvXkTDhg2Vx0OGDAEAdO7cGX5+fnjx4oUyyQAAR0dH7Nu3D4MHD8aCBQtgb2+P1atXw9PTU1mnffv2ePXqFcaPH4/g4GBUqlQJBw8eTDShm3KpuDhg1Spg1CggNBRQKIC+fYGpUwEzM21HR0RERJRrZZt9LLITrnOcQ/33n9yT4uxZeVylilz5qWpV7cZFREREWsfvd5kvR82xIEpSeDgwfLhMJM6eBUxMgAULgHPnmFQQERERZZEctSoUUSJ79gD9+wPxQ+batJFJRZEi2o2LiIiIKI9hYkE5U1CQTCh275bHDg7A4sWAl5dWwyIiIiLKqzgUinKWmBhg7ly5ud3u3UC+fHKi9o0bTCqIiIiItIg9FpRznD0L9O4NXL0qj+vUAZYvB8qX125cRERERMQeC8oB3r0D+vQBatWSSYWFBfDHH8CJE0wqiIiIiLIJ9lhQ9iUEsGkTMHgw8PKlLOvSBZg1CyhcWKuhEREREZEqJhaUPd27B/zyC3D0qDwuW1YOe6pfX7txEREREVGSOBSKspeoKGDSJMDVVSYVBgZy1+yrV5lUEBEREWVj7LGg7OPvv+Vcirt35bGnJ7BkCVCypHbjIiIiIqJUsceCtO/lS+Dnn4HGjWVSYWMDbNkCHDjApIKIiIgoh2BiQdoTFwesXAmUKQP8+SegUAD9+gG3bwPt2sljIiIiIsoROBSKtOO//+SeFGfOyOPKlYEVK4Bq1bQbFxERERFphD0WlLXCw4ERI4AqVWRSYWwMzJ8PnD/PpIKIiIgoB2OPBWWd//1PDnUKDJTHbdoACxYARYpoNy4iIiIiSjcmFpT5goKAAQOAXbvksYMDsHgx4OWlzaiIiIiIKANxKBRlnpgYYO5coFw5mVTkyweMHAncuMGkgoiIiCiXYY8FZY5z54BeveTGdgBQu7bcOdvFRbtxEREREVGmYI8FZazQUOCXXwB3d5lUWFgAq1cDJ0/+X3t3HhbFkf8P/D2Aw6AIaEAORVFUQEW5BFGzEGRlPQhEk3gl4LFqFDewRg1JvI0xiSLi8VVyqTHeu9E16qJIBA0SVAQXEfFETBYxXqB4AvX7Y370OjDcx8D4fj3PPKarq3s+VVOa+XR1TTOpICIiItJinLGg+iEEsGMH8Pe/A3l5yrLgYGD5csDMTLOxEREREVGDY2JBdXf5snKWIjZWuW1vD6xfD3h7azQsIiIiImo8vBWKau/pU2DxYuUtTrGxgEIBfPopkJbGpIKIiIjoJcMZC6qdo0eVT86+eFG5PXgw8H//B9jaajYuIiIiItIIzlhQzdy6BQQFAT4+yqTCwkK5tiImhkkFERER0UuMiQVVT0kJ8PXXyvUTW7YAMhkQEgJcuACMGqXcJiIiIqKXFm+FoqqlpytvezpxQrnt7AxERwN9+2o2LiIiIiJqMjhjQRUrLATmzFEmEidOAIaGwKpVwMmTTCqIiIiISAVnLEi9n34CZswAcnKU2yNHKpOKDh00GhYRERERNU1MLEjVjRtAaCiwZ49yu1MnYN06YNgwzcZFRERERE0ab4UipaIiIDIS6NFDmVTo6QEffghkZDCpICIiIqIqccaClGsmpk5VPtgOAAYMUD4529FRo2ERERERUfPBGYuX2f37wPTpQL9+yqSiTRvlT8oeO8akgoiIiIhqhDMWLyMhgJ07gb//Hbh5U1kWHAwsXw6YmWk2NiIiIiJqlphYvGwuX1bOUsTGKrft7IANGwBvb42GRURERETNG2+Felk8fQosWQL06qVMKvT1ldtnzzKpICIiIqI644zFy+DoUWDaNCArS7k9eLDyJ2S7dtVsXERERESkNThjoc1u3VKunfDxUSYVFhbAjh1ATAyTCiIiIqJqWLduHWxsbKBQKODh4YGTJ09WWn/37t2wt7eHQqGAo6MjDh48qLJfCIH58+fD0tISBgYG8PX1xaVLl1Tq3L17F+PGjYORkRFMTEwwadIkPHz4UNqfnZ0NmUxW7vXrr7/WX8NrgYmFNiopUf66k7098P33gEymXFeRmQmMGqXcJiIiIqJK7dy5EzNnzsSCBQtw5swZ9OnTB35+frh165ba+idOnMCYMWMwadIkpKamIjAwEIGBgTh37pxU58svv8Tq1auxYcMGJCcno1WrVvDz88OTJ0+kOuPGjUNGRgZiY2Oxf/9+HDt2DFOmTCn3fkeOHEFubq70cnV1rf9OqAGZEEJoNIIm6LfffoO1tTVu3LiBDh06aDqcmklPB957DzhxQrnt5ARERwPu7hoNi4iIiEiTavP9zsPDA3379sXatWsBACUlJbC2tsbf/vY3hIeHl6s/atQoFBYWYv/+/VJZv3794OTkhA0bNkAIASsrK3zwwQeYNWsWACA/Px/m5ubYtGkTRo8ejczMTPTo0QOnTp2Cm5sbACAmJgZDhw7Fb7/9BisrK2RnZ6Nz585ITU2Fk5NTHXum/nDGQlsUFiqflO3iokwqDA2VT9I+dYpJBREREdH/9+DBAxQUFEivp0+fqq337NkzpKSkwNfXVyrT0dGBr68vkpKS1B6TlJSkUh8A/Pz8pPrXrl3DzZs3VeoYGxvDw8NDqpOUlAQTExMpqQAAX19f6OjoIDk5WeXcr7/+Otq1a4eBAwdi3759NeiFhsHEQhvs3w/07Al8+SVQVASMGKG87SksDNDj+nwiIiKiUj169ICxsbH0WrZsmdp6t2/fRnFxMczNzVXKzc3NcbP0OWBl3Lx5s9L6pX9WVaddu3Yq+/X09NC2bVupjqGhISIiIrB7924cOHAAAwcORGBgoMaTC37rbM5++w0IDQV+/FG53akTsHYtMHy4ZuMiIiIiaqLOnz+P9u3bS9v6+voajKZ2TE1NMXPmTGm7b9+++O9//4vly5fj9ddf11hcnLFojoqKgFWrAAcHZVKhp6e8DSojg0kFERERUSVat24NIyMj6VVRYmFqagpdXV3k5eWplOfl5cHCwkLtMRYWFpXWL/2zqjplF4cXFRXh7t27Fb4voFwPcvny5Qr3NwYmFs3NyZPKNRN//zvw8CHQvz9w5gzw+edAq1aajo6IiIhIK8jlcri6uiIuLk4qKykpQVxcHDw9PdUe4+npqVIfAGJjY6X6nTt3hoWFhUqdgoICJCcnS3U8PT1x//59pKSkSHV+/vlnlJSUwMPDo8J409LSYGlpWfOG1iPeCtVc5OcDH38MrF8PCAG0aaNcUzFxIqDD/JCIiIiovs2cORPBwcFwc3ODu7s7Vq1ahcLCQkyYMAEAEBQUhPbt20vrNEJDQ+Hl5YWIiAgMGzYMO3bswOnTp/HVV18BAGQyGcLCwvDpp5+iW7du6Ny5M+bNmwcrKysEBgYCABwcHPCXv/wFkydPxoYNG/D8+XPMmDEDo0ePhpWVFQBg8+bNkMvlcHZ2BgD8+OOP+O677/DNN980cg+pYmLR1AkB7NypnKEoXSgUFASsWAGYmWk2NiIiIiItNmrUKPzxxx+YP38+bt68CScnJ8TExEiLr3NycqDzwgXe/v37Y9u2bZg7dy4+/vhjdOvWDXv37kWvXr2kOnPmzEFhYSGmTJmC+/fvY+DAgYiJiYFCoZDqbN26FTNmzMCgQYOgo6ODkSNHYvXq1SqxLVmyBNevX4eenh7s7e2xc+dOvPnmmw3cI5XjcyzUaLTnWOTkALdvV7z/4UNg6VLg8GHltp2dcsbitdcaLiYiIiIiLdSsn1PWTHDGQlNycpSJwgtPWayQvj7wySfAnDnK/yYiIiIiamKYWGjK7dvVSyo8PIAffgC6dm34mIiIiIiIaomrfpu6deuYVBARERFRk8fEoqmTyTQdARERERFRlZhYEBERERFRnTGxICIiIiKiOmNiQUREREREdcbEgoiIiIiI6oyJhaaYmgIvPGFRLYVCWY+IiIiIqInjcyw0pWNHICur8idvm5oq6xERERERNXFNYsZi3bp1sLGxgUKhgIeHB06ePFlh3efPn2Px4sWwtbWFQqFAnz59EBMTo1KnuLgY8+bNQ+fOnWFgYABbW1ssWbIEQoiGbkrNdOwIuLhU/GJSQURERETNhMYTi507d2LmzJlYsGABzpw5gz59+sDPzw+3bt1SW3/u3LmIjo7GmjVrcP78ebz33nt44403kJqaKtX54osvsH79eqxduxaZmZn44osv8OWXX2LNmjWN1SwiIiIiopeKTGj4Mr6Hhwf69u2LtWvXAgBKSkpgbW2Nv/3tbwgPDy9X38rKCp988glCQkKkspEjR8LAwAA//PADAGD48OEwNzfHt99+W2Gdyvz222+wtrbGjRs30KFDh7o2kYiIiIg0jN/vGp5GZyyePXuGlJQU+Pr6SmU6Ojrw9fVFUlKS2mOePn0KRZlFzwYGBvjll1+k7f79+yMuLg4XL14EAJw9exa//PILhgwZUuE5CwoKpNeDBw/q2jQiIiIiopeKRhdv3759G8XFxTA3N1cpNzc3x4ULF9Qe4+fnh5UrV+JPf/oTbG1tERcXhx9//BHFxcVSnfDwcBQUFMDe3h66urooLi7G0qVLMW7cOLXnXLZsGRYtWlR/DSMiIiIieslofI1FTUVFRaFbt26wt7eHXC7HjBkzMGHCBOjo/K8pu3btwtatW7Ft2zacOXMGmzdvxooVK7B582a15/zoo4+Qn58vvc6fP99YzSEiIiIi0goanbEwNTWFrq4u8vLyVMrz8vJgYWGh9hgzMzPs3bsXT548wZ07d2BlZYXw8HB06dJFqjN79myEh4dj9OjRAABHR0dcv34dy5YtQ3BwcLlz6uvrQ19fX9ouKCioj+YREREREb00NDpjIZfL4erqiri4OKmspKQEcXFx8PT0rPRYhUKB9u3bo6ioCP/85z8REBAg7Xv06JHKDAYA6OrqoqSkpH4bQEREREREAJrAA/JmzpyJ4OBguLm5wd3dHatWrUJhYSEmTJgAAAgKCkL79u2xbNkyAEBycjJ+//13ODk54ffff8fChQtRUlKCOXPmSOf09/fH0qVL0bFjR/Ts2ROpqalYuXIlJk6cqJE2EhERERFpO40nFqNGjcIff/yB+fPn4+bNm3ByckJMTIy0oDsnJ0dl9uHJkyeYO3curl69CkNDQwwdOhRbtmyBiYmJVGfNmjWYN28epk+fjlu3bsHKygpTp07F/PnzG7t5REREREQvBY0/x6Ip4u8cExEREWkXfr9reBqfsWiKStdi5ObmajgSIiIiIqoPpd/ruOa24TCxUKP0V6rc3d01HAkRERER1ae8vDx07NhR02FoJd4KpUZRURFSU1Nhbm5e7telGsqDBw/Qo0cPnD9/Hq1bt26U96T/Yf9rFvtfc9j3msX+1yz2v2Y1dv+XlJQgLy8Pzs7O0NPjtfWGwMSiiSgoKICxsTHy8/NhZGSk6XBeOux/zWL/aw77XrPY/5rF/tcs9r/2aXZP3iYiIiIioqaHiQUREREREdUZE4smQl9fHwsWLIC+vr6mQ3kpsf81i/2vOex7zWL/axb7X7PY/9qHayyIiIiIiKjOOGNBRERERER1xsSCiIiIiIjqjIkFERERERHVGRMLIiIiIiKqMyYWjeTYsWPw9/eHlZUVZDIZ9u7dW+Ux8fHxcHFxgb6+Prp27YpNmzY1eJzaqKZ9Hx8fD5lMVu518+bNxglYyyxbtgx9+/ZF69at0a5dOwQGBiIrK6vK43bv3g17e3soFAo4Ojri4MGDjRCtdqlN32/atKnc2FcoFI0UsXZZv349evfuDSMjIxgZGcHT0xP//ve/Kz2G477+1LT/OfYbzueffw6ZTIawsLBK63H8N39MLBpJYWEh+vTpg3Xr1lWr/rVr1zBs2DC89tprSEtLQ1hYGP7617/i0KFDDRyp9qlp35fKyspCbm6u9GrXrl0DRajdEhISEBISgl9//RWxsbF4/vw5Bg8ejMLCwgqPOXHiBMaMGYNJkyYhNTUVgYGBCAwMxLlz5xox8uavNn0PAEZGRipj//r1640UsXbp0KEDPv/8c6SkpOD06dPw8fFBQEAAMjIy1NbnuK9fNe1/gGO/IZw6dQrR0dHo3bt3pfU4/rWEoEYHQOzZs6fSOnPmzBE9e/ZUKRs1apTw8/NrwMi0X3X6/ujRowKAuHfvXqPE9LK5deuWACASEhIqrPP222+LYcOGqZR5eHiIqVOnNnR4Wq06fb9x40ZhbGzceEG9ZNq0aSO++eYbtfs47hteZf3PsV//Hjx4ILp16yZiY2OFl5eXCA0NrbAux7924IxFE5WUlARfX1+VMj8/PyQlJWkoopePk5MTLC0t8ec//xmJiYmaDkdr5OfnAwDatm1bYR2O/4ZRnb4HgIcPH6JTp06wtrau8govVU9xcTF27NiBwsJCeHp6qq3Dcd9wqtP/AMd+fQsJCcGwYcPKjWt1OP61g56mAyD1bt68CXNzc5Uyc3NzFBQU4PHjxzAwMNBQZNrP0tISGzZsgJubG54+fYpvvvkG3t7eSE5OhouLi6bDa9ZKSkoQFhaGAQMGoFevXhXWq2j8c51L7VW37+3s7PDdd9+hd+/eyM/Px4oVK9C/f39kZGSgQ4cOjRixdkhPT4enpyeePHkCQ0ND7NmzBz169FBbl+O+/tWk/zn269eOHTtw5swZnDp1qlr1Of61AxMLojLs7OxgZ2cnbffv3x9XrlxBZGQktmzZosHImr+QkBCcO3cOv/zyi6ZDeelUt+89PT1Vruj2798fDg4OiI6OxpIlSxo6TK1jZ2eHtLQ05Ofn4x//+AeCg4ORkJBQ4Zdbql816X+O/fpz48YNhIaGIjY2lgvgXzJMLJooCwsL5OXlqZTl5eXByMiIsxUa4O7uzi/DdTRjxgzs378fx44dq/LqX0Xj38LCoiFD1Fo16fuyWrRoAWdnZ1y+fLmBotNucrkcXbt2BQC4urri1KlTiIqKQnR0dLm6HPf1ryb9XxbHfu2lpKTg1q1bKrP8xcXFOHbsGNauXYunT59CV1dX5RiOf+3ANRZNlKenJ+Li4lTKYmNjK703lBpOWloaLC0tNR1GsySEwIwZM7Bnzx78/PPP6Ny5c5XHcPzXj9r0fVnFxcVIT0/n+K8nJSUlePr0qdp9HPcNr7L+L4tjv/YGDRqE9PR0pKWlSS83NzeMGzcOaWlp5ZIKgONfa2h69fjL4sGDByI1NVWkpqYKAGLlypUiNTVVXL9+XQghRHh4uHj33Xel+levXhUtW7YUs2fPFpmZmWLdunVCV1dXxMTEaKoJzVZN+z4yMlLs3btXXLp0SaSnp4vQ0FCho6Mjjhw5oqkmNGvTpk0TxsbGIj4+XuTm5kqvR48eSXXeffddER4eLm0nJiYKPT09sWLFCpGZmSkWLFggWrRoIdLT0zXRhGarNn2/aNEicejQIXHlyhWRkpIiRo8eLRQKhcjIyNBEE5q18PBwkZCQIK5duyb+85//iPDwcCGTycThw4eFEBz3Da2m/c+x37DK/ioUx792YmLRSEp/wrTsKzg4WAghRHBwsPDy8ip3jJOTk5DL5aJLly5i48aNjR63Nqhp33/xxRfC1tZWKBQK0bZtW+Ht7S1+/vlnzQSvBdT1PQCV8ezl5SV9HqV27dolunfvLuRyuejZs6c4cOBA4wauBWrT92FhYaJjx45CLpcLc3NzMXToUHHmzJnGD14LTJw4UXTq1EnI5XJhZmYmBg0aJH2pFYLjvqHVtP859htW2cSC4187yYQQovHmR4iIiIiISBtxjQUREREREdUZEwsiIiIiIqozJhZERERERFRnTCyIiIiIiKjOmFgQEREREVGdMbEgIiIiIqI6Y2JBRERERER1xsSCiIiIiIjqjIkFEVEztnDhQpibm0Mmk2Hv3r0YP348AgMDNR1WpeLj4yGTyXD//v0Gf687d+6gXbt2yM7OrvYxTbEPvb29ERYW1qDv0RDt3rBhA/z9/ev1nETUdDGxICJqpjIzM7Fo0SJER0cjNzcXQ4YMQVRUFDZt2qTp0CTqvhD3798fubm5MDY2bvD3X7p0KQICAmBjY1PrczTGl3ptNXHiRJw5cwbHjx/XdChE1Aj0NB0AEb0cnj17BrlcrukwtMqVK1cAAAEBAZDJZAAAfX39Rnnv58+fo0WLFrU6Vi6Xw8LCop4jKu/Ro0f49ttvcejQoQZ/r+p4Gf8OyOVyjB07FqtXr8arr76q6XCIqIFxxoKoCfP29sb777+POXPmoG3btrCwsMDChQul/dnZ2ZDJZEhLS5PK7t+/D5lMhvj4eAD/u+3k0KFDcHZ2hoGBAXx8fHDr1i38+9//hoODA4yMjDB27Fg8evSo2nHNmDEDM2bMgLGxMUxNTTFv3jwIIaQ6NjY2WLJkCYKCgmBkZIQpU6YAAP75z3+iZ8+e0NfXh42NDSIiIlTO/fTpU3z44YewtraGvr4+unbtim+//Vbaf+7cOQwZMgSGhoYwNzfHu+++i9u3b0v7//GPf8DR0REGBgZ45ZVX4Ovri8LCQqkv3N3d0apVK5iYmGDAgAG4fv26dOy//vUvuLi4QKFQoEuXLli0aBGKiooAAEIILFy4EB07doS+vj6srKzw/vvvV9pPP/30E/r27QuFQgFTU1O88cYb0r579+4hKCgIbdq0QcuWLTFkyBBcunRJ2r9p0yaYmJjg0KFDcHBwgKGhIf7yl78gNzcXgPIWqNJbTHR0dKTEouztLA8ePMC4cePQqlUrWFpaIjIystwV+NLbqF5kYmIizXyUjrOdO3fCy8sLCoUCW7duxZ07dzBmzBi0b98eLVu2hKOjI7Zv3y6dY/z48UhISEBUVBRkMhlkMhmys7PV3gpV1biwsbHBZ599hokTJ6J169bo2LEjvvrqq0r7/+DBg9DX10e/fv2ksuLiYkyaNAmdO3eGgYEB7OzsEBUVVeE5KmoDUPVYLP17EhYWBlNTU/j5+VXruMLCQgQFBcHQ0BCWlpbl+qKsixcvQiaT4cKFCyrlkZGRsLW1rVW7AWWfr1q1SqXMyclJ5d+g+/fv469//SvMzMxgZGQEHx8fnD17VuUYf39/7Nu3D48fP670/Yio+WNiQdTEbd68Ga1atUJycjK+/PJLLF68GLGxsTU+z8KFC7F27VqcOHECN27cwNtvv41Vq1Zh27ZtOHDgAA4fPow1a9bUKC49PT2cPHkSUVFRWLlyJb755huVOitWrECfPn2QmpqKefPmISUlBW+//TZGjx6N9PR0LFy4EPPmzVO5dScoKAjbt2/H6tWrkZmZiejoaBgaGgJQfonx8fGBs7MzTp8+jZiYGOTl5eHtt98GAOTm5mLMmDGYOHEiMjMzER8fjxEjRkAIgaKiIgQGBsLLywv/+c9/kJSUhClTpkhfyI8fP46goCCEhobi/PnziI6OxqZNm7B06VIAyi++kZGRiI6OxqVLl7B37144OjpW2D8HDhzAG2+8gaFDhyI1NRVxcXFwd3eX9o8fPx6nT5/Gvn37kJSUBCEEhg4diufPn0t1Hj16hBUrVmDLli04duwYcnJyMGvWLADArFmzsHHjRqndpQlHWTNnzkRiYiL27duH2NhYHD9+HGfOnKnWZ1xWeHg4QkNDkZmZCT8/Pzx58gSurq44cOAAzp07hylTpuDdd9/FyZMnAQBRUVHw9PTE5MmTpRitra3Lnbc64wIAIiIi4ObmhtTUVEyfPh3Tpk1DVlZWhfEeP34crq6uKmUlJSXo0KEDdu/ejfPnz2P+/Pn4+OOPsWvXLrXnqKgNVY3FUps3b4ZcLkdiYiI2bNhQreNmz56NhIQE/Otf/8Lhw4cRHx9f6WfWvXt3uLm5YevWrSrlW7duxdixY2vV7up66623pIsUKSkpcHFxwaBBg3D37l2pjpubG4qKipCcnFyn9yKiZkAQUZPl5eUlBg4cqFLWt29f8eGHHwohhLh27ZoAIFJTU6X99+7dEwDE0aNHhRBCHD16VAAQR44ckeosW7ZMABBXrlyRyqZOnSr8/PyqHZeDg4MoKSmRyj788EPh4OAgbXfq1EkEBgaqHDd27Fjx5z//WaVs9uzZokePHkIIIbKysgQAERsbq/Z9lyxZIgYPHqxSduPGDQFAZGVliZSUFAFAZGdnlzv2zp07AoCIj49Xe+5BgwaJzz77TKVsy5YtwtLSUgghREREhOjevbt49uyZ2uPL8vT0FOPGjVO77+LFiwKASExMlMpu374tDAwMxK5du4QQQmzcuFEAEJcvX5bqrFu3Tpibm0vbe/bsEWX/GQ8ODhYBAQFCCCEKCgpEixYtxO7du6X99+/fFy1bthShoaFSGQCxZ88elfMYGxuLjRs3CiH+N85WrVpVZbuHDRsmPvjgA2nby8tL5b2E+N+YvHfvnhCi6nEhhHI8vfPOO9J2SUmJaNeunVi/fn2FsQQEBIiJEydWGXNISIgYOXKktP1iH1bUhqrGYulxzs7ONTruwYMHQi6XS+NACOXYNTAwKBfDiyIjI4Wtra20Xfp3KTMzs9bt7tSpk4iMjFQ5pk+fPmLBggVCCCGOHz8ujIyMxJMnT1Tq2NraiujoaJWyNm3aiE2bNlUYCxFpB85YEDVxvXv3Vtm2tLTErVu36nQec3NztGzZEl26dFEpq8l5+/XrJ13tBwBPT09cunQJxcXFUpmbm5vKMZmZmRgwYIBK2YABA6Tj0tLSoKurCy8vL7XvefbsWRw9ehSGhobSy97eHoByvUGfPn0waNAgODo64q233sLXX3+Ne/fuAQDatm2L8ePHw8/PD/7+/oiKilK5yn/27FksXrxY5dylV6kfPXqEt956C48fP0aXLl0wefJk7NmzR7pNSp20tDQMGjRI7b7MzEzo6enBw8NDKnvllVdgZ2eHzMxMqaxly5bSrSxAzT/7q1ev4vnz5yozJcbGxrCzs6v2OV5U9vMsLi7GkiVL4OjoiLZt28LQ0BCHDh1CTk5Ojc5b1bgo9eIYlslksLCwqLQ/Hj9+DIVCUa583bp1cHV1hZmZGQwNDfHVV1/VOOaqxmKpsjMmVR135coVPHv2TGVstG3btsrPbPTo0cjOzsavv/4KQDlb4eLiIp27vtpdti0PHz7EK6+8otKea9euqfQBABgYGFT7Vksiar64eJuoiSu7QFYmk6GkpASA8t56ACprG168laai88hkskrPW19atWpVo/oGBgaV7n/48CH8/f3xxRdflNtnaWkJXV1dxMbG4sSJE9KtXZ988gmSk5PRuXNnbNy4Ee+//z5iYmKwc+dOzJ07F7GxsejXrx8ePnyIRYsWYcSIEeXOrVAoYG1tjaysLBw5cgSxsbGYPn06li9fjoSEBLWLmKtqS3Wo+4xe/Kzri7rzqhtHZT/P5cuXIyoqCqtWrYKjoyNatWqFsLAwPHv2rN5jBCr/u6COqamplFiW2rFjB2bNmoWIiAh4enqidevWWL58eY1v06lqLJYq22dVHXf58uUaxVHKwsICPj4+2LZtG/r164dt27Zh2rRp0v7atFtHR6fScfHw4UNYWlpK67leZGJiorJ99+5dmJmZ1aptRNR8cMaCqBkr/R/1i1feX1zI3ZDKfiH59ddf0a1bN+jq6lZ4jIODAxITE1XKEhMT0b17d+jq6sLR0RElJSVISEhQe7yLiwsyMjJgY2ODrl27qrxKv8DJZDIMGDAAixYtQmpqKuRyOfbs2SOdw9nZGR999BFOnDiBXr16Ydu2bdK5s7Kyyp23a9euUgJnYGAAf39/rF69GvHx8UhKSkJ6erraWHv37o24uLgK+6HsPed37txBVlYWevToUWH/1VSXLl3QokULnDp1SirLz8/HxYsXVeqZmZmpjKFLly5V6+pyYmIiAgIC8M4776BPnz7o0qVLuXPL5XKVWQd1qhoXteXs7Izz58+XO2///v0xffp0ODs7o2vXruWurpelrg3VGYvqVHWcra0tWrRooTI27t27V65f1Rk3bhx27tyJpKQkXL16FaNHj65Tu8uOi4KCAly7dk2lLTdv3oSenl65tpiamkr1rly5gidPnsDZ2bnKNhBR88bEgqgZMzAwQL9+/fD5558jMzMTCQkJmDt3bqO8d05ODmbOnImsrCxs374da9asQWhoaKXHfPDBB4iLi8OSJUtw8eJFbN68GWvXrpUWJNvY2CA4OBgTJ07E3r17ce3aNcTHx0sLTENCQnD37l2MGTMGp06dwpUrV3Do0CFMmDABxcXFSE5OxmeffYbTp08jJycHP/74I/744w84ODjg2rVr+Oijj5CUlITr16/j8OHDuHTpEhwcHAAA8+fPx/fff49FixYhIyMDmZmZ2LFjh9SfmzZtwrfffotz587h6tWr+OGHH2BgYIBOnTqpbeuCBQuwfft2LFiwAJmZmUhPT5euUnfr1g0BAQGYPHkyfvnlF5w9exbvvPMO2rdvj4CAgHr5fACgdevWCA4OxuzZs3H06FFkZGRg0qRJKr8iBQA+Pj5Yu3YtUlNTcfr0abz33nvV+inZbt26STNEmZmZmDp1KvLy8lTq2NjYIDk5GdnZ2bh9+7baGYaqxkVt+fn5ISMjQ2XWolu3bjh9+jQOHTqEixcvYt68eSqJlzrq2lDVWKxIVccZGhpi0qRJmD17Nn7++WecO3cO48ePl5LbyowYMQIPHjzAtGnT8Nprr8HKyqpO7fbx8cGWLVtw/PhxpKenIzg4WCXR8/X1haenJwIDA3H48GFkZ2fjxIkT+OSTT3D69Gmp3vHjx9GlSxeV2/qISDsxsSBq5r777jsUFRXB1dUVYWFh+PTTTxvlfYOCgvD48WO4u7sjJCQEoaGh0k/KVsTFxQW7du3Cjh070KtXL8yfPx+LFy/G+PHjpTrr16/Hm2++ienTp8Pe3h6TJ0+Wfi7WysoKiYmJKC4uxuDBg+Ho6IiwsDCYmJhAR0cHRkZGOHbsGIYOHYru3btj7ty5iIiIwJAhQ9CyZUtcuHABI0eORPfu3TFlyhSEhIRg6tSpAJRfQvfv34/Dhw+jb9++6NevHyIjI6XEwcTEBF9//TUGDBiA3r1748iRI/jpp5/wyiuvqG2rt7c3du/ejX379sHJyQk+Pj7SryUBwMaNG+Hq6orhw4fD09MTQggcPHiw1s+GqMjKlSvh6emJ4cOHw9fXFwMGDICDg4PK2oOIiAhYW1vj1VdfxdixYzFr1iy0bNmyynPPnTsXLi4u8PPzg7e3NywsLMo9uXnWrFnQ1dVFjx49YGZmpvae/uqMi9pwdHSUzl1q6tSpGDFiBEaNGgUPDw/cuXMH06dPr/Q86tpQ1VisSHWOW758OV599VX4+/vD19cXAwcOLLdWQ53WrVvD398fZ8+exbhx41T21abdH330Eby8vDB8+HAMGzYMgYGBKsmBTCbDwYMH8ac//QkTJkxA9+7dMXr0aFy/fh3m5uZSve3bt2Py5MlVxk9EzZ9MNMQNu0Sk1by9veHk5FTuN+6p6SssLET79u0RERGBSZMmaTqcBnfgwAHMnj0b586dq9ZVf6pfGRkZ8PHxwcWLFxvlSetEpFlcvE1EpMVSU1Nx4cIFuLu7Iz8/H4sXLwaAer3lqikbNmwYLl26hN9//13tMzSoYeXm5uL7779nUkH0kmBiQUQqcnJyKl1AXHYxLDV9K1asQFZWFuRyOVxdXXH8+HGVxbXa7sWnjFPj8vX11XQIRNSIeCsUEakoKipCdnZ2hfttbGygp8drEkRERKSKiQUREREREdUZV7IREREREVGdMbEgIiIiIqI6Y2JBRERERER1xsSCiIiIiIjqjIkFERERERHVGRMLIiIiIiKqMyYWRERERERUZ/8PFC6KkBcfqHMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_altered_value(config_name, family):\n",
    "    \"\"\"\n",
    "    Given a config name and a family, extract the altered value.\n",
    "    For each family, a different rule is applied:\n",
    "    \n",
    "    - num_processes: extract the integer after \"num_processes_\"\n",
    "    - batching: extract the integer after \"batching_\"\n",
    "    - precis: extract the precision setting; if quant4 is True, return \"load_in_4bit=True\",\n",
    "              otherwise return the float precision (e.g., \"float32\" or \"float16\")\n",
    "    - decoding: extract the decoder_temperature (as a float) from the config name.\n",
    "    - latency: if the config is exactly \"latency_False\", return \"No latency\"; otherwise, \n",
    "               extract and join all numeric values in the config string.\n",
    "    \"\"\"\n",
    "    if family == \"num_processes\":\n",
    "        m = re.search(r'num_processes_(\\d+)', config_name)\n",
    "        return int(m.group(1)) if m else config_name\n",
    "    \n",
    "    elif family == \"batching\":\n",
    "        m = re.search(r'batching_(\\d+)', config_name)\n",
    "        return int(m.group(1)) if m else config_name\n",
    "    \n",
    "    elif family == \"precis\":\n",
    "        m = re.search(r'precis_(float\\d+)', config_name)\n",
    "        precision = m.group(1) if m else None\n",
    "        # If quant4 is True, we assume load_in_4bit is the relevant setting. COME BACK TO THIS!!!\n",
    "        if \"quant4_True\" in config_name:\n",
    "            return \"load_in_4bit=True\"\n",
    "        else:\n",
    "            return precision\n",
    "        \n",
    "    elif family == \"decoding\":\n",
    "        # This family might have several variants. We extract the decoder_temperature. COME BACK TO\n",
    "        m = re.search(r'decoder_temperature_([\\d\\.]+)', config_name)\n",
    "        return float(m.group(1)) if m else config_name\n",
    "    \n",
    "    elif family == \"latency\":\n",
    "        # If it's simply \"latency_False\", nothing was altered.\n",
    "        if config_name == \"latency_False\":\n",
    "            return \"No latency\"\n",
    "        else:\n",
    "            # Find all numbers (either integer or float) in the string.\n",
    "            numbers = re.findall(r'\\d+\\.\\d+|\\d+', config_name)\n",
    "            return \", \".join(numbers)\n",
    "    else:\n",
    "        return config_name\n",
    "\n",
    "def plot_family(df, family, metric1, metric2):\n",
    "    \"\"\"\n",
    "    For a given family, subset the DataFrame (rows whose config_name starts with family).\n",
    "    Create a new column that holds the altered value for that family, sort the data by that value,\n",
    "    and plot two metrics against this altered value.\n",
    "    \n",
    "    Parameters:\n",
    "      - df: a DataFrame with a \"config_name\" column.\n",
    "      - family: the family string (e.g. \"num_processes\", \"batching\", etc).\n",
    "      - metric1: name of the first metric column to plot on the left Y axis (e.g., \"flops_per_token\").\n",
    "      - metric2: name of the second metric column to plot on the right Y axis (e.g., \"total_energy_kwh\").\n",
    "    \"\"\"\n",
    "    # Subset rows where config_name starts with the family string.\n",
    "    df_family = df[df['config_name'].str.startswith(family)].copy()\n",
    "    \n",
    "    # Apply the parser to create an \"altered_value\" column.\n",
    "    df_family['altered_value'] = df_family['config_name'].apply(lambda x: extract_altered_value(x, family))\n",
    "    \n",
    "    # Attempt to sort by altered_value.\n",
    "    # If the values are numeric, convert them.\n",
    "    try:\n",
    "        df_family['altered_value'] = pd.to_numeric(df_family['altered_value'])\n",
    "    except:\n",
    "        pass  # leave as string if conversion fails\n",
    "    \n",
    "    df_family.sort_values('altered_value', inplace=True)\n",
    "    \n",
    "    # Create a plot with twin y-axes.\n",
    "    fig, ax1 = plt.subplots(figsize=(8,5))\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # Plot metric1 on ax1 and metric2 on ax2.\n",
    "    ax1.plot(df_family['altered_value'], df_family[metric1], marker='o', label=metric1, color='blue')\n",
    "    ax2.plot(df_family['altered_value'], df_family[metric2], marker='s', label=metric2, color='red')\n",
    "    \n",
    "    ax1.set_xlabel(f'{family} configuration (altered value)')\n",
    "    ax1.set_ylabel(metric1, color='blue')\n",
    "    ax2.set_ylabel(metric2, color='red')\n",
    "    plt.title(f'{family}: {metric1} and {metric2} vs altered setting')\n",
    "    \n",
    "    # Combine the legends.\n",
    "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='best')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "families = [\"num_processes\", \"batching\", \"precis\", \"decoding\", \"latency\"]\n",
    "\n",
    "for fam in families:\n",
    "    plot_family(df_controlled_dropped, fam, metric1=\"flops_per_token\", metric2=\"energy_per_token_kwh\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

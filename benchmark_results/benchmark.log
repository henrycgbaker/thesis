[RANK-PROCESS-0][[36m2025-03-04 15:31:54,031[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Setting torch.distributed cuda device to 0[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:55,271[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Initializing torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:55,297[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Setting torch.distributed cuda device to 0[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:55,315[0m][[34mdatasets[0m][[32mINFO[0m] - PyTorch version 2.5.1 available.[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:55,366[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Initializing torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:55,407[0m][[34mdatasets[0m][[32mINFO[0m] - PyTorch version 2.5.1 available.[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:55,896[0m][[34mpytorch[0m][[32mINFO[0m] - Allocating pytorch backend[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:55,896[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Seeding backend with 42[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:55,898[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Benchmarking a Transformers model[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:55,968[0m][[34mpytorch[0m][[32mINFO[0m] - Allocating pytorch backend[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:55,968[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Seeding backend with 42[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:55,970[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Benchmarking a Transformers model[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,309[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Setting torch.distributed cuda device to 0[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,365[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Initializing torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,405[0m][[34mdatasets[0m][[32mINFO[0m] - PyTorch version 2.5.1 available.[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,955[0m][[34minference[0m][[32mINFO[0m] - Allocating inference scenario[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,956[0m][[34minference[0m][[32mINFO[0m] - 	+ Updating Text Generation kwargs with default values[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,956[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Text Generation report[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,956[0m][[34mpytorch[0m][[32mINFO[0m] - Allocating pytorch backend[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,956[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,957[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,957[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Seeding backend with 42[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,957[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Per-Token Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,957[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,957[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Memory tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,957[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking RAM memory of process 3008856[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,957[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking GPU memory of devices [0][0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,957[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking Allocated/Reserved memory of 1 Pytorch CUDA devices[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,957[0m][[34minference[0m][[32mINFO[0m] - 	+ Generating inputs for task text-generation[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,957[0m][[34mtorchrun[0m][[31mERROR[0m] - 	+ Benchmark failed with an exception[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,959[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Benchmarking a Transformers model[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,961[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Destroying torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:56,976[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting rank process[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,074[0m][[34minference[0m][[32mINFO[0m] - Allocating inference scenario[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,074[0m][[34minference[0m][[32mINFO[0m] - 	+ Updating Text Generation kwargs with default values[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,074[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Text Generation report[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,075[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,075[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,075[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Per-Token Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,075[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,075[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Memory tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,075[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking RAM memory of process 3008785[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,075[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking GPU memory of devices [0][0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,076[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking Allocated/Reserved memory of 1 Pytorch CUDA devices[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,076[0m][[34minference[0m][[32mINFO[0m] - 	+ Generating inputs for task text-generation[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,076[0m][[34mtorchrun[0m][[31mERROR[0m] - 	+ Benchmark failed with an exception[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,080[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Destroying torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,092[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting rank process[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,513[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Setting torch.distributed cuda device to 0[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,583[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Initializing torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,624[0m][[34mdatasets[0m][[32mINFO[0m] - PyTorch version 2.5.1 available.[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,940[0m][[34minference[0m][[32mINFO[0m] - Allocating inference scenario[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,940[0m][[34minference[0m][[32mINFO[0m] - 	+ Updating Text Generation kwargs with default values[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,940[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Text Generation report[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,941[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,941[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,941[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Per-Token Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,941[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,941[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Memory tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,941[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking RAM memory of process 3008995[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,941[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking GPU memory of devices [0][0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,941[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking Allocated/Reserved memory of 1 Pytorch CUDA devices[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,941[0m][[34minference[0m][[32mINFO[0m] - 	+ Generating inputs for task text-generation[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,942[0m][[34mtorchrun[0m][[31mERROR[0m] - 	+ Benchmark failed with an exception[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,945[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Destroying torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:57,963[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting rank process[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:58,177[0m][[34mpytorch[0m][[32mINFO[0m] - Allocating pytorch backend[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:58,177[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Seeding backend with 42[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:58,179[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Benchmarking a Transformers model[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:59,200[0m][[34minference[0m][[32mINFO[0m] - Allocating inference scenario[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:59,200[0m][[34minference[0m][[32mINFO[0m] - 	+ Updating Text Generation kwargs with default values[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:59,200[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Text Generation report[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:59,201[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:59,201[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:59,201[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Per-Token Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:59,201[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:59,201[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Memory tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:59,201[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking RAM memory of process 3009151[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:59,201[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking GPU memory of devices [0][0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:59,201[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking Allocated/Reserved memory of 1 Pytorch CUDA devices[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:59,202[0m][[34minference[0m][[32mINFO[0m] - 	+ Generating inputs for task text-generation[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:59,202[0m][[34mtorchrun[0m][[31mERROR[0m] - 	+ Benchmark failed with an exception[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:59,205[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Destroying torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-04 15:31:59,221[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting rank process[0m
[ISOLATED-PROCESS][[36m2025-03-04 15:32:19,350[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Sending outputs to main process[0m
[ISOLATED-PROCESS][[36m2025-03-04 15:32:19,350[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting isolated process[0m
[ISOLATED-PROCESS][[36m2025-03-04 15:32:19,970[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Sending outputs to main process[0m
[ISOLATED-PROCESS][[36m2025-03-04 15:32:19,971[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting isolated process[0m
[ISOLATED-PROCESS][[36m2025-03-04 15:32:20,562[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Sending outputs to main process[0m
[ISOLATED-PROCESS][[36m2025-03-04 15:32:20,562[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting isolated process[0m
[ISOLATED-PROCESS][[36m2025-03-04 15:32:21,861[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Sending outputs to main process[0m
[ISOLATED-PROCESS][[36m2025-03-04 15:32:21,862[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting isolated process[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:01,684[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Setting torch.distributed cuda device to 0[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:02,224[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Initializing torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:02,266[0m][[34mdatasets[0m][[32mINFO[0m] - PyTorch version 2.5.1 available.[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:02,821[0m][[34mpytorch[0m][[32mINFO[0m] - Allocating pytorch backend[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:02,821[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Seeding backend with 42[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:02,823[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Benchmarking a Transformers model[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:02,971[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Setting torch.distributed cuda device to 0[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:03,088[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Initializing torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:03,129[0m][[34mdatasets[0m][[32mINFO[0m] - PyTorch version 2.5.1 available.[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:03,723[0m][[34mpytorch[0m][[32mINFO[0m] - Allocating pytorch backend[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:03,724[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Seeding backend with 42[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:03,726[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Benchmarking a Transformers model[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:03,840[0m][[34minference[0m][[32mINFO[0m] - Allocating inference scenario[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:03,840[0m][[34minference[0m][[32mINFO[0m] - 	+ Updating Text Generation kwargs with default values[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:03,840[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Text Generation report[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:03,841[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:03,841[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:03,841[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Per-Token Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:03,841[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:03,841[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Memory tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:03,841[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking RAM memory of process 3012327[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:03,841[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking GPU memory of devices [0][0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:03,842[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking Allocated/Reserved memory of 1 Pytorch CUDA devices[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:03,842[0m][[34minference[0m][[32mINFO[0m] - 	+ Generating inputs for task text-generation[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:03,873[0m][[34minference[0m][[32mINFO[0m] - 	+ Running model loading tracking[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:04,083[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Setting torch.distributed cuda device to 0[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:04,154[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Initializing torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:04,189[0m][[34mdatasets[0m][[32mINFO[0m] - PyTorch version 2.5.1 available.[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:04,753[0m][[34mpytorch[0m][[32mINFO[0m] - Allocating pytorch backend[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:04,754[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Seeding backend with 42[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:04,756[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Benchmarking a Transformers model[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:04,930[0m][[34minference[0m][[32mINFO[0m] - Allocating inference scenario[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:04,931[0m][[34minference[0m][[32mINFO[0m] - 	+ Updating Text Generation kwargs with default values[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:04,931[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Text Generation report[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:04,931[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:04,931[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:04,932[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Per-Token Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:04,932[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:04,932[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Memory tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:04,932[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking RAM memory of process 3012465[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:04,932[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking GPU memory of devices [0][0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:04,932[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking Allocated/Reserved memory of 1 Pytorch CUDA devices[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:04,932[0m][[34minference[0m][[32mINFO[0m] - 	+ Generating inputs for task text-generation[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:04,961[0m][[34minference[0m][[32mINFO[0m] - 	+ Running model loading tracking[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:05,279[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Setting torch.distributed cuda device to 0[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:05,323[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Initializing torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:05,365[0m][[34mdatasets[0m][[32mINFO[0m] - PyTorch version 2.5.1 available.[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:05,792[0m][[34minference[0m][[32mINFO[0m] - Allocating inference scenario[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:05,792[0m][[34minference[0m][[32mINFO[0m] - 	+ Updating Text Generation kwargs with default values[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:05,793[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Text Generation report[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:05,793[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:05,793[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:05,793[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Per-Token Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:05,794[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:05,794[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Memory tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:05,794[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking RAM memory of process 3012603[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:05,794[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking GPU memory of devices [0][0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:05,794[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking Allocated/Reserved memory of 1 Pytorch CUDA devices[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:05,794[0m][[34minference[0m][[32mINFO[0m] - 	+ Generating inputs for task text-generation[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:05,815[0m][[34minference[0m][[32mINFO[0m] - 	+ Running model loading tracking[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:05,919[0m][[34mpytorch[0m][[32mINFO[0m] - Allocating pytorch backend[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:05,919[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Seeding backend with 42[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:05,921[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Benchmarking a Transformers model[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:06,940[0m][[34minference[0m][[32mINFO[0m] - Allocating inference scenario[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:06,940[0m][[34minference[0m][[32mINFO[0m] - 	+ Updating Text Generation kwargs with default values[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:06,941[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Text Generation report[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:06,941[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:06,941[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:06,941[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Per-Token Latency tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:06,942[0m][[34mlatency[0m][[32mINFO[0m] - 		+ Tracking latency using Pytorch CUDA events[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:06,942[0m][[34minference[0m][[32mINFO[0m] - 	+ Initializing Memory tracker[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:06,942[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking RAM memory of process 3012676[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:06,942[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking GPU memory of devices [0][0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:06,942[0m][[34mmemory[0m][[32mINFO[0m] - 		+ Tracking Allocated/Reserved memory of 1 Pytorch CUDA devices[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:06,942[0m][[34minference[0m][[32mINFO[0m] - 	+ Generating inputs for task text-generation[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:06,968[0m][[34minference[0m][[32mINFO[0m] - 	+ Running model loading tracking[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:15,450[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating backend temporary directory[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:15,450[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating no weights model[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:15,450[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating no weights model directory[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:15,451[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating no weights model state dict[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:15,451[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Saving no weights model safetensors[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:15,452[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Saving no weights model pretrained config[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:15,453[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading model with random weights[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:15,453[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading Transformers model using device context manager for fast initialization[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:16,741[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating backend temporary directory[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:16,742[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating no weights model[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:16,742[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating no weights model directory[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:16,743[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating no weights model state dict[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:16,743[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Saving no weights model safetensors[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:16,744[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Saving no weights model pretrained config[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:16,746[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading model with random weights[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:16,746[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading Transformers model using device context manager for fast initialization[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:17,409[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Enabling eval mode[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:17,410[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Cleaning up backend temporary directory[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:17,468[0m][[34minference[0m][[32mINFO[0m] - 	+ Preparing inputs for backend pytorch[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:17,656[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Enabling eval mode[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:17,657[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Cleaning up backend temporary directory[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:17,658[0m][[34minference[0m][[32mINFO[0m] - 	+ Warming up backend for Text Generation[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:17,662[0m][[34minference[0m][[32mINFO[0m] - 	+ Preparing inputs for backend pytorch[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:17,749[0m][[34minference[0m][[32mINFO[0m] - 	+ Warming up backend for Text Generation[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:18,185[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating backend temporary directory[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:18,186[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating no weights model[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:18,186[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating no weights model directory[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:18,186[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating no weights model state dict[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:18,187[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Saving no weights model safetensors[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:18,187[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Saving no weights model pretrained config[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:18,188[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading model with random weights[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:18,188[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading Transformers model using device context manager for fast initialization[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:18,267[0m][[34mtorchrun[0m][[31mERROR[0m] - 	+ Benchmark failed with an exception[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:18,275[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Destroying torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:18,286[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting rank process[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:19,670[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating backend temporary directory[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:19,671[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating no weights model[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:19,671[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating no weights model directory[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:19,672[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Creating no weights model state dict[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:19,673[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Saving no weights model safetensors[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:19,673[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Saving no weights model pretrained config[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:19,675[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading model with random weights[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:19,676[0m][[34mpytorch[0m][[32mINFO[0m] - 	+ Loading Transformers model using device context manager for fast initialization[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:19,722[0m][[34mtorchrun[0m][[31mERROR[0m] - 	+ Benchmark failed with an exception[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:19,732[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Destroying torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:19,748[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting rank process[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:21,139[0m][[34mtorchrun[0m][[31mERROR[0m] - 	+ Benchmark failed with an exception[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:21,147[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Destroying torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:21,166[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting rank process[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:21,566[0m][[34minference[0m][[32mINFO[0m] - 	+ Running Per-Token Text Generation latency tracking[0m
[ISOLATED-PROCESS][[36m2025-03-04 15:35:28,368[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Sending outputs to main process[0m
[ISOLATED-PROCESS][[36m2025-03-04 15:35:28,369[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting isolated process[0m
[ISOLATED-PROCESS][[36m2025-03-04 15:35:29,235[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Sending outputs to main process[0m
[ISOLATED-PROCESS][[36m2025-03-04 15:35:29,235[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting isolated process[0m
[ISOLATED-PROCESS][[36m2025-03-04 15:35:30,405[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Sending outputs to main process[0m
[ISOLATED-PROCESS][[36m2025-03-04 15:35:30,405[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting isolated process[0m
[RANK-PROCESS-0][[36m2025-03-04 15:35:38,591[0m][[34minference[0m][[32mINFO[0m] - 	+ Running Text Generation memory tracking[0m
[RANK-PROCESS-0][[36m2025-03-04 15:36:00,835[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Benchmark completed successfully[0m
[RANK-PROCESS-0][[36m2025-03-04 15:36:00,843[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Destroying torch.distributed process group[0m
[RANK-PROCESS-0][[36m2025-03-04 15:36:00,859[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting rank process[0m
[ISOLATED-PROCESS][[36m2025-03-04 15:36:27,353[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Sending outputs to main process[0m
[ISOLATED-PROCESS][[36m2025-03-04 15:36:27,353[0m][[34mtorchrun[0m][[32mINFO[0m] - 	+ Exiting isolated process[0m

[
    {
        "EXPERIMENT #0001": {
            "experiment_setup": {
                "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
                "task_type": "text_generation",
                "date": "March 04, 2025 at 07:11:46 PM",
                "cpu_count": 128,
                "cpu_model": "AMD EPYC 7742 64-Core Processor",
                "gpu_count": 2,
                "gpu_model": "4 x NVIDIA A100-PCIE-40GB",
                "os": "Linux-5.15.0-113-generic-x86_64-with-glibc2.31",
                "python_version": "3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]",
                "accelerate_config": {
                    "distributed_type": "DistributedType.MULTI_GPU",
                    "num_processes": 2
                },
                "country": "Germany",
                "region": "mecklenburg-vorpommern"
            },
            "experiment_variables": {
                "input_tokens": 2560,
                "output_tokens": 250,
                "number_runs": 5
            },
            "experiment_results": {
                "inference_performance": {
                    "total_inference_time_sec": 2.9046354780439287,
                    "average_latency_ms_per_batch": 2904.6354780439287,
                    "average_ttft_ms": 0.0,
                    "throughput_queries_per_sec": 1.721420551464691,
                    "throughput_tokens_per_sec": 86.07102757323455
                },
                "energy_performance": {
                    "cpu_power": 112.5,
                    "gpu_power": 0.0,
                    "ram_power": 188.8243260383606,
                    "energy_efficiency_tokens_per_joule": 0.17437181807253316,
                    "cpu_energy": 0.00019891567426384428,
                    "gpu_energy": 0.000264675211752774,
                    "ram_energy": 0.00033291941715275514,
                    "total_energy_consumed_kwh": 0.0007965103031693735,
                    "total_energy_consumed_joules": 2867.4370914097444,
                    "final_emissions": 0.00030343059999237283
                },
                "compute_performance": {
                    "gpu": "cuda:0",
                    "flops_forward_pass": "Error: Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: DynamicCache",
                    "cpu_usage_percent": 0.0,
                    "cpu_memory_usage_bytes": 2867941376.0
                },
                "task-specific_performance": {}
            }
        }
    },
    {
        "EXPERIMENT #0002": {
            "experiment_setup": {
                "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
                "task_type": "text_generation",
                "date": "March 04, 2025 at 07:35:00 PM",
                "cpu_count": 128,
                "cpu_model": "AMD EPYC 7742 64-Core Processor",
                "gpu_count": 2,
                "gpu_model": "4 x NVIDIA A100-PCIE-40GB",
                "os": "Linux-5.15.0-113-generic-x86_64-with-glibc2.31",
                "python_version": "3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]",
                "accelerate_config": {
                    "distributed_type": "DistributedType.MULTI_GPU",
                    "num_processes": 2
                },
                "country": "Germany",
                "region": "mecklenburg-vorpommern"
            },
            "experiment_variables": {
                "total_token_inputted": 2560,
                "total_tokens_outputted": 250,
                "number_runs": 5
            },
            "experiment_results": {
                "inference_performance": {
                    "total_inference_time_sec": 3.069109580013901,
                    "average_latency_ms_per_batch": 3069.109580013901,
                    "average_ttft_ms": 0.0,
                    "throughput_queries_per_sec": 1.6291373232080473,
                    "throughput_tokens_per_sec": 81.45686616040237
                },
                "energy_performance": {
                    "cpu_power": 112.5,
                    "gpu_power": 235.83204577308427,
                    "ram_power": 188.8243260383606,
                    "energy_efficiency_tokens_per_joule": 0.15470288405248556,
                    "cpu_energy": 0.0002534404672478558,
                    "gpu_energy": 0.00021988628699887158,
                    "ram_energy": 0.00042445479029182227,
                    "total_energy_consumed_kwh": 0.0008977815445385496,
                    "total_energy_consumed_joules": 3232.013560338779,
                    "final_emissions": 0.0003420098793919605
                },
                "compute_performance": {
                    "gpu": "cuda:0",
                    "flops_forward_pass": "Error: Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: DynamicCache",
                    "cpu_usage_percent": 0.0,
                    "cpu_memory_usage_bytes": 2872322048.0
                },
                "task-specific_performance": {}
            }
        }
    },
    {
        "EXPERIMENT #0003": {
            "experiment_setup": {
                "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
                "task_type": "text_generation",
                "date": "March 04, 2025 at 07:38:29 PM",
                "cpu_count": 128,
                "cpu_model": "AMD EPYC 7742 64-Core Processor",
                "gpu_count": 2,
                "gpu_model": "4 x NVIDIA A100-PCIE-40GB",
                "os": "Linux-5.15.0-113-generic-x86_64-with-glibc2.31",
                "python_version": "3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]",
                "accelerate_config": {
                    "distributed_type": "DistributedType.MULTI_GPU",
                    "num_processes": 2
                },
                "country": "Germany",
                "region": "mecklenburg-vorpommern"
            },
            "experiment_variables": {
                "total_token_inputted": 25600,
                "total_tokens_outputted": 2500,
                "number_runs": 50
            },
            "experiment_results": {
                "inference_performance": {
                    "total_inference_time_sec": 9.075287469662726,
                    "average_latency_ms_per_batch": 1296.4696385232464,
                    "average_ttft_ms": 0.0,
                    "throughput_queries_per_sec": 5.509471823871618,
                    "throughput_tokens_per_sec": 275.4735911935809
                },
                "energy_performance": {
                    "cpu_power": 112.5,
                    "gpu_power": 196.4996529529407,
                    "ram_power": 188.8243260383606,
                    "energy_efficiency_tokens_per_joule": 0.4935331359579749,
                    "cpu_energy": 0.0006421420079132077,
                    "gpu_energy": 0.0010969730997913985,
                    "ram_energy": 0.0010750623629472243,
                    "total_energy_consumed_kwh": 0.00281417747065183,
                    "total_energy_consumed_joules": 10131.038894346588,
                    "final_emissions": 0.0010720609074448147
                },
                "compute_performance": {
                    "gpu": "cuda:0",
                    "flops_forward_pass": "Error: Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: DynamicCache",
                    "cpu_usage_percent": 0.5,
                    "cpu_memory_usage_bytes": 2894456832.0
                },
                "task-specific_performance": {}
            }
        }
    },
    {
        "EXPERIMENT #0004": {
            "experiment_setup": {
                "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
                "task_type": "text_generation",
                "date": "March 04, 2025 at 07:55:37 PM",
                "cpu_count": 128,
                "cpu_model": "AMD EPYC 7742 64-Core Processor",
                "gpu_count": 2,
                "gpu_model": "4 x NVIDIA A100-PCIE-40GB",
                "os": "Linux-5.15.0-113-generic-x86_64-with-glibc2.31",
                "python_version": "3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]",
                "accelerate_config": {
                    "distributed_type": "DistributedType.MULTI_GPU",
                    "num_processes": 2
                },
                "country": "Germany",
                "region": "mecklenburg-vorpommern"
            },
            "experiment_variables": {
                "total_token_inputted": 2560,
                "total_tokens_outputted": 250,
                "number_runs": 5
            },
            "experiment_results": {
                "inference_performance": {
                    "total_inference_time_sec": 2.9997439426369965,
                    "average_latency_ms_per_batch": 2999.7439426369965,
                    "average_ttft_ms": 0.0,
                    "throughput_queries_per_sec": 1.666872669142737,
                    "throughput_tokens_per_sec": 83.34363345713683
                },
                "energy_performance": {
                    "cpu_power": 112.5,
                    "gpu_power": 555.0654377502071,
                    "ram_power": 188.8243260383606,
                    "energy_efficiency_tokens_per_joule": 0.22743924192892567,
                    "cpu_energy": 0.00013839303403801752,
                    "gpu_energy": 0.00024096435945608619,
                    "ram_energy": 0.00023131384432084997,
                    "total_energy_consumed_kwh": 0.0006106712378149536,
                    "total_energy_consumed_joules": 2198.416456133833,
                    "final_emissions": 0.0002326352080456066
                },
                "compute_performance": {
                    "gpu": "cuda:0",
                    "flops_forward_pass": "Error: Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: DynamicCache",
                    "cpu_usage_percent": 0.0,
                    "cpu_memory_usage_bytes": 2869719040.0
                },
                "task-specific_performance": {}
            }
        }
    },
    {
        "EXPERIMENT #0005": {
            "experiment_setup": {
                "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
                "task_type": "text_generation",
                "date": "March 04, 2025 at 08:02:08 PM",
                "cpu_count": 128,
                "cpu_model": "AMD EPYC 7742 64-Core Processor",
                "gpu_count": 2,
                "gpu_model": "4 x NVIDIA A100-PCIE-40GB",
                "os": "Linux-5.15.0-113-generic-x86_64-with-glibc2.31",
                "python_version": "3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]",
                "accelerate_config": {
                    "distributed_type": "DistributedType.MULTI_GPU",
                    "num_processes": 2
                },
                "country": "Germany",
                "region": "mecklenburg-vorpommern"
            },
            "experiment_variables": {
                "total_token_inputted": 2560,
                "total_tokens_outputted": 250,
                "number_runs": 5
            },
            "experiment_results": {
                "inference_performance": {
                    "total_inference_time_sec": 2.7191423317417502,
                    "average_latency_ms_per_batch": 2719.1423317417502,
                    "throughput_queries_per_sec": 1.838846575118427,
                    "throughput_tokens_per_sec": 91.94232875592135
                },
                "energy_performance": {
                    "cpu_power": 112.5,
                    "gpu_power": 213.0940023505005,
                    "ram_power": 188.8243260383606,
                    "energy_efficiency_tokens_per_joule": 0.2395927850907166,
                    "cpu_energy": 0.00013870108078117485,
                    "gpu_energy": 0.00020884322260883437,
                    "ram_energy": 0.0002321461152097701,
                    "total_energy_consumed_kwh": 0.0005796904185997793,
                    "total_energy_consumed_joules": 2086.8855069592055,
                    "final_emissions": 0.00022083306496558595
                },
                "compute_performance": {
                    "gpu": "cuda:0",
                    "flops_forward_pass": "Error: Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: DynamicCache",
                    "cpu_usage_percent": 0.0,
                    "cpu_memory_usage_bytes": 2875822080.0
                },
                "task-specific_performance": {}
            }
        }
    },
    {
        "EXPERIMENT #0006": {
            "experiment_setup": {
                "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
                "task_type": "text_generation",
                "date": "March 04, 2025 at 08:07:31 PM",
                "cpu_count": 128,
                "cpu_model": "AMD EPYC 7742 64-Core Processor",
                "gpu_count": 2,
                "gpu_model": "4 x NVIDIA A100-PCIE-40GB",
                "os": "Linux-5.15.0-113-generic-x86_64-with-glibc2.31",
                "python_version": "3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]",
                "accelerate_config": {
                    "distributed_type": "DistributedType.MULTI_GPU",
                    "num_processes": 2
                },
                "country": "Germany",
                "region": "mecklenburg-vorpommern"
            },
            "experiment_variables": {
                "total_token_inputted": 2560,
                "total_tokens_outputted": 250,
                "number_runs": 5
            },
            "experiment_results": {
                "inference_performance": {
                    "total_inference_time_sec": 2.7960597195196897,
                    "average_latency_ms_per_batch": 2796.0597195196897,
                    "throughput_queries_per_sec": 1.7882384353254623,
                    "throughput_tokens_per_sec": 89.41192176627312
                },
                "energy_performance": {
                    "cpu_power": 112.5,
                    "gpu_power": 224.70957974853113,
                    "ram_power": 188.8243260383606,
                    "energy_efficiency_tokens_per_joule": 0.23969306028875886,
                    "cpu_energy": 0.00013523755414644257,
                    "gpu_energy": 0.0002179215632196474,
                    "ram_energy": 0.00022629229255812113,
                    "total_energy_consumed_kwh": 0.000579451409924211,
                    "total_energy_consumed_joules": 2086.0250757271597,
                    "final_emissions": 0.0002207420146106282
                },
                "compute_performance": {
                    "gpu": "cuda:0",
                    "flops_forward_pass": "Error: Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: DynamicCache",
                    "cpu_usage_percent": 0.0,
                    "cpu_memory_usage_bytes": 2870278144.0,
                    "current_memory_allocated_bytes": 4410810880.0,
                    "max_memory_allocated_bytes": 4410810880.0,
                    "current_memory_reserved_bytes": 6715080704.0,
                    "max_memory_reserved_bytes": 6715080704.0
                },
                "task-specific_performance": {}
            }
        }
    },
    {
        "EXPERIMENT #0007": {
            "experiment_setup": {
                "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
                "task_type": "text_generation",
                "date": "March 04, 2025 at 08:20:19 PM",
                "cpu_count": 128,
                "cpu_model": "AMD EPYC 7742 64-Core Processor",
                "gpu_count": 2,
                "gpu_model": "4 x NVIDIA A100-PCIE-40GB",
                "os": "Linux-5.15.0-113-generic-x86_64-with-glibc2.31",
                "python_version": "3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]",
                "accelerate_config": {
                    "distributed_type": "DistributedType.MULTI_GPU",
                    "num_processes": 2
                },
                "country": "Germany",
                "region": "mecklenburg-vorpommern"
            },
            "experiment_variables": {
                "total_token_inputted": 2560,
                "total_tokens_outputted": 250,
                "number_runs": 5
            },
            "experiment_results": {
                "inference_performance": {
                    "total_inference_time_sec": 2.704952041618526,
                    "average_latency_ms_per_batch": 2704.952041618526,
                    "throughput_queries_per_sec": 1.848461609557605,
                    "throughput_tokens_per_sec": 92.42308047788023
                },
                "energy_performance": {
                    "cpu_power": 112.5,
                    "gpu_power": 233.760442839909,
                    "ram_power": 188.8243260383606,
                    "energy_efficiency_tokens_per_joule": 0.2369246547161872,
                    "cpu_energy": 0.00013856290474359412,
                    "gpu_energy": 0.00021579628376855453,
                    "ram_energy": 0.00023185624590005158,
                    "total_energy_consumed_kwh": 0.0005862154344122003,
                    "total_energy_consumed_joules": 2110.375563883921,
                    "final_emissions": 0.0002233187697393277
                },
                "compute_performance": {
                    "gpu": "cuda:0",
                    "flops_forward_pass": "Error: Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: DynamicCache",
                    "cpu_usage_percent": 0.0,
                    "cpu_memory_usage_bytes": 2870751232.0,
                    "current_memory_allocated_bytes": 4410810880.0,
                    "max_memory_allocated_bytes": 4410810880.0,
                    "current_memory_reserved_bytes": 6715080704.0,
                    "max_memory_reserved_bytes": 6715080704.0
                },
                "task-specific_performance": {}
            }
        }
    },
    {
        "EXPERIMENT #0008": {
            "experiment_setup": {
                "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
                "task_type": "text_generation",
                "date": "March 04, 2025 at 08:21:05 PM",
                "cpu_count": 128,
                "cpu_model": "AMD EPYC 7742 64-Core Processor",
                "gpu_count": 2,
                "gpu_model": "4 x NVIDIA A100-PCIE-40GB",
                "os": "Linux-5.15.0-113-generic-x86_64-with-glibc2.31",
                "python_version": "3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]",
                "accelerate_config": {
                    "distributed_type": "DistributedType.MULTI_GPU",
                    "num_processes": 2
                },
                "country": "Germany",
                "region": "mecklenburg-vorpommern"
            },
            "experiment_variables": {
                "total_token_inputted": 2560,
                "total_tokens_outputted": 250,
                "number_runs": 5
            },
            "experiment_results": {
                "inference_performance": {
                    "total_inference_time_sec": 2.793602622114122,
                    "average_latency_ms_per_batch": 2793.602622114122,
                    "throughput_queries_per_sec": 1.789815053666063,
                    "throughput_tokens_per_sec": 89.49075268330316
                },
                "energy_performance": {
                    "cpu_power": 112.5,
                    "gpu_power": 255.26291678050518,
                    "ram_power": 188.8243260383606,
                    "energy_efficiency_tokens_per_joule": 0.2340923220997962,
                    "cpu_energy": 0.00013597321054839996,
                    "gpu_energy": 0.0002298785172456519,
                    "ram_energy": 0.00022745646208425369,
                    "total_energy_consumed_kwh": 0.0005933081898783055,
                    "total_energy_consumed_joules": 2135.9094835619,
                    "final_emissions": 0.0002260207549341405
                },
                "compute_performance": {
                    "gpu": "cuda:0",
                    "flops_forward_pass": "Error: Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: DynamicCache",
                    "cpu_usage_percent": 0.0,
                    "cpu_memory_usage_bytes": 2871678976.0,
                    "gpu_utilization_percent": [
                        0.0,
                        0.0,
                        0.0,
                        55.0
                    ],
                    "current_memory_allocated_bytes": 4410810880.0,
                    "max_memory_allocated_bytes": 4410810880.0,
                    "current_memory_reserved_bytes": 6715080704.0,
                    "max_memory_reserved_bytes": 6715080704.0,
                    "cpu_vendor": "AMD"
                },
                "task-specific_performance": {}
            }
        }
    }
]
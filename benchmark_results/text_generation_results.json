[
    {
        "EXPERIMENT #0001": {
            "experiment_setup": {
                "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
                "task_type": "text_generation",
                "date": "March 04, 2025 at 07:11:46 PM",
                "cpu_count": 128,
                "cpu_model": "AMD EPYC 7742 64-Core Processor",
                "gpu_count": 2,
                "gpu_model": "4 x NVIDIA A100-PCIE-40GB",
                "os": "Linux-5.15.0-113-generic-x86_64-with-glibc2.31",
                "python_version": "3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]",
                "accelerate_config": {
                    "distributed_type": "DistributedType.MULTI_GPU",
                    "num_processes": 2
                },
                "country": "Germany",
                "region": "mecklenburg-vorpommern"
            },
            "experiment_variables": {
                "input_tokens": 2560,
                "output_tokens": 250,
                "number_runs": 5
            },
            "experiment_results": {
                "inference_performance": {
                    "total_inference_time_sec": 2.9046354780439287,
                    "average_latency_ms_per_batch": 2904.6354780439287,
                    "average_ttft_ms": 0.0,
                    "throughput_queries_per_sec": 1.721420551464691,
                    "throughput_tokens_per_sec": 86.07102757323455
                },
                "energy_performance": {
                    "cpu_power": 112.5,
                    "gpu_power": 0.0,
                    "ram_power": 188.8243260383606,
                    "energy_efficiency_tokens_per_joule": 0.17437181807253316,
                    "cpu_energy": 0.00019891567426384428,
                    "gpu_energy": 0.000264675211752774,
                    "ram_energy": 0.00033291941715275514,
                    "total_energy_consumed_kwh": 0.0007965103031693735,
                    "total_energy_consumed_joules": 2867.4370914097444,
                    "final_emissions": 0.00030343059999237283
                },
                "compute_performance": {
                    "gpu": "cuda:0",
                    "flops_forward_pass": "Error: Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: DynamicCache",
                    "cpu_usage_percent": 0.0,
                    "cpu_memory_usage_bytes": 2867941376.0
                },
                "task-specific_performance": {}
            }
        }
    },
    {
        "EXPERIMENT #0002": {
            "experiment_setup": {
                "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
                "task_type": "text_generation",
                "date": "March 04, 2025 at 07:35:00 PM",
                "cpu_count": 128,
                "cpu_model": "AMD EPYC 7742 64-Core Processor",
                "gpu_count": 2,
                "gpu_model": "4 x NVIDIA A100-PCIE-40GB",
                "os": "Linux-5.15.0-113-generic-x86_64-with-glibc2.31",
                "python_version": "3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]",
                "accelerate_config": {
                    "distributed_type": "DistributedType.MULTI_GPU",
                    "num_processes": 2
                },
                "country": "Germany",
                "region": "mecklenburg-vorpommern"
            },
            "experiment_variables": {
                "total_token_inputted": 2560,
                "total_tokens_outputted": 250,
                "number_runs": 5
            },
            "experiment_results": {
                "inference_performance": {
                    "total_inference_time_sec": 3.069109580013901,
                    "average_latency_ms_per_batch": 3069.109580013901,
                    "average_ttft_ms": 0.0,
                    "throughput_queries_per_sec": 1.6291373232080473,
                    "throughput_tokens_per_sec": 81.45686616040237
                },
                "energy_performance": {
                    "cpu_power": 112.5,
                    "gpu_power": 235.83204577308427,
                    "ram_power": 188.8243260383606,
                    "energy_efficiency_tokens_per_joule": 0.15470288405248556,
                    "cpu_energy": 0.0002534404672478558,
                    "gpu_energy": 0.00021988628699887158,
                    "ram_energy": 0.00042445479029182227,
                    "total_energy_consumed_kwh": 0.0008977815445385496,
                    "total_energy_consumed_joules": 3232.013560338779,
                    "final_emissions": 0.0003420098793919605
                },
                "compute_performance": {
                    "gpu": "cuda:0",
                    "flops_forward_pass": "Error: Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: DynamicCache",
                    "cpu_usage_percent": 0.0,
                    "cpu_memory_usage_bytes": 2872322048.0
                },
                "task-specific_performance": {}
            }
        }
    },
    {
        "EXPERIMENT #0003": {
            "experiment_setup": {
                "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
                "task_type": "text_generation",
                "date": "March 04, 2025 at 07:38:29 PM",
                "cpu_count": 128,
                "cpu_model": "AMD EPYC 7742 64-Core Processor",
                "gpu_count": 2,
                "gpu_model": "4 x NVIDIA A100-PCIE-40GB",
                "os": "Linux-5.15.0-113-generic-x86_64-with-glibc2.31",
                "python_version": "3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]",
                "accelerate_config": {
                    "distributed_type": "DistributedType.MULTI_GPU",
                    "num_processes": 2
                },
                "country": "Germany",
                "region": "mecklenburg-vorpommern"
            },
            "experiment_variables": {
                "total_token_inputted": 25600,
                "total_tokens_outputted": 2500,
                "number_runs": 50
            },
            "experiment_results": {
                "inference_performance": {
                    "total_inference_time_sec": 9.075287469662726,
                    "average_latency_ms_per_batch": 1296.4696385232464,
                    "average_ttft_ms": 0.0,
                    "throughput_queries_per_sec": 5.509471823871618,
                    "throughput_tokens_per_sec": 275.4735911935809
                },
                "energy_performance": {
                    "cpu_power": 112.5,
                    "gpu_power": 196.4996529529407,
                    "ram_power": 188.8243260383606,
                    "energy_efficiency_tokens_per_joule": 0.4935331359579749,
                    "cpu_energy": 0.0006421420079132077,
                    "gpu_energy": 0.0010969730997913985,
                    "ram_energy": 0.0010750623629472243,
                    "total_energy_consumed_kwh": 0.00281417747065183,
                    "total_energy_consumed_joules": 10131.038894346588,
                    "final_emissions": 0.0010720609074448147
                },
                "compute_performance": {
                    "gpu": "cuda:0",
                    "flops_forward_pass": "Error: Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: DynamicCache",
                    "cpu_usage_percent": 0.5,
                    "cpu_memory_usage_bytes": 2894456832.0
                },
                "task-specific_performance": {}
            }
        }
    },
    {
        "EXPERIMENT #0004": {
            "experiment_setup": {
                "model": "TinyLlama/TinyLlama-1.1B-Chat-v1.0",
                "task_type": "text_generation",
                "date": "March 04, 2025 at 07:55:37 PM",
                "cpu_count": 128,
                "cpu_model": "AMD EPYC 7742 64-Core Processor",
                "gpu_count": 2,
                "gpu_model": "4 x NVIDIA A100-PCIE-40GB",
                "os": "Linux-5.15.0-113-generic-x86_64-with-glibc2.31",
                "python_version": "3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]",
                "accelerate_config": {
                    "distributed_type": "DistributedType.MULTI_GPU",
                    "num_processes": 2
                },
                "country": "Germany",
                "region": "mecklenburg-vorpommern"
            },
            "experiment_variables": {
                "total_token_inputted": 2560,
                "total_tokens_outputted": 250,
                "number_runs": 5
            },
            "experiment_results": {
                "inference_performance": {
                    "total_inference_time_sec": 2.9997439426369965,
                    "average_latency_ms_per_batch": 2999.7439426369965,
                    "average_ttft_ms": 0.0,
                    "throughput_queries_per_sec": 1.666872669142737,
                    "throughput_tokens_per_sec": 83.34363345713683
                },
                "energy_performance": {
                    "cpu_power": 112.5,
                    "gpu_power": 555.0654377502071,
                    "ram_power": 188.8243260383606,
                    "energy_efficiency_tokens_per_joule": 0.22743924192892567,
                    "cpu_energy": 0.00013839303403801752,
                    "gpu_energy": 0.00024096435945608619,
                    "ram_energy": 0.00023131384432084997,
                    "total_energy_consumed_kwh": 0.0006106712378149536,
                    "total_energy_consumed_joules": 2198.416456133833,
                    "final_emissions": 0.0002326352080456066
                },
                "compute_performance": {
                    "gpu": "cuda:0",
                    "flops_forward_pass": "Error: Only tuples, lists and Variables are supported as JIT inputs/outputs. Dictionaries and strings are also accepted, but their usage is not recommended. Here, received an input of unsupported type: DynamicCache",
                    "cpu_usage_percent": 0.0,
                    "cpu_memory_usage_bytes": 2869719040.0
                },
                "task-specific_performance": {}
            }
        }
    }
]
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will later move this into function script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column(col: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean a single column name by:\n",
    "      - Stripping whitespace and replacing any non-standard quotes.\n",
    "      - Using regex to check for per-process metric patterns (e.g., gpu_energy_process_0).\n",
    "      - Otherwise, stripping off any messy prefixes using a known list of tokens.\n",
    "    \n",
    "    If no known token is found, the original column name is returned.\n",
    "    \"\"\"\n",
    "    # Normalize the column string: remove extra whitespace and fix common issues with quotes.\n",
    "    col = col.strip()\n",
    "    col = col.replace(\"“\", \"\\\"\").replace(\"”\", \"\\\"\")\n",
    "    \n",
    "    # First, check if it is a per-process metric column.\n",
    "    per_process_patterns = [\n",
    "        r'(cpu_power_process_\\d+)',\n",
    "        r'(gpu_power_process_\\d+)',\n",
    "        r'(ram_power_process_\\d+)',\n",
    "        r'(cpu_energy_process_\\d+)',\n",
    "        r'(gpu_energy_process_\\d+)',\n",
    "        r'(ram_energy_process_\\d+)',\n",
    "        r'(total_energy_kwh_process_\\d+)',\n",
    "        r'(total_energy_joules_process_\\d+)'\n",
    "    ]\n",
    "    for pattern in per_process_patterns:\n",
    "        match = re.search(pattern, col)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    \n",
    "    # For non-per-process columns, search for a known token\n",
    "    tokens = [ \n",
    "        \"config_name\", \"experiment_id\", \"date_time\", \"model\", \"is_encoder_decoder\",\n",
    "        \"task_type\", \"available_gpu_count\", \"gpu_model\", \"available_cpu_count\", \"cpu_model\",\n",
    "        \"os\", \"python_version\", \"country\", \"region\", \"fsdp_use_orig_params\", \"fsdp_cpu_offload\",\n",
    "        \"sharding_strategy\", \"distributed_type\", \"num_processes\", \"max_input_tokens\", \"max_output_tokens\",\n",
    "        \"number_input_prompts\", \"decode_token_to_text\", \"decoder_temperature\", \"decoder_top_k\", \"decoder_top_p\",\n",
    "        \"query_rate\", \"latency_simulate\", \"latency_delay_min\", \"latency_delay_max\", \"latency_simulate_burst\",\n",
    "        \"latency_burst_interval\", \"latency_burst_size\", \"fp_precision\", \"quantization\", \"load_in_8bit\",\n",
    "        \"load_in_4bit\", \"cached_flops_for_quantised_models\", \"batch_size___fixed_batching\", \"adaptive_batching\",\n",
    "        \"adaptive_max_tokens\", \"max_batch_size___adaptive_batching\", \"inference_type\", \"backend\", \"total_params\",\n",
    "        \"architecture\", \"total_input_tokens\", \"total_generated_tokens\", \"total_inference_time_sec\", \n",
    "        \"average_latency_ms_per_batch\", \"throughput_queries_per_sec\", \"throughput_tokens_per_sec\", \"flops\",\n",
    "        \"gpu_current_memory_allocated_bytes\", \"gpu_max_memory_allocated_bytes\", \"gpu_current_memory_reserved_bytes\",\n",
    "        \"gpu_max_memory_reserved_bytes\", \"gpu_utilization_percent\", \"cpu_usage_percent\", \"cpu_memory_usage_bytes\",\n",
    "        \"cpu_power_avg\", \"gpu_power_avg\", \"ram_power_avg\", \"cpu_energy_total\", \"gpu_energy_total\", \"ram_energy_total\",\n",
    "        \"total_energy_kwh\", \"total_energy_joules\", \"tokens_per_joule\", \"joules_per_token\", \"flops_per_joule\", \"joules_per_flop\",\n",
    "        \"per-process_emissions\"\n",
    "    ]\n",
    "    \n",
    "    for token in tokens:\n",
    "        # Check if the token exists anywhere in the column name.\n",
    "        if token in col:\n",
    "            idx = col.find(token)\n",
    "            return col[idx:]\n",
    "    \n",
    "    # If no known token is found, return the cleaned (normalized) column.\n",
    "    return col\n",
    "\n",
    "def clean_and_reorder_columns(df: pd.DataFrame, desired_order: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean DataFrame columns by:\n",
    "      1. Renaming each column to remove extraneous prefixes.\n",
    "      2. Reordering columns into the order specified by 'desired_order'.\n",
    "         Any columns not explicitly mentioned will be appended at the end.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with messy, flattened column names.\n",
    "        desired_order (list): List of column names (after cleaning) indicating the preferred ordering.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with cleaned and reordered columns.\n",
    "    \"\"\"\n",
    "    # Build mapping from original column names to cleaned names.\n",
    "    mapping = {}\n",
    "    for col in df.columns:\n",
    "        new_name = clean_column(col)\n",
    "        mapping[col] = new_name\n",
    "\n",
    "    # Optionally, you might want to print the mapping for debugging:\n",
    "    # for orig, new in mapping.items():\n",
    "    #     print(f\"Original: '{orig}' -> Cleaned: '{new}'\")\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    df = df.rename(columns=mapping)\n",
    "    \n",
    "    # Reorder columns: first, the ones matching the desired order.\n",
    "    ordered_cols = [col for col in desired_order if col in df.columns]\n",
    "    # Then append any remaining columns.\n",
    "    remaining_cols = [col for col in df.columns if col not in desired_order]\n",
    "    final_order = ordered_cols + remaining_cols\n",
    "    \n",
    "    return df[final_order]\n",
    "\n",
    "desired_order = [\n",
    "    \"config_name\",\n",
    "    \"experiment_id\",\n",
    "    \"date_time\",\n",
    "    \"model\",\n",
    "    \"is_encoder_decoder\",\n",
    "    \"task_type\",\n",
    "    \"available_gpu_count\",\n",
    "    \"gpu_model\",\n",
    "    \"available_cpu_count\",\n",
    "    \"cpu_model\",\n",
    "    \"os\",\n",
    "    \"python_version\",\n",
    "    \"country\",\n",
    "    \"region\",\n",
    "    \"fsdp_use_orig_params\",\n",
    "    \"fsdp_cpu_offload\",\n",
    "    \"sharding_strategy\",\n",
    "    \"distributed_type\",\n",
    "    \"num_processes\",\n",
    "    \"max_input_tokens\",\n",
    "    \"max_output_tokens\",\n",
    "    \"number_input_prompts\",\n",
    "    \"decode_token_to_text\",\n",
    "    \"decoder_temperature\",\n",
    "    \"decoder_top_k\",\n",
    "    \"decoder_top_p\",\n",
    "    \"query_rate\",\n",
    "    \"latency_simulate\",\n",
    "    \"latency_delay_min\",\n",
    "    \"latency_delay_max\",\n",
    "    \"latency_simulate_burst\",\n",
    "    \"latency_burst_interval\",\n",
    "    \"latency_burst_size\",\n",
    "    \"fp_precision\",\n",
    "    \"quantization\",\n",
    "    \"load_in_8bit\",\n",
    "    \"load_in_4bit\",\n",
    "    \"cached_flops_for_quantised_models\",\n",
    "    \"batch_size___fixed_batching\",\n",
    "    \"adaptive_batching\",\n",
    "    \"adaptive_max_tokens\",\n",
    "    \"max_batch_size___adaptive_batching\",\n",
    "    \"inference_type\",\n",
    "    \"backend\",\n",
    "    \"total_params\",\n",
    "    \"architecture\",\n",
    "    \"total_input_tokens\",\n",
    "    \"total_generated_tokens\",\n",
    "    \"total_inference_time_sec\",\n",
    "    \"average_latency_ms_per_batch\",\n",
    "    \"throughput_queries_per_sec\",\n",
    "    \"throughput_tokens_per_sec\",\n",
    "    \"flops\",\n",
    "    \"gpu_current_memory_allocated_bytes\",\n",
    "    \"gpu_max_memory_allocated_bytes\",\n",
    "    \"gpu_current_memory_reserved_bytes\",\n",
    "    \"gpu_max_memory_reserved_bytes\",\n",
    "    \"gpu_utilization_percent\",\n",
    "    \"cpu_usage_percent\",\n",
    "    \"cpu_memory_usage_bytes\",\n",
    "    # Per-process metrics:\n",
    "    \"cpu_power_process_0\", \"cpu_power_process_1\", \"cpu_power_process_2\", \"cpu_power_process_3\",\n",
    "    \"gpu_power_process_0\", \"gpu_power_process_1\", \"gpu_power_process_2\", \"gpu_power_process_3\",\n",
    "    \"ram_power_process_0\", \"ram_power_process_1\", \"ram_power_process_2\", \"ram_power_process_3\",\n",
    "    \"cpu_energy_process_0\", \"cpu_energy_process_1\", \"cpu_energy_process_2\", \"cpu_energy_process_3\",\n",
    "    \"gpu_energy_process_0\", \"gpu_energy_process_1\", \"gpu_energy_process_2\", \"gpu_energy_process_3\",\n",
    "    \"ram_energy_process_0\", \"ram_energy_process_1\", \"ram_energy_process_2\", \"ram_energy_process_3\",\n",
    "    \"total_energy_kwh_process_0\", \"total_energy_kwh_process_1\", \"total_energy_kwh_process_2\", \"total_energy_kwh_process_3\",\n",
    "    \"total_energy_joules_process_0\", \"total_energy_joules_process_1\", \"total_energy_joules_process_2\", \"total_energy_joules_process_3\",\n",
    "    # Global averages and totals:\n",
    "    \"cpu_power_avg\",\n",
    "    \"gpu_power_avg\",\n",
    "    \"ram_power_avg\",\n",
    "    \"cpu_energy_total\",\n",
    "    \"gpu_energy_total\",\n",
    "    \"ram_energy_total\",\n",
    "    \"total_energy_kwh\",\n",
    "    \"total_energy_joules\",\n",
    "    \"tokens_per_joule\",\n",
    "    \"joules_per_token\",\n",
    "    \"flops_per_joule\",\n",
    "    \"joules_per_flop\",\n",
    "    \"per-process_emissions\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>config_name</th>\n",
       "      <td>num_processes_1</td>\n",
       "      <td>num_processes_2</td>\n",
       "      <td>num_processes_3</td>\n",
       "      <td>num_processes_4</td>\n",
       "      <td>batching_1</td>\n",
       "      <td>batching_2</td>\n",
       "      <td>batching_4</td>\n",
       "      <td>batching_8</td>\n",
       "      <td>batching_16</td>\n",
       "      <td>batching_32</td>\n",
       "      <td>batching_64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <td>April 08, 2025 at 03:33:17 PM</td>\n",
       "      <td>April 08, 2025 at 03:33:53 PM</td>\n",
       "      <td>April 08, 2025 at 03:34:31 PM</td>\n",
       "      <td>April 08, 2025 at 03:35:12 PM</td>\n",
       "      <td>April 08, 2025 at 03:36:18 PM</td>\n",
       "      <td>April 08, 2025 at 03:37:11 PM</td>\n",
       "      <td>April 08, 2025 at 03:37:57 PM</td>\n",
       "      <td>April 08, 2025 at 03:38:41 PM</td>\n",
       "      <td>April 08, 2025 at 03:39:20 PM</td>\n",
       "      <td>April 08, 2025 at 03:39:55 PM</td>\n",
       "      <td>April 08, 2025 at 03:40:36 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_encoder_decoder</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_type</th>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_gpu_count</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_cpu_count</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>os</th>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python_version</th>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharding_strategy</th>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distributed_type</th>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_processes</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_input_tokens</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_output_tokens</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_input_prompts</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_input_prompts</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decode_token_to_text</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_temperature</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_k</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_p</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_rate</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp_precision</th>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantization</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_8bit</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_4bit</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size___fixed_batching</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive_batching</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive_batching</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive_max_tokens</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inference_type</th>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backend</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_input_tokens</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_generated_tokens</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_inference_time_sec</th>\n",
       "      <td>2.763379</td>\n",
       "      <td>2.750908</td>\n",
       "      <td>2.740259</td>\n",
       "      <td>2.831569</td>\n",
       "      <td>25.533837</td>\n",
       "      <td>13.109935</td>\n",
       "      <td>7.83752</td>\n",
       "      <td>5.270889</td>\n",
       "      <td>2.467701</td>\n",
       "      <td>2.880436</td>\n",
       "      <td>2.9724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_latency_ms_per_batch</th>\n",
       "      <td>2763.378764</td>\n",
       "      <td>2750.908175</td>\n",
       "      <td>2740.258832</td>\n",
       "      <td>2831.56897</td>\n",
       "      <td>2553.383669</td>\n",
       "      <td>2621.987081</td>\n",
       "      <td>2612.506737</td>\n",
       "      <td>2635.444515</td>\n",
       "      <td>2467.70092</td>\n",
       "      <td>2880.435904</td>\n",
       "      <td>2972.400019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_queries_per_sec</th>\n",
       "      <td>3.618758</td>\n",
       "      <td>3.635163</td>\n",
       "      <td>3.64929</td>\n",
       "      <td>3.531611</td>\n",
       "      <td>0.391637</td>\n",
       "      <td>0.76278</td>\n",
       "      <td>1.275914</td>\n",
       "      <td>1.897213</td>\n",
       "      <td>4.052355</td>\n",
       "      <td>3.471697</td>\n",
       "      <td>3.364285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_tokens_per_sec</th>\n",
       "      <td>361.875836</td>\n",
       "      <td>363.516314</td>\n",
       "      <td>364.929031</td>\n",
       "      <td>353.161096</td>\n",
       "      <td>39.163719</td>\n",
       "      <td>76.278026</td>\n",
       "      <td>127.591378</td>\n",
       "      <td>189.721315</td>\n",
       "      <td>405.235493</td>\n",
       "      <td>347.169676</td>\n",
       "      <td>336.428473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops</th>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_current_memory_allocated_bytes</th>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817967616</td>\n",
       "      <td>8817965056</td>\n",
       "      <td>8817964032</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_max_memory_allocated_bytes</th>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817967616</td>\n",
       "      <td>8817965056</td>\n",
       "      <td>8817964032</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_current_memory_reserved_bytes</th>\n",
       "      <td>12008292352</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_max_memory_reserved_bytes</th>\n",
       "      <td>12008292352</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_usage_percent</th>\n",
       "      <td>96.7</td>\n",
       "      <td>97.0</td>\n",
       "      <td>96.6</td>\n",
       "      <td>95.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>96.7</td>\n",
       "      <td>96.4</td>\n",
       "      <td>96.4</td>\n",
       "      <td>13.6</td>\n",
       "      <td>96.2</td>\n",
       "      <td>96.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_memory_usage_bytes</th>\n",
       "      <td>2071535616</td>\n",
       "      <td>2070253568</td>\n",
       "      <td>2070421504</td>\n",
       "      <td>2070048768</td>\n",
       "      <td>2028392448</td>\n",
       "      <td>2043359232</td>\n",
       "      <td>2052145152</td>\n",
       "      <td>2056445952</td>\n",
       "      <td>2069643264</td>\n",
       "      <td>2068746240</td>\n",
       "      <td>2072772608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_0</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_0</th>\n",
       "      <td>313.991516</td>\n",
       "      <td>596.486136</td>\n",
       "      <td>718.703111</td>\n",
       "      <td>718.451461</td>\n",
       "      <td>660.505795</td>\n",
       "      <td>658.195478</td>\n",
       "      <td>342.389902</td>\n",
       "      <td>617.829628</td>\n",
       "      <td>732.434642</td>\n",
       "      <td>871.734093</td>\n",
       "      <td>786.654447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>567.623977</td>\n",
       "      <td>684.317281</td>\n",
       "      <td>923.653844</td>\n",
       "      <td>574.738216</td>\n",
       "      <td>540.067306</td>\n",
       "      <td>393.608731</td>\n",
       "      <td>524.097376</td>\n",
       "      <td>612.755977</td>\n",
       "      <td>525.181024</td>\n",
       "      <td>321.005222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>709.778828</td>\n",
       "      <td>725.446645</td>\n",
       "      <td>573.384816</td>\n",
       "      <td>891.398237</td>\n",
       "      <td>867.352571</td>\n",
       "      <td>657.727491</td>\n",
       "      <td>692.528586</td>\n",
       "      <td>1114.343612</td>\n",
       "      <td>679.879288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>644.874559</td>\n",
       "      <td>554.9442</td>\n",
       "      <td>627.303129</td>\n",
       "      <td>524.128197</td>\n",
       "      <td>594.976599</td>\n",
       "      <td>520.007484</td>\n",
       "      <td>492.554528</td>\n",
       "      <td>596.931328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_0</th>\n",
       "      <td>0.72087</td>\n",
       "      <td>0.721713</td>\n",
       "      <td>0.720606</td>\n",
       "      <td>0.72155</td>\n",
       "      <td>0.707112</td>\n",
       "      <td>0.711908</td>\n",
       "      <td>0.715374</td>\n",
       "      <td>0.716846</td>\n",
       "      <td>0.720756</td>\n",
       "      <td>0.720925</td>\n",
       "      <td>0.722589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666942</td>\n",
       "      <td>0.669265</td>\n",
       "      <td>0.667773</td>\n",
       "      <td>0.653126</td>\n",
       "      <td>0.655879</td>\n",
       "      <td>0.662511</td>\n",
       "      <td>0.666889</td>\n",
       "      <td>0.672183</td>\n",
       "      <td>0.667015</td>\n",
       "      <td>0.667871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.666395</td>\n",
       "      <td>0.672336</td>\n",
       "      <td>0.649677</td>\n",
       "      <td>0.656283</td>\n",
       "      <td>0.665329</td>\n",
       "      <td>0.664709</td>\n",
       "      <td>0.674549</td>\n",
       "      <td>0.665015</td>\n",
       "      <td>0.668648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.67136</td>\n",
       "      <td>0.649996</td>\n",
       "      <td>0.6606</td>\n",
       "      <td>0.665155</td>\n",
       "      <td>0.665131</td>\n",
       "      <td>0.671853</td>\n",
       "      <td>0.677226</td>\n",
       "      <td>0.672393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_0</th>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.00081</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000924</td>\n",
       "      <td>0.00052</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_0</th>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000375</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.00377</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.001476</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.004234</td>\n",
       "      <td>0.002816</td>\n",
       "      <td>0.001786</td>\n",
       "      <td>0.001318</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.000583</td>\n",
       "      <td>0.000726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.00373</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.001489</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.000482</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.004235</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>0.001767</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_0</th>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.00047</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.001735</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.000679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000599</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.000939</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.003339</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.001558</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000782</td>\n",
       "      <td>0.004532</td>\n",
       "      <td>0.00266</td>\n",
       "      <td>0.001747</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.00071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000948</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.003246</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.001386</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.00075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_0</th>\n",
       "      <td>1829.842844</td>\n",
       "      <td>1693.43267</td>\n",
       "      <td>2576.391109</td>\n",
       "      <td>2776.502046</td>\n",
       "      <td>16501.500354</td>\n",
       "      <td>9721.793407</td>\n",
       "      <td>6245.397479</td>\n",
       "      <td>4209.217521</td>\n",
       "      <td>2044.749377</td>\n",
       "      <td>2327.593383</td>\n",
       "      <td>2445.026163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2154.670632</td>\n",
       "      <td>3219.985638</td>\n",
       "      <td>3379.992012</td>\n",
       "      <td>18584.829356</td>\n",
       "      <td>12018.727177</td>\n",
       "      <td>7608.657866</td>\n",
       "      <td>5609.708303</td>\n",
       "      <td>2425.735696</td>\n",
       "      <td>2488.823218</td>\n",
       "      <td>3103.378067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2407.301886</td>\n",
       "      <td>2815.908501</td>\n",
       "      <td>16315.533379</td>\n",
       "      <td>9574.828386</td>\n",
       "      <td>6288.649164</td>\n",
       "      <td>4286.453548</td>\n",
       "      <td>2029.018626</td>\n",
       "      <td>2411.356206</td>\n",
       "      <td>2554.800499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3412.892238</td>\n",
       "      <td>18582.62481</td>\n",
       "      <td>11686.985166</td>\n",
       "      <td>7516.518942</td>\n",
       "      <td>4987.917806</td>\n",
       "      <td>2482.115181</td>\n",
       "      <td>2823.20656</td>\n",
       "      <td>2699.624032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_avg</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_avg</th>\n",
       "      <td>313.991516</td>\n",
       "      <td>582.055057</td>\n",
       "      <td>704.266407</td>\n",
       "      <td>753.106627</td>\n",
       "      <td>590.893257</td>\n",
       "      <td>679.241038</td>\n",
       "      <td>531.86985</td>\n",
       "      <td>598.657774</td>\n",
       "      <td>639.431672</td>\n",
       "      <td>750.953314</td>\n",
       "      <td>596.117571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_avg</th>\n",
       "      <td>0.72087</td>\n",
       "      <td>0.694327</td>\n",
       "      <td>0.685422</td>\n",
       "      <td>0.683255</td>\n",
       "      <td>0.664978</td>\n",
       "      <td>0.671168</td>\n",
       "      <td>0.677093</td>\n",
       "      <td>0.678394</td>\n",
       "      <td>0.684835</td>\n",
       "      <td>0.682545</td>\n",
       "      <td>0.682875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_total</th>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.00021</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.00055</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>0.001854</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000369</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.000487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_total</th>\n",
       "      <td>0.000413</td>\n",
       "      <td>0.000857</td>\n",
       "      <td>0.00191</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>0.015969</td>\n",
       "      <td>0.010082</td>\n",
       "      <td>0.006518</td>\n",
       "      <td>0.004498</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.002355</td>\n",
       "      <td>0.002511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_total</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh</th>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.001069</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.00344</td>\n",
       "      <td>0.01944</td>\n",
       "      <td>0.011945</td>\n",
       "      <td>0.007683</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.002495</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>0.003001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules</th>\n",
       "      <td>1829.842844</td>\n",
       "      <td>3848.103302</td>\n",
       "      <td>8203.678633</td>\n",
       "      <td>12385.294796</td>\n",
       "      <td>69984.487898</td>\n",
       "      <td>43002.334136</td>\n",
       "      <td>27659.223452</td>\n",
       "      <td>19093.297178</td>\n",
       "      <td>8981.61888</td>\n",
       "      <td>10050.979367</td>\n",
       "      <td>10802.828761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens_per_joule</th>\n",
       "      <td>0.546495</td>\n",
       "      <td>0.259868</td>\n",
       "      <td>0.121897</td>\n",
       "      <td>0.080741</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.023255</td>\n",
       "      <td>0.036154</td>\n",
       "      <td>0.052374</td>\n",
       "      <td>0.111339</td>\n",
       "      <td>0.099493</td>\n",
       "      <td>0.092568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_token</th>\n",
       "      <td>1.829843</td>\n",
       "      <td>3.848103</td>\n",
       "      <td>8.203679</td>\n",
       "      <td>12.385295</td>\n",
       "      <td>69.984488</td>\n",
       "      <td>43.002334</td>\n",
       "      <td>27.659223</td>\n",
       "      <td>19.093297</td>\n",
       "      <td>8.981619</td>\n",
       "      <td>10.050979</td>\n",
       "      <td>10.802829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops_per_joule</th>\n",
       "      <td>565373213.077254</td>\n",
       "      <td>268845206.817153</td>\n",
       "      <td>126107344.561251</td>\n",
       "      <td>83530036.629457</td>\n",
       "      <td>14782477.647264</td>\n",
       "      <td>24057859.85308</td>\n",
       "      <td>37403223.912325</td>\n",
       "      <td>54183628.86052</td>\n",
       "      <td>115184594.427958</td>\n",
       "      <td>102929683.786364</td>\n",
       "      <td>95766039.702745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_flop</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variables_sharding_config_fsdp_config_use_orig_params</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.001967</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variables_latency_simulation_simulate_burst</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variables_sharding_config_fsdp_config_cpu_offload</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variables_latency_simulation_burst_size</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.001746</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_architecture_architecture</th>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variables_latency_simulation_burst_interval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_0</th>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.001029</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variables_latency_simulation_simulate</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.00027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variables_latency_simulation_delay_max</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_architecture_total_params</th>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variables_latency_simulation_delay_min</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                      0   \\\n",
       "config_name                                                                              num_processes_1   \n",
       "experiment_id                                                                                         12   \n",
       "experiment_id                                                                                         12   \n",
       "date_time                                                                  April 08, 2025 at 03:33:17 PM   \n",
       "model                                                                    AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                          4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                 False   \n",
       "task_type                                                                                text_generation   \n",
       "available_gpu_count                                                                                    4   \n",
       "available_cpu_count                                                                                  128   \n",
       "os                                                        Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                         3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                          Germany   \n",
       "region                                                                                            saxony   \n",
       "sharding_strategy                                                                               NO_SHARD   \n",
       "distributed_type                                                               DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                          1   \n",
       "max_input_tokens                                                                                     100   \n",
       "max_output_tokens                                                                                    100   \n",
       "number_input_prompts                                                                                  10   \n",
       "number_input_prompts                                                                                  10   \n",
       "decode_token_to_text                                                                                True   \n",
       "decoder_temperature                                                                                  1.0   \n",
       "decoder_top_k                                                                                          0   \n",
       "decoder_top_p                                                                                        0.0   \n",
       "query_rate                                                                                           1.0   \n",
       "fp_precision                                                                               torch.float32   \n",
       "quantization                                                                                       False   \n",
       "load_in_8bit                                                                                       False   \n",
       "load_in_4bit                                                                                       False   \n",
       "batch_size___fixed_batching                                                                           16   \n",
       "adaptive_batching                                                                                      0   \n",
       "adaptive_batching                                                                                  False   \n",
       "adaptive_max_tokens                                                                                    0   \n",
       "inference_type                                                                           pure_generative   \n",
       "backend                                                                                          pytorch   \n",
       "total_input_tokens                                                                                  1000   \n",
       "total_generated_tokens                                                                              1000   \n",
       "total_inference_time_sec                                                                        2.763379   \n",
       "average_latency_ms_per_batch                                                                 2763.378764   \n",
       "throughput_queries_per_sec                                                                      3.618758   \n",
       "throughput_tokens_per_sec                                                                     361.875836   \n",
       "flops                                                                                      1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                            8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                            12008292352   \n",
       "gpu_max_memory_reserved_bytes                                                                12008292352   \n",
       "cpu_usage_percent                                                                                   96.7   \n",
       "cpu_memory_usage_bytes                                                                        2071535616   \n",
       "cpu_power_process_0                                                                                112.5   \n",
       "cpu_power_process_1                                                                                  NaN   \n",
       "cpu_power_process_2                                                                                  NaN   \n",
       "cpu_power_process_3                                                                                  NaN   \n",
       "gpu_power_process_0                                                                           313.991516   \n",
       "gpu_power_process_1                                                                                  NaN   \n",
       "gpu_power_process_2                                                                                  NaN   \n",
       "gpu_power_process_3                                                                                  NaN   \n",
       "ram_power_process_0                                                                              0.72087   \n",
       "ram_power_process_1                                                                                  NaN   \n",
       "ram_power_process_2                                                                                  NaN   \n",
       "ram_power_process_3                                                                                  NaN   \n",
       "cpu_energy_process_0                                                                            0.000095   \n",
       "cpu_energy_process_1                                                                                 NaN   \n",
       "cpu_energy_process_2                                                                                 NaN   \n",
       "cpu_energy_process_3                                                                                 NaN   \n",
       "gpu_energy_process_0                                                                            0.000413   \n",
       "gpu_energy_process_1                                                                                 NaN   \n",
       "gpu_energy_process_2                                                                                 NaN   \n",
       "gpu_energy_process_3                                                                                 NaN   \n",
       "ram_energy_process_0                                                                                 0.0   \n",
       "ram_energy_process_1                                                                                 NaN   \n",
       "ram_energy_process_2                                                                                 NaN   \n",
       "ram_energy_process_3                                                                                 NaN   \n",
       "total_energy_kwh_process_0                                                                      0.000508   \n",
       "total_energy_kwh_process_1                                                                           NaN   \n",
       "total_energy_kwh_process_2                                                                           NaN   \n",
       "total_energy_kwh_process_3                                                                           NaN   \n",
       "total_energy_joules_process_0                                                                1829.842844   \n",
       "total_energy_joules_process_1                                                                        NaN   \n",
       "total_energy_joules_process_2                                                                        NaN   \n",
       "total_energy_joules_process_3                                                                        NaN   \n",
       "cpu_power_avg                                                                                      112.5   \n",
       "gpu_power_avg                                                                                 313.991516   \n",
       "ram_power_avg                                                                                    0.72087   \n",
       "cpu_energy_total                                                                                0.000095   \n",
       "gpu_energy_total                                                                                0.000413   \n",
       "ram_energy_total                                                                                     0.0   \n",
       "total_energy_kwh                                                                                0.000508   \n",
       "total_energy_joules                                                                          1829.842844   \n",
       "tokens_per_joule                                                                                0.546495   \n",
       "joules_per_token                                                                                1.829843   \n",
       "flops_per_joule                                                                         565373213.077254   \n",
       "joules_per_flop                                                                                      0.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "per-process_emissions_1                                                                              NaN   \n",
       "gpu_utilization_percent_2                                                                            0.0   \n",
       "gpu_utilization_percent_1                                                                            1.0   \n",
       "models                                                                                    82763530240000   \n",
       "variables_latency_simulation_simulate_burst                                                        False   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "variables_latency_simulation_burst_size                                                                0   \n",
       "per-process_emissions_2                                                                              NaN   \n",
       "model_architecture_architecture                                            Unknown (no config attribute)   \n",
       "variables_latency_simulation_burst_interval                                                          0.0   \n",
       "gpu_utilization_percent_0                                                                            4.0   \n",
       "per-process_emissions_0                                                                         0.000194   \n",
       "variables_latency_simulation_simulate                                                              False   \n",
       "per-process_emissions_3                                                                              NaN   \n",
       "variables_latency_simulation_delay_max                                                                 0   \n",
       "model_architecture_total_params                                                               1100048384   \n",
       "gpu_utilization_percent_3                                                                            1.0   \n",
       "variables_latency_simulation_delay_min                                                                 0   \n",
       "\n",
       "                                                                                                      1   \\\n",
       "config_name                                                                              num_processes_2   \n",
       "experiment_id                                                                                         13   \n",
       "experiment_id                                                                                         13   \n",
       "date_time                                                                  April 08, 2025 at 03:33:53 PM   \n",
       "model                                                                    AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                          4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                 False   \n",
       "task_type                                                                                text_generation   \n",
       "available_gpu_count                                                                                    4   \n",
       "available_cpu_count                                                                                  128   \n",
       "os                                                        Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                         3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                          Germany   \n",
       "region                                                                                            saxony   \n",
       "sharding_strategy                                                                               NO_SHARD   \n",
       "distributed_type                                                               DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                          2   \n",
       "max_input_tokens                                                                                     100   \n",
       "max_output_tokens                                                                                    100   \n",
       "number_input_prompts                                                                                  10   \n",
       "number_input_prompts                                                                                  10   \n",
       "decode_token_to_text                                                                                True   \n",
       "decoder_temperature                                                                                  1.0   \n",
       "decoder_top_k                                                                                          0   \n",
       "decoder_top_p                                                                                        0.0   \n",
       "query_rate                                                                                           1.0   \n",
       "fp_precision                                                                               torch.float32   \n",
       "quantization                                                                                       False   \n",
       "load_in_8bit                                                                                       False   \n",
       "load_in_4bit                                                                                       False   \n",
       "batch_size___fixed_batching                                                                           16   \n",
       "adaptive_batching                                                                                      0   \n",
       "adaptive_batching                                                                                  False   \n",
       "adaptive_max_tokens                                                                                    0   \n",
       "inference_type                                                                           pure_generative   \n",
       "backend                                                                                          pytorch   \n",
       "total_input_tokens                                                                                  1000   \n",
       "total_generated_tokens                                                                              1000   \n",
       "total_inference_time_sec                                                                        2.750908   \n",
       "average_latency_ms_per_batch                                                                 2750.908175   \n",
       "throughput_queries_per_sec                                                                      3.635163   \n",
       "throughput_tokens_per_sec                                                                     363.516314   \n",
       "flops                                                                                      1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                            8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                            13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                13203668992   \n",
       "cpu_usage_percent                                                                                   97.0   \n",
       "cpu_memory_usage_bytes                                                                        2070253568   \n",
       "cpu_power_process_0                                                                                112.5   \n",
       "cpu_power_process_1                                                                                112.5   \n",
       "cpu_power_process_2                                                                                  NaN   \n",
       "cpu_power_process_3                                                                                  NaN   \n",
       "gpu_power_process_0                                                                           596.486136   \n",
       "gpu_power_process_1                                                                           567.623977   \n",
       "gpu_power_process_2                                                                                  NaN   \n",
       "gpu_power_process_3                                                                                  NaN   \n",
       "ram_power_process_0                                                                             0.721713   \n",
       "ram_power_process_1                                                                             0.666942   \n",
       "ram_power_process_2                                                                                  NaN   \n",
       "ram_power_process_3                                                                                  NaN   \n",
       "cpu_energy_process_0                                                                            0.000095   \n",
       "cpu_energy_process_1                                                                            0.000116   \n",
       "cpu_energy_process_2                                                                                 NaN   \n",
       "cpu_energy_process_3                                                                                 NaN   \n",
       "gpu_energy_process_0                                                                            0.000375   \n",
       "gpu_energy_process_1                                                                            0.000482   \n",
       "gpu_energy_process_2                                                                                 NaN   \n",
       "gpu_energy_process_3                                                                                 NaN   \n",
       "ram_energy_process_0                                                                            0.000001   \n",
       "ram_energy_process_1                                                                            0.000001   \n",
       "ram_energy_process_2                                                                                 NaN   \n",
       "ram_energy_process_3                                                                                 NaN   \n",
       "total_energy_kwh_process_0                                                                       0.00047   \n",
       "total_energy_kwh_process_1                                                                      0.000599   \n",
       "total_energy_kwh_process_2                                                                           NaN   \n",
       "total_energy_kwh_process_3                                                                           NaN   \n",
       "total_energy_joules_process_0                                                                 1693.43267   \n",
       "total_energy_joules_process_1                                                                2154.670632   \n",
       "total_energy_joules_process_2                                                                        NaN   \n",
       "total_energy_joules_process_3                                                                        NaN   \n",
       "cpu_power_avg                                                                                      112.5   \n",
       "gpu_power_avg                                                                                 582.055057   \n",
       "ram_power_avg                                                                                   0.694327   \n",
       "cpu_energy_total                                                                                 0.00021   \n",
       "gpu_energy_total                                                                                0.000857   \n",
       "ram_energy_total                                                                                0.000001   \n",
       "total_energy_kwh                                                                                0.001069   \n",
       "total_energy_joules                                                                          3848.103302   \n",
       "tokens_per_joule                                                                                0.259868   \n",
       "joules_per_token                                                                                3.848103   \n",
       "flops_per_joule                                                                         268845206.817153   \n",
       "joules_per_flop                                                                                      0.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "per-process_emissions_1                                                                         0.000228   \n",
       "gpu_utilization_percent_2                                                                            0.0   \n",
       "gpu_utilization_percent_1                                                                          100.0   \n",
       "models                                                                                    82763530240000   \n",
       "variables_latency_simulation_simulate_burst                                                        False   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "variables_latency_simulation_burst_size                                                                0   \n",
       "per-process_emissions_2                                                                              NaN   \n",
       "model_architecture_architecture                                            Unknown (no config attribute)   \n",
       "variables_latency_simulation_burst_interval                                                          0.0   \n",
       "gpu_utilization_percent_0                                                                           11.0   \n",
       "per-process_emissions_0                                                                         0.000179   \n",
       "variables_latency_simulation_simulate                                                              False   \n",
       "per-process_emissions_3                                                                              NaN   \n",
       "variables_latency_simulation_delay_max                                                                 0   \n",
       "model_architecture_total_params                                                               1100048384   \n",
       "gpu_utilization_percent_3                                                                          100.0   \n",
       "variables_latency_simulation_delay_min                                                                 0   \n",
       "\n",
       "                                                                                                      2   \\\n",
       "config_name                                                                              num_processes_3   \n",
       "experiment_id                                                                                         14   \n",
       "experiment_id                                                                                         14   \n",
       "date_time                                                                  April 08, 2025 at 03:34:31 PM   \n",
       "model                                                                    AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                          4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                 False   \n",
       "task_type                                                                                text_generation   \n",
       "available_gpu_count                                                                                    4   \n",
       "available_cpu_count                                                                                  128   \n",
       "os                                                        Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                         3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                          Germany   \n",
       "region                                                                                            saxony   \n",
       "sharding_strategy                                                                               NO_SHARD   \n",
       "distributed_type                                                               DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                          3   \n",
       "max_input_tokens                                                                                     100   \n",
       "max_output_tokens                                                                                    100   \n",
       "number_input_prompts                                                                                  10   \n",
       "number_input_prompts                                                                                  10   \n",
       "decode_token_to_text                                                                                True   \n",
       "decoder_temperature                                                                                  1.0   \n",
       "decoder_top_k                                                                                          0   \n",
       "decoder_top_p                                                                                        0.0   \n",
       "query_rate                                                                                           1.0   \n",
       "fp_precision                                                                               torch.float32   \n",
       "quantization                                                                                       False   \n",
       "load_in_8bit                                                                                       False   \n",
       "load_in_4bit                                                                                       False   \n",
       "batch_size___fixed_batching                                                                           16   \n",
       "adaptive_batching                                                                                      0   \n",
       "adaptive_batching                                                                                  False   \n",
       "adaptive_max_tokens                                                                                    0   \n",
       "inference_type                                                                           pure_generative   \n",
       "backend                                                                                          pytorch   \n",
       "total_input_tokens                                                                                  1000   \n",
       "total_generated_tokens                                                                              1000   \n",
       "total_inference_time_sec                                                                        2.740259   \n",
       "average_latency_ms_per_batch                                                                 2740.258832   \n",
       "throughput_queries_per_sec                                                                       3.64929   \n",
       "throughput_tokens_per_sec                                                                     364.929031   \n",
       "flops                                                                                      1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                            8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                            13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                13203668992   \n",
       "cpu_usage_percent                                                                                   96.6   \n",
       "cpu_memory_usage_bytes                                                                        2070421504   \n",
       "cpu_power_process_0                                                                                112.5   \n",
       "cpu_power_process_1                                                                                112.5   \n",
       "cpu_power_process_2                                                                                112.5   \n",
       "cpu_power_process_3                                                                                  NaN   \n",
       "gpu_power_process_0                                                                           718.703111   \n",
       "gpu_power_process_1                                                                           684.317281   \n",
       "gpu_power_process_2                                                                           709.778828   \n",
       "gpu_power_process_3                                                                                  NaN   \n",
       "ram_power_process_0                                                                             0.720606   \n",
       "ram_power_process_1                                                                             0.669265   \n",
       "ram_power_process_2                                                                             0.666395   \n",
       "ram_power_process_3                                                                                  NaN   \n",
       "cpu_energy_process_0                                                                            0.000134   \n",
       "cpu_energy_process_1                                                                            0.000135   \n",
       "cpu_energy_process_2                                                                            0.000099   \n",
       "cpu_energy_process_3                                                                                 NaN   \n",
       "gpu_energy_process_0                                                                            0.000581   \n",
       "gpu_energy_process_1                                                                            0.000759   \n",
       "gpu_energy_process_2                                                                            0.000569   \n",
       "gpu_energy_process_3                                                                                 NaN   \n",
       "ram_energy_process_0                                                                            0.000001   \n",
       "ram_energy_process_1                                                                            0.000001   \n",
       "ram_energy_process_2                                                                            0.000001   \n",
       "ram_energy_process_3                                                                                 NaN   \n",
       "total_energy_kwh_process_0                                                                      0.000716   \n",
       "total_energy_kwh_process_1                                                                      0.000894   \n",
       "total_energy_kwh_process_2                                                                      0.000669   \n",
       "total_energy_kwh_process_3                                                                           NaN   \n",
       "total_energy_joules_process_0                                                                2576.391109   \n",
       "total_energy_joules_process_1                                                                3219.985638   \n",
       "total_energy_joules_process_2                                                                2407.301886   \n",
       "total_energy_joules_process_3                                                                        NaN   \n",
       "cpu_power_avg                                                                                      112.5   \n",
       "gpu_power_avg                                                                                 704.266407   \n",
       "ram_power_avg                                                                                   0.685422   \n",
       "cpu_energy_total                                                                                0.000367   \n",
       "gpu_energy_total                                                                                 0.00191   \n",
       "ram_energy_total                                                                                0.000002   \n",
       "total_energy_kwh                                                                                0.002279   \n",
       "total_energy_joules                                                                          8203.678633   \n",
       "tokens_per_joule                                                                                0.121897   \n",
       "joules_per_token                                                                                8.203679   \n",
       "flops_per_joule                                                                         126107344.561251   \n",
       "joules_per_flop                                                                                      0.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "per-process_emissions_1                                                                         0.000255   \n",
       "gpu_utilization_percent_2                                                                          100.0   \n",
       "gpu_utilization_percent_1                                                                          100.0   \n",
       "models                                                                                    82763530240000   \n",
       "variables_latency_simulation_simulate_burst                                                        False   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "variables_latency_simulation_burst_size                                                                0   \n",
       "per-process_emissions_2                                                                         0.000341   \n",
       "model_architecture_architecture                                            Unknown (no config attribute)   \n",
       "variables_latency_simulation_burst_interval                                                          0.0   \n",
       "gpu_utilization_percent_0                                                                           17.0   \n",
       "per-process_emissions_0                                                                         0.000273   \n",
       "variables_latency_simulation_simulate                                                              False   \n",
       "per-process_emissions_3                                                                              NaN   \n",
       "variables_latency_simulation_delay_max                                                                 0   \n",
       "model_architecture_total_params                                                               1100048384   \n",
       "gpu_utilization_percent_3                                                                          100.0   \n",
       "variables_latency_simulation_delay_min                                                                 0   \n",
       "\n",
       "                                                                                                      3   \\\n",
       "config_name                                                                              num_processes_4   \n",
       "experiment_id                                                                                         15   \n",
       "experiment_id                                                                                         15   \n",
       "date_time                                                                  April 08, 2025 at 03:35:12 PM   \n",
       "model                                                                    AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                          4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                 False   \n",
       "task_type                                                                                text_generation   \n",
       "available_gpu_count                                                                                    4   \n",
       "available_cpu_count                                                                                  128   \n",
       "os                                                        Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                         3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                          Germany   \n",
       "region                                                                                            saxony   \n",
       "sharding_strategy                                                                               NO_SHARD   \n",
       "distributed_type                                                               DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                          4   \n",
       "max_input_tokens                                                                                     100   \n",
       "max_output_tokens                                                                                    100   \n",
       "number_input_prompts                                                                                  10   \n",
       "number_input_prompts                                                                                  10   \n",
       "decode_token_to_text                                                                                True   \n",
       "decoder_temperature                                                                                  1.0   \n",
       "decoder_top_k                                                                                          0   \n",
       "decoder_top_p                                                                                        0.0   \n",
       "query_rate                                                                                           1.0   \n",
       "fp_precision                                                                               torch.float32   \n",
       "quantization                                                                                       False   \n",
       "load_in_8bit                                                                                       False   \n",
       "load_in_4bit                                                                                       False   \n",
       "batch_size___fixed_batching                                                                           16   \n",
       "adaptive_batching                                                                                      0   \n",
       "adaptive_batching                                                                                  False   \n",
       "adaptive_max_tokens                                                                                    0   \n",
       "inference_type                                                                           pure_generative   \n",
       "backend                                                                                          pytorch   \n",
       "total_input_tokens                                                                                  1000   \n",
       "total_generated_tokens                                                                              1000   \n",
       "total_inference_time_sec                                                                        2.831569   \n",
       "average_latency_ms_per_batch                                                                  2831.56897   \n",
       "throughput_queries_per_sec                                                                      3.531611   \n",
       "throughput_tokens_per_sec                                                                     353.161096   \n",
       "flops                                                                                      1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                            8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                            13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                13203668992   \n",
       "cpu_usage_percent                                                                                   95.8   \n",
       "cpu_memory_usage_bytes                                                                        2070048768   \n",
       "cpu_power_process_0                                                                                112.5   \n",
       "cpu_power_process_1                                                                                112.5   \n",
       "cpu_power_process_2                                                                                112.5   \n",
       "cpu_power_process_3                                                                                112.5   \n",
       "gpu_power_process_0                                                                           718.451461   \n",
       "gpu_power_process_1                                                                           923.653844   \n",
       "gpu_power_process_2                                                                           725.446645   \n",
       "gpu_power_process_3                                                                           644.874559   \n",
       "ram_power_process_0                                                                              0.72155   \n",
       "ram_power_process_1                                                                             0.667773   \n",
       "ram_power_process_2                                                                             0.672336   \n",
       "ram_power_process_3                                                                              0.67136   \n",
       "cpu_energy_process_0                                                                            0.000138   \n",
       "cpu_energy_process_1                                                                            0.000135   \n",
       "cpu_energy_process_2                                                                             0.00014   \n",
       "cpu_energy_process_3                                                                            0.000136   \n",
       "gpu_energy_process_0                                                                            0.000632   \n",
       "gpu_energy_process_1                                                                            0.000803   \n",
       "gpu_energy_process_2                                                                            0.000641   \n",
       "gpu_energy_process_3                                                                            0.000811   \n",
       "ram_energy_process_0                                                                            0.000001   \n",
       "ram_energy_process_1                                                                            0.000001   \n",
       "ram_energy_process_2                                                                            0.000001   \n",
       "ram_energy_process_3                                                                            0.000001   \n",
       "total_energy_kwh_process_0                                                                      0.000771   \n",
       "total_energy_kwh_process_1                                                                      0.000939   \n",
       "total_energy_kwh_process_2                                                                      0.000782   \n",
       "total_energy_kwh_process_3                                                                      0.000948   \n",
       "total_energy_joules_process_0                                                                2776.502046   \n",
       "total_energy_joules_process_1                                                                3379.992012   \n",
       "total_energy_joules_process_2                                                                2815.908501   \n",
       "total_energy_joules_process_3                                                                3412.892238   \n",
       "cpu_power_avg                                                                                      112.5   \n",
       "gpu_power_avg                                                                                 753.106627   \n",
       "ram_power_avg                                                                                   0.683255   \n",
       "cpu_energy_total                                                                                 0.00055   \n",
       "gpu_energy_total                                                                                0.002888   \n",
       "ram_energy_total                                                                                0.000003   \n",
       "total_energy_kwh                                                                                 0.00344   \n",
       "total_energy_joules                                                                         12385.294796   \n",
       "tokens_per_joule                                                                                0.080741   \n",
       "joules_per_token                                                                               12.385295   \n",
       "flops_per_joule                                                                          83530036.629457   \n",
       "joules_per_flop                                                                                      0.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "per-process_emissions_1                                                                         0.000294   \n",
       "gpu_utilization_percent_2                                                                          100.0   \n",
       "gpu_utilization_percent_1                                                                          100.0   \n",
       "models                                                                                    82763530240000   \n",
       "variables_latency_simulation_simulate_burst                                                        False   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "variables_latency_simulation_burst_size                                                                0   \n",
       "per-process_emissions_2                                                                         0.000358   \n",
       "model_architecture_architecture                                            Unknown (no config attribute)   \n",
       "variables_latency_simulation_burst_interval                                                          0.0   \n",
       "gpu_utilization_percent_0                                                                           35.0   \n",
       "per-process_emissions_0                                                                         0.000361   \n",
       "variables_latency_simulation_simulate                                                              False   \n",
       "per-process_emissions_3                                                                         0.000298   \n",
       "variables_latency_simulation_delay_max                                                                 0   \n",
       "model_architecture_total_params                                                               1100048384   \n",
       "gpu_utilization_percent_3                                                                          100.0   \n",
       "variables_latency_simulation_delay_min                                                                 0   \n",
       "\n",
       "                                                                                                      4   \\\n",
       "config_name                                                                                   batching_1   \n",
       "experiment_id                                                                                         16   \n",
       "experiment_id                                                                                         16   \n",
       "date_time                                                                  April 08, 2025 at 03:36:18 PM   \n",
       "model                                                                    AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                          4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                 False   \n",
       "task_type                                                                                text_generation   \n",
       "available_gpu_count                                                                                    4   \n",
       "available_cpu_count                                                                                  128   \n",
       "os                                                        Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                         3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                          Germany   \n",
       "region                                                                                            saxony   \n",
       "sharding_strategy                                                                               NO_SHARD   \n",
       "distributed_type                                                               DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                          4   \n",
       "max_input_tokens                                                                                     100   \n",
       "max_output_tokens                                                                                    100   \n",
       "number_input_prompts                                                                                  10   \n",
       "number_input_prompts                                                                                  10   \n",
       "decode_token_to_text                                                                                True   \n",
       "decoder_temperature                                                                                  1.0   \n",
       "decoder_top_k                                                                                          0   \n",
       "decoder_top_p                                                                                        0.0   \n",
       "query_rate                                                                                           1.0   \n",
       "fp_precision                                                                               torch.float32   \n",
       "quantization                                                                                       False   \n",
       "load_in_8bit                                                                                       False   \n",
       "load_in_4bit                                                                                       False   \n",
       "batch_size___fixed_batching                                                                            1   \n",
       "adaptive_batching                                                                                      0   \n",
       "adaptive_batching                                                                                  False   \n",
       "adaptive_max_tokens                                                                                    0   \n",
       "inference_type                                                                           pure_generative   \n",
       "backend                                                                                          pytorch   \n",
       "total_input_tokens                                                                                  1000   \n",
       "total_generated_tokens                                                                              1000   \n",
       "total_inference_time_sec                                                                       25.533837   \n",
       "average_latency_ms_per_batch                                                                 2553.383669   \n",
       "throughput_queries_per_sec                                                                      0.391637   \n",
       "throughput_tokens_per_sec                                                                      39.163719   \n",
       "flops                                                                                      1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                            8817967616   \n",
       "gpu_max_memory_allocated_bytes                                                                8817967616   \n",
       "gpu_current_memory_reserved_bytes                                                            13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                13203668992   \n",
       "cpu_usage_percent                                                                                    5.7   \n",
       "cpu_memory_usage_bytes                                                                        2028392448   \n",
       "cpu_power_process_0                                                                                112.5   \n",
       "cpu_power_process_1                                                                                112.5   \n",
       "cpu_power_process_2                                                                                112.5   \n",
       "cpu_power_process_3                                                                                112.5   \n",
       "gpu_power_process_0                                                                           660.505795   \n",
       "gpu_power_process_1                                                                           574.738216   \n",
       "gpu_power_process_2                                                                           573.384816   \n",
       "gpu_power_process_3                                                                             554.9442   \n",
       "ram_power_process_0                                                                             0.707112   \n",
       "ram_power_process_1                                                                             0.653126   \n",
       "ram_power_process_2                                                                             0.649677   \n",
       "ram_power_process_3                                                                             0.649996   \n",
       "cpu_energy_process_0                                                                             0.00081   \n",
       "cpu_energy_process_1                                                                            0.000924   \n",
       "cpu_energy_process_2                                                                            0.000799   \n",
       "cpu_energy_process_3                                                                            0.000922   \n",
       "gpu_energy_process_0                                                                             0.00377   \n",
       "gpu_energy_process_1                                                                            0.004234   \n",
       "gpu_energy_process_2                                                                             0.00373   \n",
       "gpu_energy_process_3                                                                            0.004235   \n",
       "ram_energy_process_0                                                                            0.000004   \n",
       "ram_energy_process_1                                                                            0.000004   \n",
       "ram_energy_process_2                                                                            0.000003   \n",
       "ram_energy_process_3                                                                            0.000004   \n",
       "total_energy_kwh_process_0                                                                      0.004584   \n",
       "total_energy_kwh_process_1                                                                      0.005162   \n",
       "total_energy_kwh_process_2                                                                      0.004532   \n",
       "total_energy_kwh_process_3                                                                      0.005162   \n",
       "total_energy_joules_process_0                                                               16501.500354   \n",
       "total_energy_joules_process_1                                                               18584.829356   \n",
       "total_energy_joules_process_2                                                               16315.533379   \n",
       "total_energy_joules_process_3                                                                18582.62481   \n",
       "cpu_power_avg                                                                                      112.5   \n",
       "gpu_power_avg                                                                                 590.893257   \n",
       "ram_power_avg                                                                                   0.664978   \n",
       "cpu_energy_total                                                                                0.003455   \n",
       "gpu_energy_total                                                                                0.015969   \n",
       "ram_energy_total                                                                                0.000016   \n",
       "total_energy_kwh                                                                                 0.01944   \n",
       "total_energy_joules                                                                         69984.487898   \n",
       "tokens_per_joule                                                                                0.014289   \n",
       "joules_per_token                                                                               69.984488   \n",
       "flops_per_joule                                                                          14782477.647264   \n",
       "joules_per_flop                                                                                      0.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "per-process_emissions_1                                                                         0.001967   \n",
       "gpu_utilization_percent_2                                                                           99.0   \n",
       "gpu_utilization_percent_1                                                                          100.0   \n",
       "models                                                                                    82763530240000   \n",
       "variables_latency_simulation_simulate_burst                                                        False   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "variables_latency_simulation_burst_size                                                                0   \n",
       "per-process_emissions_2                                                                         0.001746   \n",
       "model_architecture_architecture                                            Unknown (no config attribute)   \n",
       "variables_latency_simulation_burst_interval                                                          0.0   \n",
       "gpu_utilization_percent_0                                                                           11.0   \n",
       "per-process_emissions_0                                                                         0.001727   \n",
       "variables_latency_simulation_simulate                                                              False   \n",
       "per-process_emissions_3                                                                         0.001966   \n",
       "variables_latency_simulation_delay_max                                                                 0   \n",
       "model_architecture_total_params                                                               1100048384   \n",
       "gpu_utilization_percent_3                                                                          100.0   \n",
       "variables_latency_simulation_delay_min                                                                 0   \n",
       "\n",
       "                                                                                                      5   \\\n",
       "config_name                                                                                   batching_2   \n",
       "experiment_id                                                                                         17   \n",
       "experiment_id                                                                                         17   \n",
       "date_time                                                                  April 08, 2025 at 03:37:11 PM   \n",
       "model                                                                    AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                          4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                 False   \n",
       "task_type                                                                                text_generation   \n",
       "available_gpu_count                                                                                    4   \n",
       "available_cpu_count                                                                                  128   \n",
       "os                                                        Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                         3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                          Germany   \n",
       "region                                                                                            saxony   \n",
       "sharding_strategy                                                                               NO_SHARD   \n",
       "distributed_type                                                               DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                          4   \n",
       "max_input_tokens                                                                                     100   \n",
       "max_output_tokens                                                                                    100   \n",
       "number_input_prompts                                                                                  10   \n",
       "number_input_prompts                                                                                  10   \n",
       "decode_token_to_text                                                                                True   \n",
       "decoder_temperature                                                                                  1.0   \n",
       "decoder_top_k                                                                                          0   \n",
       "decoder_top_p                                                                                        0.0   \n",
       "query_rate                                                                                           1.0   \n",
       "fp_precision                                                                               torch.float32   \n",
       "quantization                                                                                       False   \n",
       "load_in_8bit                                                                                       False   \n",
       "load_in_4bit                                                                                       False   \n",
       "batch_size___fixed_batching                                                                            2   \n",
       "adaptive_batching                                                                                      0   \n",
       "adaptive_batching                                                                                  False   \n",
       "adaptive_max_tokens                                                                                    0   \n",
       "inference_type                                                                           pure_generative   \n",
       "backend                                                                                          pytorch   \n",
       "total_input_tokens                                                                                  1000   \n",
       "total_generated_tokens                                                                              1000   \n",
       "total_inference_time_sec                                                                       13.109935   \n",
       "average_latency_ms_per_batch                                                                 2621.987081   \n",
       "throughput_queries_per_sec                                                                       0.76278   \n",
       "throughput_tokens_per_sec                                                                      76.278026   \n",
       "flops                                                                                      1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                            8817965056   \n",
       "gpu_max_memory_allocated_bytes                                                                8817965056   \n",
       "gpu_current_memory_reserved_bytes                                                            13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                13203668992   \n",
       "cpu_usage_percent                                                                                   96.7   \n",
       "cpu_memory_usage_bytes                                                                        2043359232   \n",
       "cpu_power_process_0                                                                                112.5   \n",
       "cpu_power_process_1                                                                                112.5   \n",
       "cpu_power_process_2                                                                                112.5   \n",
       "cpu_power_process_3                                                                                112.5   \n",
       "gpu_power_process_0                                                                           658.195478   \n",
       "gpu_power_process_1                                                                           540.067306   \n",
       "gpu_power_process_2                                                                           891.398237   \n",
       "gpu_power_process_3                                                                           627.303129   \n",
       "ram_power_process_0                                                                             0.711908   \n",
       "ram_power_process_1                                                                             0.655879   \n",
       "ram_power_process_2                                                                             0.656283   \n",
       "ram_power_process_3                                                                               0.6606   \n",
       "cpu_energy_process_0                                                                            0.000417   \n",
       "cpu_energy_process_1                                                                             0.00052   \n",
       "cpu_energy_process_2                                                                            0.000413   \n",
       "cpu_energy_process_3                                                                            0.000505   \n",
       "gpu_energy_process_0                                                                            0.002281   \n",
       "gpu_energy_process_1                                                                            0.002816   \n",
       "gpu_energy_process_2                                                                            0.002245   \n",
       "gpu_energy_process_3                                                                            0.002739   \n",
       "ram_energy_process_0                                                                            0.000002   \n",
       "ram_energy_process_1                                                                            0.000002   \n",
       "ram_energy_process_2                                                                            0.000002   \n",
       "ram_energy_process_3                                                                            0.000002   \n",
       "total_energy_kwh_process_0                                                                        0.0027   \n",
       "total_energy_kwh_process_1                                                                      0.003339   \n",
       "total_energy_kwh_process_2                                                                       0.00266   \n",
       "total_energy_kwh_process_3                                                                      0.003246   \n",
       "total_energy_joules_process_0                                                                9721.793407   \n",
       "total_energy_joules_process_1                                                               12018.727177   \n",
       "total_energy_joules_process_2                                                                9574.828386   \n",
       "total_energy_joules_process_3                                                               11686.985166   \n",
       "cpu_power_avg                                                                                      112.5   \n",
       "gpu_power_avg                                                                                 679.241038   \n",
       "ram_power_avg                                                                                   0.671168   \n",
       "cpu_energy_total                                                                                0.001854   \n",
       "gpu_energy_total                                                                                0.010082   \n",
       "ram_energy_total                                                                                0.000009   \n",
       "total_energy_kwh                                                                                0.011945   \n",
       "total_energy_joules                                                                         43002.334136   \n",
       "tokens_per_joule                                                                                0.023255   \n",
       "joules_per_token                                                                               43.002334   \n",
       "flops_per_joule                                                                           24057859.85308   \n",
       "joules_per_flop                                                                                      0.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "per-process_emissions_1                                                                         0.001237   \n",
       "gpu_utilization_percent_2                                                                          100.0   \n",
       "gpu_utilization_percent_1                                                                          100.0   \n",
       "models                                                                                    82763530240000   \n",
       "variables_latency_simulation_simulate_burst                                                        False   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "variables_latency_simulation_burst_size                                                                0   \n",
       "per-process_emissions_2                                                                         0.001272   \n",
       "model_architecture_architecture                                            Unknown (no config attribute)   \n",
       "variables_latency_simulation_burst_interval                                                          0.0   \n",
       "gpu_utilization_percent_0                                                                           11.0   \n",
       "per-process_emissions_0                                                                         0.001029   \n",
       "variables_latency_simulation_simulate                                                              False   \n",
       "per-process_emissions_3                                                                         0.001013   \n",
       "variables_latency_simulation_delay_max                                                                 0   \n",
       "model_architecture_total_params                                                               1100048384   \n",
       "gpu_utilization_percent_3                                                                          100.0   \n",
       "variables_latency_simulation_delay_min                                                                 0   \n",
       "\n",
       "                                                                                                      6   \\\n",
       "config_name                                                                                   batching_4   \n",
       "experiment_id                                                                                         18   \n",
       "experiment_id                                                                                         18   \n",
       "date_time                                                                  April 08, 2025 at 03:37:57 PM   \n",
       "model                                                                    AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                          4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                 False   \n",
       "task_type                                                                                text_generation   \n",
       "available_gpu_count                                                                                    4   \n",
       "available_cpu_count                                                                                  128   \n",
       "os                                                        Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                         3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                          Germany   \n",
       "region                                                                                            saxony   \n",
       "sharding_strategy                                                                               NO_SHARD   \n",
       "distributed_type                                                               DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                          4   \n",
       "max_input_tokens                                                                                     100   \n",
       "max_output_tokens                                                                                    100   \n",
       "number_input_prompts                                                                                  10   \n",
       "number_input_prompts                                                                                  10   \n",
       "decode_token_to_text                                                                                True   \n",
       "decoder_temperature                                                                                  1.0   \n",
       "decoder_top_k                                                                                          0   \n",
       "decoder_top_p                                                                                        0.0   \n",
       "query_rate                                                                                           1.0   \n",
       "fp_precision                                                                               torch.float32   \n",
       "quantization                                                                                       False   \n",
       "load_in_8bit                                                                                       False   \n",
       "load_in_4bit                                                                                       False   \n",
       "batch_size___fixed_batching                                                                            4   \n",
       "adaptive_batching                                                                                      0   \n",
       "adaptive_batching                                                                                  False   \n",
       "adaptive_max_tokens                                                                                    0   \n",
       "inference_type                                                                           pure_generative   \n",
       "backend                                                                                          pytorch   \n",
       "total_input_tokens                                                                                  1000   \n",
       "total_generated_tokens                                                                              1000   \n",
       "total_inference_time_sec                                                                         7.83752   \n",
       "average_latency_ms_per_batch                                                                 2612.506737   \n",
       "throughput_queries_per_sec                                                                      1.275914   \n",
       "throughput_tokens_per_sec                                                                     127.591378   \n",
       "flops                                                                                      1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                            8817964032   \n",
       "gpu_max_memory_allocated_bytes                                                                8817964032   \n",
       "gpu_current_memory_reserved_bytes                                                            13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                13203668992   \n",
       "cpu_usage_percent                                                                                   96.4   \n",
       "cpu_memory_usage_bytes                                                                        2052145152   \n",
       "cpu_power_process_0                                                                                112.5   \n",
       "cpu_power_process_1                                                                                112.5   \n",
       "cpu_power_process_2                                                                                112.5   \n",
       "cpu_power_process_3                                                                                112.5   \n",
       "gpu_power_process_0                                                                           342.389902   \n",
       "gpu_power_process_1                                                                           393.608731   \n",
       "gpu_power_process_2                                                                           867.352571   \n",
       "gpu_power_process_3                                                                           524.128197   \n",
       "ram_power_process_0                                                                             0.715374   \n",
       "ram_power_process_1                                                                             0.662511   \n",
       "ram_power_process_2                                                                             0.665329   \n",
       "ram_power_process_3                                                                             0.665155   \n",
       "cpu_energy_process_0                                                                            0.000257   \n",
       "cpu_energy_process_1                                                                            0.000326   \n",
       "cpu_energy_process_2                                                                            0.000257   \n",
       "cpu_energy_process_3                                                                            0.000319   \n",
       "gpu_energy_process_0                                                                            0.001476   \n",
       "gpu_energy_process_1                                                                            0.001786   \n",
       "gpu_energy_process_2                                                                            0.001489   \n",
       "gpu_energy_process_3                                                                            0.001767   \n",
       "ram_energy_process_0                                                                            0.000001   \n",
       "ram_energy_process_1                                                                            0.000001   \n",
       "ram_energy_process_2                                                                            0.000001   \n",
       "ram_energy_process_3                                                                            0.000002   \n",
       "total_energy_kwh_process_0                                                                      0.001735   \n",
       "total_energy_kwh_process_1                                                                      0.002114   \n",
       "total_energy_kwh_process_2                                                                      0.001747   \n",
       "total_energy_kwh_process_3                                                                      0.002088   \n",
       "total_energy_joules_process_0                                                                6245.397479   \n",
       "total_energy_joules_process_1                                                                7608.657866   \n",
       "total_energy_joules_process_2                                                                6288.649164   \n",
       "total_energy_joules_process_3                                                                7516.518942   \n",
       "cpu_power_avg                                                                                      112.5   \n",
       "gpu_power_avg                                                                                  531.86985   \n",
       "ram_power_avg                                                                                   0.677093   \n",
       "cpu_energy_total                                                                                0.001159   \n",
       "gpu_energy_total                                                                                0.006518   \n",
       "ram_energy_total                                                                                0.000006   \n",
       "total_energy_kwh                                                                                0.007683   \n",
       "total_energy_joules                                                                         27659.223452   \n",
       "tokens_per_joule                                                                                0.036154   \n",
       "joules_per_token                                                                               27.659223   \n",
       "flops_per_joule                                                                          37403223.912325   \n",
       "joules_per_flop                                                                                      0.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "per-process_emissions_1                                                                         0.000665   \n",
       "gpu_utilization_percent_2                                                                           98.0   \n",
       "gpu_utilization_percent_1                                                                           49.0   \n",
       "models                                                                                    82763530240000   \n",
       "variables_latency_simulation_simulate_burst                                                        False   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "variables_latency_simulation_burst_size                                                                0   \n",
       "per-process_emissions_2                                                                         0.000661   \n",
       "model_architecture_architecture                                            Unknown (no config attribute)   \n",
       "variables_latency_simulation_burst_interval                                                          0.0   \n",
       "gpu_utilization_percent_0                                                                           11.0   \n",
       "per-process_emissions_0                                                                         0.000805   \n",
       "variables_latency_simulation_simulate                                                              False   \n",
       "per-process_emissions_3                                                                         0.000795   \n",
       "variables_latency_simulation_delay_max                                                                 0   \n",
       "model_architecture_total_params                                                               1100048384   \n",
       "gpu_utilization_percent_3                                                                          100.0   \n",
       "variables_latency_simulation_delay_min                                                                 0   \n",
       "\n",
       "                                                                                                      7   \\\n",
       "config_name                                                                                   batching_8   \n",
       "experiment_id                                                                                         19   \n",
       "experiment_id                                                                                         19   \n",
       "date_time                                                                  April 08, 2025 at 03:38:41 PM   \n",
       "model                                                                    AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                          4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                 False   \n",
       "task_type                                                                                text_generation   \n",
       "available_gpu_count                                                                                    4   \n",
       "available_cpu_count                                                                                  128   \n",
       "os                                                        Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                         3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                          Germany   \n",
       "region                                                                                            saxony   \n",
       "sharding_strategy                                                                               NO_SHARD   \n",
       "distributed_type                                                               DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                          4   \n",
       "max_input_tokens                                                                                     100   \n",
       "max_output_tokens                                                                                    100   \n",
       "number_input_prompts                                                                                  10   \n",
       "number_input_prompts                                                                                  10   \n",
       "decode_token_to_text                                                                                True   \n",
       "decoder_temperature                                                                                  1.0   \n",
       "decoder_top_k                                                                                          0   \n",
       "decoder_top_p                                                                                        0.0   \n",
       "query_rate                                                                                           1.0   \n",
       "fp_precision                                                                               torch.float32   \n",
       "quantization                                                                                       False   \n",
       "load_in_8bit                                                                                       False   \n",
       "load_in_4bit                                                                                       False   \n",
       "batch_size___fixed_batching                                                                            8   \n",
       "adaptive_batching                                                                                      0   \n",
       "adaptive_batching                                                                                  False   \n",
       "adaptive_max_tokens                                                                                    0   \n",
       "inference_type                                                                           pure_generative   \n",
       "backend                                                                                          pytorch   \n",
       "total_input_tokens                                                                                  1000   \n",
       "total_generated_tokens                                                                              1000   \n",
       "total_inference_time_sec                                                                        5.270889   \n",
       "average_latency_ms_per_batch                                                                 2635.444515   \n",
       "throughput_queries_per_sec                                                                      1.897213   \n",
       "throughput_tokens_per_sec                                                                     189.721315   \n",
       "flops                                                                                      1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                            8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                            13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                13203668992   \n",
       "cpu_usage_percent                                                                                   96.4   \n",
       "cpu_memory_usage_bytes                                                                        2056445952   \n",
       "cpu_power_process_0                                                                                112.5   \n",
       "cpu_power_process_1                                                                                112.5   \n",
       "cpu_power_process_2                                                                                112.5   \n",
       "cpu_power_process_3                                                                                112.5   \n",
       "gpu_power_process_0                                                                           617.829628   \n",
       "gpu_power_process_1                                                                           524.097376   \n",
       "gpu_power_process_2                                                                           657.727491   \n",
       "gpu_power_process_3                                                                           594.976599   \n",
       "ram_power_process_0                                                                             0.716846   \n",
       "ram_power_process_1                                                                             0.666889   \n",
       "ram_power_process_2                                                                             0.664709   \n",
       "ram_power_process_3                                                                             0.665131   \n",
       "cpu_energy_process_0                                                                            0.000175   \n",
       "cpu_energy_process_1                                                                             0.00024   \n",
       "cpu_energy_process_2                                                                            0.000178   \n",
       "cpu_energy_process_3                                                                            0.000209   \n",
       "gpu_energy_process_0                                                                            0.000994   \n",
       "gpu_energy_process_1                                                                            0.001318   \n",
       "gpu_energy_process_2                                                                            0.001011   \n",
       "gpu_energy_process_3                                                                            0.001176   \n",
       "ram_energy_process_0                                                                            0.000001   \n",
       "ram_energy_process_1                                                                            0.000001   \n",
       "ram_energy_process_2                                                                            0.000001   \n",
       "ram_energy_process_3                                                                            0.000001   \n",
       "total_energy_kwh_process_0                                                                      0.001169   \n",
       "total_energy_kwh_process_1                                                                      0.001558   \n",
       "total_energy_kwh_process_2                                                                      0.001191   \n",
       "total_energy_kwh_process_3                                                                      0.001386   \n",
       "total_energy_joules_process_0                                                                4209.217521   \n",
       "total_energy_joules_process_1                                                                5609.708303   \n",
       "total_energy_joules_process_2                                                                4286.453548   \n",
       "total_energy_joules_process_3                                                                4987.917806   \n",
       "cpu_power_avg                                                                                      112.5   \n",
       "gpu_power_avg                                                                                 598.657774   \n",
       "ram_power_avg                                                                                   0.678394   \n",
       "cpu_energy_total                                                                                0.000801   \n",
       "gpu_energy_total                                                                                0.004498   \n",
       "ram_energy_total                                                                                0.000004   \n",
       "total_energy_kwh                                                                                0.005304   \n",
       "total_energy_joules                                                                         19093.297178   \n",
       "tokens_per_joule                                                                                0.052374   \n",
       "joules_per_token                                                                               19.093297   \n",
       "flops_per_joule                                                                           54183628.86052   \n",
       "joules_per_flop                                                                                      0.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "per-process_emissions_1                                                                         0.000528   \n",
       "gpu_utilization_percent_2                                                                          100.0   \n",
       "gpu_utilization_percent_1                                                                          100.0   \n",
       "models                                                                                    82763530240000   \n",
       "variables_latency_simulation_simulate_burst                                                        False   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "variables_latency_simulation_burst_size                                                                0   \n",
       "per-process_emissions_2                                                                         0.000454   \n",
       "model_architecture_architecture                                            Unknown (no config attribute)   \n",
       "variables_latency_simulation_burst_interval                                                          0.0   \n",
       "gpu_utilization_percent_0                                                                           10.0   \n",
       "per-process_emissions_0                                                                         0.000594   \n",
       "variables_latency_simulation_simulate                                                              False   \n",
       "per-process_emissions_3                                                                         0.000445   \n",
       "variables_latency_simulation_delay_max                                                                 0   \n",
       "model_architecture_total_params                                                               1100048384   \n",
       "gpu_utilization_percent_3                                                                          100.0   \n",
       "variables_latency_simulation_delay_min                                                                 0   \n",
       "\n",
       "                                                                                                      8   \\\n",
       "config_name                                                                                  batching_16   \n",
       "experiment_id                                                                                         20   \n",
       "experiment_id                                                                                         20   \n",
       "date_time                                                                  April 08, 2025 at 03:39:20 PM   \n",
       "model                                                                    AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                          4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                 False   \n",
       "task_type                                                                                text_generation   \n",
       "available_gpu_count                                                                                    4   \n",
       "available_cpu_count                                                                                  128   \n",
       "os                                                        Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                         3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                          Germany   \n",
       "region                                                                                            saxony   \n",
       "sharding_strategy                                                                               NO_SHARD   \n",
       "distributed_type                                                               DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                          4   \n",
       "max_input_tokens                                                                                     100   \n",
       "max_output_tokens                                                                                    100   \n",
       "number_input_prompts                                                                                  10   \n",
       "number_input_prompts                                                                                  10   \n",
       "decode_token_to_text                                                                                True   \n",
       "decoder_temperature                                                                                  1.0   \n",
       "decoder_top_k                                                                                          0   \n",
       "decoder_top_p                                                                                        0.0   \n",
       "query_rate                                                                                           1.0   \n",
       "fp_precision                                                                               torch.float32   \n",
       "quantization                                                                                       False   \n",
       "load_in_8bit                                                                                       False   \n",
       "load_in_4bit                                                                                       False   \n",
       "batch_size___fixed_batching                                                                           16   \n",
       "adaptive_batching                                                                                      0   \n",
       "adaptive_batching                                                                                  False   \n",
       "adaptive_max_tokens                                                                                    0   \n",
       "inference_type                                                                           pure_generative   \n",
       "backend                                                                                          pytorch   \n",
       "total_input_tokens                                                                                  1000   \n",
       "total_generated_tokens                                                                              1000   \n",
       "total_inference_time_sec                                                                        2.467701   \n",
       "average_latency_ms_per_batch                                                                  2467.70092   \n",
       "throughput_queries_per_sec                                                                      4.052355   \n",
       "throughput_tokens_per_sec                                                                     405.235493   \n",
       "flops                                                                                      1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                            8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                            13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                13203668992   \n",
       "cpu_usage_percent                                                                                   13.6   \n",
       "cpu_memory_usage_bytes                                                                        2069643264   \n",
       "cpu_power_process_0                                                                                112.5   \n",
       "cpu_power_process_1                                                                                112.5   \n",
       "cpu_power_process_2                                                                                112.5   \n",
       "cpu_power_process_3                                                                                112.5   \n",
       "gpu_power_process_0                                                                           732.434642   \n",
       "gpu_power_process_1                                                                           612.755977   \n",
       "gpu_power_process_2                                                                           692.528586   \n",
       "gpu_power_process_3                                                                           520.007484   \n",
       "ram_power_process_0                                                                             0.720756   \n",
       "ram_power_process_1                                                                             0.672183   \n",
       "ram_power_process_2                                                                             0.674549   \n",
       "ram_power_process_3                                                                             0.671853   \n",
       "cpu_energy_process_0                                                                            0.000082   \n",
       "cpu_energy_process_1                                                                            0.000102   \n",
       "cpu_energy_process_2                                                                            0.000081   \n",
       "cpu_energy_process_3                                                                            0.000104   \n",
       "gpu_energy_process_0                                                                            0.000486   \n",
       "gpu_energy_process_1                                                                            0.000571   \n",
       "gpu_energy_process_2                                                                            0.000482   \n",
       "gpu_energy_process_3                                                                            0.000585   \n",
       "ram_energy_process_0                                                                                 0.0   \n",
       "ram_energy_process_1                                                                            0.000001   \n",
       "ram_energy_process_2                                                                                 0.0   \n",
       "ram_energy_process_3                                                                            0.000001   \n",
       "total_energy_kwh_process_0                                                                      0.000568   \n",
       "total_energy_kwh_process_1                                                                      0.000674   \n",
       "total_energy_kwh_process_2                                                                      0.000564   \n",
       "total_energy_kwh_process_3                                                                      0.000689   \n",
       "total_energy_joules_process_0                                                                2044.749377   \n",
       "total_energy_joules_process_1                                                                2425.735696   \n",
       "total_energy_joules_process_2                                                                2029.018626   \n",
       "total_energy_joules_process_3                                                                2482.115181   \n",
       "cpu_power_avg                                                                                      112.5   \n",
       "gpu_power_avg                                                                                 639.431672   \n",
       "ram_power_avg                                                                                   0.684835   \n",
       "cpu_energy_total                                                                                0.000369   \n",
       "gpu_energy_total                                                                                0.002124   \n",
       "ram_energy_total                                                                                0.000002   \n",
       "total_energy_kwh                                                                                0.002495   \n",
       "total_energy_joules                                                                           8981.61888   \n",
       "tokens_per_joule                                                                                0.111339   \n",
       "joules_per_token                                                                                8.981619   \n",
       "flops_per_joule                                                                         115184594.427958   \n",
       "joules_per_flop                                                                                      0.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "per-process_emissions_1                                                                         0.000216   \n",
       "gpu_utilization_percent_2                                                                          100.0   \n",
       "gpu_utilization_percent_1                                                                           85.0   \n",
       "models                                                                                    82763530240000   \n",
       "variables_latency_simulation_simulate_burst                                                        False   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "variables_latency_simulation_burst_size                                                                0   \n",
       "per-process_emissions_2                                                                         0.000257   \n",
       "model_architecture_architecture                                            Unknown (no config attribute)   \n",
       "variables_latency_simulation_burst_interval                                                          0.0   \n",
       "gpu_utilization_percent_0                                                                           11.0   \n",
       "per-process_emissions_0                                                                         0.000263   \n",
       "variables_latency_simulation_simulate                                                              False   \n",
       "per-process_emissions_3                                                                         0.000215   \n",
       "variables_latency_simulation_delay_max                                                                 0   \n",
       "model_architecture_total_params                                                               1100048384   \n",
       "gpu_utilization_percent_3                                                                          100.0   \n",
       "variables_latency_simulation_delay_min                                                                 0   \n",
       "\n",
       "                                                                                                      9   \\\n",
       "config_name                                                                                  batching_32   \n",
       "experiment_id                                                                                         21   \n",
       "experiment_id                                                                                         21   \n",
       "date_time                                                                  April 08, 2025 at 03:39:55 PM   \n",
       "model                                                                    AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                          4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                 False   \n",
       "task_type                                                                                text_generation   \n",
       "available_gpu_count                                                                                    4   \n",
       "available_cpu_count                                                                                  128   \n",
       "os                                                        Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                         3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                          Germany   \n",
       "region                                                                                            saxony   \n",
       "sharding_strategy                                                                               NO_SHARD   \n",
       "distributed_type                                                               DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                          4   \n",
       "max_input_tokens                                                                                     100   \n",
       "max_output_tokens                                                                                    100   \n",
       "number_input_prompts                                                                                  10   \n",
       "number_input_prompts                                                                                  10   \n",
       "decode_token_to_text                                                                                True   \n",
       "decoder_temperature                                                                                  1.0   \n",
       "decoder_top_k                                                                                          0   \n",
       "decoder_top_p                                                                                        0.0   \n",
       "query_rate                                                                                           1.0   \n",
       "fp_precision                                                                               torch.float32   \n",
       "quantization                                                                                       False   \n",
       "load_in_8bit                                                                                       False   \n",
       "load_in_4bit                                                                                       False   \n",
       "batch_size___fixed_batching                                                                           32   \n",
       "adaptive_batching                                                                                      0   \n",
       "adaptive_batching                                                                                  False   \n",
       "adaptive_max_tokens                                                                                    0   \n",
       "inference_type                                                                           pure_generative   \n",
       "backend                                                                                          pytorch   \n",
       "total_input_tokens                                                                                  1000   \n",
       "total_generated_tokens                                                                              1000   \n",
       "total_inference_time_sec                                                                        2.880436   \n",
       "average_latency_ms_per_batch                                                                 2880.435904   \n",
       "throughput_queries_per_sec                                                                      3.471697   \n",
       "throughput_tokens_per_sec                                                                     347.169676   \n",
       "flops                                                                                      1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                            8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                            13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                13203668992   \n",
       "cpu_usage_percent                                                                                   96.2   \n",
       "cpu_memory_usage_bytes                                                                        2068746240   \n",
       "cpu_power_process_0                                                                                112.5   \n",
       "cpu_power_process_1                                                                                112.5   \n",
       "cpu_power_process_2                                                                                112.5   \n",
       "cpu_power_process_3                                                                                112.5   \n",
       "gpu_power_process_0                                                                           871.734093   \n",
       "gpu_power_process_1                                                                           525.181024   \n",
       "gpu_power_process_2                                                                          1114.343612   \n",
       "gpu_power_process_3                                                                           492.554528   \n",
       "ram_power_process_0                                                                             0.720925   \n",
       "ram_power_process_1                                                                             0.667015   \n",
       "ram_power_process_2                                                                             0.665015   \n",
       "ram_power_process_3                                                                             0.677226   \n",
       "cpu_energy_process_0                                                                            0.000099   \n",
       "cpu_energy_process_1                                                                            0.000108   \n",
       "cpu_energy_process_2                                                                            0.000103   \n",
       "cpu_energy_process_3                                                                            0.000126   \n",
       "gpu_energy_process_0                                                                            0.000547   \n",
       "gpu_energy_process_1                                                                            0.000583   \n",
       "gpu_energy_process_2                                                                            0.000566   \n",
       "gpu_energy_process_3                                                                            0.000658   \n",
       "ram_energy_process_0                                                                            0.000001   \n",
       "ram_energy_process_1                                                                            0.000001   \n",
       "ram_energy_process_2                                                                            0.000001   \n",
       "ram_energy_process_3                                                                            0.000001   \n",
       "total_energy_kwh_process_0                                                                      0.000647   \n",
       "total_energy_kwh_process_1                                                                      0.000691   \n",
       "total_energy_kwh_process_2                                                                       0.00067   \n",
       "total_energy_kwh_process_3                                                                      0.000784   \n",
       "total_energy_joules_process_0                                                                2327.593383   \n",
       "total_energy_joules_process_1                                                                2488.823218   \n",
       "total_energy_joules_process_2                                                                2411.356206   \n",
       "total_energy_joules_process_3                                                                 2823.20656   \n",
       "cpu_power_avg                                                                                      112.5   \n",
       "gpu_power_avg                                                                                 750.953314   \n",
       "ram_power_avg                                                                                   0.682545   \n",
       "cpu_energy_total                                                                                0.000435   \n",
       "gpu_energy_total                                                                                0.002355   \n",
       "ram_energy_total                                                                                0.000002   \n",
       "total_energy_kwh                                                                                0.002792   \n",
       "total_energy_joules                                                                         10050.979367   \n",
       "tokens_per_joule                                                                                0.099493   \n",
       "joules_per_token                                                                               10.050979   \n",
       "flops_per_joule                                                                         102929683.786364   \n",
       "joules_per_flop                                                                                      0.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "per-process_emissions_1                                                                         0.000299   \n",
       "gpu_utilization_percent_2                                                                           98.0   \n",
       "gpu_utilization_percent_1                                                                          100.0   \n",
       "models                                                                                    82763530240000   \n",
       "variables_latency_simulation_simulate_burst                                                        False   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "variables_latency_simulation_burst_size                                                                0   \n",
       "per-process_emissions_2                                                                         0.000246   \n",
       "model_architecture_architecture                                            Unknown (no config attribute)   \n",
       "variables_latency_simulation_burst_interval                                                          0.0   \n",
       "gpu_utilization_percent_0                                                                           11.0   \n",
       "per-process_emissions_0                                                                         0.000255   \n",
       "variables_latency_simulation_simulate                                                              False   \n",
       "per-process_emissions_3                                                                         0.000263   \n",
       "variables_latency_simulation_delay_max                                                                 0   \n",
       "model_architecture_total_params                                                               1100048384   \n",
       "gpu_utilization_percent_3                                                                           74.0   \n",
       "variables_latency_simulation_delay_min                                                                 0   \n",
       "\n",
       "                                                                                                      10  \n",
       "config_name                                                                                  batching_64  \n",
       "experiment_id                                                                                         22  \n",
       "experiment_id                                                                                         22  \n",
       "date_time                                                                  April 08, 2025 at 03:40:36 PM  \n",
       "model                                                                    AMD EPYC 7742 64-Core Processor  \n",
       "model                                                                          4 x NVIDIA A100-PCIE-40GB  \n",
       "model                                                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0  \n",
       "is_encoder_decoder                                                                                 False  \n",
       "task_type                                                                                text_generation  \n",
       "available_gpu_count                                                                                    4  \n",
       "available_cpu_count                                                                                  128  \n",
       "os                                                        Linux-5.15.0-113-generic-x86_64-with-glibc2.31  \n",
       "python_version                                         3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]  \n",
       "country                                                                                          Germany  \n",
       "region                                                                                            saxony  \n",
       "sharding_strategy                                                                               NO_SHARD  \n",
       "distributed_type                                                               DistributedType.MULTI_GPU  \n",
       "num_processes                                                                                          4  \n",
       "max_input_tokens                                                                                     100  \n",
       "max_output_tokens                                                                                    100  \n",
       "number_input_prompts                                                                                  10  \n",
       "number_input_prompts                                                                                  10  \n",
       "decode_token_to_text                                                                                True  \n",
       "decoder_temperature                                                                                  1.0  \n",
       "decoder_top_k                                                                                          0  \n",
       "decoder_top_p                                                                                        0.0  \n",
       "query_rate                                                                                           1.0  \n",
       "fp_precision                                                                               torch.float32  \n",
       "quantization                                                                                       False  \n",
       "load_in_8bit                                                                                       False  \n",
       "load_in_4bit                                                                                       False  \n",
       "batch_size___fixed_batching                                                                           64  \n",
       "adaptive_batching                                                                                      0  \n",
       "adaptive_batching                                                                                  False  \n",
       "adaptive_max_tokens                                                                                    0  \n",
       "inference_type                                                                           pure_generative  \n",
       "backend                                                                                          pytorch  \n",
       "total_input_tokens                                                                                  1000  \n",
       "total_generated_tokens                                                                              1000  \n",
       "total_inference_time_sec                                                                          2.9724  \n",
       "average_latency_ms_per_batch                                                                 2972.400019  \n",
       "throughput_queries_per_sec                                                                      3.364285  \n",
       "throughput_tokens_per_sec                                                                     336.428473  \n",
       "flops                                                                                      1034544128000  \n",
       "gpu_current_memory_allocated_bytes                                                            8817963520  \n",
       "gpu_max_memory_allocated_bytes                                                                8817963520  \n",
       "gpu_current_memory_reserved_bytes                                                            13203668992  \n",
       "gpu_max_memory_reserved_bytes                                                                13203668992  \n",
       "cpu_usage_percent                                                                                   96.3  \n",
       "cpu_memory_usage_bytes                                                                        2072772608  \n",
       "cpu_power_process_0                                                                                112.5  \n",
       "cpu_power_process_1                                                                                112.5  \n",
       "cpu_power_process_2                                                                                112.5  \n",
       "cpu_power_process_3                                                                                112.5  \n",
       "gpu_power_process_0                                                                           786.654447  \n",
       "gpu_power_process_1                                                                           321.005222  \n",
       "gpu_power_process_2                                                                           679.879288  \n",
       "gpu_power_process_3                                                                           596.931328  \n",
       "ram_power_process_0                                                                             0.722589  \n",
       "ram_power_process_1                                                                             0.667871  \n",
       "ram_power_process_2                                                                             0.668648  \n",
       "ram_power_process_3                                                                             0.672393  \n",
       "cpu_energy_process_0                                                                            0.000103  \n",
       "cpu_energy_process_1                                                                            0.000135  \n",
       "cpu_energy_process_2                                                                            0.000135  \n",
       "cpu_energy_process_3                                                                            0.000114  \n",
       "gpu_energy_process_0                                                                            0.000576  \n",
       "gpu_energy_process_1                                                                            0.000726  \n",
       "gpu_energy_process_2                                                                            0.000574  \n",
       "gpu_energy_process_3                                                                            0.000635  \n",
       "ram_energy_process_0                                                                            0.000001  \n",
       "ram_energy_process_1                                                                            0.000001  \n",
       "ram_energy_process_2                                                                            0.000001  \n",
       "ram_energy_process_3                                                                            0.000001  \n",
       "total_energy_kwh_process_0                                                                      0.000679  \n",
       "total_energy_kwh_process_1                                                                      0.000862  \n",
       "total_energy_kwh_process_2                                                                       0.00071  \n",
       "total_energy_kwh_process_3                                                                       0.00075  \n",
       "total_energy_joules_process_0                                                                2445.026163  \n",
       "total_energy_joules_process_1                                                                3103.378067  \n",
       "total_energy_joules_process_2                                                                2554.800499  \n",
       "total_energy_joules_process_3                                                                2699.624032  \n",
       "cpu_power_avg                                                                                      112.5  \n",
       "gpu_power_avg                                                                                 596.117571  \n",
       "ram_power_avg                                                                                   0.682875  \n",
       "cpu_energy_total                                                                                0.000487  \n",
       "gpu_energy_total                                                                                0.002511  \n",
       "ram_energy_total                                                                                0.000002  \n",
       "total_energy_kwh                                                                                0.003001  \n",
       "total_energy_joules                                                                         10802.828761  \n",
       "tokens_per_joule                                                                                0.092568  \n",
       "joules_per_token                                                                               10.802829  \n",
       "flops_per_joule                                                                          95766039.702745  \n",
       "joules_per_flop                                                                                      0.0  \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                              False  \n",
       "per-process_emissions_1                                                                         0.000328  \n",
       "gpu_utilization_percent_2                                                                          100.0  \n",
       "gpu_utilization_percent_1                                                                          100.0  \n",
       "models                                                                                    82763530240000  \n",
       "variables_latency_simulation_simulate_burst                                                        False  \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                  False  \n",
       "variables_latency_simulation_burst_size                                                                0  \n",
       "per-process_emissions_2                                                                         0.000259  \n",
       "model_architecture_architecture                                            Unknown (no config attribute)  \n",
       "variables_latency_simulation_burst_interval                                                          0.0  \n",
       "gpu_utilization_percent_0                                                                           45.0  \n",
       "per-process_emissions_0                                                                         0.000286  \n",
       "variables_latency_simulation_simulate                                                              False  \n",
       "per-process_emissions_3                                                                          0.00027  \n",
       "variables_latency_simulation_delay_max                                                                 0  \n",
       "model_architecture_total_params                                                               1100048384  \n",
       "gpu_utilization_percent_3                                                                          100.0  \n",
       "variables_latency_simulation_delay_min                                                                 0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def inspect_results(name, desired_order):\n",
    "    # Build filenames\n",
    "    input_file = f\"results/{name}_results.csv\"\n",
    "    output_file = f\"results/cleaned_{name}.csv\"\n",
    "    \n",
    "    # Load\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # Clean and reorder\n",
    "    df_cleaned = clean_and_reorder_columns(df, desired_order)\n",
    "    \n",
    "    # Save cleaned version\n",
    "    df_cleaned.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Set pandas display options\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    \n",
    "    # Display transposed cleaned DataFrame\n",
    "    display(df_cleaned.T)\n",
    "    \n",
    "    # Return in case you want it\n",
    "    return df_cleaned\n",
    "\n",
    "df_controlled = inspect_results('controlled', desired_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>config_name</th>\n",
       "      <td>precis_float32_quant_False_quant8_False_quant4_False</td>\n",
       "      <td>precis_float16_quant_False_quant8_False_quant4_False</td>\n",
       "      <td>precis_float16_quant_True_quant8_True_quant4_False</td>\n",
       "      <td>precis_float16_quant_True_quant8_False_quant4_True</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.7</td>\n",
       "      <td>decoding_greedy_decoder_temperature_1.0</td>\n",
       "      <td>decoding_greedy_decoder_temperature_1.3</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temperature_0</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temperature_0.7</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temperature_1.0</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temperature_1.3</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_temperature_0</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.7</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.0</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.3</td>\n",
       "      <td>latency_False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <td>23</td>\n",
       "      <td>24</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>27</td>\n",
       "      <td>28</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>31</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "      <td>38</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <td>April 08, 2025 at 03:41:15 PM</td>\n",
       "      <td>April 08, 2025 at 03:41:53 PM</td>\n",
       "      <td>April 08, 2025 at 03:43:03 PM</td>\n",
       "      <td>April 08, 2025 at 03:43:44 PM</td>\n",
       "      <td>April 08, 2025 at 03:44:24 PM</td>\n",
       "      <td>April 08, 2025 at 03:45:04 PM</td>\n",
       "      <td>April 08, 2025 at 03:45:43 PM</td>\n",
       "      <td>April 08, 2025 at 03:46:23 PM</td>\n",
       "      <td>April 08, 2025 at 03:47:02 PM</td>\n",
       "      <td>April 08, 2025 at 03:47:43 PM</td>\n",
       "      <td>April 08, 2025 at 03:48:22 PM</td>\n",
       "      <td>April 08, 2025 at 03:49:02 PM</td>\n",
       "      <td>April 08, 2025 at 03:49:43 PM</td>\n",
       "      <td>April 08, 2025 at 03:50:25 PM</td>\n",
       "      <td>April 08, 2025 at 03:51:06 PM</td>\n",
       "      <td>April 08, 2025 at 03:51:47 PM</td>\n",
       "      <td>April 08, 2025 at 03:52:27 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_encoder_decoder</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_type</th>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_gpu_count</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_cpu_count</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>os</th>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python_version</th>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharding_strategy</th>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distributed_type</th>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_processes</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_input_tokens</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_output_tokens</th>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_input_prompts</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_input_prompts</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decode_token_to_text</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_temperature</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_k</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_p</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_rate</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp_precision</th>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantization</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_8bit</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_4bit</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size___fixed_batching</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive_batching</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive_batching</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive_max_tokens</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inference_type</th>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backend</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_input_tokens</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_generated_tokens</th>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_inference_time_sec</th>\n",
       "      <td>2.869202</td>\n",
       "      <td>2.755901</td>\n",
       "      <td>8.456946</td>\n",
       "      <td>3.861104</td>\n",
       "      <td>2.794137</td>\n",
       "      <td>2.767929</td>\n",
       "      <td>2.741904</td>\n",
       "      <td>2.812577</td>\n",
       "      <td>2.675273</td>\n",
       "      <td>3.069971</td>\n",
       "      <td>2.641877</td>\n",
       "      <td>3.126667</td>\n",
       "      <td>2.859009</td>\n",
       "      <td>2.967788</td>\n",
       "      <td>2.941688</td>\n",
       "      <td>3.231563</td>\n",
       "      <td>3.015216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_latency_ms_per_batch</th>\n",
       "      <td>2869.201633</td>\n",
       "      <td>2755.900639</td>\n",
       "      <td>8456.945638</td>\n",
       "      <td>3861.103626</td>\n",
       "      <td>2794.136554</td>\n",
       "      <td>2767.92937</td>\n",
       "      <td>2741.904338</td>\n",
       "      <td>2812.577311</td>\n",
       "      <td>2675.273327</td>\n",
       "      <td>3069.971252</td>\n",
       "      <td>2641.876749</td>\n",
       "      <td>3126.666937</td>\n",
       "      <td>2859.009457</td>\n",
       "      <td>2967.787678</td>\n",
       "      <td>2941.687886</td>\n",
       "      <td>3231.563369</td>\n",
       "      <td>3015.216474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_queries_per_sec</th>\n",
       "      <td>3.48529</td>\n",
       "      <td>3.628578</td>\n",
       "      <td>1.18246</td>\n",
       "      <td>2.589933</td>\n",
       "      <td>3.578923</td>\n",
       "      <td>3.612809</td>\n",
       "      <td>3.6471</td>\n",
       "      <td>3.555458</td>\n",
       "      <td>3.737936</td>\n",
       "      <td>3.257359</td>\n",
       "      <td>3.785188</td>\n",
       "      <td>3.198294</td>\n",
       "      <td>3.497715</td>\n",
       "      <td>3.369513</td>\n",
       "      <td>3.399409</td>\n",
       "      <td>3.094477</td>\n",
       "      <td>3.316511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_tokens_per_sec</th>\n",
       "      <td>348.529008</td>\n",
       "      <td>362.857784</td>\n",
       "      <td>118.246001</td>\n",
       "      <td>258.993308</td>\n",
       "      <td>357.892315</td>\n",
       "      <td>361.280895</td>\n",
       "      <td>364.710025</td>\n",
       "      <td>355.545782</td>\n",
       "      <td>373.793582</td>\n",
       "      <td>325.735949</td>\n",
       "      <td>378.518794</td>\n",
       "      <td>319.829397</td>\n",
       "      <td>349.771491</td>\n",
       "      <td>336.951328</td>\n",
       "      <td>339.940891</td>\n",
       "      <td>309.447746</td>\n",
       "      <td>331.651146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops</th>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_current_memory_allocated_bytes</th>\n",
       "      <td>8817963520</td>\n",
       "      <td>4419607552</td>\n",
       "      <td>1576284160</td>\n",
       "      <td>1087442944</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_max_memory_allocated_bytes</th>\n",
       "      <td>8817963520</td>\n",
       "      <td>4419607552</td>\n",
       "      <td>1576284160</td>\n",
       "      <td>1087442944</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "      <td>8817963520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_current_memory_reserved_bytes</th>\n",
       "      <td>13203668992</td>\n",
       "      <td>6838812672</td>\n",
       "      <td>2885681152</td>\n",
       "      <td>1927282688</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_max_memory_reserved_bytes</th>\n",
       "      <td>13203668992</td>\n",
       "      <td>6838812672</td>\n",
       "      <td>2885681152</td>\n",
       "      <td>1927282688</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "      <td>13203668992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_usage_percent</th>\n",
       "      <td>96.6</td>\n",
       "      <td>96.1</td>\n",
       "      <td>96.4</td>\n",
       "      <td>95.4</td>\n",
       "      <td>95.5</td>\n",
       "      <td>95.9</td>\n",
       "      <td>96.2</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.4</td>\n",
       "      <td>97.1</td>\n",
       "      <td>46.6</td>\n",
       "      <td>96.3</td>\n",
       "      <td>97.2</td>\n",
       "      <td>95.3</td>\n",
       "      <td>95.9</td>\n",
       "      <td>95.9</td>\n",
       "      <td>96.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_memory_usage_bytes</th>\n",
       "      <td>2068631552</td>\n",
       "      <td>3163099136</td>\n",
       "      <td>2758508544</td>\n",
       "      <td>2685648896</td>\n",
       "      <td>2056417280</td>\n",
       "      <td>2069155840</td>\n",
       "      <td>2064257024</td>\n",
       "      <td>2071588864</td>\n",
       "      <td>2064756736</td>\n",
       "      <td>2075975680</td>\n",
       "      <td>2075889664</td>\n",
       "      <td>2078822400</td>\n",
       "      <td>2032533504</td>\n",
       "      <td>2067853312</td>\n",
       "      <td>2071113728</td>\n",
       "      <td>2072543232</td>\n",
       "      <td>2069954560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_0</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_1</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_2</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_3</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_0</th>\n",
       "      <td>944.689262</td>\n",
       "      <td>340.054686</td>\n",
       "      <td>495.248188</td>\n",
       "      <td>637.814902</td>\n",
       "      <td>773.700247</td>\n",
       "      <td>712.787356</td>\n",
       "      <td>739.678197</td>\n",
       "      <td>745.352074</td>\n",
       "      <td>753.745171</td>\n",
       "      <td>647.410642</td>\n",
       "      <td>752.265318</td>\n",
       "      <td>808.938639</td>\n",
       "      <td>12263.533476</td>\n",
       "      <td>1049.721677</td>\n",
       "      <td>870.948542</td>\n",
       "      <td>735.975673</td>\n",
       "      <td>1040.455759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_1</th>\n",
       "      <td>678.755896</td>\n",
       "      <td>368.927211</td>\n",
       "      <td>379.896394</td>\n",
       "      <td>616.940644</td>\n",
       "      <td>535.355905</td>\n",
       "      <td>547.161044</td>\n",
       "      <td>638.725419</td>\n",
       "      <td>651.174457</td>\n",
       "      <td>20.708975</td>\n",
       "      <td>548.49153</td>\n",
       "      <td>844.64678</td>\n",
       "      <td>506.432007</td>\n",
       "      <td>480.180383</td>\n",
       "      <td>607.781764</td>\n",
       "      <td>520.617213</td>\n",
       "      <td>565.373927</td>\n",
       "      <td>478.508266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>314.014383</td>\n",
       "      <td>556.125643</td>\n",
       "      <td>607.041167</td>\n",
       "      <td>734.358757</td>\n",
       "      <td>694.567051</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>779.758478</td>\n",
       "      <td>747.658574</td>\n",
       "      <td>684.404149</td>\n",
       "      <td>805.839761</td>\n",
       "      <td>0.0</td>\n",
       "      <td>734.245196</td>\n",
       "      <td>519.26956</td>\n",
       "      <td>861.06761</td>\n",
       "      <td>724.024972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_3</th>\n",
       "      <td>648.728794</td>\n",
       "      <td>399.906421</td>\n",
       "      <td>292.7091</td>\n",
       "      <td>631.078684</td>\n",
       "      <td>555.452066</td>\n",
       "      <td>644.696368</td>\n",
       "      <td>600.628501</td>\n",
       "      <td>586.925912</td>\n",
       "      <td>616.004623</td>\n",
       "      <td>608.532838</td>\n",
       "      <td>538.501664</td>\n",
       "      <td>640.429931</td>\n",
       "      <td>515.020115</td>\n",
       "      <td>628.091364</td>\n",
       "      <td>517.444485</td>\n",
       "      <td>32181.115723</td>\n",
       "      <td>625.458328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_0</th>\n",
       "      <td>0.720174</td>\n",
       "      <td>1.103278</td>\n",
       "      <td>0.962677</td>\n",
       "      <td>0.936603</td>\n",
       "      <td>0.716875</td>\n",
       "      <td>0.72014</td>\n",
       "      <td>0.719606</td>\n",
       "      <td>0.721074</td>\n",
       "      <td>0.719122</td>\n",
       "      <td>0.722956</td>\n",
       "      <td>0.723018</td>\n",
       "      <td>0.724714</td>\n",
       "      <td>0.707761</td>\n",
       "      <td>0.720743</td>\n",
       "      <td>0.721996</td>\n",
       "      <td>0.72189</td>\n",
       "      <td>0.721667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_1</th>\n",
       "      <td>0.67408</td>\n",
       "      <td>0.872201</td>\n",
       "      <td>1.011455</td>\n",
       "      <td>0.998652</td>\n",
       "      <td>0.624679</td>\n",
       "      <td>0.67276</td>\n",
       "      <td>0.664907</td>\n",
       "      <td>0.670245</td>\n",
       "      <td>0.652069</td>\n",
       "      <td>0.684111</td>\n",
       "      <td>0.68077</td>\n",
       "      <td>0.681772</td>\n",
       "      <td>0.639447</td>\n",
       "      <td>0.668226</td>\n",
       "      <td>0.674508</td>\n",
       "      <td>0.66819</td>\n",
       "      <td>0.665766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_2</th>\n",
       "      <td>0.671472</td>\n",
       "      <td>0.871948</td>\n",
       "      <td>1.01097</td>\n",
       "      <td>0.993148</td>\n",
       "      <td>0.6403</td>\n",
       "      <td>0.676954</td>\n",
       "      <td>0.677173</td>\n",
       "      <td>0.667696</td>\n",
       "      <td>0.652044</td>\n",
       "      <td>0.681514</td>\n",
       "      <td>0.685035</td>\n",
       "      <td>0.68814</td>\n",
       "      <td>0.63836</td>\n",
       "      <td>0.671392</td>\n",
       "      <td>0.66577</td>\n",
       "      <td>0.670599</td>\n",
       "      <td>0.670034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_3</th>\n",
       "      <td>0.672167</td>\n",
       "      <td>0.903816</td>\n",
       "      <td>1.016258</td>\n",
       "      <td>0.978388</td>\n",
       "      <td>0.63905</td>\n",
       "      <td>0.672438</td>\n",
       "      <td>0.669751</td>\n",
       "      <td>0.669778</td>\n",
       "      <td>0.639876</td>\n",
       "      <td>0.692551</td>\n",
       "      <td>0.682091</td>\n",
       "      <td>0.681619</td>\n",
       "      <td>0.632754</td>\n",
       "      <td>0.668241</td>\n",
       "      <td>0.669057</td>\n",
       "      <td>0.6773</td>\n",
       "      <td>0.667248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_0</th>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000089</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.000108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_1</th>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000933</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.00014</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_2</th>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.00011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_3</th>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.00012</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_0</th>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.00056</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>0.00056</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_1</th>\n",
       "      <td>0.00074</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.00073</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000543</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.000718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_2</th>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.00053</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_3</th>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.003209</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.000613</td>\n",
       "      <td>0.000602</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000565</td>\n",
       "      <td>0.000651</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_0</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_1</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_2</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_0</th>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.00141</td>\n",
       "      <td>0.00077</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.000657</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.000551</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.000684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_1</th>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.005078</td>\n",
       "      <td>0.000894</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.000887</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.000908</td>\n",
       "      <td>0.000857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_2</th>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.001465</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.000575</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.000694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_3</th>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.000858</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.000753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_0</th>\n",
       "      <td>2353.684091</td>\n",
       "      <td>1643.235863</td>\n",
       "      <td>5076.699524</td>\n",
       "      <td>2771.798058</td>\n",
       "      <td>2319.777102</td>\n",
       "      <td>2364.728032</td>\n",
       "      <td>2242.278495</td>\n",
       "      <td>2275.835796</td>\n",
       "      <td>2224.196435</td>\n",
       "      <td>2471.924988</td>\n",
       "      <td>1983.614085</td>\n",
       "      <td>2502.251794</td>\n",
       "      <td>2381.504424</td>\n",
       "      <td>2589.21229</td>\n",
       "      <td>2392.58356</td>\n",
       "      <td>2608.786572</td>\n",
       "      <td>2461.824321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_1</th>\n",
       "      <td>3158.100782</td>\n",
       "      <td>1831.453229</td>\n",
       "      <td>18280.020179</td>\n",
       "      <td>3217.707811</td>\n",
       "      <td>3072.704013</td>\n",
       "      <td>3093.551885</td>\n",
       "      <td>3122.08692</td>\n",
       "      <td>2625.754094</td>\n",
       "      <td>3192.510503</td>\n",
       "      <td>3231.009007</td>\n",
       "      <td>2326.728691</td>\n",
       "      <td>3192.10686</td>\n",
       "      <td>2709.139767</td>\n",
       "      <td>3260.198365</td>\n",
       "      <td>2811.455466</td>\n",
       "      <td>3268.690201</td>\n",
       "      <td>3084.588804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_2</th>\n",
       "      <td>2418.919707</td>\n",
       "      <td>1626.621983</td>\n",
       "      <td>5272.598505</td>\n",
       "      <td>2832.829212</td>\n",
       "      <td>2506.749335</td>\n",
       "      <td>2256.931965</td>\n",
       "      <td>2418.345159</td>\n",
       "      <td>2348.283028</td>\n",
       "      <td>2228.495986</td>\n",
       "      <td>2509.031713</td>\n",
       "      <td>2068.934883</td>\n",
       "      <td>2468.957795</td>\n",
       "      <td>2507.358338</td>\n",
       "      <td>2624.092794</td>\n",
       "      <td>2533.847387</td>\n",
       "      <td>2516.566999</td>\n",
       "      <td>2499.282586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_3</th>\n",
       "      <td>2550.868674</td>\n",
       "      <td>1797.22883</td>\n",
       "      <td>14166.512982</td>\n",
       "      <td>3146.414494</td>\n",
       "      <td>2745.581307</td>\n",
       "      <td>2605.535079</td>\n",
       "      <td>2560.508516</td>\n",
       "      <td>2753.115736</td>\n",
       "      <td>2439.634454</td>\n",
       "      <td>2740.181489</td>\n",
       "      <td>2432.301372</td>\n",
       "      <td>2778.654486</td>\n",
       "      <td>2582.3027</td>\n",
       "      <td>3087.455976</td>\n",
       "      <td>2675.423085</td>\n",
       "      <td>3142.047445</td>\n",
       "      <td>2710.511309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_avg</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_avg</th>\n",
       "      <td>568.043488</td>\n",
       "      <td>355.725676</td>\n",
       "      <td>430.994831</td>\n",
       "      <td>623.218849</td>\n",
       "      <td>649.716744</td>\n",
       "      <td>649.802955</td>\n",
       "      <td>494.758029</td>\n",
       "      <td>495.863111</td>\n",
       "      <td>542.554312</td>\n",
       "      <td>638.023396</td>\n",
       "      <td>704.954478</td>\n",
       "      <td>690.410084</td>\n",
       "      <td>3314.683493</td>\n",
       "      <td>754.96</td>\n",
       "      <td>607.06995</td>\n",
       "      <td>8585.883233</td>\n",
       "      <td>717.111831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_avg</th>\n",
       "      <td>0.684473</td>\n",
       "      <td>0.937811</td>\n",
       "      <td>1.00034</td>\n",
       "      <td>0.976698</td>\n",
       "      <td>0.655226</td>\n",
       "      <td>0.685573</td>\n",
       "      <td>0.682859</td>\n",
       "      <td>0.682198</td>\n",
       "      <td>0.665778</td>\n",
       "      <td>0.695283</td>\n",
       "      <td>0.692728</td>\n",
       "      <td>0.694061</td>\n",
       "      <td>0.654581</td>\n",
       "      <td>0.68215</td>\n",
       "      <td>0.682833</td>\n",
       "      <td>0.684495</td>\n",
       "      <td>0.681179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_total</th>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.002205</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.000448</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>0.000475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_total</th>\n",
       "      <td>0.002466</td>\n",
       "      <td>0.001512</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>0.00278</td>\n",
       "      <td>0.002507</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.002426</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>0.002346</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.002563</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>0.00251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_total</th>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh</th>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.001916</td>\n",
       "      <td>0.011888</td>\n",
       "      <td>0.003325</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.002801</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.002448</td>\n",
       "      <td>0.003039</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.003204</td>\n",
       "      <td>0.002988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules</th>\n",
       "      <td>10481.573255</td>\n",
       "      <td>6898.539905</td>\n",
       "      <td>42795.831191</td>\n",
       "      <td>11968.749575</td>\n",
       "      <td>10644.811757</td>\n",
       "      <td>10320.74696</td>\n",
       "      <td>10343.21909</td>\n",
       "      <td>10002.988654</td>\n",
       "      <td>10084.837378</td>\n",
       "      <td>10952.147197</td>\n",
       "      <td>8811.579031</td>\n",
       "      <td>10941.970935</td>\n",
       "      <td>10180.305229</td>\n",
       "      <td>11560.959424</td>\n",
       "      <td>10413.309498</td>\n",
       "      <td>11536.091218</td>\n",
       "      <td>10756.207022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens_per_joule</th>\n",
       "      <td>0.095406</td>\n",
       "      <td>0.144958</td>\n",
       "      <td>0.023367</td>\n",
       "      <td>0.083551</td>\n",
       "      <td>0.093942</td>\n",
       "      <td>0.096892</td>\n",
       "      <td>0.096682</td>\n",
       "      <td>0.09997</td>\n",
       "      <td>0.099159</td>\n",
       "      <td>0.091306</td>\n",
       "      <td>0.113487</td>\n",
       "      <td>0.091391</td>\n",
       "      <td>0.098229</td>\n",
       "      <td>0.086498</td>\n",
       "      <td>0.096031</td>\n",
       "      <td>0.086684</td>\n",
       "      <td>0.09297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_token</th>\n",
       "      <td>10.481573</td>\n",
       "      <td>6.89854</td>\n",
       "      <td>42.795831</td>\n",
       "      <td>11.96875</td>\n",
       "      <td>10.644812</td>\n",
       "      <td>10.320747</td>\n",
       "      <td>10.343219</td>\n",
       "      <td>10.002989</td>\n",
       "      <td>10.084837</td>\n",
       "      <td>10.952147</td>\n",
       "      <td>8.811579</td>\n",
       "      <td>10.941971</td>\n",
       "      <td>10.180305</td>\n",
       "      <td>11.560959</td>\n",
       "      <td>10.413309</td>\n",
       "      <td>11.536091</td>\n",
       "      <td>10.756207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops_per_joule</th>\n",
       "      <td>98701225.741572</td>\n",
       "      <td>149965665.523027</td>\n",
       "      <td>1933915709.461524</td>\n",
       "      <td>6914968829.801407</td>\n",
       "      <td>97187639.540895</td>\n",
       "      <td>100239268.725924</td>\n",
       "      <td>100021484.514354</td>\n",
       "      <td>103423503.097025</td>\n",
       "      <td>102584116.053762</td>\n",
       "      <td>94460392.963445</td>\n",
       "      <td>117407348.26131</td>\n",
       "      <td>94548243.102703</td>\n",
       "      <td>101622112.965438</td>\n",
       "      <td>89486009.771486</td>\n",
       "      <td>99348255.053844</td>\n",
       "      <td>89678913.631807</td>\n",
       "      <td>96181128.341084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_flop</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variables_latency_simulation_simulate</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_architecture_total_params</th>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>615606272</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variables_latency_simulation_delay_max</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variables_latency_simulation_delay_min</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_1</th>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.001499</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variables_latency_simulation_burst_interval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variables_decoder_config_decoding_mode</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variables_latency_simulation_simulate_burst</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_2</th>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.00021</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_3</th>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.00019</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.00034</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.00025</td>\n",
       "      <td>0.00033</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.000261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "      <td>82763530240000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variables_sharding_config_fsdp_config_cpu_offload</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_0</th>\n",
       "      <td>0.00027</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.00029</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.000283</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variables_latency_simulation_burst_size</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variables_sharding_config_fsdp_config_use_orig_params</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_architecture_architecture</th>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                         0   \\\n",
       "config_name                                            precis_float32_quant_False_quant8_False_quant4_False   \n",
       "experiment_id                                                                                            23   \n",
       "experiment_id                                                                                            23   \n",
       "date_time                                                                     April 08, 2025 at 03:41:15 PM   \n",
       "model                                                                       AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                             4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                    TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                    False   \n",
       "task_type                                                                                   text_generation   \n",
       "available_gpu_count                                                                                       4   \n",
       "available_cpu_count                                                                                     128   \n",
       "os                                                           Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                            3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                             Germany   \n",
       "region                                                                                               saxony   \n",
       "sharding_strategy                                                                                  NO_SHARD   \n",
       "distributed_type                                                                  DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                             4   \n",
       "max_input_tokens                                                                                        100   \n",
       "max_output_tokens                                                                                       100   \n",
       "number_input_prompts                                                                                     10   \n",
       "number_input_prompts                                                                                     10   \n",
       "decode_token_to_text                                                                                   True   \n",
       "decoder_temperature                                                                                     1.0   \n",
       "decoder_top_k                                                                                             0   \n",
       "decoder_top_p                                                                                           0.0   \n",
       "query_rate                                                                                              1.0   \n",
       "fp_precision                                                                                  torch.float32   \n",
       "quantization                                                                                          False   \n",
       "load_in_8bit                                                                                          False   \n",
       "load_in_4bit                                                                                          False   \n",
       "batch_size___fixed_batching                                                                              16   \n",
       "adaptive_batching                                                                                         0   \n",
       "adaptive_batching                                                                                     False   \n",
       "adaptive_max_tokens                                                                                       0   \n",
       "inference_type                                                                              pure_generative   \n",
       "backend                                                                                             pytorch   \n",
       "total_input_tokens                                                                                     1000   \n",
       "total_generated_tokens                                                                                 1000   \n",
       "total_inference_time_sec                                                                           2.869202   \n",
       "average_latency_ms_per_batch                                                                    2869.201633   \n",
       "throughput_queries_per_sec                                                                          3.48529   \n",
       "throughput_tokens_per_sec                                                                        348.529008   \n",
       "flops                                                                                         1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                               8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                   8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                               13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                   13203668992   \n",
       "cpu_usage_percent                                                                                      96.6   \n",
       "cpu_memory_usage_bytes                                                                           2068631552   \n",
       "cpu_power_process_0                                                                                   112.5   \n",
       "cpu_power_process_1                                                                                   112.5   \n",
       "cpu_power_process_2                                                                                   112.5   \n",
       "cpu_power_process_3                                                                                   112.5   \n",
       "gpu_power_process_0                                                                              944.689262   \n",
       "gpu_power_process_1                                                                              678.755896   \n",
       "gpu_power_process_2                                                                                     0.0   \n",
       "gpu_power_process_3                                                                              648.728794   \n",
       "ram_power_process_0                                                                                0.720174   \n",
       "ram_power_process_1                                                                                 0.67408   \n",
       "ram_power_process_2                                                                                0.671472   \n",
       "ram_power_process_3                                                                                0.672167   \n",
       "cpu_energy_process_0                                                                               0.000099   \n",
       "cpu_energy_process_1                                                                               0.000137   \n",
       "cpu_energy_process_2                                                                               0.000101   \n",
       "cpu_energy_process_3                                                                               0.000107   \n",
       "gpu_energy_process_0                                                                               0.000555   \n",
       "gpu_energy_process_1                                                                                0.00074   \n",
       "gpu_energy_process_2                                                                               0.000571   \n",
       "gpu_energy_process_3                                                                               0.000601   \n",
       "ram_energy_process_0                                                                               0.000001   \n",
       "ram_energy_process_1                                                                               0.000001   \n",
       "ram_energy_process_2                                                                               0.000001   \n",
       "ram_energy_process_3                                                                                    0.0   \n",
       "total_energy_kwh_process_0                                                                         0.000654   \n",
       "total_energy_kwh_process_1                                                                         0.000877   \n",
       "total_energy_kwh_process_2                                                                         0.000672   \n",
       "total_energy_kwh_process_3                                                                         0.000709   \n",
       "total_energy_joules_process_0                                                                   2353.684091   \n",
       "total_energy_joules_process_1                                                                   3158.100782   \n",
       "total_energy_joules_process_2                                                                   2418.919707   \n",
       "total_energy_joules_process_3                                                                   2550.868674   \n",
       "cpu_power_avg                                                                                         112.5   \n",
       "gpu_power_avg                                                                                    568.043488   \n",
       "ram_power_avg                                                                                      0.684473   \n",
       "cpu_energy_total                                                                                   0.000443   \n",
       "gpu_energy_total                                                                                   0.002466   \n",
       "ram_energy_total                                                                                   0.000002   \n",
       "total_energy_kwh                                                                                   0.002912   \n",
       "total_energy_joules                                                                            10481.573255   \n",
       "tokens_per_joule                                                                                   0.095406   \n",
       "joules_per_token                                                                                  10.481573   \n",
       "flops_per_joule                                                                             98701225.741572   \n",
       "joules_per_flop                                                                                         0.0   \n",
       "gpu_utilization_percent_2                                                                             100.0   \n",
       "variables_latency_simulation_simulate                                                                 False   \n",
       "gpu_utilization_percent_3                                                                             100.0   \n",
       "model_architecture_total_params                                                                  1100048384   \n",
       "variables_latency_simulation_delay_max                                                                    0   \n",
       "variables_latency_simulation_delay_min                                                                    0   \n",
       "per-process_emissions_1                                                                            0.000334   \n",
       "variables_latency_simulation_burst_interval                                                             0.0   \n",
       "variables_decoder_config_decoding_mode                                                                  NaN   \n",
       "variables_latency_simulation_simulate_burst                                                           False   \n",
       "per-process_emissions_2                                                                            0.000256   \n",
       "per-process_emissions_3                                                                            0.000249   \n",
       "models                                                                                       82763530240000   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                     False   \n",
       "per-process_emissions_0                                                                             0.00027   \n",
       "variables_latency_simulation_burst_size                                                                   0   \n",
       "gpu_utilization_percent_0                                                                              11.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                                 False   \n",
       "model_architecture_architecture                                               Unknown (no config attribute)   \n",
       "gpu_utilization_percent_1                                                                             100.0   \n",
       "\n",
       "                                                                                                         1   \\\n",
       "config_name                                            precis_float16_quant_False_quant8_False_quant4_False   \n",
       "experiment_id                                                                                            24   \n",
       "experiment_id                                                                                            24   \n",
       "date_time                                                                     April 08, 2025 at 03:41:53 PM   \n",
       "model                                                                       AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                             4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                    TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                    False   \n",
       "task_type                                                                                   text_generation   \n",
       "available_gpu_count                                                                                       4   \n",
       "available_cpu_count                                                                                     128   \n",
       "os                                                           Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                            3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                             Germany   \n",
       "region                                                                                               saxony   \n",
       "sharding_strategy                                                                                  NO_SHARD   \n",
       "distributed_type                                                                  DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                             4   \n",
       "max_input_tokens                                                                                        100   \n",
       "max_output_tokens                                                                                       100   \n",
       "number_input_prompts                                                                                     10   \n",
       "number_input_prompts                                                                                     10   \n",
       "decode_token_to_text                                                                                   True   \n",
       "decoder_temperature                                                                                     1.0   \n",
       "decoder_top_k                                                                                             0   \n",
       "decoder_top_p                                                                                           0.0   \n",
       "query_rate                                                                                              1.0   \n",
       "fp_precision                                                                                  torch.float16   \n",
       "quantization                                                                                          False   \n",
       "load_in_8bit                                                                                          False   \n",
       "load_in_4bit                                                                                          False   \n",
       "batch_size___fixed_batching                                                                              16   \n",
       "adaptive_batching                                                                                         0   \n",
       "adaptive_batching                                                                                     False   \n",
       "adaptive_max_tokens                                                                                       0   \n",
       "inference_type                                                                              pure_generative   \n",
       "backend                                                                                             pytorch   \n",
       "total_input_tokens                                                                                     1000   \n",
       "total_generated_tokens                                                                                 1000   \n",
       "total_inference_time_sec                                                                           2.755901   \n",
       "average_latency_ms_per_batch                                                                    2755.900639   \n",
       "throughput_queries_per_sec                                                                         3.628578   \n",
       "throughput_tokens_per_sec                                                                        362.857784   \n",
       "flops                                                                                         1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                               4419607552   \n",
       "gpu_max_memory_allocated_bytes                                                                   4419607552   \n",
       "gpu_current_memory_reserved_bytes                                                                6838812672   \n",
       "gpu_max_memory_reserved_bytes                                                                    6838812672   \n",
       "cpu_usage_percent                                                                                      96.1   \n",
       "cpu_memory_usage_bytes                                                                           3163099136   \n",
       "cpu_power_process_0                                                                                   112.5   \n",
       "cpu_power_process_1                                                                                   112.5   \n",
       "cpu_power_process_2                                                                                   112.5   \n",
       "cpu_power_process_3                                                                                   112.5   \n",
       "gpu_power_process_0                                                                              340.054686   \n",
       "gpu_power_process_1                                                                              368.927211   \n",
       "gpu_power_process_2                                                                              314.014383   \n",
       "gpu_power_process_3                                                                              399.906421   \n",
       "ram_power_process_0                                                                                1.103278   \n",
       "ram_power_process_1                                                                                0.872201   \n",
       "ram_power_process_2                                                                                0.871948   \n",
       "ram_power_process_3                                                                                0.903816   \n",
       "cpu_energy_process_0                                                                               0.000095   \n",
       "cpu_energy_process_1                                                                               0.000108   \n",
       "cpu_energy_process_2                                                                               0.000094   \n",
       "cpu_energy_process_3                                                                               0.000105   \n",
       "gpu_energy_process_0                                                                                0.00036   \n",
       "gpu_energy_process_1                                                                                 0.0004   \n",
       "gpu_energy_process_2                                                                               0.000358   \n",
       "gpu_energy_process_3                                                                               0.000394   \n",
       "ram_energy_process_0                                                                               0.000001   \n",
       "ram_energy_process_1                                                                               0.000001   \n",
       "ram_energy_process_2                                                                               0.000001   \n",
       "ram_energy_process_3                                                                               0.000001   \n",
       "total_energy_kwh_process_0                                                                         0.000456   \n",
       "total_energy_kwh_process_1                                                                         0.000509   \n",
       "total_energy_kwh_process_2                                                                         0.000452   \n",
       "total_energy_kwh_process_3                                                                         0.000499   \n",
       "total_energy_joules_process_0                                                                   1643.235863   \n",
       "total_energy_joules_process_1                                                                   1831.453229   \n",
       "total_energy_joules_process_2                                                                   1626.621983   \n",
       "total_energy_joules_process_3                                                                    1797.22883   \n",
       "cpu_power_avg                                                                                         112.5   \n",
       "gpu_power_avg                                                                                    355.725676   \n",
       "ram_power_avg                                                                                      0.937811   \n",
       "cpu_energy_total                                                                                   0.000402   \n",
       "gpu_energy_total                                                                                   0.001512   \n",
       "ram_energy_total                                                                                   0.000003   \n",
       "total_energy_kwh                                                                                   0.001916   \n",
       "total_energy_joules                                                                             6898.539905   \n",
       "tokens_per_joule                                                                                   0.144958   \n",
       "joules_per_token                                                                                    6.89854   \n",
       "flops_per_joule                                                                            149965665.523027   \n",
       "joules_per_flop                                                                                         0.0   \n",
       "gpu_utilization_percent_2                                                                             100.0   \n",
       "variables_latency_simulation_simulate                                                                 False   \n",
       "gpu_utilization_percent_3                                                                             100.0   \n",
       "model_architecture_total_params                                                                  1100048384   \n",
       "variables_latency_simulation_delay_max                                                                    0   \n",
       "variables_latency_simulation_delay_min                                                                    0   \n",
       "per-process_emissions_1                                                                            0.000174   \n",
       "variables_latency_simulation_burst_interval                                                             0.0   \n",
       "variables_decoder_config_decoding_mode                                                                  NaN   \n",
       "variables_latency_simulation_simulate_burst                                                           False   \n",
       "per-process_emissions_2                                                                            0.000194   \n",
       "per-process_emissions_3                                                                             0.00019   \n",
       "models                                                                                       82763530240000   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                     False   \n",
       "per-process_emissions_0                                                                            0.000172   \n",
       "variables_latency_simulation_burst_size                                                                   0   \n",
       "gpu_utilization_percent_0                                                                               4.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                                 False   \n",
       "model_architecture_architecture                                               Unknown (no config attribute)   \n",
       "gpu_utilization_percent_1                                                                              61.0   \n",
       "\n",
       "                                                                                                       2   \\\n",
       "config_name                                            precis_float16_quant_True_quant8_True_quant4_False   \n",
       "experiment_id                                                                                          25   \n",
       "experiment_id                                                                                          25   \n",
       "date_time                                                                   April 08, 2025 at 03:43:03 PM   \n",
       "model                                                                     AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                           4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                  TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                  False   \n",
       "task_type                                                                                 text_generation   \n",
       "available_gpu_count                                                                                     4   \n",
       "available_cpu_count                                                                                   128   \n",
       "os                                                         Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                          3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                           Germany   \n",
       "region                                                                                             saxony   \n",
       "sharding_strategy                                                                                NO_SHARD   \n",
       "distributed_type                                                                DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                           4   \n",
       "max_input_tokens                                                                                      100   \n",
       "max_output_tokens                                                                                     100   \n",
       "number_input_prompts                                                                                   10   \n",
       "number_input_prompts                                                                                   10   \n",
       "decode_token_to_text                                                                                 True   \n",
       "decoder_temperature                                                                                   1.0   \n",
       "decoder_top_k                                                                                           0   \n",
       "decoder_top_p                                                                                         0.0   \n",
       "query_rate                                                                                            1.0   \n",
       "fp_precision                                                                                torch.float16   \n",
       "quantization                                                                                         True   \n",
       "load_in_8bit                                                                                         True   \n",
       "load_in_4bit                                                                                        False   \n",
       "batch_size___fixed_batching                                                                            16   \n",
       "adaptive_batching                                                                                       0   \n",
       "adaptive_batching                                                                                   False   \n",
       "adaptive_max_tokens                                                                                     0   \n",
       "inference_type                                                                            pure_generative   \n",
       "backend                                                                                           pytorch   \n",
       "total_input_tokens                                                                                   1000   \n",
       "total_generated_tokens                                                                               1000   \n",
       "total_inference_time_sec                                                                         8.456946   \n",
       "average_latency_ms_per_batch                                                                  8456.945638   \n",
       "throughput_queries_per_sec                                                                        1.18246   \n",
       "throughput_tokens_per_sec                                                                      118.246001   \n",
       "flops                                                                                      82763530240000   \n",
       "gpu_current_memory_allocated_bytes                                                             1576284160   \n",
       "gpu_max_memory_allocated_bytes                                                                 1576284160   \n",
       "gpu_current_memory_reserved_bytes                                                              2885681152   \n",
       "gpu_max_memory_reserved_bytes                                                                  2885681152   \n",
       "cpu_usage_percent                                                                                    96.4   \n",
       "cpu_memory_usage_bytes                                                                         2758508544   \n",
       "cpu_power_process_0                                                                                 112.5   \n",
       "cpu_power_process_1                                                                                 112.5   \n",
       "cpu_power_process_2                                                                                 112.5   \n",
       "cpu_power_process_3                                                                                 112.5   \n",
       "gpu_power_process_0                                                                            495.248188   \n",
       "gpu_power_process_1                                                                            379.896394   \n",
       "gpu_power_process_2                                                                            556.125643   \n",
       "gpu_power_process_3                                                                              292.7091   \n",
       "ram_power_process_0                                                                              0.962677   \n",
       "ram_power_process_1                                                                              1.011455   \n",
       "ram_power_process_2                                                                               1.01097   \n",
       "ram_power_process_3                                                                              1.016258   \n",
       "cpu_energy_process_0                                                                             0.000271   \n",
       "cpu_energy_process_1                                                                             0.000933   \n",
       "cpu_energy_process_2                                                                             0.000281   \n",
       "cpu_energy_process_3                                                                              0.00072   \n",
       "gpu_energy_process_0                                                                             0.001137   \n",
       "gpu_energy_process_1                                                                             0.004138   \n",
       "gpu_energy_process_2                                                                             0.001182   \n",
       "gpu_energy_process_3                                                                             0.003209   \n",
       "ram_energy_process_0                                                                             0.000002   \n",
       "ram_energy_process_1                                                                             0.000007   \n",
       "ram_energy_process_2                                                                             0.000002   \n",
       "ram_energy_process_3                                                                             0.000006   \n",
       "total_energy_kwh_process_0                                                                        0.00141   \n",
       "total_energy_kwh_process_1                                                                       0.005078   \n",
       "total_energy_kwh_process_2                                                                       0.001465   \n",
       "total_energy_kwh_process_3                                                                       0.003935   \n",
       "total_energy_joules_process_0                                                                 5076.699524   \n",
       "total_energy_joules_process_1                                                                18280.020179   \n",
       "total_energy_joules_process_2                                                                 5272.598505   \n",
       "total_energy_joules_process_3                                                                14166.512982   \n",
       "cpu_power_avg                                                                                       112.5   \n",
       "gpu_power_avg                                                                                  430.994831   \n",
       "ram_power_avg                                                                                     1.00034   \n",
       "cpu_energy_total                                                                                 0.002205   \n",
       "gpu_energy_total                                                                                 0.009666   \n",
       "ram_energy_total                                                                                 0.000017   \n",
       "total_energy_kwh                                                                                 0.011888   \n",
       "total_energy_joules                                                                          42795.831191   \n",
       "tokens_per_joule                                                                                 0.023367   \n",
       "joules_per_token                                                                                42.795831   \n",
       "flops_per_joule                                                                         1933915709.461524   \n",
       "joules_per_flop                                                                                       0.0   \n",
       "gpu_utilization_percent_2                                                                           100.0   \n",
       "variables_latency_simulation_simulate                                                               False   \n",
       "gpu_utilization_percent_3                                                                           100.0   \n",
       "model_architecture_total_params                                                                1100048384   \n",
       "variables_latency_simulation_delay_max                                                                  0   \n",
       "variables_latency_simulation_delay_min                                                                  0   \n",
       "per-process_emissions_1                                                                          0.001499   \n",
       "variables_latency_simulation_burst_interval                                                           0.0   \n",
       "variables_decoder_config_decoding_mode                                                                NaN   \n",
       "variables_latency_simulation_simulate_burst                                                         False   \n",
       "per-process_emissions_2                                                                          0.001934   \n",
       "per-process_emissions_3                                                                          0.000537   \n",
       "models                                                                                     82763530240000   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                   False   \n",
       "per-process_emissions_0                                                                          0.000558   \n",
       "variables_latency_simulation_burst_size                                                                 0   \n",
       "gpu_utilization_percent_0                                                                            26.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                               False   \n",
       "model_architecture_architecture                                             Unknown (no config attribute)   \n",
       "gpu_utilization_percent_1                                                                            85.0   \n",
       "\n",
       "                                                                                                       3   \\\n",
       "config_name                                            precis_float16_quant_True_quant8_False_quant4_True   \n",
       "experiment_id                                                                                          26   \n",
       "experiment_id                                                                                          26   \n",
       "date_time                                                                   April 08, 2025 at 03:43:44 PM   \n",
       "model                                                                     AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                           4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                  TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                  False   \n",
       "task_type                                                                                 text_generation   \n",
       "available_gpu_count                                                                                     4   \n",
       "available_cpu_count                                                                                   128   \n",
       "os                                                         Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                          3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                           Germany   \n",
       "region                                                                                             saxony   \n",
       "sharding_strategy                                                                                NO_SHARD   \n",
       "distributed_type                                                                DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                           4   \n",
       "max_input_tokens                                                                                      100   \n",
       "max_output_tokens                                                                                     100   \n",
       "number_input_prompts                                                                                   10   \n",
       "number_input_prompts                                                                                   10   \n",
       "decode_token_to_text                                                                                 True   \n",
       "decoder_temperature                                                                                   1.0   \n",
       "decoder_top_k                                                                                           0   \n",
       "decoder_top_p                                                                                         0.0   \n",
       "query_rate                                                                                            1.0   \n",
       "fp_precision                                                                                torch.float16   \n",
       "quantization                                                                                         True   \n",
       "load_in_8bit                                                                                        False   \n",
       "load_in_4bit                                                                                         True   \n",
       "batch_size___fixed_batching                                                                            16   \n",
       "adaptive_batching                                                                                       0   \n",
       "adaptive_batching                                                                                   False   \n",
       "adaptive_max_tokens                                                                                     0   \n",
       "inference_type                                                                            pure_generative   \n",
       "backend                                                                                           pytorch   \n",
       "total_input_tokens                                                                                   1000   \n",
       "total_generated_tokens                                                                               1000   \n",
       "total_inference_time_sec                                                                         3.861104   \n",
       "average_latency_ms_per_batch                                                                  3861.103626   \n",
       "throughput_queries_per_sec                                                                       2.589933   \n",
       "throughput_tokens_per_sec                                                                      258.993308   \n",
       "flops                                                                                      82763530240000   \n",
       "gpu_current_memory_allocated_bytes                                                             1087442944   \n",
       "gpu_max_memory_allocated_bytes                                                                 1087442944   \n",
       "gpu_current_memory_reserved_bytes                                                              1927282688   \n",
       "gpu_max_memory_reserved_bytes                                                                  1927282688   \n",
       "cpu_usage_percent                                                                                    95.4   \n",
       "cpu_memory_usage_bytes                                                                         2685648896   \n",
       "cpu_power_process_0                                                                                 112.5   \n",
       "cpu_power_process_1                                                                                 112.5   \n",
       "cpu_power_process_2                                                                                 112.5   \n",
       "cpu_power_process_3                                                                                 112.5   \n",
       "gpu_power_process_0                                                                            637.814902   \n",
       "gpu_power_process_1                                                                            616.940644   \n",
       "gpu_power_process_2                                                                            607.041167   \n",
       "gpu_power_process_3                                                                            631.078684   \n",
       "ram_power_process_0                                                                              0.936603   \n",
       "ram_power_process_1                                                                              0.998652   \n",
       "ram_power_process_2                                                                              0.993148   \n",
       "ram_power_process_3                                                                              0.978388   \n",
       "cpu_energy_process_0                                                                             0.000125   \n",
       "cpu_energy_process_1                                                                             0.000146   \n",
       "cpu_energy_process_2                                                                             0.000128   \n",
       "cpu_energy_process_3                                                                             0.000142   \n",
       "gpu_energy_process_0                                                                             0.000644   \n",
       "gpu_energy_process_1                                                                             0.000747   \n",
       "gpu_energy_process_2                                                                             0.000658   \n",
       "gpu_energy_process_3                                                                             0.000731   \n",
       "ram_energy_process_0                                                                             0.000001   \n",
       "ram_energy_process_1                                                                             0.000001   \n",
       "ram_energy_process_2                                                                             0.000001   \n",
       "ram_energy_process_3                                                                             0.000001   \n",
       "total_energy_kwh_process_0                                                                        0.00077   \n",
       "total_energy_kwh_process_1                                                                       0.000894   \n",
       "total_energy_kwh_process_2                                                                       0.000787   \n",
       "total_energy_kwh_process_3                                                                       0.000874   \n",
       "total_energy_joules_process_0                                                                 2771.798058   \n",
       "total_energy_joules_process_1                                                                 3217.707811   \n",
       "total_energy_joules_process_2                                                                 2832.829212   \n",
       "total_energy_joules_process_3                                                                 3146.414494   \n",
       "cpu_power_avg                                                                                       112.5   \n",
       "gpu_power_avg                                                                                  623.218849   \n",
       "ram_power_avg                                                                                    0.976698   \n",
       "cpu_energy_total                                                                                 0.000541   \n",
       "gpu_energy_total                                                                                  0.00278   \n",
       "ram_energy_total                                                                                 0.000004   \n",
       "total_energy_kwh                                                                                 0.003325   \n",
       "total_energy_joules                                                                          11968.749575   \n",
       "tokens_per_joule                                                                                 0.083551   \n",
       "joules_per_token                                                                                 11.96875   \n",
       "flops_per_joule                                                                         6914968829.801407   \n",
       "joules_per_flop                                                                                       0.0   \n",
       "gpu_utilization_percent_2                                                                            99.0   \n",
       "variables_latency_simulation_simulate                                                               False   \n",
       "gpu_utilization_percent_3                                                                           100.0   \n",
       "model_architecture_total_params                                                                 615606272   \n",
       "variables_latency_simulation_delay_max                                                                  0   \n",
       "variables_latency_simulation_delay_min                                                                  0   \n",
       "per-process_emissions_1                                                                            0.0003   \n",
       "variables_latency_simulation_burst_interval                                                           0.0   \n",
       "variables_decoder_config_decoding_mode                                                                NaN   \n",
       "variables_latency_simulation_simulate_burst                                                         False   \n",
       "per-process_emissions_2                                                                          0.000293   \n",
       "per-process_emissions_3                                                                           0.00034   \n",
       "models                                                                                     82763530240000   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                   False   \n",
       "per-process_emissions_0                                                                          0.000333   \n",
       "variables_latency_simulation_burst_size                                                                 0   \n",
       "gpu_utilization_percent_0                                                                            57.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                               False   \n",
       "model_architecture_architecture                                             Unknown (no config attribute)   \n",
       "gpu_utilization_percent_1                                                                           100.0   \n",
       "\n",
       "                                                                                                      4   \\\n",
       "config_name                                                        decoding_greedy_decoder_temperature_0   \n",
       "experiment_id                                                                                         27   \n",
       "experiment_id                                                                                         27   \n",
       "date_time                                                                  April 08, 2025 at 03:44:24 PM   \n",
       "model                                                                    AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                          4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                 False   \n",
       "task_type                                                                                text_generation   \n",
       "available_gpu_count                                                                                    4   \n",
       "available_cpu_count                                                                                  128   \n",
       "os                                                        Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                         3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                          Germany   \n",
       "region                                                                                            saxony   \n",
       "sharding_strategy                                                                               NO_SHARD   \n",
       "distributed_type                                                               DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                          4   \n",
       "max_input_tokens                                                                                     100   \n",
       "max_output_tokens                                                                                    100   \n",
       "number_input_prompts                                                                                  10   \n",
       "number_input_prompts                                                                                  10   \n",
       "decode_token_to_text                                                                                True   \n",
       "decoder_temperature                                                                                  0.0   \n",
       "decoder_top_k                                                                                          0   \n",
       "decoder_top_p                                                                                        0.0   \n",
       "query_rate                                                                                           1.0   \n",
       "fp_precision                                                                               torch.float32   \n",
       "quantization                                                                                       False   \n",
       "load_in_8bit                                                                                       False   \n",
       "load_in_4bit                                                                                       False   \n",
       "batch_size___fixed_batching                                                                           16   \n",
       "adaptive_batching                                                                                      0   \n",
       "adaptive_batching                                                                                  False   \n",
       "adaptive_max_tokens                                                                                    0   \n",
       "inference_type                                                                           pure_generative   \n",
       "backend                                                                                          pytorch   \n",
       "total_input_tokens                                                                                  1000   \n",
       "total_generated_tokens                                                                              1000   \n",
       "total_inference_time_sec                                                                        2.794137   \n",
       "average_latency_ms_per_batch                                                                 2794.136554   \n",
       "throughput_queries_per_sec                                                                      3.578923   \n",
       "throughput_tokens_per_sec                                                                     357.892315   \n",
       "flops                                                                                      1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                            8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                            13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                13203668992   \n",
       "cpu_usage_percent                                                                                   95.5   \n",
       "cpu_memory_usage_bytes                                                                        2056417280   \n",
       "cpu_power_process_0                                                                                112.5   \n",
       "cpu_power_process_1                                                                                112.5   \n",
       "cpu_power_process_2                                                                                112.5   \n",
       "cpu_power_process_3                                                                                112.5   \n",
       "gpu_power_process_0                                                                           773.700247   \n",
       "gpu_power_process_1                                                                           535.355905   \n",
       "gpu_power_process_2                                                                           734.358757   \n",
       "gpu_power_process_3                                                                           555.452066   \n",
       "ram_power_process_0                                                                             0.716875   \n",
       "ram_power_process_1                                                                             0.624679   \n",
       "ram_power_process_2                                                                               0.6403   \n",
       "ram_power_process_3                                                                              0.63905   \n",
       "cpu_energy_process_0                                                                            0.000096   \n",
       "cpu_energy_process_1                                                                            0.000132   \n",
       "cpu_energy_process_2                                                                            0.000104   \n",
       "cpu_energy_process_3                                                                            0.000116   \n",
       "gpu_energy_process_0                                                                            0.000548   \n",
       "gpu_energy_process_1                                                                            0.000721   \n",
       "gpu_energy_process_2                                                                            0.000592   \n",
       "gpu_energy_process_3                                                                            0.000646   \n",
       "ram_energy_process_0                                                                                 0.0   \n",
       "ram_energy_process_1                                                                            0.000001   \n",
       "ram_energy_process_2                                                                            0.000001   \n",
       "ram_energy_process_3                                                                            0.000001   \n",
       "total_energy_kwh_process_0                                                                      0.000644   \n",
       "total_energy_kwh_process_1                                                                      0.000854   \n",
       "total_energy_kwh_process_2                                                                      0.000696   \n",
       "total_energy_kwh_process_3                                                                      0.000763   \n",
       "total_energy_joules_process_0                                                                2319.777102   \n",
       "total_energy_joules_process_1                                                                3072.704013   \n",
       "total_energy_joules_process_2                                                                2506.749335   \n",
       "total_energy_joules_process_3                                                                2745.581307   \n",
       "cpu_power_avg                                                                                      112.5   \n",
       "gpu_power_avg                                                                                 649.716744   \n",
       "ram_power_avg                                                                                   0.655226   \n",
       "cpu_energy_total                                                                                0.000448   \n",
       "gpu_energy_total                                                                                0.002507   \n",
       "ram_energy_total                                                                                0.000002   \n",
       "total_energy_kwh                                                                                0.002957   \n",
       "total_energy_joules                                                                         10644.811757   \n",
       "tokens_per_joule                                                                                0.093942   \n",
       "joules_per_token                                                                               10.644812   \n",
       "flops_per_joule                                                                          97187639.540895   \n",
       "joules_per_flop                                                                                      0.0   \n",
       "gpu_utilization_percent_2                                                                          100.0   \n",
       "variables_latency_simulation_simulate                                                              False   \n",
       "gpu_utilization_percent_3                                                                          100.0   \n",
       "model_architecture_total_params                                                               1100048384   \n",
       "variables_latency_simulation_delay_max                                                                 0   \n",
       "variables_latency_simulation_delay_min                                                                 0   \n",
       "per-process_emissions_1                                                                         0.000245   \n",
       "variables_latency_simulation_burst_interval                                                          0.0   \n",
       "variables_decoder_config_decoding_mode                                                            greedy   \n",
       "variables_latency_simulation_simulate_burst                                                        False   \n",
       "per-process_emissions_2                                                                         0.000325   \n",
       "per-process_emissions_3                                                                         0.000291   \n",
       "models                                                                                    82763530240000   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "per-process_emissions_0                                                                         0.000265   \n",
       "variables_latency_simulation_burst_size                                                                0   \n",
       "gpu_utilization_percent_0                                                                            8.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "model_architecture_architecture                                            Unknown (no config attribute)   \n",
       "gpu_utilization_percent_1                                                                          100.0   \n",
       "\n",
       "                                                                                                      5   \\\n",
       "config_name                                                      decoding_greedy_decoder_temperature_0.7   \n",
       "experiment_id                                                                                         28   \n",
       "experiment_id                                                                                         28   \n",
       "date_time                                                                  April 08, 2025 at 03:45:04 PM   \n",
       "model                                                                    AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                          4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                 False   \n",
       "task_type                                                                                text_generation   \n",
       "available_gpu_count                                                                                    4   \n",
       "available_cpu_count                                                                                  128   \n",
       "os                                                        Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                         3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                          Germany   \n",
       "region                                                                                            saxony   \n",
       "sharding_strategy                                                                               NO_SHARD   \n",
       "distributed_type                                                               DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                          4   \n",
       "max_input_tokens                                                                                     100   \n",
       "max_output_tokens                                                                                    100   \n",
       "number_input_prompts                                                                                  10   \n",
       "number_input_prompts                                                                                  10   \n",
       "decode_token_to_text                                                                                True   \n",
       "decoder_temperature                                                                                  0.7   \n",
       "decoder_top_k                                                                                          0   \n",
       "decoder_top_p                                                                                        0.0   \n",
       "query_rate                                                                                           1.0   \n",
       "fp_precision                                                                               torch.float32   \n",
       "quantization                                                                                       False   \n",
       "load_in_8bit                                                                                       False   \n",
       "load_in_4bit                                                                                       False   \n",
       "batch_size___fixed_batching                                                                           16   \n",
       "adaptive_batching                                                                                      0   \n",
       "adaptive_batching                                                                                  False   \n",
       "adaptive_max_tokens                                                                                    0   \n",
       "inference_type                                                                           pure_generative   \n",
       "backend                                                                                          pytorch   \n",
       "total_input_tokens                                                                                  1000   \n",
       "total_generated_tokens                                                                              1000   \n",
       "total_inference_time_sec                                                                        2.767929   \n",
       "average_latency_ms_per_batch                                                                  2767.92937   \n",
       "throughput_queries_per_sec                                                                      3.612809   \n",
       "throughput_tokens_per_sec                                                                     361.280895   \n",
       "flops                                                                                      1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                            8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                            13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                13203668992   \n",
       "cpu_usage_percent                                                                                   95.9   \n",
       "cpu_memory_usage_bytes                                                                        2069155840   \n",
       "cpu_power_process_0                                                                                112.5   \n",
       "cpu_power_process_1                                                                                112.5   \n",
       "cpu_power_process_2                                                                                112.5   \n",
       "cpu_power_process_3                                                                                112.5   \n",
       "gpu_power_process_0                                                                           712.787356   \n",
       "gpu_power_process_1                                                                           547.161044   \n",
       "gpu_power_process_2                                                                           694.567051   \n",
       "gpu_power_process_3                                                                           644.696368   \n",
       "ram_power_process_0                                                                              0.72014   \n",
       "ram_power_process_1                                                                              0.67276   \n",
       "ram_power_process_2                                                                             0.676954   \n",
       "ram_power_process_3                                                                             0.672438   \n",
       "cpu_energy_process_0                                                                              0.0001   \n",
       "cpu_energy_process_1                                                                            0.000135   \n",
       "cpu_energy_process_2                                                                            0.000096   \n",
       "cpu_energy_process_3                                                                             0.00011   \n",
       "gpu_energy_process_0                                                                            0.000556   \n",
       "gpu_energy_process_1                                                                            0.000724   \n",
       "gpu_energy_process_2                                                                             0.00053   \n",
       "gpu_energy_process_3                                                                            0.000613   \n",
       "ram_energy_process_0                                                                            0.000001   \n",
       "ram_energy_process_1                                                                            0.000001   \n",
       "ram_energy_process_2                                                                                 0.0   \n",
       "ram_energy_process_3                                                                            0.000001   \n",
       "total_energy_kwh_process_0                                                                      0.000657   \n",
       "total_energy_kwh_process_1                                                                      0.000859   \n",
       "total_energy_kwh_process_2                                                                      0.000627   \n",
       "total_energy_kwh_process_3                                                                      0.000724   \n",
       "total_energy_joules_process_0                                                                2364.728032   \n",
       "total_energy_joules_process_1                                                                3093.551885   \n",
       "total_energy_joules_process_2                                                                2256.931965   \n",
       "total_energy_joules_process_3                                                                2605.535079   \n",
       "cpu_power_avg                                                                                      112.5   \n",
       "gpu_power_avg                                                                                 649.802955   \n",
       "ram_power_avg                                                                                   0.685573   \n",
       "cpu_energy_total                                                                                0.000441   \n",
       "gpu_energy_total                                                                                0.002424   \n",
       "ram_energy_total                                                                                0.000002   \n",
       "total_energy_kwh                                                                                0.002867   \n",
       "total_energy_joules                                                                          10320.74696   \n",
       "tokens_per_joule                                                                                0.096892   \n",
       "joules_per_token                                                                               10.320747   \n",
       "flops_per_joule                                                                         100239268.725924   \n",
       "joules_per_flop                                                                                      0.0   \n",
       "gpu_utilization_percent_2                                                                          100.0   \n",
       "variables_latency_simulation_simulate                                                              False   \n",
       "gpu_utilization_percent_3                                                                          100.0   \n",
       "model_architecture_total_params                                                               1100048384   \n",
       "variables_latency_simulation_delay_max                                                                 0   \n",
       "variables_latency_simulation_delay_min                                                                 0   \n",
       "per-process_emissions_1                                                                         0.000327   \n",
       "variables_latency_simulation_burst_interval                                                          0.0   \n",
       "variables_decoder_config_decoding_mode                                                            greedy   \n",
       "variables_latency_simulation_simulate_burst                                                        False   \n",
       "per-process_emissions_2                                                                         0.000276   \n",
       "per-process_emissions_3                                                                          0.00025   \n",
       "models                                                                                    82763530240000   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "per-process_emissions_0                                                                         0.000239   \n",
       "variables_latency_simulation_burst_size                                                                0   \n",
       "gpu_utilization_percent_0                                                                           11.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "model_architecture_architecture                                            Unknown (no config attribute)   \n",
       "gpu_utilization_percent_1                                                                          100.0   \n",
       "\n",
       "                                                                                                      6   \\\n",
       "config_name                                                      decoding_greedy_decoder_temperature_1.0   \n",
       "experiment_id                                                                                         29   \n",
       "experiment_id                                                                                         29   \n",
       "date_time                                                                  April 08, 2025 at 03:45:43 PM   \n",
       "model                                                                    AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                          4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                 False   \n",
       "task_type                                                                                text_generation   \n",
       "available_gpu_count                                                                                    4   \n",
       "available_cpu_count                                                                                  128   \n",
       "os                                                        Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                         3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                          Germany   \n",
       "region                                                                                            saxony   \n",
       "sharding_strategy                                                                               NO_SHARD   \n",
       "distributed_type                                                               DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                          4   \n",
       "max_input_tokens                                                                                     100   \n",
       "max_output_tokens                                                                                    100   \n",
       "number_input_prompts                                                                                  10   \n",
       "number_input_prompts                                                                                  10   \n",
       "decode_token_to_text                                                                                True   \n",
       "decoder_temperature                                                                                  1.0   \n",
       "decoder_top_k                                                                                          0   \n",
       "decoder_top_p                                                                                        0.0   \n",
       "query_rate                                                                                           1.0   \n",
       "fp_precision                                                                               torch.float32   \n",
       "quantization                                                                                       False   \n",
       "load_in_8bit                                                                                       False   \n",
       "load_in_4bit                                                                                       False   \n",
       "batch_size___fixed_batching                                                                           16   \n",
       "adaptive_batching                                                                                      0   \n",
       "adaptive_batching                                                                                  False   \n",
       "adaptive_max_tokens                                                                                    0   \n",
       "inference_type                                                                           pure_generative   \n",
       "backend                                                                                          pytorch   \n",
       "total_input_tokens                                                                                  1000   \n",
       "total_generated_tokens                                                                              1000   \n",
       "total_inference_time_sec                                                                        2.741904   \n",
       "average_latency_ms_per_batch                                                                 2741.904338   \n",
       "throughput_queries_per_sec                                                                        3.6471   \n",
       "throughput_tokens_per_sec                                                                     364.710025   \n",
       "flops                                                                                      1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                            8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                            13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                13203668992   \n",
       "cpu_usage_percent                                                                                   96.2   \n",
       "cpu_memory_usage_bytes                                                                        2064257024   \n",
       "cpu_power_process_0                                                                                112.5   \n",
       "cpu_power_process_1                                                                                112.5   \n",
       "cpu_power_process_2                                                                                112.5   \n",
       "cpu_power_process_3                                                                                112.5   \n",
       "gpu_power_process_0                                                                           739.678197   \n",
       "gpu_power_process_1                                                                           638.725419   \n",
       "gpu_power_process_2                                                                                  0.0   \n",
       "gpu_power_process_3                                                                           600.628501   \n",
       "ram_power_process_0                                                                             0.719606   \n",
       "ram_power_process_1                                                                             0.664907   \n",
       "ram_power_process_2                                                                             0.677173   \n",
       "ram_power_process_3                                                                             0.669751   \n",
       "cpu_energy_process_0                                                                            0.000096   \n",
       "cpu_energy_process_1                                                                            0.000137   \n",
       "cpu_energy_process_2                                                                            0.000103   \n",
       "cpu_energy_process_3                                                                            0.000109   \n",
       "gpu_energy_process_0                                                                            0.000526   \n",
       "gpu_energy_process_1                                                                             0.00073   \n",
       "gpu_energy_process_2                                                                            0.000568   \n",
       "gpu_energy_process_3                                                                            0.000602   \n",
       "ram_energy_process_0                                                                            0.000001   \n",
       "ram_energy_process_1                                                                            0.000001   \n",
       "ram_energy_process_2                                                                            0.000001   \n",
       "ram_energy_process_3                                                                            0.000001   \n",
       "total_energy_kwh_process_0                                                                      0.000623   \n",
       "total_energy_kwh_process_1                                                                      0.000867   \n",
       "total_energy_kwh_process_2                                                                      0.000672   \n",
       "total_energy_kwh_process_3                                                                      0.000711   \n",
       "total_energy_joules_process_0                                                                2242.278495   \n",
       "total_energy_joules_process_1                                                                 3122.08692   \n",
       "total_energy_joules_process_2                                                                2418.345159   \n",
       "total_energy_joules_process_3                                                                2560.508516   \n",
       "cpu_power_avg                                                                                      112.5   \n",
       "gpu_power_avg                                                                                 494.758029   \n",
       "ram_power_avg                                                                                   0.682859   \n",
       "cpu_energy_total                                                                                0.000445   \n",
       "gpu_energy_total                                                                                0.002426   \n",
       "ram_energy_total                                                                                0.000002   \n",
       "total_energy_kwh                                                                                0.002873   \n",
       "total_energy_joules                                                                          10343.21909   \n",
       "tokens_per_joule                                                                                0.096682   \n",
       "joules_per_token                                                                               10.343219   \n",
       "flops_per_joule                                                                         100021484.514354   \n",
       "joules_per_flop                                                                                      0.0   \n",
       "gpu_utilization_percent_2                                                                          100.0   \n",
       "variables_latency_simulation_simulate                                                              False   \n",
       "gpu_utilization_percent_3                                                                          100.0   \n",
       "model_architecture_total_params                                                               1100048384   \n",
       "variables_latency_simulation_delay_max                                                                 0   \n",
       "variables_latency_simulation_delay_min                                                                 0   \n",
       "per-process_emissions_1                                                                         0.000256   \n",
       "variables_latency_simulation_burst_interval                                                          0.0   \n",
       "variables_decoder_config_decoding_mode                                                            greedy   \n",
       "variables_latency_simulation_simulate_burst                                                        False   \n",
       "per-process_emissions_2                                                                         0.000271   \n",
       "per-process_emissions_3                                                                          0.00033   \n",
       "models                                                                                    82763530240000   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "per-process_emissions_0                                                                         0.000237   \n",
       "variables_latency_simulation_burst_size                                                                0   \n",
       "gpu_utilization_percent_0                                                                            2.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "model_architecture_architecture                                            Unknown (no config attribute)   \n",
       "gpu_utilization_percent_1                                                                          100.0   \n",
       "\n",
       "                                                                                                      7   \\\n",
       "config_name                                                      decoding_greedy_decoder_temperature_1.3   \n",
       "experiment_id                                                                                         30   \n",
       "experiment_id                                                                                         30   \n",
       "date_time                                                                  April 08, 2025 at 03:46:23 PM   \n",
       "model                                                                    AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                          4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                 False   \n",
       "task_type                                                                                text_generation   \n",
       "available_gpu_count                                                                                    4   \n",
       "available_cpu_count                                                                                  128   \n",
       "os                                                        Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                         3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                          Germany   \n",
       "region                                                                                            saxony   \n",
       "sharding_strategy                                                                               NO_SHARD   \n",
       "distributed_type                                                               DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                          4   \n",
       "max_input_tokens                                                                                     100   \n",
       "max_output_tokens                                                                                    100   \n",
       "number_input_prompts                                                                                  10   \n",
       "number_input_prompts                                                                                  10   \n",
       "decode_token_to_text                                                                                True   \n",
       "decoder_temperature                                                                                  1.3   \n",
       "decoder_top_k                                                                                          0   \n",
       "decoder_top_p                                                                                        0.0   \n",
       "query_rate                                                                                           1.0   \n",
       "fp_precision                                                                               torch.float32   \n",
       "quantization                                                                                       False   \n",
       "load_in_8bit                                                                                       False   \n",
       "load_in_4bit                                                                                       False   \n",
       "batch_size___fixed_batching                                                                           16   \n",
       "adaptive_batching                                                                                      0   \n",
       "adaptive_batching                                                                                  False   \n",
       "adaptive_max_tokens                                                                                    0   \n",
       "inference_type                                                                           pure_generative   \n",
       "backend                                                                                          pytorch   \n",
       "total_input_tokens                                                                                  1000   \n",
       "total_generated_tokens                                                                              1000   \n",
       "total_inference_time_sec                                                                        2.812577   \n",
       "average_latency_ms_per_batch                                                                 2812.577311   \n",
       "throughput_queries_per_sec                                                                      3.555458   \n",
       "throughput_tokens_per_sec                                                                     355.545782   \n",
       "flops                                                                                      1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                            8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                            13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                13203668992   \n",
       "cpu_usage_percent                                                                                   96.0   \n",
       "cpu_memory_usage_bytes                                                                        2071588864   \n",
       "cpu_power_process_0                                                                                112.5   \n",
       "cpu_power_process_1                                                                                112.5   \n",
       "cpu_power_process_2                                                                                112.5   \n",
       "cpu_power_process_3                                                                                112.5   \n",
       "gpu_power_process_0                                                                           745.352074   \n",
       "gpu_power_process_1                                                                           651.174457   \n",
       "gpu_power_process_2                                                                                  0.0   \n",
       "gpu_power_process_3                                                                           586.925912   \n",
       "ram_power_process_0                                                                             0.721074   \n",
       "ram_power_process_1                                                                             0.670245   \n",
       "ram_power_process_2                                                                             0.667696   \n",
       "ram_power_process_3                                                                             0.669778   \n",
       "cpu_energy_process_0                                                                            0.000101   \n",
       "cpu_energy_process_1                                                                            0.000116   \n",
       "cpu_energy_process_2                                                                            0.000104   \n",
       "cpu_energy_process_3                                                                            0.000122   \n",
       "gpu_energy_process_0                                                                            0.000531   \n",
       "gpu_energy_process_1                                                                            0.000613   \n",
       "gpu_energy_process_2                                                                            0.000547   \n",
       "gpu_energy_process_3                                                                            0.000642   \n",
       "ram_energy_process_0                                                                            0.000001   \n",
       "ram_energy_process_1                                                                            0.000001   \n",
       "ram_energy_process_2                                                                            0.000001   \n",
       "ram_energy_process_3                                                                            0.000001   \n",
       "total_energy_kwh_process_0                                                                      0.000632   \n",
       "total_energy_kwh_process_1                                                                      0.000729   \n",
       "total_energy_kwh_process_2                                                                      0.000652   \n",
       "total_energy_kwh_process_3                                                                      0.000765   \n",
       "total_energy_joules_process_0                                                                2275.835796   \n",
       "total_energy_joules_process_1                                                                2625.754094   \n",
       "total_energy_joules_process_2                                                                2348.283028   \n",
       "total_energy_joules_process_3                                                                2753.115736   \n",
       "cpu_power_avg                                                                                      112.5   \n",
       "gpu_power_avg                                                                                 495.863111   \n",
       "ram_power_avg                                                                                   0.682198   \n",
       "cpu_energy_total                                                                                0.000443   \n",
       "gpu_energy_total                                                                                0.002333   \n",
       "ram_energy_total                                                                                0.000002   \n",
       "total_energy_kwh                                                                                0.002779   \n",
       "total_energy_joules                                                                         10002.988654   \n",
       "tokens_per_joule                                                                                 0.09997   \n",
       "joules_per_token                                                                               10.002989   \n",
       "flops_per_joule                                                                         103423503.097025   \n",
       "joules_per_flop                                                                                      0.0   \n",
       "gpu_utilization_percent_2                                                                          100.0   \n",
       "variables_latency_simulation_simulate                                                              False   \n",
       "gpu_utilization_percent_3                                                                          100.0   \n",
       "model_architecture_total_params                                                               1100048384   \n",
       "variables_latency_simulation_delay_max                                                                 0   \n",
       "variables_latency_simulation_delay_min                                                                 0   \n",
       "per-process_emissions_1                                                                         0.000241   \n",
       "variables_latency_simulation_burst_interval                                                          0.0   \n",
       "variables_decoder_config_decoding_mode                                                            greedy   \n",
       "variables_latency_simulation_simulate_burst                                                        False   \n",
       "per-process_emissions_2                                                                         0.000248   \n",
       "per-process_emissions_3                                                                         0.000291   \n",
       "models                                                                                    82763530240000   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "per-process_emissions_0                                                                         0.000278   \n",
       "variables_latency_simulation_burst_size                                                                0   \n",
       "gpu_utilization_percent_0                                                                           18.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "model_architecture_architecture                                            Unknown (no config attribute)   \n",
       "gpu_utilization_percent_1                                                                          100.0   \n",
       "\n",
       "                                                                                                          8   \\\n",
       "config_name                                            decoding_top_k_decoder_top_k_50_decoder_temperature_0   \n",
       "experiment_id                                                                                             31   \n",
       "experiment_id                                                                                             31   \n",
       "date_time                                                                      April 08, 2025 at 03:47:02 PM   \n",
       "model                                                                        AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                              4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                     TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                     False   \n",
       "task_type                                                                                    text_generation   \n",
       "available_gpu_count                                                                                        4   \n",
       "available_cpu_count                                                                                      128   \n",
       "os                                                            Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                             3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                              Germany   \n",
       "region                                                                                                saxony   \n",
       "sharding_strategy                                                                                   NO_SHARD   \n",
       "distributed_type                                                                   DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                              4   \n",
       "max_input_tokens                                                                                         100   \n",
       "max_output_tokens                                                                                        100   \n",
       "number_input_prompts                                                                                      10   \n",
       "number_input_prompts                                                                                      10   \n",
       "decode_token_to_text                                                                                    True   \n",
       "decoder_temperature                                                                                      0.0   \n",
       "decoder_top_k                                                                                             50   \n",
       "decoder_top_p                                                                                            0.0   \n",
       "query_rate                                                                                               1.0   \n",
       "fp_precision                                                                                   torch.float32   \n",
       "quantization                                                                                           False   \n",
       "load_in_8bit                                                                                           False   \n",
       "load_in_4bit                                                                                           False   \n",
       "batch_size___fixed_batching                                                                               16   \n",
       "adaptive_batching                                                                                          0   \n",
       "adaptive_batching                                                                                      False   \n",
       "adaptive_max_tokens                                                                                        0   \n",
       "inference_type                                                                               pure_generative   \n",
       "backend                                                                                              pytorch   \n",
       "total_input_tokens                                                                                      1000   \n",
       "total_generated_tokens                                                                                  1000   \n",
       "total_inference_time_sec                                                                            2.675273   \n",
       "average_latency_ms_per_batch                                                                     2675.273327   \n",
       "throughput_queries_per_sec                                                                          3.737936   \n",
       "throughput_tokens_per_sec                                                                         373.793582   \n",
       "flops                                                                                          1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                                8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                    8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                                13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                    13203668992   \n",
       "cpu_usage_percent                                                                                       96.4   \n",
       "cpu_memory_usage_bytes                                                                            2064756736   \n",
       "cpu_power_process_0                                                                                    112.5   \n",
       "cpu_power_process_1                                                                                    112.5   \n",
       "cpu_power_process_2                                                                                    112.5   \n",
       "cpu_power_process_3                                                                                    112.5   \n",
       "gpu_power_process_0                                                                               753.745171   \n",
       "gpu_power_process_1                                                                                20.708975   \n",
       "gpu_power_process_2                                                                               779.758478   \n",
       "gpu_power_process_3                                                                               616.004623   \n",
       "ram_power_process_0                                                                                 0.719122   \n",
       "ram_power_process_1                                                                                 0.652069   \n",
       "ram_power_process_2                                                                                 0.652044   \n",
       "ram_power_process_3                                                                                 0.639876   \n",
       "cpu_energy_process_0                                                                                0.000092   \n",
       "cpu_energy_process_1                                                                                0.000166   \n",
       "cpu_energy_process_2                                                                                0.000093   \n",
       "cpu_energy_process_3                                                                                0.000102   \n",
       "gpu_energy_process_0                                                                                0.000525   \n",
       "gpu_energy_process_1                                                                                 0.00072   \n",
       "gpu_energy_process_2                                                                                0.000526   \n",
       "gpu_energy_process_3                                                                                0.000575   \n",
       "ram_energy_process_0                                                                                     0.0   \n",
       "ram_energy_process_1                                                                                0.000001   \n",
       "ram_energy_process_2                                                                                     0.0   \n",
       "ram_energy_process_3                                                                                0.000001   \n",
       "total_energy_kwh_process_0                                                                          0.000618   \n",
       "total_energy_kwh_process_1                                                                          0.000887   \n",
       "total_energy_kwh_process_2                                                                          0.000619   \n",
       "total_energy_kwh_process_3                                                                          0.000678   \n",
       "total_energy_joules_process_0                                                                    2224.196435   \n",
       "total_energy_joules_process_1                                                                    3192.510503   \n",
       "total_energy_joules_process_2                                                                    2228.495986   \n",
       "total_energy_joules_process_3                                                                    2439.634454   \n",
       "cpu_power_avg                                                                                          112.5   \n",
       "gpu_power_avg                                                                                     542.554312   \n",
       "ram_power_avg                                                                                       0.665778   \n",
       "cpu_energy_total                                                                                    0.000453   \n",
       "gpu_energy_total                                                                                    0.002346   \n",
       "ram_energy_total                                                                                    0.000002   \n",
       "total_energy_kwh                                                                                    0.002801   \n",
       "total_energy_joules                                                                             10084.837378   \n",
       "tokens_per_joule                                                                                    0.099159   \n",
       "joules_per_token                                                                                   10.084837   \n",
       "flops_per_joule                                                                             102584116.053762   \n",
       "joules_per_flop                                                                                          0.0   \n",
       "gpu_utilization_percent_2                                                                              100.0   \n",
       "variables_latency_simulation_simulate                                                                  False   \n",
       "gpu_utilization_percent_3                                                                              100.0   \n",
       "model_architecture_total_params                                                                   1100048384   \n",
       "variables_latency_simulation_delay_max                                                                     0   \n",
       "variables_latency_simulation_delay_min                                                                     0   \n",
       "per-process_emissions_1                                                                             0.000258   \n",
       "variables_latency_simulation_burst_interval                                                              0.0   \n",
       "variables_decoder_config_decoding_mode                                                                 top_k   \n",
       "variables_latency_simulation_simulate_burst                                                            False   \n",
       "per-process_emissions_2                                                                             0.000236   \n",
       "per-process_emissions_3                                                                             0.000235   \n",
       "models                                                                                        82763530240000   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                      False   \n",
       "per-process_emissions_0                                                                             0.000338   \n",
       "variables_latency_simulation_burst_size                                                                    0   \n",
       "gpu_utilization_percent_0                                                                               34.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                                  False   \n",
       "model_architecture_architecture                                                Unknown (no config attribute)   \n",
       "gpu_utilization_percent_1                                                                              100.0   \n",
       "\n",
       "                                                                                                            9   \\\n",
       "config_name                                            decoding_top_k_decoder_top_k_50_decoder_temperature_0.7   \n",
       "experiment_id                                                                                               32   \n",
       "experiment_id                                                                                               32   \n",
       "date_time                                                                        April 08, 2025 at 03:47:43 PM   \n",
       "model                                                                          AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                                4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                       False   \n",
       "task_type                                                                                      text_generation   \n",
       "available_gpu_count                                                                                          4   \n",
       "available_cpu_count                                                                                        128   \n",
       "os                                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                                Germany   \n",
       "region                                                                                                  saxony   \n",
       "sharding_strategy                                                                                     NO_SHARD   \n",
       "distributed_type                                                                     DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                                4   \n",
       "max_input_tokens                                                                                           100   \n",
       "max_output_tokens                                                                                          100   \n",
       "number_input_prompts                                                                                        10   \n",
       "number_input_prompts                                                                                        10   \n",
       "decode_token_to_text                                                                                      True   \n",
       "decoder_temperature                                                                                        0.7   \n",
       "decoder_top_k                                                                                               50   \n",
       "decoder_top_p                                                                                              0.0   \n",
       "query_rate                                                                                                 1.0   \n",
       "fp_precision                                                                                     torch.float32   \n",
       "quantization                                                                                             False   \n",
       "load_in_8bit                                                                                             False   \n",
       "load_in_4bit                                                                                             False   \n",
       "batch_size___fixed_batching                                                                                 16   \n",
       "adaptive_batching                                                                                            0   \n",
       "adaptive_batching                                                                                        False   \n",
       "adaptive_max_tokens                                                                                          0   \n",
       "inference_type                                                                                 pure_generative   \n",
       "backend                                                                                                pytorch   \n",
       "total_input_tokens                                                                                        1000   \n",
       "total_generated_tokens                                                                                    1000   \n",
       "total_inference_time_sec                                                                              3.069971   \n",
       "average_latency_ms_per_batch                                                                       3069.971252   \n",
       "throughput_queries_per_sec                                                                            3.257359   \n",
       "throughput_tokens_per_sec                                                                           325.735949   \n",
       "flops                                                                                            1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                      13203668992   \n",
       "cpu_usage_percent                                                                                         97.1   \n",
       "cpu_memory_usage_bytes                                                                              2075975680   \n",
       "cpu_power_process_0                                                                                      112.5   \n",
       "cpu_power_process_1                                                                                      112.5   \n",
       "cpu_power_process_2                                                                                      112.5   \n",
       "cpu_power_process_3                                                                                      112.5   \n",
       "gpu_power_process_0                                                                                 647.410642   \n",
       "gpu_power_process_1                                                                                  548.49153   \n",
       "gpu_power_process_2                                                                                 747.658574   \n",
       "gpu_power_process_3                                                                                 608.532838   \n",
       "ram_power_process_0                                                                                   0.722956   \n",
       "ram_power_process_1                                                                                   0.684111   \n",
       "ram_power_process_2                                                                                   0.681514   \n",
       "ram_power_process_3                                                                                   0.692551   \n",
       "cpu_energy_process_0                                                                                  0.000108   \n",
       "cpu_energy_process_1                                                                                  0.000145   \n",
       "cpu_energy_process_2                                                                                  0.000111   \n",
       "cpu_energy_process_3                                                                                  0.000121   \n",
       "gpu_energy_process_0                                                                                  0.000577   \n",
       "gpu_energy_process_1                                                                                  0.000752   \n",
       "gpu_energy_process_2                                                                                  0.000586   \n",
       "gpu_energy_process_3                                                                                  0.000639   \n",
       "ram_energy_process_0                                                                                  0.000001   \n",
       "ram_energy_process_1                                                                                  0.000001   \n",
       "ram_energy_process_2                                                                                       0.0   \n",
       "ram_energy_process_3                                                                                  0.000001   \n",
       "total_energy_kwh_process_0                                                                            0.000687   \n",
       "total_energy_kwh_process_1                                                                            0.000898   \n",
       "total_energy_kwh_process_2                                                                            0.000697   \n",
       "total_energy_kwh_process_3                                                                            0.000761   \n",
       "total_energy_joules_process_0                                                                      2471.924988   \n",
       "total_energy_joules_process_1                                                                      3231.009007   \n",
       "total_energy_joules_process_2                                                                      2509.031713   \n",
       "total_energy_joules_process_3                                                                      2740.181489   \n",
       "cpu_power_avg                                                                                            112.5   \n",
       "gpu_power_avg                                                                                       638.023396   \n",
       "ram_power_avg                                                                                         0.695283   \n",
       "cpu_energy_total                                                                                      0.000485   \n",
       "gpu_energy_total                                                                                      0.002555   \n",
       "ram_energy_total                                                                                      0.000003   \n",
       "total_energy_kwh                                                                                      0.003042   \n",
       "total_energy_joules                                                                               10952.147197   \n",
       "tokens_per_joule                                                                                      0.091306   \n",
       "joules_per_token                                                                                     10.952147   \n",
       "flops_per_joule                                                                                94460392.963445   \n",
       "joules_per_flop                                                                                            0.0   \n",
       "gpu_utilization_percent_2                                                                                100.0   \n",
       "variables_latency_simulation_simulate                                                                    False   \n",
       "gpu_utilization_percent_3                                                                                100.0   \n",
       "model_architecture_total_params                                                                     1100048384   \n",
       "variables_latency_simulation_delay_max                                                                       0   \n",
       "variables_latency_simulation_delay_min                                                                       0   \n",
       "per-process_emissions_1                                                                               0.000262   \n",
       "variables_latency_simulation_burst_interval                                                                0.0   \n",
       "variables_decoder_config_decoding_mode                                                                   top_k   \n",
       "variables_latency_simulation_simulate_burst                                                              False   \n",
       "per-process_emissions_2                                                                               0.000266   \n",
       "per-process_emissions_3                                                                               0.000342   \n",
       "models                                                                                          82763530240000   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                        False   \n",
       "per-process_emissions_0                                                                                0.00029   \n",
       "variables_latency_simulation_burst_size                                                                      0   \n",
       "gpu_utilization_percent_0                                                                                 11.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                                    False   \n",
       "model_architecture_architecture                                                  Unknown (no config attribute)   \n",
       "gpu_utilization_percent_1                                                                                100.0   \n",
       "\n",
       "                                                                                                            10  \\\n",
       "config_name                                            decoding_top_k_decoder_top_k_50_decoder_temperature_1.0   \n",
       "experiment_id                                                                                               33   \n",
       "experiment_id                                                                                               33   \n",
       "date_time                                                                        April 08, 2025 at 03:48:22 PM   \n",
       "model                                                                          AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                                4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                       False   \n",
       "task_type                                                                                      text_generation   \n",
       "available_gpu_count                                                                                          4   \n",
       "available_cpu_count                                                                                        128   \n",
       "os                                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                                Germany   \n",
       "region                                                                                                  saxony   \n",
       "sharding_strategy                                                                                     NO_SHARD   \n",
       "distributed_type                                                                     DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                                4   \n",
       "max_input_tokens                                                                                           100   \n",
       "max_output_tokens                                                                                          100   \n",
       "number_input_prompts                                                                                        10   \n",
       "number_input_prompts                                                                                        10   \n",
       "decode_token_to_text                                                                                      True   \n",
       "decoder_temperature                                                                                        1.0   \n",
       "decoder_top_k                                                                                               50   \n",
       "decoder_top_p                                                                                              0.0   \n",
       "query_rate                                                                                                 1.0   \n",
       "fp_precision                                                                                     torch.float32   \n",
       "quantization                                                                                             False   \n",
       "load_in_8bit                                                                                             False   \n",
       "load_in_4bit                                                                                             False   \n",
       "batch_size___fixed_batching                                                                                 16   \n",
       "adaptive_batching                                                                                            0   \n",
       "adaptive_batching                                                                                        False   \n",
       "adaptive_max_tokens                                                                                          0   \n",
       "inference_type                                                                                 pure_generative   \n",
       "backend                                                                                                pytorch   \n",
       "total_input_tokens                                                                                        1000   \n",
       "total_generated_tokens                                                                                    1000   \n",
       "total_inference_time_sec                                                                              2.641877   \n",
       "average_latency_ms_per_batch                                                                       2641.876749   \n",
       "throughput_queries_per_sec                                                                            3.785188   \n",
       "throughput_tokens_per_sec                                                                           378.518794   \n",
       "flops                                                                                            1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                      13203668992   \n",
       "cpu_usage_percent                                                                                         46.6   \n",
       "cpu_memory_usage_bytes                                                                              2075889664   \n",
       "cpu_power_process_0                                                                                      112.5   \n",
       "cpu_power_process_1                                                                                      112.5   \n",
       "cpu_power_process_2                                                                                      112.5   \n",
       "cpu_power_process_3                                                                                      112.5   \n",
       "gpu_power_process_0                                                                                 752.265318   \n",
       "gpu_power_process_1                                                                                  844.64678   \n",
       "gpu_power_process_2                                                                                 684.404149   \n",
       "gpu_power_process_3                                                                                 538.501664   \n",
       "ram_power_process_0                                                                                   0.723018   \n",
       "ram_power_process_1                                                                                    0.68077   \n",
       "ram_power_process_2                                                                                   0.685035   \n",
       "ram_power_process_3                                                                                   0.682091   \n",
       "cpu_energy_process_0                                                                                  0.000089   \n",
       "cpu_energy_process_1                                                                                  0.000103   \n",
       "cpu_energy_process_2                                                                                  0.000095   \n",
       "cpu_energy_process_3                                                                                   0.00011   \n",
       "gpu_energy_process_0                                                                                  0.000461   \n",
       "gpu_energy_process_1                                                                                  0.000543   \n",
       "gpu_energy_process_2                                                                                  0.000479   \n",
       "gpu_energy_process_3                                                                                  0.000565   \n",
       "ram_energy_process_0                                                                                       0.0   \n",
       "ram_energy_process_1                                                                                       0.0   \n",
       "ram_energy_process_2                                                                                       0.0   \n",
       "ram_energy_process_3                                                                                  0.000001   \n",
       "total_energy_kwh_process_0                                                                            0.000551   \n",
       "total_energy_kwh_process_1                                                                            0.000646   \n",
       "total_energy_kwh_process_2                                                                            0.000575   \n",
       "total_energy_kwh_process_3                                                                            0.000676   \n",
       "total_energy_joules_process_0                                                                      1983.614085   \n",
       "total_energy_joules_process_1                                                                      2326.728691   \n",
       "total_energy_joules_process_2                                                                      2068.934883   \n",
       "total_energy_joules_process_3                                                                      2432.301372   \n",
       "cpu_power_avg                                                                                            112.5   \n",
       "gpu_power_avg                                                                                       704.954478   \n",
       "ram_power_avg                                                                                         0.692728   \n",
       "cpu_energy_total                                                                                      0.000397   \n",
       "gpu_energy_total                                                                                      0.002048   \n",
       "ram_energy_total                                                                                      0.000002   \n",
       "total_energy_kwh                                                                                      0.002448   \n",
       "total_energy_joules                                                                                8811.579031   \n",
       "tokens_per_joule                                                                                      0.113487   \n",
       "joules_per_token                                                                                      8.811579   \n",
       "flops_per_joule                                                                                117407348.26131   \n",
       "joules_per_flop                                                                                            0.0   \n",
       "gpu_utilization_percent_2                                                                                 99.0   \n",
       "variables_latency_simulation_simulate                                                                    False   \n",
       "gpu_utilization_percent_3                                                                                100.0   \n",
       "model_architecture_total_params                                                                     1100048384   \n",
       "variables_latency_simulation_delay_max                                                                       0   \n",
       "variables_latency_simulation_delay_min                                                                       0   \n",
       "per-process_emissions_1                                                                               0.000219   \n",
       "variables_latency_simulation_burst_interval                                                                0.0   \n",
       "variables_decoder_config_decoding_mode                                                                   top_k   \n",
       "variables_latency_simulation_simulate_burst                                                              False   \n",
       "per-process_emissions_2                                                                                0.00021   \n",
       "per-process_emissions_3                                                                               0.000257   \n",
       "models                                                                                          82763530240000   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                        False   \n",
       "per-process_emissions_0                                                                               0.000246   \n",
       "variables_latency_simulation_burst_size                                                                      0   \n",
       "gpu_utilization_percent_0                                                                                 50.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                                    False   \n",
       "model_architecture_architecture                                                  Unknown (no config attribute)   \n",
       "gpu_utilization_percent_1                                                                                100.0   \n",
       "\n",
       "                                                                                                            11  \\\n",
       "config_name                                            decoding_top_k_decoder_top_k_50_decoder_temperature_1.3   \n",
       "experiment_id                                                                                               34   \n",
       "experiment_id                                                                                               34   \n",
       "date_time                                                                        April 08, 2025 at 03:49:02 PM   \n",
       "model                                                                          AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                                4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                       False   \n",
       "task_type                                                                                      text_generation   \n",
       "available_gpu_count                                                                                          4   \n",
       "available_cpu_count                                                                                        128   \n",
       "os                                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                                Germany   \n",
       "region                                                                                                  saxony   \n",
       "sharding_strategy                                                                                     NO_SHARD   \n",
       "distributed_type                                                                     DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                                4   \n",
       "max_input_tokens                                                                                           100   \n",
       "max_output_tokens                                                                                          100   \n",
       "number_input_prompts                                                                                        10   \n",
       "number_input_prompts                                                                                        10   \n",
       "decode_token_to_text                                                                                      True   \n",
       "decoder_temperature                                                                                        1.3   \n",
       "decoder_top_k                                                                                               50   \n",
       "decoder_top_p                                                                                              0.0   \n",
       "query_rate                                                                                                 1.0   \n",
       "fp_precision                                                                                     torch.float32   \n",
       "quantization                                                                                             False   \n",
       "load_in_8bit                                                                                             False   \n",
       "load_in_4bit                                                                                             False   \n",
       "batch_size___fixed_batching                                                                                 16   \n",
       "adaptive_batching                                                                                            0   \n",
       "adaptive_batching                                                                                        False   \n",
       "adaptive_max_tokens                                                                                          0   \n",
       "inference_type                                                                                 pure_generative   \n",
       "backend                                                                                                pytorch   \n",
       "total_input_tokens                                                                                        1000   \n",
       "total_generated_tokens                                                                                    1000   \n",
       "total_inference_time_sec                                                                              3.126667   \n",
       "average_latency_ms_per_batch                                                                       3126.666937   \n",
       "throughput_queries_per_sec                                                                            3.198294   \n",
       "throughput_tokens_per_sec                                                                           319.829397   \n",
       "flops                                                                                            1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                                  8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                      8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                                  13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                      13203668992   \n",
       "cpu_usage_percent                                                                                         96.3   \n",
       "cpu_memory_usage_bytes                                                                              2078822400   \n",
       "cpu_power_process_0                                                                                      112.5   \n",
       "cpu_power_process_1                                                                                      112.5   \n",
       "cpu_power_process_2                                                                                      112.5   \n",
       "cpu_power_process_3                                                                                      112.5   \n",
       "gpu_power_process_0                                                                                 808.938639   \n",
       "gpu_power_process_1                                                                                 506.432007   \n",
       "gpu_power_process_2                                                                                 805.839761   \n",
       "gpu_power_process_3                                                                                 640.429931   \n",
       "ram_power_process_0                                                                                   0.724714   \n",
       "ram_power_process_1                                                                                   0.681772   \n",
       "ram_power_process_2                                                                                    0.68814   \n",
       "ram_power_process_3                                                                                   0.681619   \n",
       "cpu_energy_process_0                                                                                  0.000108   \n",
       "cpu_energy_process_1                                                                                   0.00014   \n",
       "cpu_energy_process_2                                                                                  0.000106   \n",
       "cpu_energy_process_3                                                                                   0.00012   \n",
       "gpu_energy_process_0                                                                                  0.000586   \n",
       "gpu_energy_process_1                                                                                  0.000746   \n",
       "gpu_energy_process_2                                                                                  0.000579   \n",
       "gpu_energy_process_3                                                                                  0.000651   \n",
       "ram_energy_process_0                                                                                  0.000001   \n",
       "ram_energy_process_1                                                                                  0.000001   \n",
       "ram_energy_process_2                                                                                       0.0   \n",
       "ram_energy_process_3                                                                                  0.000001   \n",
       "total_energy_kwh_process_0                                                                            0.000695   \n",
       "total_energy_kwh_process_1                                                                            0.000887   \n",
       "total_energy_kwh_process_2                                                                            0.000686   \n",
       "total_energy_kwh_process_3                                                                            0.000772   \n",
       "total_energy_joules_process_0                                                                      2502.251794   \n",
       "total_energy_joules_process_1                                                                       3192.10686   \n",
       "total_energy_joules_process_2                                                                      2468.957795   \n",
       "total_energy_joules_process_3                                                                      2778.654486   \n",
       "cpu_power_avg                                                                                            112.5   \n",
       "gpu_power_avg                                                                                       690.410084   \n",
       "ram_power_avg                                                                                         0.694061   \n",
       "cpu_energy_total                                                                                      0.000474   \n",
       "gpu_energy_total                                                                                      0.002563   \n",
       "ram_energy_total                                                                                      0.000002   \n",
       "total_energy_kwh                                                                                      0.003039   \n",
       "total_energy_joules                                                                               10941.970935   \n",
       "tokens_per_joule                                                                                      0.091391   \n",
       "joules_per_token                                                                                     10.941971   \n",
       "flops_per_joule                                                                                94548243.102703   \n",
       "joules_per_flop                                                                                            0.0   \n",
       "gpu_utilization_percent_2                                                                                100.0   \n",
       "variables_latency_simulation_simulate                                                                    False   \n",
       "gpu_utilization_percent_3                                                                                100.0   \n",
       "model_architecture_total_params                                                                     1100048384   \n",
       "variables_latency_simulation_delay_max                                                                       0   \n",
       "variables_latency_simulation_delay_min                                                                       0   \n",
       "per-process_emissions_1                                                                               0.000265   \n",
       "variables_latency_simulation_burst_interval                                                                0.0   \n",
       "variables_decoder_config_decoding_mode                                                                   top_k   \n",
       "variables_latency_simulation_simulate_burst                                                              False   \n",
       "per-process_emissions_2                                                                               0.000338   \n",
       "per-process_emissions_3                                                                               0.000294   \n",
       "models                                                                                          82763530240000   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                        False   \n",
       "per-process_emissions_0                                                                               0.000261   \n",
       "variables_latency_simulation_burst_size                                                                      0   \n",
       "gpu_utilization_percent_0                                                                                 11.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                                    False   \n",
       "model_architecture_architecture                                                  Unknown (no config attribute)   \n",
       "gpu_utilization_percent_1                                                                                100.0   \n",
       "\n",
       "                                                                                                           12  \\\n",
       "config_name                                            decoding_top_p_decoder_top_p_0.9_decoder_temperature_0   \n",
       "experiment_id                                                                                              35   \n",
       "experiment_id                                                                                              35   \n",
       "date_time                                                                       April 08, 2025 at 03:49:43 PM   \n",
       "model                                                                         AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                               4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                      TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                      False   \n",
       "task_type                                                                                     text_generation   \n",
       "available_gpu_count                                                                                         4   \n",
       "available_cpu_count                                                                                       128   \n",
       "os                                                             Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                              3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                               Germany   \n",
       "region                                                                                                 saxony   \n",
       "sharding_strategy                                                                                    NO_SHARD   \n",
       "distributed_type                                                                    DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                               4   \n",
       "max_input_tokens                                                                                          100   \n",
       "max_output_tokens                                                                                         100   \n",
       "number_input_prompts                                                                                       10   \n",
       "number_input_prompts                                                                                       10   \n",
       "decode_token_to_text                                                                                     True   \n",
       "decoder_temperature                                                                                       0.0   \n",
       "decoder_top_k                                                                                               0   \n",
       "decoder_top_p                                                                                             0.9   \n",
       "query_rate                                                                                                1.0   \n",
       "fp_precision                                                                                    torch.float32   \n",
       "quantization                                                                                            False   \n",
       "load_in_8bit                                                                                            False   \n",
       "load_in_4bit                                                                                            False   \n",
       "batch_size___fixed_batching                                                                                16   \n",
       "adaptive_batching                                                                                           0   \n",
       "adaptive_batching                                                                                       False   \n",
       "adaptive_max_tokens                                                                                         0   \n",
       "inference_type                                                                                pure_generative   \n",
       "backend                                                                                               pytorch   \n",
       "total_input_tokens                                                                                       1000   \n",
       "total_generated_tokens                                                                                   1000   \n",
       "total_inference_time_sec                                                                             2.859009   \n",
       "average_latency_ms_per_batch                                                                      2859.009457   \n",
       "throughput_queries_per_sec                                                                           3.497715   \n",
       "throughput_tokens_per_sec                                                                          349.771491   \n",
       "flops                                                                                           1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                                 8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                     8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                                 13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                     13203668992   \n",
       "cpu_usage_percent                                                                                        97.2   \n",
       "cpu_memory_usage_bytes                                                                             2032533504   \n",
       "cpu_power_process_0                                                                                     112.5   \n",
       "cpu_power_process_1                                                                                     112.5   \n",
       "cpu_power_process_2                                                                                     112.5   \n",
       "cpu_power_process_3                                                                                     112.5   \n",
       "gpu_power_process_0                                                                              12263.533476   \n",
       "gpu_power_process_1                                                                                480.180383   \n",
       "gpu_power_process_2                                                                                       0.0   \n",
       "gpu_power_process_3                                                                                515.020115   \n",
       "ram_power_process_0                                                                                  0.707761   \n",
       "ram_power_process_1                                                                                  0.639447   \n",
       "ram_power_process_2                                                                                   0.63836   \n",
       "ram_power_process_3                                                                                  0.632754   \n",
       "cpu_energy_process_0                                                                                 0.000101   \n",
       "cpu_energy_process_1                                                                                  0.00012   \n",
       "cpu_energy_process_2                                                                                 0.000133   \n",
       "cpu_energy_process_3                                                                                 0.000112   \n",
       "gpu_energy_process_0                                                                                  0.00056   \n",
       "gpu_energy_process_1                                                                                 0.000632   \n",
       "gpu_energy_process_2                                                                                 0.000563   \n",
       "gpu_energy_process_3                                                                                 0.000605   \n",
       "ram_energy_process_0                                                                                 0.000001   \n",
       "ram_energy_process_1                                                                                 0.000001   \n",
       "ram_energy_process_2                                                                                 0.000001   \n",
       "ram_energy_process_3                                                                                      0.0   \n",
       "total_energy_kwh_process_0                                                                           0.000662   \n",
       "total_energy_kwh_process_1                                                                           0.000753   \n",
       "total_energy_kwh_process_2                                                                           0.000696   \n",
       "total_energy_kwh_process_3                                                                           0.000717   \n",
       "total_energy_joules_process_0                                                                     2381.504424   \n",
       "total_energy_joules_process_1                                                                     2709.139767   \n",
       "total_energy_joules_process_2                                                                     2507.358338   \n",
       "total_energy_joules_process_3                                                                       2582.3027   \n",
       "cpu_power_avg                                                                                           112.5   \n",
       "gpu_power_avg                                                                                     3314.683493   \n",
       "ram_power_avg                                                                                        0.654581   \n",
       "cpu_energy_total                                                                                     0.000465   \n",
       "gpu_energy_total                                                                                     0.002361   \n",
       "ram_energy_total                                                                                     0.000002   \n",
       "total_energy_kwh                                                                                     0.002828   \n",
       "total_energy_joules                                                                              10180.305229   \n",
       "tokens_per_joule                                                                                     0.098229   \n",
       "joules_per_token                                                                                    10.180305   \n",
       "flops_per_joule                                                                              101622112.965438   \n",
       "joules_per_flop                                                                                           0.0   \n",
       "gpu_utilization_percent_2                                                                               100.0   \n",
       "variables_latency_simulation_simulate                                                                   False   \n",
       "gpu_utilization_percent_3                                                                               100.0   \n",
       "model_architecture_total_params                                                                    1100048384   \n",
       "variables_latency_simulation_delay_max                                                                      0   \n",
       "variables_latency_simulation_delay_min                                                                      0   \n",
       "per-process_emissions_1                                                                              0.000287   \n",
       "variables_latency_simulation_burst_interval                                                               0.0   \n",
       "variables_decoder_config_decoding_mode                                                                  top_p   \n",
       "variables_latency_simulation_simulate_burst                                                             False   \n",
       "per-process_emissions_2                                                                              0.000265   \n",
       "per-process_emissions_3                                                                              0.000273   \n",
       "models                                                                                         82763530240000   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                       False   \n",
       "per-process_emissions_0                                                                              0.000252   \n",
       "variables_latency_simulation_burst_size                                                                     0   \n",
       "gpu_utilization_percent_0                                                                                11.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                                   False   \n",
       "model_architecture_architecture                                                 Unknown (no config attribute)   \n",
       "gpu_utilization_percent_1                                                                                72.0   \n",
       "\n",
       "                                                                                                             13  \\\n",
       "config_name                                            decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.7   \n",
       "experiment_id                                                                                                36   \n",
       "experiment_id                                                                                                36   \n",
       "date_time                                                                         April 08, 2025 at 03:50:25 PM   \n",
       "model                                                                           AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                                 4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                        TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                        False   \n",
       "task_type                                                                                       text_generation   \n",
       "available_gpu_count                                                                                           4   \n",
       "available_cpu_count                                                                                         128   \n",
       "os                                                               Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                                3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                                 Germany   \n",
       "region                                                                                                   saxony   \n",
       "sharding_strategy                                                                                      NO_SHARD   \n",
       "distributed_type                                                                      DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                                 4   \n",
       "max_input_tokens                                                                                            100   \n",
       "max_output_tokens                                                                                           100   \n",
       "number_input_prompts                                                                                         10   \n",
       "number_input_prompts                                                                                         10   \n",
       "decode_token_to_text                                                                                       True   \n",
       "decoder_temperature                                                                                         0.7   \n",
       "decoder_top_k                                                                                                 0   \n",
       "decoder_top_p                                                                                               0.9   \n",
       "query_rate                                                                                                  1.0   \n",
       "fp_precision                                                                                      torch.float32   \n",
       "quantization                                                                                              False   \n",
       "load_in_8bit                                                                                              False   \n",
       "load_in_4bit                                                                                              False   \n",
       "batch_size___fixed_batching                                                                                  16   \n",
       "adaptive_batching                                                                                             0   \n",
       "adaptive_batching                                                                                         False   \n",
       "adaptive_max_tokens                                                                                           0   \n",
       "inference_type                                                                                  pure_generative   \n",
       "backend                                                                                                 pytorch   \n",
       "total_input_tokens                                                                                         1000   \n",
       "total_generated_tokens                                                                                     1000   \n",
       "total_inference_time_sec                                                                               2.967788   \n",
       "average_latency_ms_per_batch                                                                        2967.787678   \n",
       "throughput_queries_per_sec                                                                             3.369513   \n",
       "throughput_tokens_per_sec                                                                            336.951328   \n",
       "flops                                                                                             1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                                   8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                       8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                                   13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                       13203668992   \n",
       "cpu_usage_percent                                                                                          95.3   \n",
       "cpu_memory_usage_bytes                                                                               2067853312   \n",
       "cpu_power_process_0                                                                                       112.5   \n",
       "cpu_power_process_1                                                                                       112.5   \n",
       "cpu_power_process_2                                                                                       112.5   \n",
       "cpu_power_process_3                                                                                       112.5   \n",
       "gpu_power_process_0                                                                                 1049.721677   \n",
       "gpu_power_process_1                                                                                  607.781764   \n",
       "gpu_power_process_2                                                                                  734.245196   \n",
       "gpu_power_process_3                                                                                  628.091364   \n",
       "ram_power_process_0                                                                                    0.720743   \n",
       "ram_power_process_1                                                                                    0.668226   \n",
       "ram_power_process_2                                                                                    0.671392   \n",
       "ram_power_process_3                                                                                    0.668241   \n",
       "cpu_energy_process_0                                                                                   0.000103   \n",
       "cpu_energy_process_1                                                                                   0.000133   \n",
       "cpu_energy_process_2                                                                                   0.000104   \n",
       "cpu_energy_process_3                                                                                   0.000126   \n",
       "gpu_energy_process_0                                                                                   0.000615   \n",
       "gpu_energy_process_1                                                                                   0.000771   \n",
       "gpu_energy_process_2                                                                                   0.000624   \n",
       "gpu_energy_process_3                                                                                   0.000731   \n",
       "ram_energy_process_0                                                                                   0.000001   \n",
       "ram_energy_process_1                                                                                   0.000001   \n",
       "ram_energy_process_2                                                                                        0.0   \n",
       "ram_energy_process_3                                                                                   0.000001   \n",
       "total_energy_kwh_process_0                                                                             0.000719   \n",
       "total_energy_kwh_process_1                                                                             0.000906   \n",
       "total_energy_kwh_process_2                                                                             0.000729   \n",
       "total_energy_kwh_process_3                                                                             0.000858   \n",
       "total_energy_joules_process_0                                                                        2589.21229   \n",
       "total_energy_joules_process_1                                                                       3260.198365   \n",
       "total_energy_joules_process_2                                                                       2624.092794   \n",
       "total_energy_joules_process_3                                                                       3087.455976   \n",
       "cpu_power_avg                                                                                             112.5   \n",
       "gpu_power_avg                                                                                            754.96   \n",
       "ram_power_avg                                                                                           0.68215   \n",
       "cpu_energy_total                                                                                       0.000467   \n",
       "gpu_energy_total                                                                                       0.002742   \n",
       "ram_energy_total                                                                                       0.000003   \n",
       "total_energy_kwh                                                                                       0.003211   \n",
       "total_energy_joules                                                                                11560.959424   \n",
       "tokens_per_joule                                                                                       0.086498   \n",
       "joules_per_token                                                                                      11.560959   \n",
       "flops_per_joule                                                                                 89486009.771486   \n",
       "joules_per_flop                                                                                             0.0   \n",
       "gpu_utilization_percent_2                                                                                 100.0   \n",
       "variables_latency_simulation_simulate                                                                     False   \n",
       "gpu_utilization_percent_3                                                                                 100.0   \n",
       "model_architecture_total_params                                                                      1100048384   \n",
       "variables_latency_simulation_delay_max                                                                        0   \n",
       "variables_latency_simulation_delay_min                                                                        0   \n",
       "per-process_emissions_1                                                                                0.000274   \n",
       "variables_latency_simulation_burst_interval                                                                 0.0   \n",
       "variables_decoder_config_decoding_mode                                                                    top_p   \n",
       "variables_latency_simulation_simulate_burst                                                               False   \n",
       "per-process_emissions_2                                                                                0.000278   \n",
       "per-process_emissions_3                                                                                0.000345   \n",
       "models                                                                                           82763530240000   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                         False   \n",
       "per-process_emissions_0                                                                                0.000327   \n",
       "variables_latency_simulation_burst_size                                                                       0   \n",
       "gpu_utilization_percent_0                                                                                  11.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                                     False   \n",
       "model_architecture_architecture                                                   Unknown (no config attribute)   \n",
       "gpu_utilization_percent_1                                                                                 100.0   \n",
       "\n",
       "                                                                                                             14  \\\n",
       "config_name                                            decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.0   \n",
       "experiment_id                                                                                                37   \n",
       "experiment_id                                                                                                37   \n",
       "date_time                                                                         April 08, 2025 at 03:51:06 PM   \n",
       "model                                                                           AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                                 4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                        TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                        False   \n",
       "task_type                                                                                       text_generation   \n",
       "available_gpu_count                                                                                           4   \n",
       "available_cpu_count                                                                                         128   \n",
       "os                                                               Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                                3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                                 Germany   \n",
       "region                                                                                                   saxony   \n",
       "sharding_strategy                                                                                      NO_SHARD   \n",
       "distributed_type                                                                      DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                                 4   \n",
       "max_input_tokens                                                                                            100   \n",
       "max_output_tokens                                                                                           100   \n",
       "number_input_prompts                                                                                         10   \n",
       "number_input_prompts                                                                                         10   \n",
       "decode_token_to_text                                                                                       True   \n",
       "decoder_temperature                                                                                         1.0   \n",
       "decoder_top_k                                                                                                 0   \n",
       "decoder_top_p                                                                                               0.9   \n",
       "query_rate                                                                                                  1.0   \n",
       "fp_precision                                                                                      torch.float32   \n",
       "quantization                                                                                              False   \n",
       "load_in_8bit                                                                                              False   \n",
       "load_in_4bit                                                                                              False   \n",
       "batch_size___fixed_batching                                                                                  16   \n",
       "adaptive_batching                                                                                             0   \n",
       "adaptive_batching                                                                                         False   \n",
       "adaptive_max_tokens                                                                                           0   \n",
       "inference_type                                                                                  pure_generative   \n",
       "backend                                                                                                 pytorch   \n",
       "total_input_tokens                                                                                         1000   \n",
       "total_generated_tokens                                                                                     1000   \n",
       "total_inference_time_sec                                                                               2.941688   \n",
       "average_latency_ms_per_batch                                                                        2941.687886   \n",
       "throughput_queries_per_sec                                                                             3.399409   \n",
       "throughput_tokens_per_sec                                                                            339.940891   \n",
       "flops                                                                                             1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                                   8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                       8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                                   13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                       13203668992   \n",
       "cpu_usage_percent                                                                                          95.9   \n",
       "cpu_memory_usage_bytes                                                                               2071113728   \n",
       "cpu_power_process_0                                                                                       112.5   \n",
       "cpu_power_process_1                                                                                       112.5   \n",
       "cpu_power_process_2                                                                                       112.5   \n",
       "cpu_power_process_3                                                                                       112.5   \n",
       "gpu_power_process_0                                                                                  870.948542   \n",
       "gpu_power_process_1                                                                                  520.617213   \n",
       "gpu_power_process_2                                                                                   519.26956   \n",
       "gpu_power_process_3                                                                                  517.444485   \n",
       "ram_power_process_0                                                                                    0.721996   \n",
       "ram_power_process_1                                                                                    0.674508   \n",
       "ram_power_process_2                                                                                     0.66577   \n",
       "ram_power_process_3                                                                                    0.669057   \n",
       "cpu_energy_process_0                                                                                   0.000104   \n",
       "cpu_energy_process_1                                                                                   0.000125   \n",
       "cpu_energy_process_2                                                                                   0.000108   \n",
       "cpu_energy_process_3                                                                                   0.000118   \n",
       "gpu_energy_process_0                                                                                    0.00056   \n",
       "gpu_energy_process_1                                                                                   0.000655   \n",
       "gpu_energy_process_2                                                                                   0.000595   \n",
       "gpu_energy_process_3                                                                                   0.000625   \n",
       "ram_energy_process_0                                                                                   0.000001   \n",
       "ram_energy_process_1                                                                                   0.000001   \n",
       "ram_energy_process_2                                                                                        0.0   \n",
       "ram_energy_process_3                                                                                   0.000001   \n",
       "total_energy_kwh_process_0                                                                             0.000665   \n",
       "total_energy_kwh_process_1                                                                             0.000781   \n",
       "total_energy_kwh_process_2                                                                             0.000704   \n",
       "total_energy_kwh_process_3                                                                             0.000743   \n",
       "total_energy_joules_process_0                                                                        2392.58356   \n",
       "total_energy_joules_process_1                                                                       2811.455466   \n",
       "total_energy_joules_process_2                                                                       2533.847387   \n",
       "total_energy_joules_process_3                                                                       2675.423085   \n",
       "cpu_power_avg                                                                                             112.5   \n",
       "gpu_power_avg                                                                                         607.06995   \n",
       "ram_power_avg                                                                                          0.682833   \n",
       "cpu_energy_total                                                                                       0.000455   \n",
       "gpu_energy_total                                                                                       0.002435   \n",
       "ram_energy_total                                                                                       0.000002   \n",
       "total_energy_kwh                                                                                       0.002893   \n",
       "total_energy_joules                                                                                10413.309498   \n",
       "tokens_per_joule                                                                                       0.096031   \n",
       "joules_per_token                                                                                      10.413309   \n",
       "flops_per_joule                                                                                 99348255.053844   \n",
       "joules_per_flop                                                                                             0.0   \n",
       "gpu_utilization_percent_2                                                                                 100.0   \n",
       "variables_latency_simulation_simulate                                                                     False   \n",
       "gpu_utilization_percent_3                                                                                 100.0   \n",
       "model_architecture_total_params                                                                      1100048384   \n",
       "variables_latency_simulation_delay_max                                                                        0   \n",
       "variables_latency_simulation_delay_min                                                                        0   \n",
       "per-process_emissions_1                                                                                0.000253   \n",
       "variables_latency_simulation_burst_interval                                                                 0.0   \n",
       "variables_decoder_config_decoding_mode                                                                    top_p   \n",
       "variables_latency_simulation_simulate_burst                                                               False   \n",
       "per-process_emissions_2                                                                                0.000298   \n",
       "per-process_emissions_3                                                                                0.000268   \n",
       "models                                                                                           82763530240000   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                         False   \n",
       "per-process_emissions_0                                                                                0.000283   \n",
       "variables_latency_simulation_burst_size                                                                       0   \n",
       "gpu_utilization_percent_0                                                                                   0.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                                     False   \n",
       "model_architecture_architecture                                                   Unknown (no config attribute)   \n",
       "gpu_utilization_percent_1                                                                                 100.0   \n",
       "\n",
       "                                                                                                             15  \\\n",
       "config_name                                            decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.3   \n",
       "experiment_id                                                                                                38   \n",
       "experiment_id                                                                                                38   \n",
       "date_time                                                                         April 08, 2025 at 03:51:47 PM   \n",
       "model                                                                           AMD EPYC 7742 64-Core Processor   \n",
       "model                                                                                 4 x NVIDIA A100-PCIE-40GB   \n",
       "model                                                                        TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "is_encoder_decoder                                                                                        False   \n",
       "task_type                                                                                       text_generation   \n",
       "available_gpu_count                                                                                           4   \n",
       "available_cpu_count                                                                                         128   \n",
       "os                                                               Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                                                3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                                 Germany   \n",
       "region                                                                                                   saxony   \n",
       "sharding_strategy                                                                                      NO_SHARD   \n",
       "distributed_type                                                                      DistributedType.MULTI_GPU   \n",
       "num_processes                                                                                                 4   \n",
       "max_input_tokens                                                                                            100   \n",
       "max_output_tokens                                                                                           100   \n",
       "number_input_prompts                                                                                         10   \n",
       "number_input_prompts                                                                                         10   \n",
       "decode_token_to_text                                                                                       True   \n",
       "decoder_temperature                                                                                         1.3   \n",
       "decoder_top_k                                                                                                 0   \n",
       "decoder_top_p                                                                                               0.9   \n",
       "query_rate                                                                                                  1.0   \n",
       "fp_precision                                                                                      torch.float32   \n",
       "quantization                                                                                              False   \n",
       "load_in_8bit                                                                                              False   \n",
       "load_in_4bit                                                                                              False   \n",
       "batch_size___fixed_batching                                                                                  16   \n",
       "adaptive_batching                                                                                             0   \n",
       "adaptive_batching                                                                                         False   \n",
       "adaptive_max_tokens                                                                                           0   \n",
       "inference_type                                                                                  pure_generative   \n",
       "backend                                                                                                 pytorch   \n",
       "total_input_tokens                                                                                         1000   \n",
       "total_generated_tokens                                                                                     1000   \n",
       "total_inference_time_sec                                                                               3.231563   \n",
       "average_latency_ms_per_batch                                                                        3231.563369   \n",
       "throughput_queries_per_sec                                                                             3.094477   \n",
       "throughput_tokens_per_sec                                                                            309.447746   \n",
       "flops                                                                                             1034544128000   \n",
       "gpu_current_memory_allocated_bytes                                                                   8817963520   \n",
       "gpu_max_memory_allocated_bytes                                                                       8817963520   \n",
       "gpu_current_memory_reserved_bytes                                                                   13203668992   \n",
       "gpu_max_memory_reserved_bytes                                                                       13203668992   \n",
       "cpu_usage_percent                                                                                          95.9   \n",
       "cpu_memory_usage_bytes                                                                               2072543232   \n",
       "cpu_power_process_0                                                                                       112.5   \n",
       "cpu_power_process_1                                                                                       112.5   \n",
       "cpu_power_process_2                                                                                       112.5   \n",
       "cpu_power_process_3                                                                                       112.5   \n",
       "gpu_power_process_0                                                                                  735.975673   \n",
       "gpu_power_process_1                                                                                  565.373927   \n",
       "gpu_power_process_2                                                                                   861.06761   \n",
       "gpu_power_process_3                                                                                32181.115723   \n",
       "ram_power_process_0                                                                                     0.72189   \n",
       "ram_power_process_1                                                                                     0.66819   \n",
       "ram_power_process_2                                                                                    0.670599   \n",
       "ram_power_process_3                                                                                      0.6773   \n",
       "cpu_energy_process_0                                                                                    0.00011   \n",
       "cpu_energy_process_1                                                                                   0.000139   \n",
       "cpu_energy_process_2                                                                                   0.000106   \n",
       "cpu_energy_process_3                                                                                   0.000133   \n",
       "gpu_energy_process_0                                                                                   0.000614   \n",
       "gpu_energy_process_1                                                                                   0.000768   \n",
       "gpu_energy_process_2                                                                                   0.000593   \n",
       "gpu_energy_process_3                                                                                   0.000739   \n",
       "ram_energy_process_0                                                                                   0.000001   \n",
       "ram_energy_process_1                                                                                   0.000001   \n",
       "ram_energy_process_2                                                                                        0.0   \n",
       "ram_energy_process_3                                                                                   0.000001   \n",
       "total_energy_kwh_process_0                                                                             0.000725   \n",
       "total_energy_kwh_process_1                                                                             0.000908   \n",
       "total_energy_kwh_process_2                                                                             0.000699   \n",
       "total_energy_kwh_process_3                                                                             0.000873   \n",
       "total_energy_joules_process_0                                                                       2608.786572   \n",
       "total_energy_joules_process_1                                                                       3268.690201   \n",
       "total_energy_joules_process_2                                                                       2516.566999   \n",
       "total_energy_joules_process_3                                                                       3142.047445   \n",
       "cpu_power_avg                                                                                             112.5   \n",
       "gpu_power_avg                                                                                       8585.883233   \n",
       "ram_power_avg                                                                                          0.684495   \n",
       "cpu_energy_total                                                                                       0.000488   \n",
       "gpu_energy_total                                                                                       0.002714   \n",
       "ram_energy_total                                                                                       0.000002   \n",
       "total_energy_kwh                                                                                       0.003204   \n",
       "total_energy_joules                                                                                11536.091218   \n",
       "tokens_per_joule                                                                                       0.086684   \n",
       "joules_per_token                                                                                      11.536091   \n",
       "flops_per_joule                                                                                 89678913.631807   \n",
       "joules_per_flop                                                                                             0.0   \n",
       "gpu_utilization_percent_2                                                                                 100.0   \n",
       "variables_latency_simulation_simulate                                                                     False   \n",
       "gpu_utilization_percent_3                                                                                 100.0   \n",
       "model_architecture_total_params                                                                      1100048384   \n",
       "variables_latency_simulation_delay_max                                                                        0   \n",
       "variables_latency_simulation_delay_min                                                                        0   \n",
       "per-process_emissions_1                                                                                0.000266   \n",
       "variables_latency_simulation_burst_interval                                                                 0.0   \n",
       "variables_decoder_config_decoding_mode                                                                    top_p   \n",
       "variables_latency_simulation_simulate_burst                                                               False   \n",
       "per-process_emissions_2                                                                                0.000276   \n",
       "per-process_emissions_3                                                                                0.000346   \n",
       "models                                                                                           82763530240000   \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                         False   \n",
       "per-process_emissions_0                                                                                0.000332   \n",
       "variables_latency_simulation_burst_size                                                                       0   \n",
       "gpu_utilization_percent_0                                                                                  10.0   \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                                     False   \n",
       "model_architecture_architecture                                                   Unknown (no config attribute)   \n",
       "gpu_utilization_percent_1                                                                                 100.0   \n",
       "\n",
       "                                                                                                      16  \n",
       "config_name                                                                                latency_False  \n",
       "experiment_id                                                                                         39  \n",
       "experiment_id                                                                                         39  \n",
       "date_time                                                                  April 08, 2025 at 03:52:27 PM  \n",
       "model                                                                    AMD EPYC 7742 64-Core Processor  \n",
       "model                                                                          4 x NVIDIA A100-PCIE-40GB  \n",
       "model                                                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0  \n",
       "is_encoder_decoder                                                                                 False  \n",
       "task_type                                                                                text_generation  \n",
       "available_gpu_count                                                                                    4  \n",
       "available_cpu_count                                                                                  128  \n",
       "os                                                        Linux-5.15.0-113-generic-x86_64-with-glibc2.31  \n",
       "python_version                                         3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]  \n",
       "country                                                                                          Germany  \n",
       "region                                                                                            saxony  \n",
       "sharding_strategy                                                                               NO_SHARD  \n",
       "distributed_type                                                               DistributedType.MULTI_GPU  \n",
       "num_processes                                                                                          4  \n",
       "max_input_tokens                                                                                     100  \n",
       "max_output_tokens                                                                                    100  \n",
       "number_input_prompts                                                                                  10  \n",
       "number_input_prompts                                                                                  10  \n",
       "decode_token_to_text                                                                                True  \n",
       "decoder_temperature                                                                                  1.0  \n",
       "decoder_top_k                                                                                          0  \n",
       "decoder_top_p                                                                                        0.0  \n",
       "query_rate                                                                                           1.0  \n",
       "fp_precision                                                                               torch.float32  \n",
       "quantization                                                                                       False  \n",
       "load_in_8bit                                                                                       False  \n",
       "load_in_4bit                                                                                       False  \n",
       "batch_size___fixed_batching                                                                           16  \n",
       "adaptive_batching                                                                                      0  \n",
       "adaptive_batching                                                                                  False  \n",
       "adaptive_max_tokens                                                                                    0  \n",
       "inference_type                                                                           pure_generative  \n",
       "backend                                                                                          pytorch  \n",
       "total_input_tokens                                                                                  1000  \n",
       "total_generated_tokens                                                                              1000  \n",
       "total_inference_time_sec                                                                        3.015216  \n",
       "average_latency_ms_per_batch                                                                 3015.216474  \n",
       "throughput_queries_per_sec                                                                      3.316511  \n",
       "throughput_tokens_per_sec                                                                     331.651146  \n",
       "flops                                                                                      1034544128000  \n",
       "gpu_current_memory_allocated_bytes                                                            8817963520  \n",
       "gpu_max_memory_allocated_bytes                                                                8817963520  \n",
       "gpu_current_memory_reserved_bytes                                                            13203668992  \n",
       "gpu_max_memory_reserved_bytes                                                                13203668992  \n",
       "cpu_usage_percent                                                                                   96.9  \n",
       "cpu_memory_usage_bytes                                                                        2069954560  \n",
       "cpu_power_process_0                                                                                112.5  \n",
       "cpu_power_process_1                                                                                112.5  \n",
       "cpu_power_process_2                                                                                112.5  \n",
       "cpu_power_process_3                                                                                112.5  \n",
       "gpu_power_process_0                                                                          1040.455759  \n",
       "gpu_power_process_1                                                                           478.508266  \n",
       "gpu_power_process_2                                                                           724.024972  \n",
       "gpu_power_process_3                                                                           625.458328  \n",
       "ram_power_process_0                                                                             0.721667  \n",
       "ram_power_process_1                                                                             0.665766  \n",
       "ram_power_process_2                                                                             0.670034  \n",
       "ram_power_process_3                                                                             0.667248  \n",
       "cpu_energy_process_0                                                                            0.000108  \n",
       "cpu_energy_process_1                                                                            0.000138  \n",
       "cpu_energy_process_2                                                                             0.00011  \n",
       "cpu_energy_process_3                                                                            0.000118  \n",
       "gpu_energy_process_0                                                                            0.000575  \n",
       "gpu_energy_process_1                                                                            0.000718  \n",
       "gpu_energy_process_2                                                                            0.000584  \n",
       "gpu_energy_process_3                                                                            0.000634  \n",
       "ram_energy_process_0                                                                            0.000001  \n",
       "ram_energy_process_1                                                                            0.000001  \n",
       "ram_energy_process_2                                                                                 0.0  \n",
       "ram_energy_process_3                                                                            0.000001  \n",
       "total_energy_kwh_process_0                                                                      0.000684  \n",
       "total_energy_kwh_process_1                                                                      0.000857  \n",
       "total_energy_kwh_process_2                                                                      0.000694  \n",
       "total_energy_kwh_process_3                                                                      0.000753  \n",
       "total_energy_joules_process_0                                                                2461.824321  \n",
       "total_energy_joules_process_1                                                                3084.588804  \n",
       "total_energy_joules_process_2                                                                2499.282586  \n",
       "total_energy_joules_process_3                                                                2710.511309  \n",
       "cpu_power_avg                                                                                      112.5  \n",
       "gpu_power_avg                                                                                 717.111831  \n",
       "ram_power_avg                                                                                   0.681179  \n",
       "cpu_energy_total                                                                                0.000475  \n",
       "gpu_energy_total                                                                                 0.00251  \n",
       "ram_energy_total                                                                                0.000002  \n",
       "total_energy_kwh                                                                                0.002988  \n",
       "total_energy_joules                                                                         10756.207022  \n",
       "tokens_per_joule                                                                                 0.09297  \n",
       "joules_per_token                                                                               10.756207  \n",
       "flops_per_joule                                                                          96181128.341084  \n",
       "joules_per_flop                                                                                      0.0  \n",
       "gpu_utilization_percent_2                                                                           99.0  \n",
       "variables_latency_simulation_simulate                                                              False  \n",
       "gpu_utilization_percent_3                                                                          100.0  \n",
       "model_architecture_total_params                                                               1100048384  \n",
       "variables_latency_simulation_delay_max                                                                 0  \n",
       "variables_latency_simulation_delay_min                                                                 0  \n",
       "per-process_emissions_1                                                                         0.000326  \n",
       "variables_latency_simulation_burst_interval                                                          0.0  \n",
       "variables_decoder_config_decoding_mode                                                               NaN  \n",
       "variables_latency_simulation_simulate_burst                                                        False  \n",
       "per-process_emissions_2                                                                         0.000264  \n",
       "per-process_emissions_3                                                                         0.000261  \n",
       "models                                                                                    82763530240000  \n",
       "variables_sharding_config_fsdp_config_cpu_offload                                                  False  \n",
       "per-process_emissions_0                                                                         0.000287  \n",
       "variables_latency_simulation_burst_size                                                                0  \n",
       "gpu_utilization_percent_0                                                                           24.0  \n",
       "variables_sharding_config_fsdp_config_use_orig_params                                              False  \n",
       "model_architecture_architecture                                            Unknown (no config attribute)  \n",
       "gpu_utilization_percent_1                                                                          100.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_text_generation = inspect_results('text_generation', desired_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_generation = inspect_results('text_generation', desired_order)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will later move this into function script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'analysis_08_04/results/controlled_results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43manalysis_08_04/results/controlled_results.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(df\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns:\n",
      "File \u001b[0;32m~/thesis/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/thesis/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/thesis/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/thesis/thesis/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/thesis/thesis/lib/python3.10/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'analysis_08_04/results/controlled_results.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('analysis_08_04/results/controlled_results.csv')\n",
    "columns = list(df.columns)\n",
    "for col in columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column(col: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean a single column name by:\n",
    "      - Stripping whitespace and replacing any non-standard quotes.\n",
    "      - Checking for per-process metric patterns.\n",
    "      - Applying special renames.\n",
    "      - Removing the 'variables_' prefix if present.\n",
    "      - Otherwise, attempting to strip off any messy prefixes using a known list of tokens.\n",
    "    \n",
    "    If no known token is found, the original (normalized) column name is returned.\n",
    "    \"\"\"\n",
    "    # Normalize the column string: remove extra whitespace and fix common issues with quotes.\n",
    "    col = col.strip()\n",
    "    col = col.replace(\"“\", \"\\\"\").replace(\"”\", \"\\\"\")\n",
    "    \n",
    "    # 1. Special exact mappings.\n",
    "    special_mappings = {\n",
    "        \"setup_cpu_model\": \"cpu_model\",\n",
    "        \"setup_gpu_model\": \"gpu_model\",\n",
    "        \"model_architecture_total_params\": \"total_params\",  # now maps to total_params\n",
    "        \"model_architecture_architecture\": \"model_arch\"\n",
    "    }\n",
    "    if col in special_mappings:\n",
    "        return special_mappings[col]\n",
    "    \n",
    "    # 2. Remove the 'variables_' prefix if it exists.\n",
    "    if col.startswith(\"variables_\"):\n",
    "        col = col[len(\"variables_\"):]\n",
    "    \n",
    "    # 3. First, check if it is a per-process metric column.\n",
    "    per_process_patterns = [\n",
    "        r'(cpu_power_process_\\d+)',\n",
    "        r'(gpu_power_process_\\d+)',\n",
    "        r'(ram_power_process_\\d+)',\n",
    "        r'(cpu_energy_process_\\d+)',\n",
    "        r'(gpu_energy_process_\\d+)',\n",
    "        r'(ram_energy_process_\\d+)',\n",
    "        r'(total_energy_kwh_process_\\d+)',\n",
    "        r'(total_energy_joules_process_\\d+)'\n",
    "    ]\n",
    "    for pattern in per_process_patterns:\n",
    "        match = re.search(pattern, col)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    \n",
    "    # 4. For non-per-process columns, search for a known token in the cleaned column.\n",
    "    tokens = [\n",
    "        \"config_name\", \"experiment_id\", \"date_time\", \"model\", \"is_encoder_decoder\",\n",
    "        \"task_type\", \"available_gpu_count\", \"gpu_model\", \"available_cpu_count\", \"cpu_model\",\n",
    "        \"os\", \"python_version\", \"country\", \"region\", \"fsdp_use_orig_params\", \"fsdp_cpu_offload\",\n",
    "        \"sharding_strategy\", \"distributed_type\", \"num_processes\", \"max_input_tokens\", \"max_output_tokens\",\n",
    "        \"number_input_prompts\", \"decode_token_to_text\", \"decoder_temperature\", \"decoder_top_k\", \"decoder_top_p\",\n",
    "        \"query_rate\", \"latency_simulate\", \"latency_delay_min\", \"latency_delay_max\", \"latency_simulate_burst\",\n",
    "        \"latency_burst_interval\", \"latency_burst_size\", \"fp_precision\", \"quantization\", \"load_in_8bit\",\n",
    "        \"load_in_4bit\", \"cached_flops_for_quantised_models\", \"batch_size___fixed_batching\", \"adaptive_batching\",\n",
    "        \"adaptive_max_tokens\", \"max_batch_size___adaptive_batching\", \"inference_type\", \"backend\", \"total_params\",\n",
    "        \"architecture\", \"total_input_tokens\", \"total_generated_tokens\", \"total_inference_time_sec\", \n",
    "        \"average_latency_ms_per_batch\", \"throughput_queries_per_sec\", \"throughput_tokens_per_sec\", \"flops\",\n",
    "        \"gpu_current_memory_allocated_bytes\", \"gpu_max_memory_allocated_bytes\", \"gpu_current_memory_reserved_bytes\",\n",
    "        \"gpu_max_memory_reserved_bytes\", \"gpu_utilization_percent\", \"cpu_usage_percent\", \"cpu_memory_usage_bytes\",\n",
    "        # Per-process metrics:\n",
    "        \"cpu_power_process_0\", \"gpu_power_process_0\", \"ram_power_process_0\",\n",
    "        \"cpu_energy_process_0\", \"gpu_energy_process_0\", \"ram_energy_process_0\",\n",
    "        \"total_energy_kwh_process_0\", \"total_energy_joules_process_0\",\n",
    "        # Global averages and totals:\n",
    "        \"cpu_power_avg\", \"gpu_power_avg\", \"ram_power_avg\", \"cpu_energy_total\", \"gpu_energy_total\", \"ram_energy_total\",\n",
    "        \"total_energy_kwh\", \"total_energy_joules\", \"tokens_per_joule\", \"joules_per_token\", \"flops_per_joule\", \"joules_per_flop\",\n",
    "        \"per-process_emissions\"\n",
    "    ]\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in col:\n",
    "            idx = col.find(token)\n",
    "            return col[idx:]\n",
    "    \n",
    "    return col\n",
    "\n",
    "def resolve_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Resolve duplicate columns in the DataFrame.\n",
    "    \n",
    "    For any column that appears more than once:\n",
    "      - For 'adaptive_batching', if duplicates exist, prefer the one with a boolean dtype;\n",
    "        otherwise, pick the first occurrence.\n",
    "      - For all other columns (including 'experiment_id' and 'number_input_prompts'),\n",
    "        keep only the first occurrence.\n",
    "    \"\"\"\n",
    "    # Build a mapping of column name to list of indices where it occurs.\n",
    "    seen = {}\n",
    "    for idx, col in enumerate(df.columns):\n",
    "        seen.setdefault(col, []).append(idx)\n",
    "    \n",
    "    # Choose one index per duplicate group.\n",
    "    chosen_indices = []\n",
    "    for col, indices in seen.items():\n",
    "        if len(indices) == 1:\n",
    "            chosen_indices.append(indices[0])\n",
    "        else:\n",
    "            if col == \"adaptive_batching\":\n",
    "                # Look for a column with boolean type.\n",
    "                bool_idx = None\n",
    "                for i in indices:\n",
    "                    if pd.api.types.is_bool_dtype(df.iloc[:, i]):\n",
    "                        bool_idx = i\n",
    "                        break\n",
    "                chosen_indices.append(bool_idx if bool_idx is not None else indices[0])\n",
    "            else:\n",
    "                # For experiment_id, number_input_prompts, or any duplicate, keep the first occurrence.\n",
    "                chosen_indices.append(indices[0])\n",
    "    \n",
    "    # Sort indices to preserve the original order.\n",
    "    chosen_indices.sort()\n",
    "    return df.iloc[:, chosen_indices]\n",
    "\n",
    "def clean_and_reorder_columns(df: pd.DataFrame, desired_order: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean DataFrame columns by:\n",
    "      1. Renaming each column to remove extraneous prefixes and apply special mappings.\n",
    "      2. Removing duplicates (applying special resolution for some columns).\n",
    "      3. Reordering columns into the order specified by 'desired_order'. Any columns not explicitly mentioned\n",
    "         will be appended at the end.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with messy, flattened column names.\n",
    "        desired_order (list): List of column names (after cleaning) indicating the preferred ordering.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with cleaned and reordered columns.\n",
    "    \"\"\"\n",
    "    # Build mapping from original column names to cleaned names.\n",
    "    mapping = {col: clean_column(col) for col in df.columns}\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    df = df.rename(columns=mapping)\n",
    "    \n",
    "    # Resolve duplicates as required.\n",
    "    df = resolve_duplicates(df)\n",
    "    \n",
    "    # Reorder columns: first, the ones matching the desired order.\n",
    "    ordered_cols = [col for col in desired_order if col in df.columns]\n",
    "    # Then, append any remaining columns.\n",
    "    remaining_cols = [col for col in df.columns if col not in desired_order]\n",
    "    final_order = ordered_cols + remaining_cols\n",
    "    \n",
    "    return df[final_order]\n",
    "\n",
    "# Example desired order list\n",
    "desired_order = [\n",
    "    \"config_name\",\n",
    "    \"experiment_id\",\n",
    "    \"date_time\",\n",
    "    \"model\",\n",
    "    # num_process\n",
    "    \"num_processes\",\n",
    "    # batching\n",
    "    \"batch_size___fixed_batching\",\n",
    "    # decodeer\n",
    "    \"decoder_temperature\",\n",
    "    \"decoder_top_k\",\n",
    "    \"decoder_top_p\",\n",
    "    # latency\n",
    "    \"latency_simulation_simulate\"\n",
    "    \"latency_simulation_delay_max\",\n",
    "    \"latency_simulation_delay_min\",\n",
    "    \"latency_simulation_simulate_burst\",\n",
    "    \"latency_simulation_burst_size\",\n",
    "    \"latency_simulation_burst_interval\",\n",
    "    # precision / quantisation\n",
    "    \"fp_precision\",\n",
    "    \"quantization\",\n",
    "    \"load_in_8bit\",\n",
    "    \"load_in_4bit\",\n",
    "    \"cached_flops_for_quantised_models\",\n",
    "    \n",
    "    # UNUSED PARAMS\n",
    "    \"sharding_strategy\",\n",
    "    \"sharding_config_fsdp_config_use_orig_params\",\n",
    "    \"sharding_config_fsdp_config_cpu_offload\",\n",
    "    \"adaptive_batching\",\n",
    "    \"adaptive_max_tokens\",\n",
    "    \"query_rate\",\n",
    "    \"total_input_tokens\",\n",
    "    \"total_generated_tokens\"\n",
    "    \n",
    "    # CONSTANT SETUP ====\n",
    "    \"date_time\",\n",
    "    \"is_encoder_decoder\",\n",
    "    \"task_type\",\n",
    "    \"available_gpu_count\",\n",
    "    \"gpu_model\",\n",
    "    \"available_cpu_count\",\n",
    "    \"cpu_model\",\n",
    "    \"os\",\n",
    "    \"python_version\",\n",
    "    \"country\",\n",
    "    \"region\",\n",
    "    \"distributed_type\",\n",
    "    \"decode_token_to_text\",\n",
    "    \"inference_type\",\n",
    "    \"backend\",\n",
    "    \"total_params\",\n",
    "    \"model_arch\",\n",
    "\n",
    "    # Validation (should be same):\n",
    "    \"max_input_tokens\",\n",
    "    \"max_output_tokens\",\n",
    "    \"number_input_prompts\",\n",
    "    \n",
    "    # RESULTS =====\n",
    "    # energy\n",
    "    \"total_energy_kwh\",\n",
    "    \"total_energy_joules\",\n",
    "    # FLOPS\n",
    "    \"flops\",\n",
    "    \"tokens_per_joule\",\n",
    "    \"joules_per_token\",\n",
    "    \"flops_per_joule\",\n",
    "    \"joules_per_flop\",\n",
    "    \"total_inference_time_sec\", \n",
    "    # inference performance\n",
    "    \"average_latency_ms_per_batch\",\n",
    "    \"throughput_queries_per_sec\",\n",
    "    \"throughput_tokens_per_sec\",\n",
    "    # CPU utilization\n",
    "    \"cpu_usage_percent\",\n",
    "    \"cpu_memory_usage_bytes\",\n",
    "    # GPU utilization\n",
    "    \"gpu_utilization_percent_0\", \"gpu_utilization_percent_1\", \"gpu_utilization_percent_2\", \"gpu_utilization_percent_3\",\n",
    "    # Compute mem\n",
    "    \"gpu_current_memory_allocated_bytes\",\n",
    "    \"gpu_max_memory_allocated_bytes\",\n",
    "    \"gpu_current_memory_reserved_bytes\",\n",
    "    \"gpu_max_memory_reserved_bytes\",\n",
    "    # Per-process metrics:\n",
    "    \"cpu_power_process_0\", \"cpu_power_process_1\", \"cpu_power_process_2\", \"cpu_power_process_3\",\n",
    "    \"gpu_power_process_0\", \"gpu_power_process_1\", \"gpu_power_process_2\", \"gpu_power_process_3\",\n",
    "    \"ram_power_process_0\", \"ram_power_process_1\", \"ram_power_process_2\", \"ram_power_process_3\",\n",
    "    \"cpu_energy_process_0\", \"cpu_energy_process_1\", \"cpu_energy_process_2\", \"cpu_energy_process_3\",\n",
    "    \"gpu_energy_process_0\", \"gpu_energy_process_1\", \"gpu_energy_process_2\", \"gpu_energy_process_3\",\n",
    "    \"ram_energy_process_0\", \"ram_energy_process_1\", \"ram_energy_process_2\", \"ram_energy_process_3\",\n",
    "    \"total_energy_kwh_process_0\", \"total_energy_kwh_process_1\", \"total_energy_kwh_process_2\", \"total_energy_kwh_process_3\",\n",
    "    \"total_energy_joules_process_0\", \"total_energy_joules_process_1\", \"total_energy_joules_process_2\", \"total_energy_joules_process_3\",\n",
    "    # Global averages and totals:\n",
    "    \"cpu_power_avg\",\n",
    "    \"gpu_power_avg\",\n",
    "    \"ram_power_avg\",\n",
    "    \"cpu_energy_total\",\n",
    "    \"gpu_energy_total\",\n",
    "    \"ram_energy_total\",\n",
    "    # per-process_emsisisons\n",
    "    \"per-process_emissions_0\", \"per-process_emissions_1\", \"per-process_emissions_2\",\"per-process_emissions_3\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect_results(name, desired_order):\n",
    "    input_file = f\"analysis_08_04/results/{name}_results.csv\"\n",
    "    \n",
    "    df = pd.read_csv(input_file)\n",
    "    df_cleaned = clean_and_reorder_columns(df, desired_order)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "possible_files = [\"controlled\", \"scenarios\", \"grid\", \"text_generation\"]\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "for file in possible_files:\n",
    "    try:\n",
    "        var_name = f\"df_{file}_cleaned\"\n",
    "        globals()[var_name] = inspect_results(file, desired_order)  # dynamically create variable\n",
    "        print(f\"Found & inspecting: {var_name}\")\n",
    "        display(globals()[var_name].T)\n",
    "    except Exception as e:\n",
    "        print(f\"{file} did not exist: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second round ordering\n",
    "#existing_cols = [col for col in desired_order if col in df.columns]\n",
    "#df_controlled = df[existing_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    \"sharding_strategy\",\n",
    "    \"sharding_config_fsdp_config_use_orig_params\",\n",
    "    \"sharding_config_fsdp_config_cpu_offload\",\n",
    "    \"adaptive_batching\",\n",
    "    \"adaptive_max_tokens\",\n",
    "    \"query_rate\",\n",
    "    \"is_encoder_decoder\",\n",
    "    \"task_type\",\n",
    "    \"available_gpu_count\",\n",
    "    \"gpu_model\",\n",
    "    \"available_cpu_count\",\n",
    "    \"cpu_model\",\n",
    "    \"os\",\n",
    "    \"python_version\",\n",
    "    \"country\",\n",
    "    \"region\",\n",
    "    \"distributed_type\",\n",
    "    \"decode_token_to_text\",\n",
    "    \"inference_type\",\n",
    "    \"backend\",\n",
    "    \"model_arch\",\n",
    "    \"gpu_current_memory_allocated_bytes\",\n",
    "    \"gpu_max_memory_allocated_bytes\",\n",
    "    \"gpu_current_memory_reserved_bytes\",\n",
    "    \"gpu_max_memory_reserved_bytes\",\n",
    "    \"per-process_emissions_0\", \"per-process_emissions_1\", \"per-process_emissions_2\",\"per-process_emissions_3\" # OR IS THIS NICE TO HAVE?\n",
    "]\n",
    "\n",
    "for file in possible_files:\n",
    "    try:\n",
    "        cleaned_var = f\"df_{file}_cleaned\"   # e.g., df_controlled_cleaned\n",
    "        dropped_var = f\"df_{file}_dropped\"     # e.g., df_controlled_dropped\n",
    "        \n",
    "        # Drop the specified columns from the cleaned DataFrame.\n",
    "        globals()[dropped_var] = globals()[cleaned_var].drop(columns=columns_to_drop)\n",
    "        print(f\"Found & inspecting dropped version: {dropped_var}\")\n",
    "        display(globals()[dropped_var].T)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all flops are constant\n",
    "df_controlled_dropped['flops'].unique()\n",
    "# TO DO: MAKE THIS DYANMIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MOVE THIS CALCULATION INTO THE RESULTS GENERATED \n",
    "df_controlled_dropped['flops_per_token'] = df_controlled_dropped['flops'] / df_controlled_dropped['total_generated_tokens']\n",
    "df_controlled_dropped['energy_per_token_kwh'] = df_controlled_dropped['total_energy_kwh'] / df_controlled_dropped['total_generated_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_controlled_dropped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_controlled_dropped['config_name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def extract_altered_value(config_name, family):\n",
    "    \"\"\"\n",
    "    Given a config name and a family, extract the altered value.\n",
    "    For each family, a different rule is applied:\n",
    "    \n",
    "    - num_processes: extract the integer after \"num_processes_\"\n",
    "    - batching: extract the integer after \"batching_\"\n",
    "    - precis: extract the precision setting; if quant4 is True, return \"load_in_4bit=True\",\n",
    "              otherwise return the float precision (e.g., \"float32\" or \"float16\")\n",
    "    - decoding: extract the decoder_temperature (as a float) from the config name.\n",
    "    - latency: if the config is exactly \"latency_False\", return \"No latency\"; otherwise, \n",
    "               extract and join all numeric values in the config string.\n",
    "    \"\"\"\n",
    "    if family == \"num_processes\":\n",
    "        m = re.search(r'num_processes_(\\d+)', config_name)\n",
    "        return int(m.group(1)) if m else config_name\n",
    "    \n",
    "    elif family == \"batching\":\n",
    "        m = re.search(r'batching_(\\d+)', config_name)\n",
    "        return int(m.group(1)) if m else config_name\n",
    "    \n",
    "    elif family == \"precis\":\n",
    "        m = re.search(r'precis_(float\\d+)', config_name)\n",
    "        precision = m.group(1) if m else None\n",
    "        # If quant4 is True, we assume load_in_4bit is the relevant setting. COME BACK TO THIS!!!\n",
    "        if \"quant4_True\" in config_name:\n",
    "            return \"load_in_4bit=True\"\n",
    "        else:\n",
    "            return precision\n",
    "        \n",
    "    elif family == \"decoding\":\n",
    "        # This family might have several variants. We extract the decoder_temperature. COME BACK TO\n",
    "        m = re.search(r'decoder_temperature_([\\d\\.]+)', config_name)\n",
    "        return float(m.group(1)) if m else config_name\n",
    "    \n",
    "    elif family == \"latency\":\n",
    "        # If it's simply \"latency_False\", nothing was altered.\n",
    "        if config_name == \"latency_False\":\n",
    "            return \"No latency\"\n",
    "        else:\n",
    "            # Find all numbers (either integer or float) in the string.\n",
    "            numbers = re.findall(r'\\d+\\.\\d+|\\d+', config_name)\n",
    "            return \", \".join(numbers)\n",
    "    else:\n",
    "        return config_name\n",
    "\n",
    "def plot_family(df, family, metric1, metric2):\n",
    "    \"\"\"\n",
    "    For a given family, subset the DataFrame (rows whose config_name starts with family).\n",
    "    Create a new column that holds the altered value for that family, sort the data by that value,\n",
    "    and plot two metrics against this altered value.\n",
    "    \n",
    "    Parameters:\n",
    "      - df: a DataFrame with a \"config_name\" column.\n",
    "      - family: the family string (e.g. \"num_processes\", \"batching\", etc).\n",
    "      - metric1: name of the first metric column to plot on the left Y axis (e.g., \"flops_per_token\").\n",
    "      - metric2: name of the second metric column to plot on the right Y axis (e.g., \"total_energy_kwh\").\n",
    "    \"\"\"\n",
    "    # Subset rows where config_name starts with the family string.\n",
    "    df_family = df[df['config_name'].str.startswith(family)].copy()\n",
    "    \n",
    "    # Apply the parser to create an \"altered_value\" column.\n",
    "    df_family['altered_value'] = df_family['config_name'].apply(lambda x: extract_altered_value(x, family))\n",
    "    \n",
    "    # Attempt to sort by altered_value.\n",
    "    # If the values are numeric, convert them.\n",
    "    try:\n",
    "        df_family['altered_value'] = pd.to_numeric(df_family['altered_value'])\n",
    "    except:\n",
    "        pass  # leave as string if conversion fails\n",
    "    \n",
    "    df_family.sort_values('altered_value', inplace=True)\n",
    "    \n",
    "    # Create a plot with twin y-axes.\n",
    "    fig, ax1 = plt.subplots(figsize=(8,5))\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # Plot metric1 on ax1 and metric2 on ax2.\n",
    "    ax1.plot(df_family['altered_value'], df_family[metric1], marker='o', label=metric1, color='blue')\n",
    "    ax2.plot(df_family['altered_value'], df_family[metric2], marker='s', label=metric2, color='red')\n",
    "    \n",
    "    ax1.set_xlabel(f'{family} configuration')\n",
    "    ax1.set_ylabel(metric1, color='blue')\n",
    "    ax2.set_ylabel(metric2, color='red')\n",
    "    plt.title(f'{family}: {metric1} and {metric2} vs altered setting')\n",
    "    \n",
    "    # Combine the legends.\n",
    "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='best')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "families = [\"num_processes\", \"batching\", \"precis\", \"decoding\", \"latency\"]\n",
    "\n",
    "for fam in families:\n",
    "    plot_family(df_controlled_dropped, fam, metric1=\"flops_per_token\", metric2=\"energy_per_token_kwh\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# RESTART FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# First, organise your separate dfs into a list of (name, df) pairs\n",
    "dfs = [\n",
    "    (\"Num Processes\", num_processes_df),\n",
    "    (\"Batching\", batching_df),\n",
    "    (\"Precision\", precics_df),\n",
    "    (\"Decoding\", decoding_df),\n",
    "    (\"Latency\", latency_df)\n",
    "]\n",
    "\n",
    "for name, df in dfs:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # ----- First subplot: Divergence Energy vs Batch Size -----\n",
    "    axes[0].plot(\n",
    "        df['num_processes'],\n",
    "        df['divergence_energy_flops_per_token'],\n",
    "        marker='o', \n",
    "        linestyle='-',\n",
    "        color='orange'\n",
    "    )\n",
    "    axes[0].set_xlabel('Batch Size (Fixed Batching)')\n",
    "    axes[0].set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "    axes[0].set_title(f'Divergence Energy vs Batch Size ({name})')\n",
    "    axes[0].set_xticks(df['num_processes'])\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # ----- Second subplot: Two Y-axes with Energy per Token and FLOPs per Token -----\n",
    "    ax1 = axes[1]\n",
    "    line1, = ax1.plot(\n",
    "        df['num_processes'], \n",
    "        df['energy_per_token_kwh'], \n",
    "        marker='o', \n",
    "        linestyle='-', \n",
    "        color='blue', \n",
    "        label='Energy per Token (kWh)'\n",
    "    )\n",
    "    ax1.set_xlabel('Batch Size (Fixed Batching)')\n",
    "    ax1.set_ylabel('Energy per Token (kWh)', color='blue')\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax1.set_xticks(df['num_processes'])\n",
    "    ax1.set_title(f'Metrics vs Batch Size ({name})')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    line2, = ax2.plot(\n",
    "        df['num_processes'], \n",
    "        df['flops_per_token'], \n",
    "        marker='s', \n",
    "        linestyle='--', \n",
    "        color='red', \n",
    "        label='FLOPs per Token'\n",
    "    )\n",
    "    ax2.set_ylabel('FLOPs per Token', color='red')\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    # Combine legends\n",
    "    lines = [line1, line2]\n",
    "    labels = [line.get_label() for line in lines]\n",
    "    ax1.legend(lines, labels, loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Create a new 'precision' column for plotting\n",
    "def determine_precision(row):\n",
    "    if row.get('load_in_4bit', False):\n",
    "        return 'INT4'\n",
    "    elif row.get('load_in_8bit', False):\n",
    "        return 'INT8'\n",
    "    elif row.get('fp_precision') == 'torch.float16':\n",
    "        return 'FP16'\n",
    "    else:\n",
    "        return 'FP32'\n",
    "\n",
    "precics_df['precision'] = precics_df.apply(determine_precision, axis=1)\n",
    "\n",
    "# Step 2: Define custom precision order\n",
    "precision_order = ['FP32', 'FP16', 'INT8', 'INT4']\n",
    "\n",
    "# Step 3: Sort the dataframe according to precision order\n",
    "precics_df['precision'] = pd.Categorical(precics_df['precision'], categories=precision_order, ordered=True)\n",
    "precics_df = precics_df.sort_values('precision')\n",
    "\n",
    "# Step 4: Plotting\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# ----- First subplot: Divergence Energy vs Precision -----\n",
    "axes[0].plot(\n",
    "    precics_df['precision'],\n",
    "    precics_df['divergence_energy_flops_per_token'],\n",
    "    marker='o', \n",
    "    linestyle='-',\n",
    "    color='orange'\n",
    ")\n",
    "axes[0].set_xlabel('Precision')\n",
    "axes[0].set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "axes[0].set_title('Divergence Energy vs Precision')\n",
    "axes[0].grid(True)\n",
    "\n",
    "# ----- Second subplot: Two Y-axes with Energy per Token and FLOPs per Token -----\n",
    "ax1 = axes[1]\n",
    "line1, = ax1.plot(\n",
    "    precics_df['precision'], \n",
    "    precics_df['energy_per_token_kwh'], \n",
    "    marker='o', \n",
    "    linestyle='-', \n",
    "    color='blue', \n",
    "    label='Energy per Token (kWh)'\n",
    ")\n",
    "ax1.set_xlabel('Precision')\n",
    "ax1.set_ylabel('Energy per Token (kWh)', color='blue')\n",
    "ax1.tick_params(axis='y')\n",
    "ax1.set_title('Metrics vs Precision')\n",
    "ax1.grid(True)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "line2, = ax2.plot(\n",
    "    precics_df['precision'], \n",
    "    precics_df['flops_per_token'], \n",
    "    marker='s', \n",
    "    linestyle='--', \n",
    "    color='red', \n",
    "    label='FLOPs per Token'\n",
    ")\n",
    "ax2.set_ylabel('FLOPs per Token', color='red')\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "# Combine legends\n",
    "lines = [line1, line2]\n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# --- Step 1: Filter the dataframe based on the config names ---\n",
    "config_names = [\n",
    "    'decoding_greedy_decoder_temperature_0',\n",
    "    'decoding_greedy_decoder_temperature_0.7',\n",
    "    'decoding_greedy_decoder_temperature_1.0',\n",
    "    'decoding_greedy_decoder_temperature_1.3',\n",
    "    'decoding_top_k_decoder_top_k_50_decoder_temperature_0',\n",
    "    'decoding_top_k_decoder_top_k_50_decoder_temperature_0.7',\n",
    "    'decoding_top_k_decoder_top_k_50_decoder_temperature_1.0',\n",
    "    'decoding_top_k_decoder_top_k_50_decoder_temperature_1.3',\n",
    "    'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0',\n",
    "    'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.7',\n",
    "    'decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.0',\n",
    "    'decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.3'\n",
    "]\n",
    "filtered_decoding = decoding_df[decoding_df['config_name'].isin(config_names)].copy()\n",
    "\n",
    "# --- Step 2: Extract method and temperature from the config_name ---\n",
    "def extract_method_and_temp(config):\n",
    "    if config.startswith(\"decoding_greedy_decoder_temperature_\"):\n",
    "        temp = float(config.split(\"decoding_greedy_decoder_temperature_\")[-1])\n",
    "        return \"greedy\", temp\n",
    "    elif config.startswith(\"decoding_top_k_decoder_top_k_50_decoder_temperature_\"):\n",
    "        temp = float(config.split(\"decoding_top_k_decoder_top_k_50_decoder_temperature_\")[-1])\n",
    "        return \"top_k\", temp\n",
    "    elif config.startswith(\"decoding_top_p_decoder_top_p_0.9_decoder_temperature_\"):\n",
    "        temp = float(config.split(\"decoding_top_p_decoder_top_p_0.9_decoder_temperature_\")[-1])\n",
    "        return \"top_p\", temp\n",
    "    else:\n",
    "        return \"unknown\", None\n",
    "\n",
    "# Apply the extraction function and assign to new columns\n",
    "filtered_decoding[['method', 'temperature']] = filtered_decoding['config_name'].apply(\n",
    "    lambda x: pd.Series(extract_method_and_temp(x))\n",
    ")\n",
    "\n",
    "# Optionally sort the dataframe by method and temperature for clarity.\n",
    "filtered_decoding = filtered_decoding.sort_values(['method', 'temperature'])\n",
    "\n",
    "# --- Step 3: Plotting ---\n",
    "\n",
    "# Define colors for each method\n",
    "colors = {\n",
    "    'greedy': 'blue',\n",
    "    'top_k': 'green',\n",
    "    'top_p': 'red'\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# --- Left subplot: Divergence Energy vs Temperature ---\n",
    "ax_left = axes[0]\n",
    "methods = filtered_decoding['method'].unique()\n",
    "for m in methods:\n",
    "    subdf = filtered_decoding[filtered_decoding['method'] == m]\n",
    "    ax_left.plot(subdf['temperature'], subdf['divergence_energy_flops_per_token'],\n",
    "                 marker='o', linestyle='-', label=m, color=colors.get(m))\n",
    "ax_left.set_xlabel('Decoder Temperature')\n",
    "ax_left.set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "ax_left.set_title('Divergence Energy vs Decoder Temperature')\n",
    "ax_left.grid(True)\n",
    "ax_left.legend(title=\"Method\")\n",
    "\n",
    "# --- Right subplot: Two Y-axes with Energy per Token and FLOPs per Token ---\n",
    "ax1 = axes[1]\n",
    "# Primary axis for Energy per Token\n",
    "for m in methods:\n",
    "    subdf = filtered_decoding[filtered_decoding['method'] == m]\n",
    "    ax1.plot(subdf['temperature'], subdf['energy_per_token_kwh'],\n",
    "             marker='o', linestyle='-', label=f'{m} Energy', color=colors.get(m))\n",
    "ax1.set_xlabel('Decoder Temperature')\n",
    "ax1.set_ylabel('Energy per Token (kWh)', color='black')\n",
    "ax1.set_title('Metrics vs Decoder Temperature')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Secondary axis for FLOPs per Token\n",
    "ax2 = ax1.twinx()\n",
    "for m in methods:\n",
    "    subdf = filtered_decoding[filtered_decoding['method'] == m]\n",
    "    ax2.plot(subdf['temperature'], subdf['flops_per_token'],\n",
    "             marker='s', linestyle='--', label=f'{m} FLOPs', color=colors.get(m))\n",
    "ax2.set_ylabel('FLOPs per Token', color='black')\n",
    "\n",
    "# --- Combine legends from both axes ---\n",
    "lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "ax1.legend(lines1 + lines2, labels1 + labels2, loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1. Filter the latency_df to only keep the specified configurations ---\n",
    "latency_configs = [\n",
    "    'latency_False',\n",
    "    'latency_True_latency_0.05_latency_0.2_latency_False',\n",
    "    'latency_True_latency_0.2_latency_0.6_latency_False',\n",
    "    'latency_True_latency_0.05_latency_0.2_latency_True_latency_4.0_latency_5',\n",
    "    'latency_True_latency_0.2_latency_0.6_latency_True_latency_5.0_latency_8'\n",
    "]\n",
    "latency_filtered = latency_df[latency_df['config_name'].isin(latency_configs)].copy()\n",
    "\n",
    "# --- 2. Define a function to parse the config string ---\n",
    "def parse_latency_config(config):\n",
    "    \"\"\"\n",
    "    Parses a latency configuration string and returns a dict with:\n",
    "      - simulate (boolean)\n",
    "      - delay_min (float or None)\n",
    "      - delay_max (float or None)\n",
    "      - simulate_burst (boolean or None)\n",
    "      - burst_size (float or None)\n",
    "      - burst_interval (float or None)\n",
    "    \"\"\"\n",
    "    tokens = config.split('_')\n",
    "    \n",
    "    # There will be extra \"latency\" tokens in the string.\n",
    "    # Look at the total number of tokens:\n",
    "    # For baseline: e.g., \"latency_False\" -> tokens: [\"latency\", \"False\"]\n",
    "    # Without burst: 8 tokens, e.g.:\n",
    "    #   [\"latency\", \"True\", \"latency\", \"0.05\", \"latency\", \"0.2\", \"latency\", \"False\"]\n",
    "    # With burst: 12 tokens, e.g.:\n",
    "    #   [\"latency\", \"True\", \"latency\", \"0.05\", \"latency\", \"0.2\", \"latency\", \"True\", \"latency\", \"4.0\", \"latency\", \"5\"]\n",
    "    res = {}\n",
    "    if len(tokens) == 2:\n",
    "        # Baseline: no simulation\n",
    "        res['simulate'] = (tokens[1] == \"True\")\n",
    "        res['delay_min'] = None\n",
    "        res['delay_max'] = None\n",
    "        res['simulate_burst'] = None\n",
    "        res['burst_size'] = None\n",
    "        res['burst_interval'] = None\n",
    "    elif len(tokens) == 8:\n",
    "        # Without burst: tokens at positions 1, 3, 5, and 7 are our values.\n",
    "        res['simulate'] = (tokens[1] == \"True\")\n",
    "        res['delay_min'] = float(tokens[3])\n",
    "        res['delay_max'] = float(tokens[5])\n",
    "        res['simulate_burst'] = (tokens[7] == \"True\")\n",
    "        res['burst_size'] = None\n",
    "        res['burst_interval'] = None\n",
    "    elif len(tokens) == 12:\n",
    "        # With burst: tokens at positions 1, 3, 5, 7, 9, and 11.\n",
    "        res['simulate'] = (tokens[1] == \"True\")\n",
    "        res['delay_min'] = float(tokens[3])\n",
    "        res['delay_max'] = float(tokens[5])\n",
    "        res['simulate_burst'] = (tokens[7] == \"True\")\n",
    "        res['burst_size'] = float(tokens[9])\n",
    "        res['burst_interval'] = float(tokens[11])\n",
    "    else:\n",
    "        res['simulate'] = None\n",
    "        res['delay_min'] = None\n",
    "        res['delay_max'] = None\n",
    "        res['simulate_burst'] = None\n",
    "        res['burst_size'] = None\n",
    "        res['burst_interval'] = None\n",
    "    return res\n",
    "\n",
    "# Apply the parser so that we have new columns for the latency parameters\n",
    "latency_params = latency_filtered['config_name'].apply(lambda x: pd.Series(parse_latency_config(x)))\n",
    "latency_filtered = pd.concat([latency_filtered, latency_params], axis=1)\n",
    "\n",
    "# --- 3. Create a user-friendly label for each configuration ---\n",
    "def make_latency_label(row):\n",
    "    if row['simulate'] is False:\n",
    "        return \"No simulation\"\n",
    "    elif row['simulate'] is True and row['simulate_burst'] is False:\n",
    "        return f\"Sim ({row['delay_min']}-{row['delay_max']})\"\n",
    "    elif row['simulate'] is True and row['simulate_burst'] is True:\n",
    "        return f\"Sim ({row['delay_min']}-{row['delay_max']}) Burst ({row['burst_size']},{row['burst_interval']})\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "latency_filtered['latency_label'] = latency_filtered.apply(make_latency_label, axis=1)\n",
    "\n",
    "# --- 4. Order the configurations as desired ---\n",
    "order_labels = [\n",
    "    \"No simulation\",\n",
    "    \"Sim (0.05-0.2)\",\n",
    "    \"Sim (0.2-0.6)\",\n",
    "    \"Sim (0.05-0.2) Burst (4.0,5)\",\n",
    "    \"Sim (0.2-0.6) Burst (5.0,8)\"\n",
    "]\n",
    "latency_filtered['latency_label'] = pd.Categorical(latency_filtered['latency_label'], \n",
    "                                                     categories=order_labels, ordered=True)\n",
    "latency_filtered = latency_filtered.sort_values('latency_label')\n",
    "\n",
    "# --- 5. Create the two subplots ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Left Subplot: Divergence Energy vs Latency Configuration (categorical x-axis)\n",
    "axes[0].plot(\n",
    "    latency_filtered['latency_label'],\n",
    "    latency_filtered['divergence_energy_flops_per_token'],\n",
    "    marker='o',\n",
    "    linestyle='-',\n",
    "    color='orange'\n",
    ")\n",
    "axes[0].set_xlabel('Latency Configuration')\n",
    "axes[0].set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "axes[0].set_title('Divergence Energy vs Latency Config')\n",
    "axes[0].grid(True)\n",
    "\n",
    "# Right Subplot: Two y-axes for Energy per Token and FLOPs per Token\n",
    "ax1 = axes[1]\n",
    "line1, = ax1.plot(\n",
    "    latency_filtered['latency_label'],\n",
    "    latency_filtered['energy_per_token_kwh'],\n",
    "    marker='o',\n",
    "    linestyle='-',\n",
    "    color='blue',\n",
    "    label='Energy per Token (kWh)'\n",
    ")\n",
    "ax1.set_xlabel('Latency Configuration')\n",
    "ax1.set_ylabel('Energy per Token (kWh)', color='blue')\n",
    "ax1.tick_params(axis='y')\n",
    "ax1.set_title('Metrics vs Latency Config')\n",
    "ax1.grid(True)\n",
    "\n",
    "# Create secondary y-axis for FLOPs per Token\n",
    "ax2 = ax1.twinx()\n",
    "line2, = ax2.plot(\n",
    "    latency_filtered['latency_label'],\n",
    "    latency_filtered['flops_per_token'],\n",
    "    marker='s',\n",
    "    linestyle='--',\n",
    "    color='red',\n",
    "    label='FLOPs per Token'\n",
    ")\n",
    "ax2.set_ylabel('FLOPs per Token', color='red')\n",
    "ax2.tick_params(axis='y')\n",
    "\n",
    "# Combine legends from both axes\n",
    "lines = [line1, line2]\n",
    "labels = [line.get_label() for line in lines]\n",
    "ax1.legend(lines, labels, loc='best')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_controlled_dropped.total_energy_kwh.max() / df_controlled_dropped.total_energy_kwh.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scenarios_dropped.total_energy_kwh.max() / df_scenarios_dropped.total_energy_kwh.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORK OUT STANDARD DEVIATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Histogram of raw total_energy_kwh\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_scenarios_dropped['total_energy_kwh'], bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Total Energy (kWh)')\n",
    "plt.xlabel('Total Energy (kWh)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot to spot outliers\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.boxplot(df_scenarios_dropped['total_energy_kwh'], vert=False)\n",
    "plt.title('Boxplot of Total Energy (kWh)')\n",
    "plt.xlabel('Total Energy (kWh)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# If distribution is very skewed: log-transform\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(np.log(df_scenarios_dropped['total_energy_kwh']), bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Log-Transformed Total Energy (kWh)')\n",
    "plt.xlabel('Log(Total Energy (kWh))')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

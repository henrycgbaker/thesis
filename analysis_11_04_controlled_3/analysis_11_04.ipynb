{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will later move this into function script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_files = [\"controlled\", \"scenarios\", \"grid\", \"text_generation\"]\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "def process_possible_files(func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Loops over the global list 'possible_files', calls the provided function on each file,\n",
    "    and creates a global variable with the naming convention 'df_<file>_cleaned'\n",
    "    to store the resulting DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        func (callable): A function that takes at least a file name (first argument).\n",
    "        *args: Additional positional arguments that 'func' needs.\n",
    "        **kwargs: Additional keyword arguments that 'func' needs.\n",
    "    \n",
    "    The function will also attempt to display each transposed DataFrame.\n",
    "    \"\"\"\n",
    "    for file in possible_files:\n",
    "        try:\n",
    "            var_name = f\"df_{file}_cleaned\"\n",
    "            # Run the provided function on the file, passing along any additional arguments.\n",
    "            result_df = func(file, *args, **kwargs)\n",
    "            # Dynamically create a global variable with the result.\n",
    "            globals()[var_name] = result_df\n",
    "            print(f\"Found & inspecting: {var_name}\")\n",
    "            display(result_df.T)\n",
    "        except Exception as e:\n",
    "            print(f\"{file} did not process correctly: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_energy_metrics_local_process_results_cpu_power_process_2\n",
      "global_energy_metrics_global_experiment_results_gpu_energy_total\n",
      "compute_metrics_compute_utilisation_cpu_usage_percent\n",
      "global_energy_metrics_per-process_emissions_1\n",
      "variables_backend\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_0\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_3\n",
      "variables_sharding_config_fsdp_config_cpu_offload\n",
      "model_architecture_total_params\n",
      "variables_config_name\n",
      "global_energy_metrics_local_process_results_ram_energy_process_3\n",
      "inference_metrics_raw_inference_metrics_total_generated_tokens\n",
      "setup_os\n",
      "setup_available_gpu_count\n",
      "global_energy_metrics_global_experiment_results_cpu_power_avg\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_2\n",
      "global_energy_metrics_experiment_id\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_2\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_0\n",
      "variables_number_input_prompts\n",
      "inference_metrics_raw_inference_metrics_total_input_tokens\n",
      "setup_python_version\n",
      "compute_metrics_memory_gpu_current_memory_reserved_bytes\n",
      "compute_metrics_memory_gpu_max_memory_allocated_bytes\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_1\n",
      "setup_is_encoder_decoder\n",
      "setup_date_time\n",
      "variables_decoder_config_decoder_temperature\n",
      "variables_accelerate_config_distributed_type\n",
      "setup_gpu_model\n",
      "global_energy_metrics_global_derived_quantities_tokens_per_joule\n",
      "global_energy_metrics_global_experiment_results_cpu_energy_total\n",
      "inference_metrics_inference_performance_total_inference_time_sec\n",
      "variables_latency_simulation_burst_size\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_0\n",
      "global_energy_metrics_local_process_results_ram_power_process_2\n",
      "variables_quantisation_cached_flops_for_quantised_models\n",
      "global_energy_metrics_global_experiment_results_total_energy_kwh\n",
      "inference_metrics_inference_performance_average_latency_ms_per_batch\n",
      "compute_metrics_flops\n",
      "variables_max_output_tokens\n",
      "variables_accelerate_config_num_processes\n",
      "variables_batching_options_batch_size___fixed_batching\n",
      "inference_metrics_inference_performance_throughput_queries_per_sec\n",
      "global_energy_metrics_local_process_results_gpu_power_process_3\n",
      "global_energy_metrics_local_process_results_ram_power_process_1\n",
      "global_energy_metrics_global_experiment_results_ram_power_avg\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_2\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_0\n",
      "variables_quantisation_quantization\n",
      "global_energy_metrics_local_process_results_cpu_power_process_0\n",
      "variables_decoder_config_decoder_top_p\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_3\n",
      "global_energy_metrics_local_process_results_ram_energy_process_2\n",
      "global_energy_metrics_local_process_results_ram_energy_process_0\n",
      "inference_metrics_inference_performance_throughput_tokens_per_sec\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_1\n",
      "global_energy_metrics_local_process_results_cpu_power_process_3\n",
      "setup_experiment_id\n",
      "global_energy_metrics_local_process_results_gpu_power_process_1\n",
      "global_energy_metrics_local_process_results_gpu_power_process_0\n",
      "compute_metrics_memory_gpu_current_memory_allocated_bytes\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_3\n",
      "variables_batching_options_adaptive_batching\n",
      "setup_cpu_model\n",
      "global_energy_metrics_global_derived_quantities_joules_per_token\n",
      "global_energy_metrics_local_process_results_gpu_power_process_2\n",
      "variables_sharding_config_sharding_strategy\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_0\n",
      "setup_task_type\n",
      "setup_region\n",
      "global_energy_metrics_local_process_results_cpu_power_process_1\n",
      "compute_metrics_memory_gpu_max_memory_reserved_bytes\n",
      "global_energy_metrics_global_derived_quantities_joules_per_flop\n",
      "setup_available_cpu_count\n",
      "variables_inference_type\n",
      "global_energy_metrics_global_experiment_results_gpu_power_avg\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_1\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_3\n",
      "variables_decoder_config_decoder_top_k\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_2\n",
      "global_energy_metrics_local_process_results_ram_power_process_3\n",
      "global_energy_metrics_local_process_results_ram_power_process_0\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_1\n",
      "variables_latency_simulation_delay_min\n",
      "variables_quantisation_load_in_8bit\n",
      "global_energy_metrics_global_derived_quantities_flops_per_joule\n",
      "global_energy_metrics_global_experiment_results_ram_energy_total\n",
      "variables_latency_simulation_simulate_burst\n",
      "inference_metrics_raw_inference_metrics_number_input_prompts\n",
      "model_architecture_architecture\n",
      "global_energy_metrics_per-process_emissions_2\n",
      "variables_fp_precision\n",
      "compute_metrics_compute_utilisation_cpu_memory_usage_bytes\n",
      "global_energy_metrics_per-process_emissions_0\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_1\n",
      "variables_decoder_config_decoding_mode\n",
      "variables_sharding_config_fsdp_config_use_orig_params\n",
      "variables_batching_options_adaptive_max_tokens\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_2\n",
      "variables_latency_simulation_delay_max\n",
      "setup_model\n",
      "variables_latency_simulation_simulate\n",
      "variables_query_rate\n",
      "variables_latency_simulation_burst_interval\n",
      "variables_max_input_tokens\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_3\n",
      "setup_country\n",
      "global_energy_metrics_local_process_results_ram_energy_process_1\n",
      "global_energy_metrics_per-process_emissions_3\n",
      "variables_batching_options_max_batch_size___adaptive_batching\n",
      "variables_quantisation_load_in_4bit\n",
      "variables_decode_token_to_text\n",
      "global_energy_metrics_global_experiment_results_total_energy_joules\n"
     ]
    }
   ],
   "source": [
    "notebook_dir = os.getcwd()\n",
    "df = process_possible_files\n",
    "df = pd.read_csv(\"controlled_results.csv\")\n",
    "\n",
    "columns = list(df.columns)\n",
    "for col in columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column(col: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean a single column name by:\n",
    "      - Stripping whitespace and replacing any non-standard quotes.\n",
    "      - Checking for per-process metric patterns.\n",
    "      - Applying special renames.\n",
    "      - Removing the 'variables_' prefix if present.\n",
    "      - Otherwise, attempting to strip off any messy prefixes using a known list of tokens.\n",
    "    \n",
    "    If no known token is found, the original (normalized) column name is returned.\n",
    "    \"\"\"\n",
    "    # Normalize the column string: remove extra whitespace and fix common issues with quotes.\n",
    "    col = col.strip()\n",
    "    col = col.replace(\"“\", \"\\\"\").replace(\"”\", \"\\\"\")\n",
    "    \n",
    "    # 1. Special exact mappings.\n",
    "    special_mappings = {\n",
    "        \"setup_cpu_model\": \"cpu_model\",\n",
    "        \"setup_gpu_model\": \"gpu_model\",\n",
    "        \"model_architecture_total_params\": \"total_params\",  # now maps to total_params\n",
    "        \"model_architecture_architecture\": \"model_arch\"\n",
    "    }\n",
    "    if col in special_mappings:\n",
    "        return special_mappings[col]\n",
    "    \n",
    "    # 2. Remove the 'variables_' prefix if it exists.\n",
    "    if col.startswith(\"variables_\"):\n",
    "        col = col[len(\"variables_\"):]\n",
    "    \n",
    "    # 3. First, check if it is a per-process metric column.\n",
    "    per_process_patterns = [\n",
    "        r'(cpu_power_process_\\d+)',\n",
    "        r'(gpu_power_process_\\d+)',\n",
    "        r'(ram_power_process_\\d+)',\n",
    "        r'(cpu_energy_process_\\d+)',\n",
    "        r'(gpu_energy_process_\\d+)',\n",
    "        r'(ram_energy_process_\\d+)',\n",
    "        r'(total_energy_kwh_process_\\d+)',\n",
    "        r'(total_energy_joules_process_\\d+)'\n",
    "    ]\n",
    "    for pattern in per_process_patterns:\n",
    "        match = re.search(pattern, col)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    \n",
    "    # 4. For non-per-process columns, search for a known token in the cleaned column.\n",
    "    tokens = [\n",
    "        \"config_name\", \"experiment_id\", \"date_time\", \"model\", \"is_encoder_decoder\",\n",
    "        \"task_type\", \"available_gpu_count\", \"gpu_model\", \"available_cpu_count\", \"cpu_model\",\n",
    "        \"os\", \"python_version\", \"country\", \"region\", \"fsdp_use_orig_params\", \"fsdp_cpu_offload\",\n",
    "        \"sharding_strategy\", \"distributed_type\", \"num_processes\", \"max_input_tokens\", \"max_output_tokens\",\n",
    "        \"number_input_prompts\", \"decode_token_to_text\", \"decoder_temperature\", \"decoder_top_k\", \"decoder_top_p\",\n",
    "        \"query_rate\", \"latency_simulate\", \"latency_delay_min\", \"latency_delay_max\", \"latency_simulate_burst\",\n",
    "        \"latency_burst_interval\", \"latency_burst_size\", \"fp_precision\", \"quantization\", \"load_in_8bit\",\n",
    "        \"load_in_4bit\", \"cached_flops_for_quantised_models\", \"batch_size___fixed_batching\", \"adaptive_batching\",\n",
    "        \"adaptive_max_tokens\", \"max_batch_size___adaptive_batching\", \"inference_type\", \"backend\", \"total_params\",\n",
    "        \"architecture\", \"total_input_tokens\", \"total_generated_tokens\", \"total_inference_time_sec\", \n",
    "        \"average_latency_ms_per_batch\", \"throughput_queries_per_sec\", \"throughput_tokens_per_sec\", \"flops\",\n",
    "        \"gpu_current_memory_allocated_bytes\", \"gpu_max_memory_allocated_bytes\", \"gpu_current_memory_reserved_bytes\",\n",
    "        \"gpu_max_memory_reserved_bytes\", \"gpu_utilization_percent\", \"cpu_usage_percent\", \"cpu_memory_usage_bytes\",\n",
    "        # Per-process metrics:\n",
    "        \"cpu_power_process_0\", \"gpu_power_process_0\", \"ram_power_process_0\",\n",
    "        \"cpu_energy_process_0\", \"gpu_energy_process_0\", \"ram_energy_process_0\",\n",
    "        \"total_energy_kwh_process_0\", \"total_energy_joules_process_0\",\n",
    "        # Global averages and totals:\n",
    "        \"cpu_power_avg\", \"gpu_power_avg\", \"ram_power_avg\", \"cpu_energy_total\", \"gpu_energy_total\", \"ram_energy_total\",\n",
    "        \"total_energy_kwh\", \"total_energy_joules\", \"tokens_per_joule\", \"joules_per_token\", \"flops_per_joule\", \"joules_per_flop\",\n",
    "        \"per-process_emissions\"\n",
    "    ]\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in col:\n",
    "            idx = col.find(token)\n",
    "            return col[idx:]\n",
    "    \n",
    "    return col\n",
    "\n",
    "def resolve_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Resolve duplicate columns in the DataFrame.\n",
    "    \n",
    "    For any column that appears more than once:\n",
    "      - For 'adaptive_batching', if duplicates exist, prefer the one with a boolean dtype;\n",
    "        otherwise, pick the first occurrence.\n",
    "      - For all other columns (including 'experiment_id' and 'number_input_prompts'),\n",
    "        keep only the first occurrence.\n",
    "    \"\"\"\n",
    "    # Build a mapping of column name to list of indices where it occurs.\n",
    "    seen = {}\n",
    "    for idx, col in enumerate(df.columns):\n",
    "        seen.setdefault(col, []).append(idx)\n",
    "    \n",
    "    # Choose one index per duplicate group.\n",
    "    chosen_indices = []\n",
    "    for col, indices in seen.items():\n",
    "        if len(indices) == 1:\n",
    "            chosen_indices.append(indices[0])\n",
    "        else:\n",
    "            if col == \"adaptive_batching\":\n",
    "                # Look for a column with boolean type.\n",
    "                bool_idx = None\n",
    "                for i in indices:\n",
    "                    if pd.api.types.is_bool_dtype(df.iloc[:, i]):\n",
    "                        bool_idx = i\n",
    "                        break\n",
    "                chosen_indices.append(bool_idx if bool_idx is not None else indices[0])\n",
    "            else:\n",
    "                # For experiment_id, number_input_prompts, or any duplicate, keep the first occurrence.\n",
    "                chosen_indices.append(indices[0])\n",
    "    \n",
    "    # Sort indices to preserve the original order.\n",
    "    chosen_indices.sort()\n",
    "    return df.iloc[:, chosen_indices]\n",
    "\n",
    "def clean_and_reorder_columns(df: pd.DataFrame, desired_order: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean DataFrame columns by:\n",
    "      1. Renaming each column to remove extraneous prefixes and apply special mappings.\n",
    "      2. Removing duplicates (applying special resolution for some columns).\n",
    "      3. Reordering columns into the order specified by 'desired_order'. Any columns not explicitly mentioned\n",
    "         will be appended at the end.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with messy, flattened column names.\n",
    "        desired_order (list): List of column names (after cleaning) indicating the preferred ordering.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with cleaned and reordered columns.\n",
    "    \"\"\"\n",
    "    # Build mapping from original column names to cleaned names.\n",
    "    mapping = {col: clean_column(col) for col in df.columns}\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    df = df.rename(columns=mapping)\n",
    "    \n",
    "    # Resolve duplicates as required.\n",
    "    df = resolve_duplicates(df)\n",
    "    \n",
    "    # Reorder columns: first, the ones matching the desired order.\n",
    "    ordered_cols = [col for col in desired_order if col in df.columns]\n",
    "    # Then, append any remaining columns.\n",
    "    remaining_cols = [col for col in df.columns if col not in desired_order]\n",
    "    final_order = ordered_cols + remaining_cols\n",
    "    \n",
    "    return df[final_order]\n",
    "\n",
    "# Example desired order list\n",
    "desired_order = [\n",
    "    \"config_name\",\n",
    "    \"experiment_id\",\n",
    "    \"date_time\",\n",
    "    \"model\",\n",
    "    # num_process\n",
    "    \"num_processes\",\n",
    "    # batching\n",
    "    \"batch_size___fixed_batching\",\n",
    "    # decodeer\n",
    "    \"decoder_temperature\",\n",
    "    \"decoder_top_k\",\n",
    "    \"decoder_top_p\",\n",
    "    # latency\n",
    "    \"latency_simulation_simulate\"\n",
    "    \"latency_simulation_delay_max\",\n",
    "    \"latency_simulation_delay_min\",\n",
    "    \"latency_simulation_simulate_burst\",\n",
    "    \"latency_simulation_burst_size\",\n",
    "    \"latency_simulation_burst_interval\",\n",
    "    # precision / quantisation\n",
    "    \"fp_precision\",\n",
    "    \"quantization\",\n",
    "    \"load_in_8bit\",\n",
    "    \"load_in_4bit\",\n",
    "    \"cached_flops_for_quantised_models\",\n",
    "    \n",
    "    # UNUSED PARAMS\n",
    "    \"sharding_strategy\",\n",
    "    \"sharding_config_fsdp_config_use_orig_params\",\n",
    "    \"sharding_config_fsdp_config_cpu_offload\",\n",
    "    \"adaptive_batching\",\n",
    "    \"adaptive_max_tokens\",\n",
    "    \"query_rate\",\n",
    "    \"total_input_tokens\",\n",
    "    \"total_generated_tokens\"\n",
    "    \n",
    "    # CONSTANT SETUP ====\n",
    "    \"date_time\",\n",
    "    \"is_encoder_decoder\",\n",
    "    \"task_type\",\n",
    "    \"available_gpu_count\",\n",
    "    \"gpu_model\",\n",
    "    \"available_cpu_count\",\n",
    "    \"cpu_model\",\n",
    "    \"os\",\n",
    "    \"python_version\",\n",
    "    \"country\",\n",
    "    \"region\",\n",
    "    \"distributed_type\",\n",
    "    \"decode_token_to_text\",\n",
    "    \"inference_type\",\n",
    "    \"backend\",\n",
    "    \"total_params\",\n",
    "    \"model_arch\",\n",
    "\n",
    "    # Validation (should be same):\n",
    "    \"max_input_tokens\",\n",
    "    \"max_output_tokens\",\n",
    "    \"number_input_prompts\",\n",
    "    \n",
    "    # RESULTS =====\n",
    "    # energy\n",
    "    \"total_energy_kwh\",\n",
    "    \"total_energy_joules\",\n",
    "    # FLOPS\n",
    "    \"flops\",\n",
    "    \"tokens_per_joule\",\n",
    "    \"joules_per_token\",\n",
    "    \"flops_per_joule\",\n",
    "    \"joules_per_flop\",\n",
    "    \"total_inference_time_sec\", \n",
    "    # inference performance\n",
    "    \"average_latency_ms_per_batch\",\n",
    "    \"throughput_queries_per_sec\",\n",
    "    \"throughput_tokens_per_sec\",\n",
    "    # CPU utilization\n",
    "    \"cpu_usage_percent\",\n",
    "    \"cpu_memory_usage_bytes\",\n",
    "    # GPU utilization\n",
    "    \"gpu_utilization_percent_0\", \"gpu_utilization_percent_1\", \"gpu_utilization_percent_2\", \"gpu_utilization_percent_3\",\n",
    "    # Compute mem\n",
    "    \"gpu_current_memory_allocated_bytes\",\n",
    "    \"gpu_max_memory_allocated_bytes\",\n",
    "    \"gpu_current_memory_reserved_bytes\",\n",
    "    \"gpu_max_memory_reserved_bytes\",\n",
    "    # Per-process metrics:\n",
    "    \"cpu_power_process_0\", \"cpu_power_process_1\", \"cpu_power_process_2\", \"cpu_power_process_3\",\n",
    "    \"gpu_power_process_0\", \"gpu_power_process_1\", \"gpu_power_process_2\", \"gpu_power_process_3\",\n",
    "    \"ram_power_process_0\", \"ram_power_process_1\", \"ram_power_process_2\", \"ram_power_process_3\",\n",
    "    \"cpu_energy_process_0\", \"cpu_energy_process_1\", \"cpu_energy_process_2\", \"cpu_energy_process_3\",\n",
    "    \"gpu_energy_process_0\", \"gpu_energy_process_1\", \"gpu_energy_process_2\", \"gpu_energy_process_3\",\n",
    "    \"ram_energy_process_0\", \"ram_energy_process_1\", \"ram_energy_process_2\", \"ram_energy_process_3\",\n",
    "    \"total_energy_kwh_process_0\", \"total_energy_kwh_process_1\", \"total_energy_kwh_process_2\", \"total_energy_kwh_process_3\",\n",
    "    \"total_energy_joules_process_0\", \"total_energy_joules_process_1\", \"total_energy_joules_process_2\", \"total_energy_joules_process_3\",\n",
    "    # Global averages and totals:\n",
    "    \"cpu_power_avg\",\n",
    "    \"gpu_power_avg\",\n",
    "    \"ram_power_avg\",\n",
    "    \"cpu_energy_total\",\n",
    "    \"gpu_energy_total\",\n",
    "    \"ram_energy_total\",\n",
    "    # per-process_emsisisons\n",
    "    \"per-process_emissions_0\", \"per-process_emissions_1\", \"per-process_emissions_2\",\"per-process_emissions_3\"\n",
    "]\n",
    "\n",
    "def inspect_results(name, desired_order):\n",
    "    input_file = f\"{name}_results.csv\"\n",
    "    \n",
    "    df = pd.read_csv(input_file)\n",
    "    df_cleaned = clean_and_reorder_columns(df, desired_order)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "# COME BACK TO THIS\n",
    "#process_possible_files(func=clean_and_reorder_columns, \n",
    "#                       desired_order=desired_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found & inspecting: df_controlled_cleaned\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>config_name</th>\n",
       "      <td>num_processes_1</td>\n",
       "      <td>num_processes_2</td>\n",
       "      <td>num_processes_3</td>\n",
       "      <td>num_processes_4</td>\n",
       "      <td>batching_1</td>\n",
       "      <td>batching_2</td>\n",
       "      <td>batching_4</td>\n",
       "      <td>batching_8</td>\n",
       "      <td>batching_16</td>\n",
       "      <td>batching_32</td>\n",
       "      <td>batching_64</td>\n",
       "      <td>precis_float32_quant_False_quant8_False_quant4...</td>\n",
       "      <td>precis_float16_quant_False_quant8_False_quant4...</td>\n",
       "      <td>precis_float16_quant_True_quant8_True_quant4_F...</td>\n",
       "      <td>precis_float16_quant_True_quant8_False_quant4_...</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.2</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.4</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.6</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.8</td>\n",
       "      <td>decoding_greedy_decoder_temperature_1.0</td>\n",
       "      <td>decoding_greedy_decoder_temperature_1.2</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>latency_False</td>\n",
       "      <td>latency_True_latency_0.05_latency_0.2_latency_...</td>\n",
       "      <td>latency_True_latency_0.2_latency_0.6_latency_F...</td>\n",
       "      <td>latency_True_latency_0.05_latency_0.2_latency_...</td>\n",
       "      <td>latency_True_latency_0.2_latency_0.6_latency_T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <td>109</td>\n",
       "      <td>110</td>\n",
       "      <td>111</td>\n",
       "      <td>112</td>\n",
       "      <td>113</td>\n",
       "      <td>114</td>\n",
       "      <td>115</td>\n",
       "      <td>116</td>\n",
       "      <td>117</td>\n",
       "      <td>118</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>121</td>\n",
       "      <td>122</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "      <td>128</td>\n",
       "      <td>129</td>\n",
       "      <td>130</td>\n",
       "      <td>132</td>\n",
       "      <td>133</td>\n",
       "      <td>134</td>\n",
       "      <td>135</td>\n",
       "      <td>136</td>\n",
       "      <td>137</td>\n",
       "      <td>138</td>\n",
       "      <td>139</td>\n",
       "      <td>140</td>\n",
       "      <td>141</td>\n",
       "      <td>142</td>\n",
       "      <td>143</td>\n",
       "      <td>144</td>\n",
       "      <td>145</td>\n",
       "      <td>146</td>\n",
       "      <td>147</td>\n",
       "      <td>148</td>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>152</td>\n",
       "      <td>153</td>\n",
       "      <td>154</td>\n",
       "      <td>155</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "      <td>160</td>\n",
       "      <td>161</td>\n",
       "      <td>162</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>165</td>\n",
       "      <td>166</td>\n",
       "      <td>172</td>\n",
       "      <td>173</td>\n",
       "      <td>174</td>\n",
       "      <td>175</td>\n",
       "      <td>176</td>\n",
       "      <td>177</td>\n",
       "      <td>178</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>192</td>\n",
       "      <td>193</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>204</td>\n",
       "      <td>205</td>\n",
       "      <td>206</td>\n",
       "      <td>207</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <td>April 11, 2025 at 01:21:09 PM</td>\n",
       "      <td>April 11, 2025 at 01:22:13 PM</td>\n",
       "      <td>April 11, 2025 at 01:23:18 PM</td>\n",
       "      <td>April 11, 2025 at 01:24:25 PM</td>\n",
       "      <td>April 11, 2025 at 01:30:52 PM</td>\n",
       "      <td>April 11, 2025 at 01:35:11 PM</td>\n",
       "      <td>April 11, 2025 at 01:37:39 PM</td>\n",
       "      <td>April 11, 2025 at 01:39:15 PM</td>\n",
       "      <td>April 11, 2025 at 01:40:22 PM</td>\n",
       "      <td>April 11, 2025 at 01:41:15 PM</td>\n",
       "      <td>April 11, 2025 at 01:42:03 PM</td>\n",
       "      <td>April 11, 2025 at 01:43:09 PM</td>\n",
       "      <td>April 11, 2025 at 01:44:07 PM</td>\n",
       "      <td>April 11, 2025 at 01:47:13 PM</td>\n",
       "      <td>April 11, 2025 at 01:48:28 PM</td>\n",
       "      <td>April 11, 2025 at 01:49:39 PM</td>\n",
       "      <td>April 11, 2025 at 01:50:49 PM</td>\n",
       "      <td>April 11, 2025 at 01:52:03 PM</td>\n",
       "      <td>April 11, 2025 at 01:53:15 PM</td>\n",
       "      <td>April 11, 2025 at 01:54:27 PM</td>\n",
       "      <td>April 11, 2025 at 02:07:40 PM</td>\n",
       "      <td>April 11, 2025 at 02:08:53 PM</td>\n",
       "      <td>April 11, 2025 at 02:10:30 PM</td>\n",
       "      <td>April 11, 2025 at 02:11:31 PM</td>\n",
       "      <td>April 11, 2025 at 02:12:30 PM</td>\n",
       "      <td>April 11, 2025 at 02:13:34 PM</td>\n",
       "      <td>April 11, 2025 at 02:14:36 PM</td>\n",
       "      <td>April 11, 2025 at 02:15:38 PM</td>\n",
       "      <td>April 11, 2025 at 02:16:46 PM</td>\n",
       "      <td>April 11, 2025 at 02:17:47 PM</td>\n",
       "      <td>April 11, 2025 at 02:18:50 PM</td>\n",
       "      <td>April 11, 2025 at 02:19:51 PM</td>\n",
       "      <td>April 11, 2025 at 02:20:54 PM</td>\n",
       "      <td>April 11, 2025 at 02:21:57 PM</td>\n",
       "      <td>April 11, 2025 at 02:22:59 PM</td>\n",
       "      <td>April 11, 2025 at 02:24:04 PM</td>\n",
       "      <td>April 11, 2025 at 02:25:08 PM</td>\n",
       "      <td>April 11, 2025 at 02:26:16 PM</td>\n",
       "      <td>April 11, 2025 at 02:27:18 PM</td>\n",
       "      <td>April 11, 2025 at 02:28:19 PM</td>\n",
       "      <td>April 11, 2025 at 02:29:23 PM</td>\n",
       "      <td>April 11, 2025 at 02:30:26 PM</td>\n",
       "      <td>April 11, 2025 at 02:31:29 PM</td>\n",
       "      <td>April 11, 2025 at 02:32:31 PM</td>\n",
       "      <td>April 11, 2025 at 02:33:34 PM</td>\n",
       "      <td>April 11, 2025 at 02:34:37 PM</td>\n",
       "      <td>April 11, 2025 at 02:35:41 PM</td>\n",
       "      <td>April 11, 2025 at 02:36:45 PM</td>\n",
       "      <td>April 11, 2025 at 02:37:48 PM</td>\n",
       "      <td>April 11, 2025 at 02:38:49 PM</td>\n",
       "      <td>April 11, 2025 at 02:39:50 PM</td>\n",
       "      <td>April 11, 2025 at 02:40:54 PM</td>\n",
       "      <td>April 11, 2025 at 02:41:56 PM</td>\n",
       "      <td>April 11, 2025 at 02:42:58 PM</td>\n",
       "      <td>April 11, 2025 at 02:44:00 PM</td>\n",
       "      <td>April 11, 2025 at 02:45:01 PM</td>\n",
       "      <td>April 11, 2025 at 02:46:03 PM</td>\n",
       "      <td>April 11, 2025 at 02:50:00 PM</td>\n",
       "      <td>April 11, 2025 at 02:51:04 PM</td>\n",
       "      <td>April 11, 2025 at 02:52:05 PM</td>\n",
       "      <td>April 11, 2025 at 02:53:06 PM</td>\n",
       "      <td>April 11, 2025 at 02:54:09 PM</td>\n",
       "      <td>April 11, 2025 at 02:55:09 PM</td>\n",
       "      <td>April 11, 2025 at 02:56:10 PM</td>\n",
       "      <td>April 11, 2025 at 02:57:12 PM</td>\n",
       "      <td>April 11, 2025 at 02:58:15 PM</td>\n",
       "      <td>April 11, 2025 at 02:59:16 PM</td>\n",
       "      <td>April 11, 2025 at 03:00:18 PM</td>\n",
       "      <td>April 11, 2025 at 03:01:19 PM</td>\n",
       "      <td>April 11, 2025 at 03:02:21 PM</td>\n",
       "      <td>April 11, 2025 at 03:03:22 PM</td>\n",
       "      <td>April 11, 2025 at 03:04:26 PM</td>\n",
       "      <td>April 11, 2025 at 03:05:27 PM</td>\n",
       "      <td>April 11, 2025 at 03:06:29 PM</td>\n",
       "      <td>April 11, 2025 at 03:07:33 PM</td>\n",
       "      <td>April 11, 2025 at 03:08:35 PM</td>\n",
       "      <td>April 11, 2025 at 03:09:37 PM</td>\n",
       "      <td>April 11, 2025 at 03:10:39 PM</td>\n",
       "      <td>April 11, 2025 at 03:11:41 PM</td>\n",
       "      <td>April 11, 2025 at 03:12:44 PM</td>\n",
       "      <td>April 11, 2025 at 03:13:47 PM</td>\n",
       "      <td>April 11, 2025 at 03:14:49 PM</td>\n",
       "      <td>April 11, 2025 at 03:15:52 PM</td>\n",
       "      <td>April 11, 2025 at 03:16:56 PM</td>\n",
       "      <td>April 11, 2025 at 03:18:00 PM</td>\n",
       "      <td>April 11, 2025 at 03:21:23 PM</td>\n",
       "      <td>April 11, 2025 at 03:22:26 PM</td>\n",
       "      <td>April 11, 2025 at 03:23:31 PM</td>\n",
       "      <td>April 11, 2025 at 03:24:40 PM</td>\n",
       "      <td>April 11, 2025 at 03:25:52 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_processes</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size___fixed_batching</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_temperature</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_k</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_p</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate_burst</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_size</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_interval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp_precision</th>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantization</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_8bit</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_4bit</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharding_strategy</th>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharding_config_fsdp_config_use_orig_params</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharding_config_fsdp_config_cpu_offload</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive_batching</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive_max_tokens</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_rate</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_input_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_encoder_decoder</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_type</th>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_gpu_count</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_model</th>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_cpu_count</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_model</th>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>os</th>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python_version</th>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distributed_type</th>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decode_token_to_text</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inference_type</th>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backend</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_params</th>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>615606272</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_arch</th>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_input_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_output_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_input_prompts</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh</th>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.011983</td>\n",
       "      <td>0.02077</td>\n",
       "      <td>0.03052</td>\n",
       "      <td>0.248756</td>\n",
       "      <td>0.172983</td>\n",
       "      <td>0.080552</td>\n",
       "      <td>0.046927</td>\n",
       "      <td>0.030332</td>\n",
       "      <td>0.01974</td>\n",
       "      <td>0.016821</td>\n",
       "      <td>0.030563</td>\n",
       "      <td>0.020205</td>\n",
       "      <td>0.081855</td>\n",
       "      <td>0.026513</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.027081</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.027891</td>\n",
       "      <td>0.027698</td>\n",
       "      <td>0.427662</td>\n",
       "      <td>0.027378</td>\n",
       "      <td>0.023482</td>\n",
       "      <td>0.021907</td>\n",
       "      <td>0.021951</td>\n",
       "      <td>0.021558</td>\n",
       "      <td>0.022163</td>\n",
       "      <td>0.022313</td>\n",
       "      <td>0.022607</td>\n",
       "      <td>0.022371</td>\n",
       "      <td>0.022527</td>\n",
       "      <td>0.022292</td>\n",
       "      <td>0.022349</td>\n",
       "      <td>0.02246</td>\n",
       "      <td>0.022236</td>\n",
       "      <td>0.022204</td>\n",
       "      <td>0.022546</td>\n",
       "      <td>0.02255</td>\n",
       "      <td>0.022035</td>\n",
       "      <td>0.022381</td>\n",
       "      <td>0.022374</td>\n",
       "      <td>0.022143</td>\n",
       "      <td>0.022079</td>\n",
       "      <td>0.022215</td>\n",
       "      <td>0.022313</td>\n",
       "      <td>0.022003</td>\n",
       "      <td>0.021963</td>\n",
       "      <td>0.022372</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>0.022286</td>\n",
       "      <td>0.022056</td>\n",
       "      <td>0.022172</td>\n",
       "      <td>0.022241</td>\n",
       "      <td>0.022124</td>\n",
       "      <td>0.021905</td>\n",
       "      <td>0.022108</td>\n",
       "      <td>0.022015</td>\n",
       "      <td>0.022108</td>\n",
       "      <td>0.021896</td>\n",
       "      <td>0.022016</td>\n",
       "      <td>0.021579</td>\n",
       "      <td>0.021987</td>\n",
       "      <td>0.022174</td>\n",
       "      <td>0.022161</td>\n",
       "      <td>0.022225</td>\n",
       "      <td>0.022037</td>\n",
       "      <td>0.022071</td>\n",
       "      <td>0.02212</td>\n",
       "      <td>0.022105</td>\n",
       "      <td>0.021988</td>\n",
       "      <td>0.02195</td>\n",
       "      <td>0.022064</td>\n",
       "      <td>0.022212</td>\n",
       "      <td>0.022266</td>\n",
       "      <td>0.022171</td>\n",
       "      <td>0.022127</td>\n",
       "      <td>0.022127</td>\n",
       "      <td>0.021753</td>\n",
       "      <td>0.022035</td>\n",
       "      <td>0.022129</td>\n",
       "      <td>0.022042</td>\n",
       "      <td>0.022019</td>\n",
       "      <td>0.022055</td>\n",
       "      <td>0.022409</td>\n",
       "      <td>0.021976</td>\n",
       "      <td>0.021932</td>\n",
       "      <td>0.022573</td>\n",
       "      <td>0.023598</td>\n",
       "      <td>0.02396</td>\n",
       "      <td>0.025477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules</th>\n",
       "      <td>16195.77922</td>\n",
       "      <td>43137.499279</td>\n",
       "      <td>74772.641025</td>\n",
       "      <td>109872.192307</td>\n",
       "      <td>895521.470895</td>\n",
       "      <td>622739.187387</td>\n",
       "      <td>289987.598049</td>\n",
       "      <td>168938.609749</td>\n",
       "      <td>109195.59459</td>\n",
       "      <td>71065.052609</td>\n",
       "      <td>60554.5696</td>\n",
       "      <td>110026.388974</td>\n",
       "      <td>72739.613361</td>\n",
       "      <td>294677.860311</td>\n",
       "      <td>95445.437568</td>\n",
       "      <td>96214.326055</td>\n",
       "      <td>97493.121231</td>\n",
       "      <td>98315.389425</td>\n",
       "      <td>100406.566327</td>\n",
       "      <td>99714.129356</td>\n",
       "      <td>1539584.096019</td>\n",
       "      <td>98560.641388</td>\n",
       "      <td>84535.873444</td>\n",
       "      <td>78864.369793</td>\n",
       "      <td>79024.314526</td>\n",
       "      <td>77607.069182</td>\n",
       "      <td>79785.192564</td>\n",
       "      <td>80326.29213</td>\n",
       "      <td>81385.43303</td>\n",
       "      <td>80534.828637</td>\n",
       "      <td>81096.772114</td>\n",
       "      <td>80252.705575</td>\n",
       "      <td>80457.547565</td>\n",
       "      <td>80855.2652</td>\n",
       "      <td>80049.35023</td>\n",
       "      <td>79935.142249</td>\n",
       "      <td>81165.046053</td>\n",
       "      <td>81180.686997</td>\n",
       "      <td>79326.35121</td>\n",
       "      <td>80571.964142</td>\n",
       "      <td>80546.838823</td>\n",
       "      <td>79714.965563</td>\n",
       "      <td>79485.169526</td>\n",
       "      <td>79973.120837</td>\n",
       "      <td>80327.286164</td>\n",
       "      <td>79212.479066</td>\n",
       "      <td>79067.881421</td>\n",
       "      <td>80539.640657</td>\n",
       "      <td>78832.359919</td>\n",
       "      <td>80229.360539</td>\n",
       "      <td>79403.040972</td>\n",
       "      <td>79820.968883</td>\n",
       "      <td>80066.319146</td>\n",
       "      <td>79646.128042</td>\n",
       "      <td>78857.96964</td>\n",
       "      <td>79588.547839</td>\n",
       "      <td>79254.830096</td>\n",
       "      <td>79588.27778</td>\n",
       "      <td>78825.275361</td>\n",
       "      <td>79257.538412</td>\n",
       "      <td>77685.286425</td>\n",
       "      <td>79153.299519</td>\n",
       "      <td>79827.530634</td>\n",
       "      <td>79778.964695</td>\n",
       "      <td>80008.879377</td>\n",
       "      <td>79332.316652</td>\n",
       "      <td>79455.767743</td>\n",
       "      <td>79631.713062</td>\n",
       "      <td>79576.984984</td>\n",
       "      <td>79156.588699</td>\n",
       "      <td>79021.660488</td>\n",
       "      <td>79431.609675</td>\n",
       "      <td>79963.061299</td>\n",
       "      <td>80159.040345</td>\n",
       "      <td>79813.883435</td>\n",
       "      <td>79658.584807</td>\n",
       "      <td>79655.924763</td>\n",
       "      <td>78312.258436</td>\n",
       "      <td>79324.468177</td>\n",
       "      <td>79663.168096</td>\n",
       "      <td>79350.575857</td>\n",
       "      <td>79267.089003</td>\n",
       "      <td>79399.139493</td>\n",
       "      <td>80672.664643</td>\n",
       "      <td>79114.439184</td>\n",
       "      <td>78954.196131</td>\n",
       "      <td>81263.371943</td>\n",
       "      <td>84951.709741</td>\n",
       "      <td>86256.402501</td>\n",
       "      <td>91716.993714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops</th>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens_per_joule</th>\n",
       "      <td>1.011622</td>\n",
       "      <td>0.379809</td>\n",
       "      <td>0.219118</td>\n",
       "      <td>0.149119</td>\n",
       "      <td>0.01644</td>\n",
       "      <td>0.02631</td>\n",
       "      <td>0.056499</td>\n",
       "      <td>0.096982</td>\n",
       "      <td>0.150043</td>\n",
       "      <td>0.230549</td>\n",
       "      <td>0.270566</td>\n",
       "      <td>0.14891</td>\n",
       "      <td>0.225242</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.171658</td>\n",
       "      <td>0.170286</td>\n",
       "      <td>0.168053</td>\n",
       "      <td>0.166647</td>\n",
       "      <td>0.163177</td>\n",
       "      <td>0.16431</td>\n",
       "      <td>0.010642</td>\n",
       "      <td>0.166233</td>\n",
       "      <td>0.193811</td>\n",
       "      <td>0.207749</td>\n",
       "      <td>0.207329</td>\n",
       "      <td>0.211115</td>\n",
       "      <td>0.205351</td>\n",
       "      <td>0.203968</td>\n",
       "      <td>0.201314</td>\n",
       "      <td>0.20344</td>\n",
       "      <td>0.20203</td>\n",
       "      <td>0.204155</td>\n",
       "      <td>0.203635</td>\n",
       "      <td>0.202634</td>\n",
       "      <td>0.204674</td>\n",
       "      <td>0.204966</td>\n",
       "      <td>0.20186</td>\n",
       "      <td>0.201821</td>\n",
       "      <td>0.206539</td>\n",
       "      <td>0.203346</td>\n",
       "      <td>0.20341</td>\n",
       "      <td>0.205532</td>\n",
       "      <td>0.206127</td>\n",
       "      <td>0.204869</td>\n",
       "      <td>0.203966</td>\n",
       "      <td>0.206836</td>\n",
       "      <td>0.207214</td>\n",
       "      <td>0.203428</td>\n",
       "      <td>0.207833</td>\n",
       "      <td>0.204215</td>\n",
       "      <td>0.20634</td>\n",
       "      <td>0.205259</td>\n",
       "      <td>0.20463</td>\n",
       "      <td>0.20571</td>\n",
       "      <td>0.207766</td>\n",
       "      <td>0.205859</td>\n",
       "      <td>0.206726</td>\n",
       "      <td>0.205859</td>\n",
       "      <td>0.207852</td>\n",
       "      <td>0.206719</td>\n",
       "      <td>0.210902</td>\n",
       "      <td>0.206991</td>\n",
       "      <td>0.205242</td>\n",
       "      <td>0.205367</td>\n",
       "      <td>0.204777</td>\n",
       "      <td>0.206524</td>\n",
       "      <td>0.206203</td>\n",
       "      <td>0.205747</td>\n",
       "      <td>0.205889</td>\n",
       "      <td>0.206982</td>\n",
       "      <td>0.207336</td>\n",
       "      <td>0.206265</td>\n",
       "      <td>0.204895</td>\n",
       "      <td>0.204394</td>\n",
       "      <td>0.205278</td>\n",
       "      <td>0.205678</td>\n",
       "      <td>0.205685</td>\n",
       "      <td>0.209214</td>\n",
       "      <td>0.206544</td>\n",
       "      <td>0.205666</td>\n",
       "      <td>0.206476</td>\n",
       "      <td>0.206694</td>\n",
       "      <td>0.20635</td>\n",
       "      <td>0.203092</td>\n",
       "      <td>0.207092</td>\n",
       "      <td>0.207513</td>\n",
       "      <td>0.201616</td>\n",
       "      <td>0.192863</td>\n",
       "      <td>0.189945</td>\n",
       "      <td>0.178636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_token</th>\n",
       "      <td>0.988512</td>\n",
       "      <td>2.632904</td>\n",
       "      <td>4.56376</td>\n",
       "      <td>6.706066</td>\n",
       "      <td>60.828792</td>\n",
       "      <td>38.008984</td>\n",
       "      <td>17.699438</td>\n",
       "      <td>10.311194</td>\n",
       "      <td>6.66477</td>\n",
       "      <td>4.337467</td>\n",
       "      <td>3.695958</td>\n",
       "      <td>6.715478</td>\n",
       "      <td>4.439674</td>\n",
       "      <td>17.985709</td>\n",
       "      <td>5.825527</td>\n",
       "      <td>5.872456</td>\n",
       "      <td>5.950508</td>\n",
       "      <td>6.000695</td>\n",
       "      <td>6.12833</td>\n",
       "      <td>6.086067</td>\n",
       "      <td>93.968756</td>\n",
       "      <td>6.015664</td>\n",
       "      <td>5.15966</td>\n",
       "      <td>4.813499</td>\n",
       "      <td>4.823261</td>\n",
       "      <td>4.73676</td>\n",
       "      <td>4.869702</td>\n",
       "      <td>4.902728</td>\n",
       "      <td>4.967373</td>\n",
       "      <td>4.915456</td>\n",
       "      <td>4.949754</td>\n",
       "      <td>4.898236</td>\n",
       "      <td>4.910739</td>\n",
       "      <td>4.935014</td>\n",
       "      <td>4.885825</td>\n",
       "      <td>4.878854</td>\n",
       "      <td>4.953921</td>\n",
       "      <td>4.954876</td>\n",
       "      <td>4.841696</td>\n",
       "      <td>4.917722</td>\n",
       "      <td>4.916189</td>\n",
       "      <td>4.865415</td>\n",
       "      <td>4.85139</td>\n",
       "      <td>4.881172</td>\n",
       "      <td>4.902788</td>\n",
       "      <td>4.834746</td>\n",
       "      <td>4.82592</td>\n",
       "      <td>4.91575</td>\n",
       "      <td>4.811545</td>\n",
       "      <td>4.896812</td>\n",
       "      <td>4.846377</td>\n",
       "      <td>4.871885</td>\n",
       "      <td>4.88686</td>\n",
       "      <td>4.861214</td>\n",
       "      <td>4.813108</td>\n",
       "      <td>4.857699</td>\n",
       "      <td>4.837331</td>\n",
       "      <td>4.857683</td>\n",
       "      <td>4.811113</td>\n",
       "      <td>4.837496</td>\n",
       "      <td>4.741534</td>\n",
       "      <td>4.831134</td>\n",
       "      <td>4.872286</td>\n",
       "      <td>4.869322</td>\n",
       "      <td>4.883354</td>\n",
       "      <td>4.84206</td>\n",
       "      <td>4.849595</td>\n",
       "      <td>4.860334</td>\n",
       "      <td>4.856994</td>\n",
       "      <td>4.831335</td>\n",
       "      <td>4.823099</td>\n",
       "      <td>4.848121</td>\n",
       "      <td>4.880558</td>\n",
       "      <td>4.89252</td>\n",
       "      <td>4.871453</td>\n",
       "      <td>4.861974</td>\n",
       "      <td>4.861812</td>\n",
       "      <td>4.779801</td>\n",
       "      <td>4.841581</td>\n",
       "      <td>4.862254</td>\n",
       "      <td>4.843175</td>\n",
       "      <td>4.838079</td>\n",
       "      <td>4.846139</td>\n",
       "      <td>4.923869</td>\n",
       "      <td>4.828762</td>\n",
       "      <td>4.818982</td>\n",
       "      <td>4.959923</td>\n",
       "      <td>5.185041</td>\n",
       "      <td>5.264673</td>\n",
       "      <td>5.597961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops_per_joule</th>\n",
       "      <td>1046567180.461082</td>\n",
       "      <td>392928919.763817</td>\n",
       "      <td>226686803.63326</td>\n",
       "      <td>154269889.744024</td>\n",
       "      <td>18927486.993933</td>\n",
       "      <td>27218410.751168</td>\n",
       "      <td>58450675.502025</td>\n",
       "      <td>100332132.591523</td>\n",
       "      <td>155225776.798502</td>\n",
       "      <td>238513451.700919</td>\n",
       "      <td>279912335.355367</td>\n",
       "      <td>154053687.949614</td>\n",
       "      <td>233022561.022627</td>\n",
       "      <td>3510762.996944</td>\n",
       "      <td>10839115.565521</td>\n",
       "      <td>176168889.687912</td>\n",
       "      <td>173858122.288034</td>\n",
       "      <td>172404046.735283</td>\n",
       "      <td>168813371.607248</td>\n",
       "      <td>169985649.00098</td>\n",
       "      <td>11009447.965185</td>\n",
       "      <td>171975047.589829</td>\n",
       "      <td>200506250.21828</td>\n",
       "      <td>214925587.277855</td>\n",
       "      <td>214490579.195115</td>\n",
       "      <td>218407564.824574</td>\n",
       "      <td>212445072.179372</td>\n",
       "      <td>211013984.881239</td>\n",
       "      <td>208267872.541956</td>\n",
       "      <td>210467586.260611</td>\n",
       "      <td>209009194.217265</td>\n",
       "      <td>211207471.096386</td>\n",
       "      <td>210669744.55767</td>\n",
       "      <td>209633484.611915</td>\n",
       "      <td>211744017.213695</td>\n",
       "      <td>212046548.191128</td>\n",
       "      <td>208833381.085398</td>\n",
       "      <td>208793145.515737</td>\n",
       "      <td>213673901.983323</td>\n",
       "      <td>210370582.046835</td>\n",
       "      <td>210436203.840162</td>\n",
       "      <td>212632231.269686</td>\n",
       "      <td>213246962.851946</td>\n",
       "      <td>211945849.002445</td>\n",
       "      <td>211011373.62713</td>\n",
       "      <td>213981069.562596</td>\n",
       "      <td>214372393.548913</td>\n",
       "      <td>210455011.407237</td>\n",
       "      <td>215012857.796897</td>\n",
       "      <td>211268927.975691</td>\n",
       "      <td>213467529.525458</td>\n",
       "      <td>212349852.805032</td>\n",
       "      <td>211699141.086514</td>\n",
       "      <td>212816007.631856</td>\n",
       "      <td>214943030.749142</td>\n",
       "      <td>212969974.366801</td>\n",
       "      <td>213866725.505504</td>\n",
       "      <td>212970697.015842</td>\n",
       "      <td>215032182.449385</td>\n",
       "      <td>213859417.447935</td>\n",
       "      <td>218187661.693502</td>\n",
       "      <td>214141054.083154</td>\n",
       "      <td>212332397.841176</td>\n",
       "      <td>212461656.501568</td>\n",
       "      <td>211851123.589203</td>\n",
       "      <td>213657834.643894</td>\n",
       "      <td>213325872.67883</td>\n",
       "      <td>212854531.709691</td>\n",
       "      <td>213000919.759229</td>\n",
       "      <td>214132155.916694</td>\n",
       "      <td>214497783.119962</td>\n",
       "      <td>213390752.907894</td>\n",
       "      <td>211972512.280364</td>\n",
       "      <td>211454265.422914</td>\n",
       "      <td>212368704.085806</td>\n",
       "      <td>212782728.11799</td>\n",
       "      <td>212789833.821877</td>\n",
       "      <td>216440839.935347</td>\n",
       "      <td>213678974.252386</td>\n",
       "      <td>212770486.013364</td>\n",
       "      <td>213608670.26088</td>\n",
       "      <td>213833650.338204</td>\n",
       "      <td>213478018.796583</td>\n",
       "      <td>210107984.757064</td>\n",
       "      <td>214246238.335844</td>\n",
       "      <td>214681066.031948</td>\n",
       "      <td>208580699.86403</td>\n",
       "      <td>199524777.604627</td>\n",
       "      <td>196506815.746624</td>\n",
       "      <td>184807311.129298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_flop</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_inference_time_sec</th>\n",
       "      <td>23.226318</td>\n",
       "      <td>23.264916</td>\n",
       "      <td>23.683534</td>\n",
       "      <td>23.531789</td>\n",
       "      <td>300.517251</td>\n",
       "      <td>170.672749</td>\n",
       "      <td>89.149648</td>\n",
       "      <td>44.280597</td>\n",
       "      <td>23.435158</td>\n",
       "      <td>13.35417</td>\n",
       "      <td>10.367802</td>\n",
       "      <td>23.777636</td>\n",
       "      <td>23.518978</td>\n",
       "      <td>74.511461</td>\n",
       "      <td>37.632226</td>\n",
       "      <td>23.034822</td>\n",
       "      <td>23.574361</td>\n",
       "      <td>23.302189</td>\n",
       "      <td>24.047179</td>\n",
       "      <td>24.1225</td>\n",
       "      <td>23.358511</td>\n",
       "      <td>23.30423</td>\n",
       "      <td>23.1588</td>\n",
       "      <td>23.033007</td>\n",
       "      <td>22.6648</td>\n",
       "      <td>22.773879</td>\n",
       "      <td>22.606347</td>\n",
       "      <td>23.66417</td>\n",
       "      <td>23.907777</td>\n",
       "      <td>23.561953</td>\n",
       "      <td>23.840143</td>\n",
       "      <td>23.885973</td>\n",
       "      <td>23.299355</td>\n",
       "      <td>23.477822</td>\n",
       "      <td>23.895986</td>\n",
       "      <td>23.82698</td>\n",
       "      <td>24.004103</td>\n",
       "      <td>24.247811</td>\n",
       "      <td>23.55748</td>\n",
       "      <td>24.153399</td>\n",
       "      <td>24.07616</td>\n",
       "      <td>23.535471</td>\n",
       "      <td>23.584799</td>\n",
       "      <td>24.044567</td>\n",
       "      <td>23.701611</td>\n",
       "      <td>23.352319</td>\n",
       "      <td>23.586959</td>\n",
       "      <td>23.279665</td>\n",
       "      <td>23.328102</td>\n",
       "      <td>23.584234</td>\n",
       "      <td>23.233562</td>\n",
       "      <td>23.687913</td>\n",
       "      <td>23.430406</td>\n",
       "      <td>23.540169</td>\n",
       "      <td>23.653556</td>\n",
       "      <td>23.883228</td>\n",
       "      <td>23.846678</td>\n",
       "      <td>22.873191</td>\n",
       "      <td>23.07682</td>\n",
       "      <td>22.701395</td>\n",
       "      <td>22.59848</td>\n",
       "      <td>23.286571</td>\n",
       "      <td>23.371715</td>\n",
       "      <td>23.444686</td>\n",
       "      <td>23.232562</td>\n",
       "      <td>23.270355</td>\n",
       "      <td>23.287194</td>\n",
       "      <td>23.249351</td>\n",
       "      <td>23.336429</td>\n",
       "      <td>23.317205</td>\n",
       "      <td>23.158494</td>\n",
       "      <td>23.202428</td>\n",
       "      <td>23.640073</td>\n",
       "      <td>23.725851</td>\n",
       "      <td>23.440052</td>\n",
       "      <td>23.257695</td>\n",
       "      <td>23.409533</td>\n",
       "      <td>23.339891</td>\n",
       "      <td>23.370914</td>\n",
       "      <td>23.21867</td>\n",
       "      <td>23.554853</td>\n",
       "      <td>23.547086</td>\n",
       "      <td>23.34714</td>\n",
       "      <td>23.360484</td>\n",
       "      <td>23.647899</td>\n",
       "      <td>23.879527</td>\n",
       "      <td>24.329177</td>\n",
       "      <td>27.506127</td>\n",
       "      <td>28.595749</td>\n",
       "      <td>32.414388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_latency_ms_per_batch</th>\n",
       "      <td>2903.289808</td>\n",
       "      <td>2908.114499</td>\n",
       "      <td>2960.441788</td>\n",
       "      <td>2941.473608</td>\n",
       "      <td>2347.791025</td>\n",
       "      <td>2666.761703</td>\n",
       "      <td>2785.926509</td>\n",
       "      <td>2767.537316</td>\n",
       "      <td>2929.394723</td>\n",
       "      <td>3338.54239</td>\n",
       "      <td>5183.901025</td>\n",
       "      <td>2972.20455</td>\n",
       "      <td>2939.872271</td>\n",
       "      <td>9313.932569</td>\n",
       "      <td>4704.02822</td>\n",
       "      <td>2879.352748</td>\n",
       "      <td>2946.795177</td>\n",
       "      <td>2912.773661</td>\n",
       "      <td>3005.897323</td>\n",
       "      <td>3015.312471</td>\n",
       "      <td>2919.81393</td>\n",
       "      <td>2913.028805</td>\n",
       "      <td>2894.850059</td>\n",
       "      <td>2879.125936</td>\n",
       "      <td>2833.09999</td>\n",
       "      <td>2846.734851</td>\n",
       "      <td>2825.793395</td>\n",
       "      <td>2958.021251</td>\n",
       "      <td>2988.472176</td>\n",
       "      <td>2945.244112</td>\n",
       "      <td>2980.017825</td>\n",
       "      <td>2985.746645</td>\n",
       "      <td>2912.419385</td>\n",
       "      <td>2934.727713</td>\n",
       "      <td>2986.998288</td>\n",
       "      <td>2978.372542</td>\n",
       "      <td>3000.512829</td>\n",
       "      <td>3030.976345</td>\n",
       "      <td>2944.685004</td>\n",
       "      <td>3019.174914</td>\n",
       "      <td>3009.520001</td>\n",
       "      <td>2941.933847</td>\n",
       "      <td>2948.099845</td>\n",
       "      <td>3005.570872</td>\n",
       "      <td>2962.701374</td>\n",
       "      <td>2919.039935</td>\n",
       "      <td>2948.36993</td>\n",
       "      <td>2909.958078</td>\n",
       "      <td>2916.012712</td>\n",
       "      <td>2948.029216</td>\n",
       "      <td>2904.195222</td>\n",
       "      <td>2960.989152</td>\n",
       "      <td>2928.800693</td>\n",
       "      <td>2942.521106</td>\n",
       "      <td>2956.694525</td>\n",
       "      <td>2985.40352</td>\n",
       "      <td>2980.834787</td>\n",
       "      <td>2859.148891</td>\n",
       "      <td>2884.602521</td>\n",
       "      <td>2837.674381</td>\n",
       "      <td>2824.809944</td>\n",
       "      <td>2910.821429</td>\n",
       "      <td>2921.464402</td>\n",
       "      <td>2930.585798</td>\n",
       "      <td>2904.070252</td>\n",
       "      <td>2908.794437</td>\n",
       "      <td>2910.899296</td>\n",
       "      <td>2906.168873</td>\n",
       "      <td>2917.05359</td>\n",
       "      <td>2914.650578</td>\n",
       "      <td>2894.811798</td>\n",
       "      <td>2900.303453</td>\n",
       "      <td>2955.009096</td>\n",
       "      <td>2965.731396</td>\n",
       "      <td>2930.006438</td>\n",
       "      <td>2907.211887</td>\n",
       "      <td>2926.191577</td>\n",
       "      <td>2917.486425</td>\n",
       "      <td>2921.364236</td>\n",
       "      <td>2902.333711</td>\n",
       "      <td>2944.35657</td>\n",
       "      <td>2943.385782</td>\n",
       "      <td>2918.392557</td>\n",
       "      <td>2920.060557</td>\n",
       "      <td>2955.987344</td>\n",
       "      <td>2984.940937</td>\n",
       "      <td>3041.147076</td>\n",
       "      <td>3438.265927</td>\n",
       "      <td>3574.468596</td>\n",
       "      <td>4051.798498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_queries_per_sec</th>\n",
       "      <td>5.51099</td>\n",
       "      <td>5.501847</td>\n",
       "      <td>5.404599</td>\n",
       "      <td>5.43945</td>\n",
       "      <td>0.425932</td>\n",
       "      <td>0.749973</td>\n",
       "      <td>1.435788</td>\n",
       "      <td>2.890657</td>\n",
       "      <td>5.461879</td>\n",
       "      <td>9.585021</td>\n",
       "      <td>12.345915</td>\n",
       "      <td>5.38321</td>\n",
       "      <td>5.442413</td>\n",
       "      <td>1.717857</td>\n",
       "      <td>3.40134</td>\n",
       "      <td>5.556804</td>\n",
       "      <td>5.429627</td>\n",
       "      <td>5.493046</td>\n",
       "      <td>5.32287</td>\n",
       "      <td>5.306249</td>\n",
       "      <td>5.479801</td>\n",
       "      <td>5.492565</td>\n",
       "      <td>5.527057</td>\n",
       "      <td>5.557242</td>\n",
       "      <td>5.647524</td>\n",
       "      <td>5.620474</td>\n",
       "      <td>5.662127</td>\n",
       "      <td>5.409021</td>\n",
       "      <td>5.353906</td>\n",
       "      <td>5.432487</td>\n",
       "      <td>5.369095</td>\n",
       "      <td>5.358794</td>\n",
       "      <td>5.493714</td>\n",
       "      <td>5.451954</td>\n",
       "      <td>5.356548</td>\n",
       "      <td>5.372061</td>\n",
       "      <td>5.332422</td>\n",
       "      <td>5.278827</td>\n",
       "      <td>5.433518</td>\n",
       "      <td>5.299461</td>\n",
       "      <td>5.316462</td>\n",
       "      <td>5.4386</td>\n",
       "      <td>5.427225</td>\n",
       "      <td>5.323448</td>\n",
       "      <td>5.400477</td>\n",
       "      <td>5.481254</td>\n",
       "      <td>5.426727</td>\n",
       "      <td>5.498361</td>\n",
       "      <td>5.486945</td>\n",
       "      <td>5.427355</td>\n",
       "      <td>5.509272</td>\n",
       "      <td>5.4036</td>\n",
       "      <td>5.462987</td>\n",
       "      <td>5.437514</td>\n",
       "      <td>5.411448</td>\n",
       "      <td>5.35941</td>\n",
       "      <td>5.367624</td>\n",
       "      <td>5.596071</td>\n",
       "      <td>5.546691</td>\n",
       "      <td>5.63842</td>\n",
       "      <td>5.664098</td>\n",
       "      <td>5.49673</td>\n",
       "      <td>5.476705</td>\n",
       "      <td>5.459659</td>\n",
       "      <td>5.509509</td>\n",
       "      <td>5.500561</td>\n",
       "      <td>5.496583</td>\n",
       "      <td>5.50553</td>\n",
       "      <td>5.484987</td>\n",
       "      <td>5.489509</td>\n",
       "      <td>5.52713</td>\n",
       "      <td>5.516664</td>\n",
       "      <td>5.414535</td>\n",
       "      <td>5.394959</td>\n",
       "      <td>5.460739</td>\n",
       "      <td>5.503555</td>\n",
       "      <td>5.467858</td>\n",
       "      <td>5.484173</td>\n",
       "      <td>5.476893</td>\n",
       "      <td>5.512805</td>\n",
       "      <td>5.434124</td>\n",
       "      <td>5.435917</td>\n",
       "      <td>5.48247</td>\n",
       "      <td>5.479338</td>\n",
       "      <td>5.412743</td>\n",
       "      <td>5.36024</td>\n",
       "      <td>5.261173</td>\n",
       "      <td>4.653509</td>\n",
       "      <td>4.47619</td>\n",
       "      <td>3.948864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_tokens_per_sec</th>\n",
       "      <td>705.406671</td>\n",
       "      <td>704.236371</td>\n",
       "      <td>691.788641</td>\n",
       "      <td>696.24966</td>\n",
       "      <td>48.988868</td>\n",
       "      <td>95.996579</td>\n",
       "      <td>183.780871</td>\n",
       "      <td>370.004044</td>\n",
       "      <td>699.120533</td>\n",
       "      <td>1226.88273</td>\n",
       "      <td>1580.277085</td>\n",
       "      <td>689.050826</td>\n",
       "      <td>696.628905</td>\n",
       "      <td>219.885637</td>\n",
       "      <td>435.371538</td>\n",
       "      <td>711.270962</td>\n",
       "      <td>694.992314</td>\n",
       "      <td>703.109901</td>\n",
       "      <td>681.327331</td>\n",
       "      <td>679.199924</td>\n",
       "      <td>701.414559</td>\n",
       "      <td>703.048317</td>\n",
       "      <td>707.463239</td>\n",
       "      <td>711.326995</td>\n",
       "      <td>722.883064</td>\n",
       "      <td>719.420707</td>\n",
       "      <td>724.752207</td>\n",
       "      <td>692.354728</td>\n",
       "      <td>685.300006</td>\n",
       "      <td>695.358321</td>\n",
       "      <td>687.244211</td>\n",
       "      <td>685.92558</td>\n",
       "      <td>703.195429</td>\n",
       "      <td>697.85009</td>\n",
       "      <td>685.638157</td>\n",
       "      <td>687.623852</td>\n",
       "      <td>682.54999</td>\n",
       "      <td>675.689866</td>\n",
       "      <td>695.490349</td>\n",
       "      <td>678.33102</td>\n",
       "      <td>680.50719</td>\n",
       "      <td>696.140738</td>\n",
       "      <td>694.684749</td>\n",
       "      <td>681.401333</td>\n",
       "      <td>691.261029</td>\n",
       "      <td>701.600542</td>\n",
       "      <td>694.621112</td>\n",
       "      <td>703.790208</td>\n",
       "      <td>702.3289</td>\n",
       "      <td>694.701392</td>\n",
       "      <td>705.186753</td>\n",
       "      <td>691.660758</td>\n",
       "      <td>699.262331</td>\n",
       "      <td>696.001805</td>\n",
       "      <td>692.665401</td>\n",
       "      <td>686.004416</td>\n",
       "      <td>687.055857</td>\n",
       "      <td>716.297079</td>\n",
       "      <td>709.976499</td>\n",
       "      <td>721.717761</td>\n",
       "      <td>725.004528</td>\n",
       "      <td>703.581463</td>\n",
       "      <td>701.018297</td>\n",
       "      <td>698.83639</td>\n",
       "      <td>705.2171</td>\n",
       "      <td>704.071754</td>\n",
       "      <td>703.562642</td>\n",
       "      <td>704.707844</td>\n",
       "      <td>702.078291</td>\n",
       "      <td>702.657127</td>\n",
       "      <td>707.47259</td>\n",
       "      <td>706.133007</td>\n",
       "      <td>693.060472</td>\n",
       "      <td>690.554783</td>\n",
       "      <td>698.974573</td>\n",
       "      <td>704.455017</td>\n",
       "      <td>699.885823</td>\n",
       "      <td>701.974132</td>\n",
       "      <td>701.042333</td>\n",
       "      <td>705.639049</td>\n",
       "      <td>695.567928</td>\n",
       "      <td>695.797341</td>\n",
       "      <td>701.756176</td>\n",
       "      <td>701.355318</td>\n",
       "      <td>692.831113</td>\n",
       "      <td>686.110728</td>\n",
       "      <td>673.430107</td>\n",
       "      <td>595.649098</td>\n",
       "      <td>572.952299</td>\n",
       "      <td>505.454553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_usage_percent</th>\n",
       "      <td>3.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>32.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_memory_usage_bytes</th>\n",
       "      <td>2013147136</td>\n",
       "      <td>2011279360</td>\n",
       "      <td>2011983872</td>\n",
       "      <td>2012934144</td>\n",
       "      <td>1982603264</td>\n",
       "      <td>2007461888</td>\n",
       "      <td>2008850432</td>\n",
       "      <td>2010365952</td>\n",
       "      <td>2011435008</td>\n",
       "      <td>2011807744</td>\n",
       "      <td>2015821824</td>\n",
       "      <td>2011570176</td>\n",
       "      <td>3105521664</td>\n",
       "      <td>2712805376</td>\n",
       "      <td>2653773824</td>\n",
       "      <td>1998827520</td>\n",
       "      <td>2012307456</td>\n",
       "      <td>1992527872</td>\n",
       "      <td>2027139072</td>\n",
       "      <td>1993207808</td>\n",
       "      <td>2013167616</td>\n",
       "      <td>2011959296</td>\n",
       "      <td>2001289216</td>\n",
       "      <td>1999810560</td>\n",
       "      <td>1995395072</td>\n",
       "      <td>1999060992</td>\n",
       "      <td>1997430784</td>\n",
       "      <td>2021974016</td>\n",
       "      <td>2016477184</td>\n",
       "      <td>2019176448</td>\n",
       "      <td>2020286464</td>\n",
       "      <td>2017255424</td>\n",
       "      <td>2019057664</td>\n",
       "      <td>2020814848</td>\n",
       "      <td>2017898496</td>\n",
       "      <td>2019971072</td>\n",
       "      <td>2018074624</td>\n",
       "      <td>2020343808</td>\n",
       "      <td>2019336192</td>\n",
       "      <td>2019917824</td>\n",
       "      <td>2017144832</td>\n",
       "      <td>2019106816</td>\n",
       "      <td>2018009088</td>\n",
       "      <td>2020339712</td>\n",
       "      <td>2021003264</td>\n",
       "      <td>2019926016</td>\n",
       "      <td>2000257024</td>\n",
       "      <td>2020048896</td>\n",
       "      <td>2019524608</td>\n",
       "      <td>2017579008</td>\n",
       "      <td>2031259648</td>\n",
       "      <td>2020073472</td>\n",
       "      <td>2023170048</td>\n",
       "      <td>2024202240</td>\n",
       "      <td>2019373056</td>\n",
       "      <td>2017050624</td>\n",
       "      <td>2018820096</td>\n",
       "      <td>1976737792</td>\n",
       "      <td>1998172160</td>\n",
       "      <td>2010185728</td>\n",
       "      <td>1999220736</td>\n",
       "      <td>2013782016</td>\n",
       "      <td>2015571968</td>\n",
       "      <td>2014027776</td>\n",
       "      <td>2016215040</td>\n",
       "      <td>2011607040</td>\n",
       "      <td>2015203328</td>\n",
       "      <td>2009636864</td>\n",
       "      <td>2014113792</td>\n",
       "      <td>2011889664</td>\n",
       "      <td>1994887168</td>\n",
       "      <td>1993248768</td>\n",
       "      <td>2012434432</td>\n",
       "      <td>2016657408</td>\n",
       "      <td>2012508160</td>\n",
       "      <td>2015485952</td>\n",
       "      <td>2012946432</td>\n",
       "      <td>2011414528</td>\n",
       "      <td>2013650944</td>\n",
       "      <td>2017865728</td>\n",
       "      <td>2012020736</td>\n",
       "      <td>2017513472</td>\n",
       "      <td>2031509504</td>\n",
       "      <td>2011983872</td>\n",
       "      <td>2016174080</td>\n",
       "      <td>2015072256</td>\n",
       "      <td>2015412224</td>\n",
       "      <td>2012401664</td>\n",
       "      <td>2018140160</td>\n",
       "      <td>2025857024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_1</th>\n",
       "      <td>67.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_3</th>\n",
       "      <td>89.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_current_memory_allocated_bytes</th>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818202112</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>4419853312</td>\n",
       "      <td>1576560640</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_max_memory_allocated_bytes</th>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818202112</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>4419853312</td>\n",
       "      <td>1576560640</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>8818209280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_current_memory_reserved_bytes</th>\n",
       "      <td>12016680960</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13214154752</td>\n",
       "      <td>13220446208</td>\n",
       "      <td>13230931968</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>6870269952</td>\n",
       "      <td>2883584000</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>12016680960</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>12633243648</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>12903776256</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>12903776256</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_max_memory_reserved_bytes</th>\n",
       "      <td>12016680960</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13214154752</td>\n",
       "      <td>13220446208</td>\n",
       "      <td>13230931968</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>6870269952</td>\n",
       "      <td>2883584000</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>12016680960</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>12633243648</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>12903776256</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>12903776256</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>13212057600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_0</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_0</th>\n",
       "      <td>696.175445</td>\n",
       "      <td>473.285169</td>\n",
       "      <td>748.448174</td>\n",
       "      <td>840.551156</td>\n",
       "      <td>627.691201</td>\n",
       "      <td>607.851348</td>\n",
       "      <td>1115.441822</td>\n",
       "      <td>737.23032</td>\n",
       "      <td>860.575376</td>\n",
       "      <td>898.907868</td>\n",
       "      <td>1099.618651</td>\n",
       "      <td>845.522618</td>\n",
       "      <td>590.607143</td>\n",
       "      <td>566.735261</td>\n",
       "      <td>487.388971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2132.583275</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.27566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1009.128141</td>\n",
       "      <td>1201.700986</td>\n",
       "      <td>1061.801104</td>\n",
       "      <td>2092.393511</td>\n",
       "      <td>74.899727</td>\n",
       "      <td>784.54132</td>\n",
       "      <td>151.414568</td>\n",
       "      <td>1161.348553</td>\n",
       "      <td>850.569025</td>\n",
       "      <td>823.337213</td>\n",
       "      <td>865.194509</td>\n",
       "      <td>932.97171</td>\n",
       "      <td>737.530858</td>\n",
       "      <td>833.971863</td>\n",
       "      <td>840.144888</td>\n",
       "      <td>1024.973746</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1702.06151</td>\n",
       "      <td>907.576366</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1296.061967</td>\n",
       "      <td>1246.937856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>774.142548</td>\n",
       "      <td>915.912752</td>\n",
       "      <td>1168.832823</td>\n",
       "      <td>882.692097</td>\n",
       "      <td>603.259737</td>\n",
       "      <td>1374.787363</td>\n",
       "      <td>784.969026</td>\n",
       "      <td>1038.966873</td>\n",
       "      <td>53.497819</td>\n",
       "      <td>1303.029478</td>\n",
       "      <td>1022.695962</td>\n",
       "      <td>989.992263</td>\n",
       "      <td>933.383914</td>\n",
       "      <td>38.689285</td>\n",
       "      <td>1465.047114</td>\n",
       "      <td>771.424644</td>\n",
       "      <td>886.299478</td>\n",
       "      <td>807.718125</td>\n",
       "      <td>1507.774547</td>\n",
       "      <td>52.111428</td>\n",
       "      <td>853.994754</td>\n",
       "      <td>657.723019</td>\n",
       "      <td>2089.517058</td>\n",
       "      <td>2453.755831</td>\n",
       "      <td>1847.083723</td>\n",
       "      <td>2041.919549</td>\n",
       "      <td>580.657842</td>\n",
       "      <td>481.238339</td>\n",
       "      <td>59.540126</td>\n",
       "      <td>84.025257</td>\n",
       "      <td>1280.226382</td>\n",
       "      <td>854.465019</td>\n",
       "      <td>800.847829</td>\n",
       "      <td>1573.157176</td>\n",
       "      <td>1695.250619</td>\n",
       "      <td>829.361042</td>\n",
       "      <td>1183.427842</td>\n",
       "      <td>1252.424</td>\n",
       "      <td>758.319875</td>\n",
       "      <td>91.654937</td>\n",
       "      <td>963.58932</td>\n",
       "      <td>761.124153</td>\n",
       "      <td>1618.269712</td>\n",
       "      <td>592.348564</td>\n",
       "      <td>24.472879</td>\n",
       "      <td>696.29275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>852.283653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>770.76088</td>\n",
       "      <td>587.868011</td>\n",
       "      <td>443.862459</td>\n",
       "      <td>472.776999</td>\n",
       "      <td>503.533111</td>\n",
       "      <td>451.594338</td>\n",
       "      <td>528.622622</td>\n",
       "      <td>471.735827</td>\n",
       "      <td>528.434789</td>\n",
       "      <td>498.917158</td>\n",
       "      <td>328.13377</td>\n",
       "      <td>506.209779</td>\n",
       "      <td>452.225727</td>\n",
       "      <td>9.292454</td>\n",
       "      <td>11.212884</td>\n",
       "      <td>597.724199</td>\n",
       "      <td>498.848218</td>\n",
       "      <td>451.682352</td>\n",
       "      <td>13.321082</td>\n",
       "      <td>1252.829711</td>\n",
       "      <td>19.490862</td>\n",
       "      <td>72.494017</td>\n",
       "      <td>788.841356</td>\n",
       "      <td>157.860419</td>\n",
       "      <td>998.434903</td>\n",
       "      <td>1979.221778</td>\n",
       "      <td>730.47263</td>\n",
       "      <td>805.794565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.604144</td>\n",
       "      <td>721.532522</td>\n",
       "      <td>1161.29246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.379849</td>\n",
       "      <td>101.913394</td>\n",
       "      <td>1262.458064</td>\n",
       "      <td>113.351432</td>\n",
       "      <td>94.053829</td>\n",
       "      <td>1646.512799</td>\n",
       "      <td>1950.269423</td>\n",
       "      <td>129.714284</td>\n",
       "      <td>1568.792356</td>\n",
       "      <td>738.719496</td>\n",
       "      <td>1283.37675</td>\n",
       "      <td>737.945279</td>\n",
       "      <td>660.254699</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1069.004617</td>\n",
       "      <td>2230.731714</td>\n",
       "      <td>45.508511</td>\n",
       "      <td>930.694166</td>\n",
       "      <td>1180.326923</td>\n",
       "      <td>958.975708</td>\n",
       "      <td>1006.102423</td>\n",
       "      <td>949.219255</td>\n",
       "      <td>31000.47471</td>\n",
       "      <td>796.74593</td>\n",
       "      <td>773.40502</td>\n",
       "      <td>820.306382</td>\n",
       "      <td>2644.588979</td>\n",
       "      <td>1049.926673</td>\n",
       "      <td>1769.71848</td>\n",
       "      <td>637.201177</td>\n",
       "      <td>2148.794721</td>\n",
       "      <td>1967.273382</td>\n",
       "      <td>940.532198</td>\n",
       "      <td>1400.781667</td>\n",
       "      <td>671.272318</td>\n",
       "      <td>1468.601516</td>\n",
       "      <td>2311.788445</td>\n",
       "      <td>85.133778</td>\n",
       "      <td>918.583448</td>\n",
       "      <td>786.069152</td>\n",
       "      <td>851.971445</td>\n",
       "      <td>944.440022</td>\n",
       "      <td>985.85255</td>\n",
       "      <td>639.712444</td>\n",
       "      <td>2603.764889</td>\n",
       "      <td>793.987273</td>\n",
       "      <td>590.211571</td>\n",
       "      <td>72.911802</td>\n",
       "      <td>2278.488365</td>\n",
       "      <td>1793.70006</td>\n",
       "      <td>1120.309099</td>\n",
       "      <td>864.480963</td>\n",
       "      <td>987.103513</td>\n",
       "      <td>674.736579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>934.252033</td>\n",
       "      <td>590.523284</td>\n",
       "      <td>530.446613</td>\n",
       "      <td>494.305105</td>\n",
       "      <td>652.840459</td>\n",
       "      <td>630.901716</td>\n",
       "      <td>606.900655</td>\n",
       "      <td>545.227387</td>\n",
       "      <td>624.886759</td>\n",
       "      <td>486.615792</td>\n",
       "      <td>494.106489</td>\n",
       "      <td>541.83233</td>\n",
       "      <td>715.638517</td>\n",
       "      <td>532.356597</td>\n",
       "      <td>5.057341</td>\n",
       "      <td>752.568957</td>\n",
       "      <td>27.024433</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62.157545</td>\n",
       "      <td>1290.999517</td>\n",
       "      <td>418.061063</td>\n",
       "      <td>1856.549041</td>\n",
       "      <td>69.415483</td>\n",
       "      <td>793.997062</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1060.037074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>702.759521</td>\n",
       "      <td>799.459307</td>\n",
       "      <td>933.957899</td>\n",
       "      <td>655.269069</td>\n",
       "      <td>613.832213</td>\n",
       "      <td>1723.878013</td>\n",
       "      <td>1029.978916</td>\n",
       "      <td>8.759803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>806.913317</td>\n",
       "      <td>124.546594</td>\n",
       "      <td>1490.421123</td>\n",
       "      <td>47.808284</td>\n",
       "      <td>875.249088</td>\n",
       "      <td>136.960885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>722.772005</td>\n",
       "      <td>928.259069</td>\n",
       "      <td>762.663717</td>\n",
       "      <td>3150.571004</td>\n",
       "      <td>1010.700407</td>\n",
       "      <td>0.0</td>\n",
       "      <td>909.304739</td>\n",
       "      <td>71.437712</td>\n",
       "      <td>1187.409604</td>\n",
       "      <td>1178.710549</td>\n",
       "      <td>1408.042542</td>\n",
       "      <td>961.608002</td>\n",
       "      <td>577.740962</td>\n",
       "      <td>147.942848</td>\n",
       "      <td>488.131338</td>\n",
       "      <td>797.146251</td>\n",
       "      <td>646.442067</td>\n",
       "      <td>2546.422016</td>\n",
       "      <td>3250.966224</td>\n",
       "      <td>833.875722</td>\n",
       "      <td>733.064031</td>\n",
       "      <td>1534.052834</td>\n",
       "      <td>985.508568</td>\n",
       "      <td>2485.634033</td>\n",
       "      <td>1137.646687</td>\n",
       "      <td>537.766222</td>\n",
       "      <td>676.799436</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.865532</td>\n",
       "      <td>724.683427</td>\n",
       "      <td>623.092399</td>\n",
       "      <td>1469.001199</td>\n",
       "      <td>908.342508</td>\n",
       "      <td>1872.834769</td>\n",
       "      <td>596.254414</td>\n",
       "      <td>1863.487297</td>\n",
       "      <td>758.812641</td>\n",
       "      <td>1208.611625</td>\n",
       "      <td>51.069227</td>\n",
       "      <td>1156.969416</td>\n",
       "      <td>1501.975819</td>\n",
       "      <td>1624.941628</td>\n",
       "      <td>52.79913</td>\n",
       "      <td>635.873796</td>\n",
       "      <td>836.395045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>702.522995</td>\n",
       "      <td>464.528704</td>\n",
       "      <td>700.458985</td>\n",
       "      <td>495.692987</td>\n",
       "      <td>646.758341</td>\n",
       "      <td>682.779136</td>\n",
       "      <td>741.472606</td>\n",
       "      <td>807.625618</td>\n",
       "      <td>672.966642</td>\n",
       "      <td>722.912342</td>\n",
       "      <td>504.428324</td>\n",
       "      <td>676.823883</td>\n",
       "      <td>11.318237</td>\n",
       "      <td>136.944676</td>\n",
       "      <td>675.2677</td>\n",
       "      <td>23.198432</td>\n",
       "      <td>1029.13102</td>\n",
       "      <td>773.054232</td>\n",
       "      <td>840.642824</td>\n",
       "      <td>57.254406</td>\n",
       "      <td>13.16597</td>\n",
       "      <td>349.193143</td>\n",
       "      <td>13.512987</td>\n",
       "      <td>650.78825</td>\n",
       "      <td>501.323353</td>\n",
       "      <td>442.503424</td>\n",
       "      <td>466.270994</td>\n",
       "      <td>52.696948</td>\n",
       "      <td>471.7604</td>\n",
       "      <td>480.62037</td>\n",
       "      <td>498.322801</td>\n",
       "      <td>451.217783</td>\n",
       "      <td>397.348075</td>\n",
       "      <td>395.676137</td>\n",
       "      <td>413.213713</td>\n",
       "      <td>10.513689</td>\n",
       "      <td>474.412727</td>\n",
       "      <td>536.56597</td>\n",
       "      <td>323.136095</td>\n",
       "      <td>442.846654</td>\n",
       "      <td>466.843438</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.899224</td>\n",
       "      <td>2326.109494</td>\n",
       "      <td>54.419399</td>\n",
       "      <td>506.299235</td>\n",
       "      <td>625.245845</td>\n",
       "      <td>673.469657</td>\n",
       "      <td>320.672289</td>\n",
       "      <td>259.877186</td>\n",
       "      <td>438.454544</td>\n",
       "      <td>0.0</td>\n",
       "      <td>373.109119</td>\n",
       "      <td>412.478468</td>\n",
       "      <td>605.047216</td>\n",
       "      <td>1061.650308</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>728.332708</td>\n",
       "      <td>13.14021</td>\n",
       "      <td>450.415693</td>\n",
       "      <td>636.255324</td>\n",
       "      <td>538.970033</td>\n",
       "      <td>432.464672</td>\n",
       "      <td>388.43613</td>\n",
       "      <td>667.79854</td>\n",
       "      <td>519.269961</td>\n",
       "      <td>460.458775</td>\n",
       "      <td>555.574279</td>\n",
       "      <td>463.830376</td>\n",
       "      <td>534.109641</td>\n",
       "      <td>836.53767</td>\n",
       "      <td>375.304828</td>\n",
       "      <td>403.857038</td>\n",
       "      <td>5386.906198</td>\n",
       "      <td>2096.363286</td>\n",
       "      <td>518.756464</td>\n",
       "      <td>421.87969</td>\n",
       "      <td>27.593747</td>\n",
       "      <td>533.796635</td>\n",
       "      <td>358.231676</td>\n",
       "      <td>538.257839</td>\n",
       "      <td>455.151437</td>\n",
       "      <td>673.337196</td>\n",
       "      <td>50.770336</td>\n",
       "      <td>489.010663</td>\n",
       "      <td>532.767231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_0</th>\n",
       "      <td>0.701849</td>\n",
       "      <td>0.70122</td>\n",
       "      <td>0.701178</td>\n",
       "      <td>0.701102</td>\n",
       "      <td>0.690853</td>\n",
       "      <td>0.6996</td>\n",
       "      <td>0.699941</td>\n",
       "      <td>0.700879</td>\n",
       "      <td>0.700577</td>\n",
       "      <td>0.700729</td>\n",
       "      <td>0.702344</td>\n",
       "      <td>0.700822</td>\n",
       "      <td>1.083248</td>\n",
       "      <td>0.94703</td>\n",
       "      <td>0.926631</td>\n",
       "      <td>0.695679</td>\n",
       "      <td>0.701025</td>\n",
       "      <td>0.693811</td>\n",
       "      <td>0.705604</td>\n",
       "      <td>0.693814</td>\n",
       "      <td>0.701212</td>\n",
       "      <td>0.700521</td>\n",
       "      <td>0.697287</td>\n",
       "      <td>0.697085</td>\n",
       "      <td>0.695669</td>\n",
       "      <td>0.696043</td>\n",
       "      <td>0.695559</td>\n",
       "      <td>0.704543</td>\n",
       "      <td>0.701859</td>\n",
       "      <td>0.703181</td>\n",
       "      <td>0.703116</td>\n",
       "      <td>0.702168</td>\n",
       "      <td>0.703071</td>\n",
       "      <td>0.704103</td>\n",
       "      <td>0.703332</td>\n",
       "      <td>0.703428</td>\n",
       "      <td>0.703474</td>\n",
       "      <td>0.704278</td>\n",
       "      <td>0.702796</td>\n",
       "      <td>0.704071</td>\n",
       "      <td>0.703132</td>\n",
       "      <td>0.703952</td>\n",
       "      <td>0.703468</td>\n",
       "      <td>0.704178</td>\n",
       "      <td>0.703823</td>\n",
       "      <td>0.704059</td>\n",
       "      <td>0.697381</td>\n",
       "      <td>0.703574</td>\n",
       "      <td>0.703661</td>\n",
       "      <td>0.703328</td>\n",
       "      <td>0.708203</td>\n",
       "      <td>0.704255</td>\n",
       "      <td>0.704736</td>\n",
       "      <td>0.705005</td>\n",
       "      <td>0.702986</td>\n",
       "      <td>0.702569</td>\n",
       "      <td>0.703385</td>\n",
       "      <td>0.689136</td>\n",
       "      <td>0.696061</td>\n",
       "      <td>0.700212</td>\n",
       "      <td>0.697014</td>\n",
       "      <td>0.701321</td>\n",
       "      <td>0.702457</td>\n",
       "      <td>0.701925</td>\n",
       "      <td>0.702041</td>\n",
       "      <td>0.701194</td>\n",
       "      <td>0.701341</td>\n",
       "      <td>0.699768</td>\n",
       "      <td>0.702147</td>\n",
       "      <td>0.700899</td>\n",
       "      <td>0.695443</td>\n",
       "      <td>0.694356</td>\n",
       "      <td>0.700981</td>\n",
       "      <td>0.703035</td>\n",
       "      <td>0.700842</td>\n",
       "      <td>0.702211</td>\n",
       "      <td>0.701301</td>\n",
       "      <td>0.700839</td>\n",
       "      <td>0.701915</td>\n",
       "      <td>0.703132</td>\n",
       "      <td>0.700809</td>\n",
       "      <td>0.703116</td>\n",
       "      <td>0.708105</td>\n",
       "      <td>0.70079</td>\n",
       "      <td>0.702488</td>\n",
       "      <td>0.702219</td>\n",
       "      <td>0.7016</td>\n",
       "      <td>0.701571</td>\n",
       "      <td>0.703331</td>\n",
       "      <td>0.705437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.655882</td>\n",
       "      <td>0.650575</td>\n",
       "      <td>0.651967</td>\n",
       "      <td>0.645085</td>\n",
       "      <td>0.65001</td>\n",
       "      <td>0.651295</td>\n",
       "      <td>0.65122</td>\n",
       "      <td>0.660244</td>\n",
       "      <td>0.650459</td>\n",
       "      <td>0.64562</td>\n",
       "      <td>0.656609</td>\n",
       "      <td>0.852912</td>\n",
       "      <td>0.991452</td>\n",
       "      <td>0.980135</td>\n",
       "      <td>0.619613</td>\n",
       "      <td>0.650712</td>\n",
       "      <td>0.65329</td>\n",
       "      <td>0.653501</td>\n",
       "      <td>0.653257</td>\n",
       "      <td>0.650597</td>\n",
       "      <td>0.655446</td>\n",
       "      <td>0.608936</td>\n",
       "      <td>0.620072</td>\n",
       "      <td>0.63238</td>\n",
       "      <td>0.625219</td>\n",
       "      <td>0.631578</td>\n",
       "      <td>0.659151</td>\n",
       "      <td>0.6666</td>\n",
       "      <td>0.668215</td>\n",
       "      <td>0.663158</td>\n",
       "      <td>0.664437</td>\n",
       "      <td>0.670727</td>\n",
       "      <td>0.667624</td>\n",
       "      <td>0.668508</td>\n",
       "      <td>0.663785</td>\n",
       "      <td>0.671883</td>\n",
       "      <td>0.663054</td>\n",
       "      <td>0.66352</td>\n",
       "      <td>0.662325</td>\n",
       "      <td>0.669359</td>\n",
       "      <td>0.663025</td>\n",
       "      <td>0.674951</td>\n",
       "      <td>0.662604</td>\n",
       "      <td>0.669487</td>\n",
       "      <td>0.668499</td>\n",
       "      <td>0.669037</td>\n",
       "      <td>0.664238</td>\n",
       "      <td>0.662991</td>\n",
       "      <td>0.669341</td>\n",
       "      <td>0.671711</td>\n",
       "      <td>0.676709</td>\n",
       "      <td>0.67122</td>\n",
       "      <td>0.664392</td>\n",
       "      <td>0.664045</td>\n",
       "      <td>0.66287</td>\n",
       "      <td>0.671908</td>\n",
       "      <td>0.619919</td>\n",
       "      <td>0.631253</td>\n",
       "      <td>0.63298</td>\n",
       "      <td>0.630647</td>\n",
       "      <td>0.658552</td>\n",
       "      <td>0.656791</td>\n",
       "      <td>0.652162</td>\n",
       "      <td>0.653923</td>\n",
       "      <td>0.650873</td>\n",
       "      <td>0.645194</td>\n",
       "      <td>0.656291</td>\n",
       "      <td>0.645009</td>\n",
       "      <td>0.649162</td>\n",
       "      <td>0.655895</td>\n",
       "      <td>0.661739</td>\n",
       "      <td>0.649854</td>\n",
       "      <td>0.652764</td>\n",
       "      <td>0.653312</td>\n",
       "      <td>0.659035</td>\n",
       "      <td>0.65507</td>\n",
       "      <td>0.649684</td>\n",
       "      <td>0.64994</td>\n",
       "      <td>0.649459</td>\n",
       "      <td>0.651531</td>\n",
       "      <td>0.648321</td>\n",
       "      <td>0.651007</td>\n",
       "      <td>0.658836</td>\n",
       "      <td>0.653818</td>\n",
       "      <td>0.648634</td>\n",
       "      <td>0.650595</td>\n",
       "      <td>0.651967</td>\n",
       "      <td>0.654479</td>\n",
       "      <td>0.658193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.651993</td>\n",
       "      <td>0.652677</td>\n",
       "      <td>0.644468</td>\n",
       "      <td>0.648281</td>\n",
       "      <td>0.651762</td>\n",
       "      <td>0.653661</td>\n",
       "      <td>0.651913</td>\n",
       "      <td>0.648046</td>\n",
       "      <td>0.649797</td>\n",
       "      <td>0.647584</td>\n",
       "      <td>0.857015</td>\n",
       "      <td>0.990413</td>\n",
       "      <td>0.976652</td>\n",
       "      <td>0.617517</td>\n",
       "      <td>0.651804</td>\n",
       "      <td>0.647007</td>\n",
       "      <td>0.651778</td>\n",
       "      <td>0.654561</td>\n",
       "      <td>0.647645</td>\n",
       "      <td>0.65005</td>\n",
       "      <td>0.628262</td>\n",
       "      <td>0.605607</td>\n",
       "      <td>0.618293</td>\n",
       "      <td>0.619406</td>\n",
       "      <td>0.638065</td>\n",
       "      <td>0.677509</td>\n",
       "      <td>0.669771</td>\n",
       "      <td>0.662082</td>\n",
       "      <td>0.669469</td>\n",
       "      <td>0.665169</td>\n",
       "      <td>0.667106</td>\n",
       "      <td>0.67189</td>\n",
       "      <td>0.668924</td>\n",
       "      <td>0.664714</td>\n",
       "      <td>0.664699</td>\n",
       "      <td>0.668273</td>\n",
       "      <td>0.667314</td>\n",
       "      <td>0.666161</td>\n",
       "      <td>0.661823</td>\n",
       "      <td>0.668996</td>\n",
       "      <td>0.673327</td>\n",
       "      <td>0.663998</td>\n",
       "      <td>0.66809</td>\n",
       "      <td>0.668465</td>\n",
       "      <td>0.671003</td>\n",
       "      <td>0.675021</td>\n",
       "      <td>0.670984</td>\n",
       "      <td>0.664939</td>\n",
       "      <td>0.665657</td>\n",
       "      <td>0.674967</td>\n",
       "      <td>0.668265</td>\n",
       "      <td>0.664093</td>\n",
       "      <td>0.665493</td>\n",
       "      <td>0.662753</td>\n",
       "      <td>0.665819</td>\n",
       "      <td>0.626741</td>\n",
       "      <td>0.619699</td>\n",
       "      <td>0.632026</td>\n",
       "      <td>0.620356</td>\n",
       "      <td>0.650073</td>\n",
       "      <td>0.650618</td>\n",
       "      <td>0.655918</td>\n",
       "      <td>0.654596</td>\n",
       "      <td>0.649035</td>\n",
       "      <td>0.653472</td>\n",
       "      <td>0.653499</td>\n",
       "      <td>0.656103</td>\n",
       "      <td>0.654551</td>\n",
       "      <td>0.655081</td>\n",
       "      <td>0.648881</td>\n",
       "      <td>0.65436</td>\n",
       "      <td>0.65512</td>\n",
       "      <td>0.653895</td>\n",
       "      <td>0.650888</td>\n",
       "      <td>0.650066</td>\n",
       "      <td>0.654472</td>\n",
       "      <td>0.652318</td>\n",
       "      <td>0.648336</td>\n",
       "      <td>0.656616</td>\n",
       "      <td>0.650671</td>\n",
       "      <td>0.649127</td>\n",
       "      <td>0.649784</td>\n",
       "      <td>0.653021</td>\n",
       "      <td>0.650369</td>\n",
       "      <td>0.655666</td>\n",
       "      <td>0.646347</td>\n",
       "      <td>0.652483</td>\n",
       "      <td>0.657608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.656146</td>\n",
       "      <td>0.643654</td>\n",
       "      <td>0.648484</td>\n",
       "      <td>0.652755</td>\n",
       "      <td>0.656559</td>\n",
       "      <td>0.65378</td>\n",
       "      <td>0.648501</td>\n",
       "      <td>0.653134</td>\n",
       "      <td>0.649917</td>\n",
       "      <td>0.872403</td>\n",
       "      <td>0.989322</td>\n",
       "      <td>0.967501</td>\n",
       "      <td>0.639288</td>\n",
       "      <td>0.652708</td>\n",
       "      <td>0.653179</td>\n",
       "      <td>0.657429</td>\n",
       "      <td>0.650559</td>\n",
       "      <td>0.648325</td>\n",
       "      <td>0.659932</td>\n",
       "      <td>0.633667</td>\n",
       "      <td>0.620702</td>\n",
       "      <td>0.618702</td>\n",
       "      <td>0.62044</td>\n",
       "      <td>0.617527</td>\n",
       "      <td>0.669405</td>\n",
       "      <td>0.669248</td>\n",
       "      <td>0.676116</td>\n",
       "      <td>0.663536</td>\n",
       "      <td>0.664172</td>\n",
       "      <td>0.669482</td>\n",
       "      <td>0.664929</td>\n",
       "      <td>0.667959</td>\n",
       "      <td>0.664591</td>\n",
       "      <td>0.665002</td>\n",
       "      <td>0.671436</td>\n",
       "      <td>0.669714</td>\n",
       "      <td>0.670774</td>\n",
       "      <td>0.680599</td>\n",
       "      <td>0.663465</td>\n",
       "      <td>0.669574</td>\n",
       "      <td>0.664515</td>\n",
       "      <td>0.665158</td>\n",
       "      <td>0.663956</td>\n",
       "      <td>0.67175</td>\n",
       "      <td>0.664653</td>\n",
       "      <td>0.669169</td>\n",
       "      <td>0.665042</td>\n",
       "      <td>0.668261</td>\n",
       "      <td>0.681427</td>\n",
       "      <td>0.676413</td>\n",
       "      <td>0.661546</td>\n",
       "      <td>0.664669</td>\n",
       "      <td>0.667863</td>\n",
       "      <td>0.670351</td>\n",
       "      <td>0.620301</td>\n",
       "      <td>0.645003</td>\n",
       "      <td>0.620424</td>\n",
       "      <td>0.619853</td>\n",
       "      <td>0.656045</td>\n",
       "      <td>0.650914</td>\n",
       "      <td>0.650775</td>\n",
       "      <td>0.648202</td>\n",
       "      <td>0.656748</td>\n",
       "      <td>0.652392</td>\n",
       "      <td>0.651119</td>\n",
       "      <td>0.65764</td>\n",
       "      <td>0.649116</td>\n",
       "      <td>0.650961</td>\n",
       "      <td>0.649638</td>\n",
       "      <td>0.649316</td>\n",
       "      <td>0.655417</td>\n",
       "      <td>0.654262</td>\n",
       "      <td>0.652259</td>\n",
       "      <td>0.65305</td>\n",
       "      <td>0.657243</td>\n",
       "      <td>0.646987</td>\n",
       "      <td>0.65073</td>\n",
       "      <td>0.6529</td>\n",
       "      <td>0.649894</td>\n",
       "      <td>0.649582</td>\n",
       "      <td>0.649331</td>\n",
       "      <td>0.662247</td>\n",
       "      <td>0.657304</td>\n",
       "      <td>0.649555</td>\n",
       "      <td>0.659393</td>\n",
       "      <td>0.653455</td>\n",
       "      <td>0.657968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_0</th>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>0.005241</td>\n",
       "      <td>0.002727</td>\n",
       "      <td>0.001364</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.000414</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.00082</td>\n",
       "      <td>0.018917</td>\n",
       "      <td>0.000753</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.00079</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.000804</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000756</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000777</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.00068</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.000614</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.00063</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.000732</td>\n",
       "      <td>0.000828</td>\n",
       "      <td>0.000871</td>\n",
       "      <td>0.000994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.010928</td>\n",
       "      <td>0.00703</td>\n",
       "      <td>0.003583</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.001098</td>\n",
       "      <td>0.000837</td>\n",
       "      <td>0.004794</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.001033</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.001088</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>0.019204</td>\n",
       "      <td>0.001071</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.000747</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.000691</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.00067</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.00064</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.000689</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.000662</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000739</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.000776</td>\n",
       "      <td>0.000973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00102</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>0.006642</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.001494</td>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>0.001053</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>0.004221</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.00089</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.000896</td>\n",
       "      <td>0.019364</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>0.000822</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.000742</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.000663</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.00072</td>\n",
       "      <td>0.00061</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.00068</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.00077</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.00079</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000628</td>\n",
       "      <td>0.000638</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000729</td>\n",
       "      <td>0.00076</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000635</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000666</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.000713</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000717</td>\n",
       "      <td>0.000656</td>\n",
       "      <td>0.000699</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.000731</td>\n",
       "      <td>0.000636</td>\n",
       "      <td>0.000681</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>0.000792</td>\n",
       "      <td>0.000926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000947</td>\n",
       "      <td>0.010234</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>0.00321</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>0.000942</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.000938</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.000863</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.019455</td>\n",
       "      <td>0.000846</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000803</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.000816</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.00077</td>\n",
       "      <td>0.000795</td>\n",
       "      <td>0.00079</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000817</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.00079</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.000798</td>\n",
       "      <td>0.000652</td>\n",
       "      <td>0.000841</td>\n",
       "      <td>0.000738</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.000688</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000827</td>\n",
       "      <td>0.000741</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000774</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.00075</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.000762</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.000692</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.000751</td>\n",
       "      <td>0.000779</td>\n",
       "      <td>0.00079</td>\n",
       "      <td>0.000932</td>\n",
       "      <td>0.000879</td>\n",
       "      <td>0.001004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_0</th>\n",
       "      <td>0.003779</td>\n",
       "      <td>0.004188</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.005287</td>\n",
       "      <td>0.047094</td>\n",
       "      <td>0.031252</td>\n",
       "      <td>0.015568</td>\n",
       "      <td>0.008683</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.003364</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>0.00388</td>\n",
       "      <td>0.010467</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.005266</td>\n",
       "      <td>0.00504</td>\n",
       "      <td>0.005266</td>\n",
       "      <td>0.005365</td>\n",
       "      <td>0.086619</td>\n",
       "      <td>0.005063</td>\n",
       "      <td>0.004825</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>0.004668</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.00479</td>\n",
       "      <td>0.004794</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.00476</td>\n",
       "      <td>0.004773</td>\n",
       "      <td>0.004655</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.004805</td>\n",
       "      <td>0.00478</td>\n",
       "      <td>0.00478</td>\n",
       "      <td>0.004769</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.004764</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.004689</td>\n",
       "      <td>0.004647</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.00463</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.004655</td>\n",
       "      <td>0.004666</td>\n",
       "      <td>0.004615</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.004712</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.004743</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>0.004769</td>\n",
       "      <td>0.004769</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.004663</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.004771</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>0.004767</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.004722</td>\n",
       "      <td>0.004804</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.005022</td>\n",
       "      <td>0.00534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005985</td>\n",
       "      <td>0.006776</td>\n",
       "      <td>0.007545</td>\n",
       "      <td>0.055061</td>\n",
       "      <td>0.040477</td>\n",
       "      <td>0.01934</td>\n",
       "      <td>0.011641</td>\n",
       "      <td>0.007444</td>\n",
       "      <td>0.004993</td>\n",
       "      <td>0.004346</td>\n",
       "      <td>0.007461</td>\n",
       "      <td>0.004443</td>\n",
       "      <td>0.02157</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.006462</td>\n",
       "      <td>0.006656</td>\n",
       "      <td>0.006801</td>\n",
       "      <td>0.006834</td>\n",
       "      <td>0.00683</td>\n",
       "      <td>0.088478</td>\n",
       "      <td>0.006818</td>\n",
       "      <td>0.004956</td>\n",
       "      <td>0.004656</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.004807</td>\n",
       "      <td>0.004797</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.00476</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.004793</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.004776</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.004736</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.004855</td>\n",
       "      <td>0.004702</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>0.004711</td>\n",
       "      <td>0.004672</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0.004702</td>\n",
       "      <td>0.004734</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>0.00474</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>0.004754</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.004648</td>\n",
       "      <td>0.004691</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>0.004781</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.004718</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>0.004745</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.004709</td>\n",
       "      <td>0.004754</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>0.004669</td>\n",
       "      <td>0.004673</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>0.004663</td>\n",
       "      <td>0.004769</td>\n",
       "      <td>0.00468</td>\n",
       "      <td>0.004741</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.004741</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.004802</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005047</td>\n",
       "      <td>0.005341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006343</td>\n",
       "      <td>0.007143</td>\n",
       "      <td>0.053492</td>\n",
       "      <td>0.038695</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>0.009446</td>\n",
       "      <td>0.007182</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>0.019362</td>\n",
       "      <td>0.005697</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.006106</td>\n",
       "      <td>0.006108</td>\n",
       "      <td>0.006199</td>\n",
       "      <td>0.006156</td>\n",
       "      <td>0.088062</td>\n",
       "      <td>0.006171</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.004679</td>\n",
       "      <td>0.004744</td>\n",
       "      <td>0.00482</td>\n",
       "      <td>0.00479</td>\n",
       "      <td>0.00476</td>\n",
       "      <td>0.004749</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.004775</td>\n",
       "      <td>0.00478</td>\n",
       "      <td>0.004784</td>\n",
       "      <td>0.004769</td>\n",
       "      <td>0.004702</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>0.004713</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>0.004767</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.004758</td>\n",
       "      <td>0.004716</td>\n",
       "      <td>0.004761</td>\n",
       "      <td>0.00472</td>\n",
       "      <td>0.004633</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0.004786</td>\n",
       "      <td>0.004767</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.004751</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.004773</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>0.004667</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.004676</td>\n",
       "      <td>0.004639</td>\n",
       "      <td>0.004739</td>\n",
       "      <td>0.004769</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.004778</td>\n",
       "      <td>0.004675</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>0.004753</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.004708</td>\n",
       "      <td>0.004706</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.004762</td>\n",
       "      <td>0.004683</td>\n",
       "      <td>0.004754</td>\n",
       "      <td>0.004774</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>0.004758</td>\n",
       "      <td>0.004759</td>\n",
       "      <td>0.004655</td>\n",
       "      <td>0.004656</td>\n",
       "      <td>0.004766</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>0.004684</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.004816</td>\n",
       "      <td>0.005078</td>\n",
       "      <td>0.005198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006707</td>\n",
       "      <td>0.051983</td>\n",
       "      <td>0.037198</td>\n",
       "      <td>0.017845</td>\n",
       "      <td>0.010616</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.00432</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>0.006634</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.015643</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>0.00573</td>\n",
       "      <td>0.005705</td>\n",
       "      <td>0.006184</td>\n",
       "      <td>0.005801</td>\n",
       "      <td>0.087116</td>\n",
       "      <td>0.005748</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>0.005018</td>\n",
       "      <td>0.00501</td>\n",
       "      <td>0.005004</td>\n",
       "      <td>0.004984</td>\n",
       "      <td>0.005131</td>\n",
       "      <td>0.005118</td>\n",
       "      <td>0.005135</td>\n",
       "      <td>0.005145</td>\n",
       "      <td>0.005098</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.005093</td>\n",
       "      <td>0.005121</td>\n",
       "      <td>0.005121</td>\n",
       "      <td>0.005072</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.005067</td>\n",
       "      <td>0.005039</td>\n",
       "      <td>0.005175</td>\n",
       "      <td>0.005069</td>\n",
       "      <td>0.005076</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.005061</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.00505</td>\n",
       "      <td>0.005027</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>0.005064</td>\n",
       "      <td>0.005057</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.00506</td>\n",
       "      <td>0.004987</td>\n",
       "      <td>0.005046</td>\n",
       "      <td>0.005023</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>0.005075</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>0.005065</td>\n",
       "      <td>0.00504</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>0.005047</td>\n",
       "      <td>0.005081</td>\n",
       "      <td>0.005097</td>\n",
       "      <td>0.005062</td>\n",
       "      <td>0.005047</td>\n",
       "      <td>0.005061</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>0.005052</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>0.005098</td>\n",
       "      <td>0.005041</td>\n",
       "      <td>0.005018</td>\n",
       "      <td>0.005094</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>0.005021</td>\n",
       "      <td>0.005016</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>0.005317</td>\n",
       "      <td>0.005476</td>\n",
       "      <td>0.00568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_0</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.00011</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_0</th>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.004908</td>\n",
       "      <td>0.005478</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>0.056351</td>\n",
       "      <td>0.036521</td>\n",
       "      <td>0.018309</td>\n",
       "      <td>0.010055</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>0.00378</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.006087</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>0.012772</td>\n",
       "      <td>0.006449</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>0.005942</td>\n",
       "      <td>0.005805</td>\n",
       "      <td>0.00594</td>\n",
       "      <td>0.006189</td>\n",
       "      <td>0.105652</td>\n",
       "      <td>0.00582</td>\n",
       "      <td>0.00555</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.005392</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>0.00542</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.005543</td>\n",
       "      <td>0.005438</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>0.005461</td>\n",
       "      <td>0.00535</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.005429</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>0.005407</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>0.005377</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>0.005372</td>\n",
       "      <td>0.005457</td>\n",
       "      <td>0.005377</td>\n",
       "      <td>0.005456</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.005437</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.005244</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>0.005466</td>\n",
       "      <td>0.005328</td>\n",
       "      <td>0.005354</td>\n",
       "      <td>0.005438</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>0.00538</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>0.005503</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.005459</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>0.005395</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.005541</td>\n",
       "      <td>0.005781</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.006339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007075</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.066043</td>\n",
       "      <td>0.047542</td>\n",
       "      <td>0.022941</td>\n",
       "      <td>0.013588</td>\n",
       "      <td>0.008557</td>\n",
       "      <td>0.005674</td>\n",
       "      <td>0.004913</td>\n",
       "      <td>0.008565</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>0.026401</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.007626</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.007748</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.107793</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>0.00539</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.00543</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.00541</td>\n",
       "      <td>0.005483</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.005394</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>0.005443</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.005448</td>\n",
       "      <td>0.00549</td>\n",
       "      <td>0.00537</td>\n",
       "      <td>0.00552</td>\n",
       "      <td>0.00538</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.005431</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>0.00538</td>\n",
       "      <td>0.005465</td>\n",
       "      <td>0.005427</td>\n",
       "      <td>0.005402</td>\n",
       "      <td>0.005358</td>\n",
       "      <td>0.005345</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.005449</td>\n",
       "      <td>0.005417</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.005417</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>0.005429</td>\n",
       "      <td>0.005465</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.005447</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>0.005381</td>\n",
       "      <td>0.005399</td>\n",
       "      <td>0.005342</td>\n",
       "      <td>0.005449</td>\n",
       "      <td>0.005496</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>0.005355</td>\n",
       "      <td>0.005544</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.005827</td>\n",
       "      <td>0.006319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007368</td>\n",
       "      <td>0.008176</td>\n",
       "      <td>0.064095</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>0.018231</td>\n",
       "      <td>0.010947</td>\n",
       "      <td>0.008233</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.023616</td>\n",
       "      <td>0.006927</td>\n",
       "      <td>0.006936</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.007059</td>\n",
       "      <td>0.007105</td>\n",
       "      <td>0.007057</td>\n",
       "      <td>0.107536</td>\n",
       "      <td>0.007065</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.005422</td>\n",
       "      <td>0.005394</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.005505</td>\n",
       "      <td>0.005422</td>\n",
       "      <td>0.005605</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.005476</td>\n",
       "      <td>0.005438</td>\n",
       "      <td>0.005542</td>\n",
       "      <td>0.00558</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.00543</td>\n",
       "      <td>0.005586</td>\n",
       "      <td>0.005588</td>\n",
       "      <td>0.005382</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.005488</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.00545</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.005403</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.00548</td>\n",
       "      <td>0.00558</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.005437</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.005399</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.005414</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>0.005404</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.005394</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>0.005406</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.00548</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.005392</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>0.005478</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.005875</td>\n",
       "      <td>0.006129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007659</td>\n",
       "      <td>0.062268</td>\n",
       "      <td>0.043549</td>\n",
       "      <td>0.021071</td>\n",
       "      <td>0.012337</td>\n",
       "      <td>0.00757</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>0.004166</td>\n",
       "      <td>0.007577</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.019066</td>\n",
       "      <td>0.006697</td>\n",
       "      <td>0.006388</td>\n",
       "      <td>0.006512</td>\n",
       "      <td>0.006551</td>\n",
       "      <td>0.007097</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>0.106682</td>\n",
       "      <td>0.006599</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>0.005809</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.005811</td>\n",
       "      <td>0.005808</td>\n",
       "      <td>0.005908</td>\n",
       "      <td>0.005938</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>0.006038</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.005887</td>\n",
       "      <td>0.005889</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.005893</td>\n",
       "      <td>0.005943</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.005807</td>\n",
       "      <td>0.005978</td>\n",
       "      <td>0.005838</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>0.005795</td>\n",
       "      <td>0.00588</td>\n",
       "      <td>0.005892</td>\n",
       "      <td>0.005716</td>\n",
       "      <td>0.005976</td>\n",
       "      <td>0.005825</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>0.005719</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.005884</td>\n",
       "      <td>0.00584</td>\n",
       "      <td>0.005781</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.005818</td>\n",
       "      <td>0.00587</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>0.005855</td>\n",
       "      <td>0.005766</td>\n",
       "      <td>0.005839</td>\n",
       "      <td>0.005826</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>0.005819</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.005802</td>\n",
       "      <td>0.005823</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.005813</td>\n",
       "      <td>0.005873</td>\n",
       "      <td>0.005876</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0.005711</td>\n",
       "      <td>0.005728</td>\n",
       "      <td>0.005904</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>0.005783</td>\n",
       "      <td>0.005844</td>\n",
       "      <td>0.005915</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.006011</td>\n",
       "      <td>0.006254</td>\n",
       "      <td>0.00636</td>\n",
       "      <td>0.006689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_0</th>\n",
       "      <td>16195.77922</td>\n",
       "      <td>17668.558761</td>\n",
       "      <td>19719.790245</td>\n",
       "      <td>21668.390967</td>\n",
       "      <td>202862.159538</td>\n",
       "      <td>131476.777867</td>\n",
       "      <td>65913.936327</td>\n",
       "      <td>36197.325349</td>\n",
       "      <td>21500.760054</td>\n",
       "      <td>13609.237095</td>\n",
       "      <td>11342.227859</td>\n",
       "      <td>21913.93914</td>\n",
       "      <td>16607.154641</td>\n",
       "      <td>45979.8298</td>\n",
       "      <td>23217.853073</td>\n",
       "      <td>21244.910513</td>\n",
       "      <td>21391.50582</td>\n",
       "      <td>20897.349946</td>\n",
       "      <td>21385.706475</td>\n",
       "      <td>22279.676289</td>\n",
       "      <td>380347.64895</td>\n",
       "      <td>20951.19653</td>\n",
       "      <td>19980.710479</td>\n",
       "      <td>19165.613535</td>\n",
       "      <td>19409.412202</td>\n",
       "      <td>18774.637131</td>\n",
       "      <td>19510.974742</td>\n",
       "      <td>19743.540879</td>\n",
       "      <td>19954.737589</td>\n",
       "      <td>19576.73708</td>\n",
       "      <td>19709.793915</td>\n",
       "      <td>19659.79529</td>\n",
       "      <td>19260.021787</td>\n",
       "      <td>19635.156896</td>\n",
       "      <td>19781.212377</td>\n",
       "      <td>19545.438086</td>\n",
       "      <td>20066.680423</td>\n",
       "      <td>19864.754521</td>\n",
       "      <td>19429.101109</td>\n",
       "      <td>20071.427558</td>\n",
       "      <td>20054.398769</td>\n",
       "      <td>19466.226544</td>\n",
       "      <td>19408.237514</td>\n",
       "      <td>19899.119422</td>\n",
       "      <td>19357.213437</td>\n",
       "      <td>19216.994373</td>\n",
       "      <td>19428.084537</td>\n",
       "      <td>19482.245789</td>\n",
       "      <td>19338.889712</td>\n",
       "      <td>19646.964429</td>\n",
       "      <td>19356.784252</td>\n",
       "      <td>19642.590894</td>\n",
       "      <td>19742.001207</td>\n",
       "      <td>19385.208812</td>\n",
       "      <td>19344.183745</td>\n",
       "      <td>19540.1874</td>\n",
       "      <td>19603.726781</td>\n",
       "      <td>19571.459222</td>\n",
       "      <td>19379.295512</td>\n",
       "      <td>19344.231032</td>\n",
       "      <td>18879.317824</td>\n",
       "      <td>19360.743744</td>\n",
       "      <td>19632.01464</td>\n",
       "      <td>19676.94247</td>\n",
       "      <td>19180.363871</td>\n",
       "      <td>19273.79627</td>\n",
       "      <td>19577.395899</td>\n",
       "      <td>19539.27857</td>\n",
       "      <td>19554.073109</td>\n",
       "      <td>19368.197392</td>\n",
       "      <td>19280.720576</td>\n",
       "      <td>19324.221231</td>\n",
       "      <td>19731.312537</td>\n",
       "      <td>19775.897441</td>\n",
       "      <td>19810.010381</td>\n",
       "      <td>19431.796821</td>\n",
       "      <td>19214.426719</td>\n",
       "      <td>19563.896959</td>\n",
       "      <td>19425.262245</td>\n",
       "      <td>19309.538146</td>\n",
       "      <td>19653.176769</td>\n",
       "      <td>19932.519983</td>\n",
       "      <td>19312.169634</td>\n",
       "      <td>19791.57957</td>\n",
       "      <td>19420.498608</td>\n",
       "      <td>19470.767844</td>\n",
       "      <td>19946.301969</td>\n",
       "      <td>20810.618516</td>\n",
       "      <td>21232.057477</td>\n",
       "      <td>22819.901136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>25468.940519</td>\n",
       "      <td>28527.65535</td>\n",
       "      <td>31199.538263</td>\n",
       "      <td>237753.201148</td>\n",
       "      <td>171150.795772</td>\n",
       "      <td>82587.666717</td>\n",
       "      <td>48917.600616</td>\n",
       "      <td>30805.085856</td>\n",
       "      <td>20427.345729</td>\n",
       "      <td>17685.400324</td>\n",
       "      <td>30832.795448</td>\n",
       "      <td>19027.674647</td>\n",
       "      <td>95043.394452</td>\n",
       "      <td>23181.478029</td>\n",
       "      <td>27001.2951</td>\n",
       "      <td>27453.434216</td>\n",
       "      <td>28421.287345</td>\n",
       "      <td>27894.212444</td>\n",
       "      <td>28081.37419</td>\n",
       "      <td>388054.628298</td>\n",
       "      <td>28420.579544</td>\n",
       "      <td>20131.056243</td>\n",
       "      <td>19266.66597</td>\n",
       "      <td>19402.612843</td>\n",
       "      <td>19070.647317</td>\n",
       "      <td>19548.20066</td>\n",
       "      <td>19796.753943</td>\n",
       "      <td>19875.208052</td>\n",
       "      <td>19622.485468</td>\n",
       "      <td>19934.468602</td>\n",
       "      <td>19874.875654</td>\n",
       "      <td>19995.542592</td>\n",
       "      <td>19937.843552</td>\n",
       "      <td>19477.738854</td>\n",
       "      <td>19739.917487</td>\n",
       "      <td>19775.650822</td>\n",
       "      <td>19802.264827</td>\n",
       "      <td>19418.099808</td>\n",
       "      <td>19800.535796</td>\n",
       "      <td>19792.426539</td>\n",
       "      <td>19473.943975</td>\n",
       "      <td>19485.442064</td>\n",
       "      <td>19593.949878</td>\n",
       "      <td>20032.110287</td>\n",
       "      <td>19458.184584</td>\n",
       "      <td>19611.249515</td>\n",
       "      <td>19763.311386</td>\n",
       "      <td>19332.564397</td>\n",
       "      <td>19873.58322</td>\n",
       "      <td>19369.401268</td>\n",
       "      <td>19635.139756</td>\n",
       "      <td>19552.473979</td>\n",
       "      <td>19664.751299</td>\n",
       "      <td>19368.892861</td>\n",
       "      <td>19673.500442</td>\n",
       "      <td>19538.016199</td>\n",
       "      <td>19446.50456</td>\n",
       "      <td>19288.685838</td>\n",
       "      <td>19243.742947</td>\n",
       "      <td>19050.339474</td>\n",
       "      <td>19283.922536</td>\n",
       "      <td>19616.766383</td>\n",
       "      <td>19502.288836</td>\n",
       "      <td>19856.752377</td>\n",
       "      <td>19501.893728</td>\n",
       "      <td>19539.781334</td>\n",
       "      <td>19545.829242</td>\n",
       "      <td>19674.885567</td>\n",
       "      <td>19431.327363</td>\n",
       "      <td>19285.441213</td>\n",
       "      <td>19608.47229</td>\n",
       "      <td>19698.507808</td>\n",
       "      <td>19731.83366</td>\n",
       "      <td>19399.541191</td>\n",
       "      <td>19471.061498</td>\n",
       "      <td>19805.983148</td>\n",
       "      <td>19217.148449</td>\n",
       "      <td>19650.38001</td>\n",
       "      <td>19373.245152</td>\n",
       "      <td>19436.980272</td>\n",
       "      <td>19231.370819</td>\n",
       "      <td>19616.363117</td>\n",
       "      <td>19787.304955</td>\n",
       "      <td>19488.021992</td>\n",
       "      <td>19279.221639</td>\n",
       "      <td>19959.656226</td>\n",
       "      <td>21175.184379</td>\n",
       "      <td>20978.666577</td>\n",
       "      <td>22750.185158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26525.19543</td>\n",
       "      <td>29432.232638</td>\n",
       "      <td>230742.699366</td>\n",
       "      <td>163334.776383</td>\n",
       "      <td>65629.995914</td>\n",
       "      <td>39410.051212</td>\n",
       "      <td>29637.863397</td>\n",
       "      <td>19474.082681</td>\n",
       "      <td>16529.155674</td>\n",
       "      <td>30001.084447</td>\n",
       "      <td>18976.248512</td>\n",
       "      <td>85017.263054</td>\n",
       "      <td>24938.418016</td>\n",
       "      <td>24971.072064</td>\n",
       "      <td>25203.596025</td>\n",
       "      <td>25414.024573</td>\n",
       "      <td>25578.007751</td>\n",
       "      <td>25403.402722</td>\n",
       "      <td>387128.374374</td>\n",
       "      <td>25433.114077</td>\n",
       "      <td>22421.505866</td>\n",
       "      <td>19518.685871</td>\n",
       "      <td>19417.424063</td>\n",
       "      <td>18842.209127</td>\n",
       "      <td>19818.57431</td>\n",
       "      <td>19518.158547</td>\n",
       "      <td>20178.213571</td>\n",
       "      <td>19782.550376</td>\n",
       "      <td>19714.900987</td>\n",
       "      <td>19578.297702</td>\n",
       "      <td>19949.876927</td>\n",
       "      <td>20087.509267</td>\n",
       "      <td>19590.509753</td>\n",
       "      <td>19548.685151</td>\n",
       "      <td>20108.210403</td>\n",
       "      <td>20117.896841</td>\n",
       "      <td>19376.997128</td>\n",
       "      <td>19793.391684</td>\n",
       "      <td>19178.647159</td>\n",
       "      <td>19758.447455</td>\n",
       "      <td>19599.244853</td>\n",
       "      <td>19619.519138</td>\n",
       "      <td>19770.177135</td>\n",
       "      <td>19327.673077</td>\n",
       "      <td>19449.798175</td>\n",
       "      <td>19780.777175</td>\n",
       "      <td>19191.822488</td>\n",
       "      <td>19726.637947</td>\n",
       "      <td>20088.689768</td>\n",
       "      <td>19494.728512</td>\n",
       "      <td>19590.352354</td>\n",
       "      <td>19572.514176</td>\n",
       "      <td>19334.277519</td>\n",
       "      <td>19494.502688</td>\n",
       "      <td>19168.708825</td>\n",
       "      <td>19439.31524</td>\n",
       "      <td>19437.420432</td>\n",
       "      <td>19590.965548</td>\n",
       "      <td>18998.701454</td>\n",
       "      <td>19489.292961</td>\n",
       "      <td>19603.913342</td>\n",
       "      <td>19566.135723</td>\n",
       "      <td>19869.082842</td>\n",
       "      <td>19456.16731</td>\n",
       "      <td>19342.955539</td>\n",
       "      <td>19597.151085</td>\n",
       "      <td>19561.48776</td>\n",
       "      <td>19470.194454</td>\n",
       "      <td>19493.519826</td>\n",
       "      <td>19377.659263</td>\n",
       "      <td>19419.411241</td>\n",
       "      <td>19725.122126</td>\n",
       "      <td>19460.265624</td>\n",
       "      <td>19601.278114</td>\n",
       "      <td>19670.382157</td>\n",
       "      <td>18972.36206</td>\n",
       "      <td>19628.091002</td>\n",
       "      <td>19727.307429</td>\n",
       "      <td>19508.364726</td>\n",
       "      <td>19284.058732</td>\n",
       "      <td>19432.082105</td>\n",
       "      <td>19801.364976</td>\n",
       "      <td>19411.705308</td>\n",
       "      <td>19325.854143</td>\n",
       "      <td>19719.588713</td>\n",
       "      <td>20453.258785</td>\n",
       "      <td>21149.179568</td>\n",
       "      <td>22065.413117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27572.030439</td>\n",
       "      <td>224163.410843</td>\n",
       "      <td>156776.837365</td>\n",
       "      <td>75855.999091</td>\n",
       "      <td>44413.632572</td>\n",
       "      <td>27251.885283</td>\n",
       "      <td>17554.387104</td>\n",
       "      <td>14997.785742</td>\n",
       "      <td>27278.569938</td>\n",
       "      <td>18128.535561</td>\n",
       "      <td>68637.373006</td>\n",
       "      <td>24107.68845</td>\n",
       "      <td>22997.048378</td>\n",
       "      <td>23444.58517</td>\n",
       "      <td>23582.72756</td>\n",
       "      <td>25548.639657</td>\n",
       "      <td>23949.676155</td>\n",
       "      <td>384053.444398</td>\n",
       "      <td>23755.751237</td>\n",
       "      <td>22002.600855</td>\n",
       "      <td>20913.404418</td>\n",
       "      <td>20794.865417</td>\n",
       "      <td>20919.575607</td>\n",
       "      <td>20907.442853</td>\n",
       "      <td>21267.838761</td>\n",
       "      <td>21377.273819</td>\n",
       "      <td>21553.055713</td>\n",
       "      <td>21737.608609</td>\n",
       "      <td>21139.736929</td>\n",
       "      <td>21252.106258</td>\n",
       "      <td>21194.755485</td>\n",
       "      <td>21199.889247</td>\n",
       "      <td>21101.101525</td>\n",
       "      <td>21214.504404</td>\n",
       "      <td>21395.770807</td>\n",
       "      <td>21102.153165</td>\n",
       "      <td>20906.609104</td>\n",
       "      <td>21521.366357</td>\n",
       "      <td>21016.347588</td>\n",
       "      <td>20992.245094</td>\n",
       "      <td>20860.532399</td>\n",
       "      <td>21167.785305</td>\n",
       "      <td>21209.627033</td>\n",
       "      <td>20578.749194</td>\n",
       "      <td>21513.306307</td>\n",
       "      <td>20969.083323</td>\n",
       "      <td>20982.174943</td>\n",
       "      <td>20588.165683</td>\n",
       "      <td>21048.509722</td>\n",
       "      <td>21181.491607</td>\n",
       "      <td>21023.653755</td>\n",
       "      <td>20810.615515</td>\n",
       "      <td>20880.357309</td>\n",
       "      <td>20944.378291</td>\n",
       "      <td>21130.998758</td>\n",
       "      <td>20719.873579</td>\n",
       "      <td>21078.598885</td>\n",
       "      <td>20756.927673</td>\n",
       "      <td>21019.340278</td>\n",
       "      <td>20974.836269</td>\n",
       "      <td>21033.597667</td>\n",
       "      <td>21102.680287</td>\n",
       "      <td>21100.459344</td>\n",
       "      <td>20995.634972</td>\n",
       "      <td>20949.454166</td>\n",
       "      <td>20786.538548</td>\n",
       "      <td>20886.86949</td>\n",
       "      <td>20961.978873</td>\n",
       "      <td>21121.256891</td>\n",
       "      <td>21113.829712</td>\n",
       "      <td>20926.187117</td>\n",
       "      <td>21144.066239</td>\n",
       "      <td>21154.448374</td>\n",
       "      <td>20965.132739</td>\n",
       "      <td>20558.850968</td>\n",
       "      <td>20620.73492</td>\n",
       "      <td>21253.077369</td>\n",
       "      <td>20752.05409</td>\n",
       "      <td>20819.139469</td>\n",
       "      <td>21038.524638</td>\n",
       "      <td>21292.415142</td>\n",
       "      <td>20794.213276</td>\n",
       "      <td>20878.352506</td>\n",
       "      <td>21637.825035</td>\n",
       "      <td>22512.64806</td>\n",
       "      <td>22896.498879</td>\n",
       "      <td>24081.494303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_avg</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_avg</th>\n",
       "      <td>696.175445</td>\n",
       "      <td>662.784411</td>\n",
       "      <td>560.900069</td>\n",
       "      <td>726.089579</td>\n",
       "      <td>552.633632</td>\n",
       "      <td>561.619474</td>\n",
       "      <td>684.188067</td>\n",
       "      <td>629.605872</td>\n",
       "      <td>650.462376</td>\n",
       "      <td>678.557621</td>\n",
       "      <td>750.966714</td>\n",
       "      <td>633.38496</td>\n",
       "      <td>576.635783</td>\n",
       "      <td>485.282421</td>\n",
       "      <td>596.515287</td>\n",
       "      <td>248.97514</td>\n",
       "      <td>570.969436</td>\n",
       "      <td>359.762385</td>\n",
       "      <td>165.805681</td>\n",
       "      <td>381.99481</td>\n",
       "      <td>574.005568</td>\n",
       "      <td>836.666102</td>\n",
       "      <td>697.486571</td>\n",
       "      <td>995.399846</td>\n",
       "      <td>141.500592</td>\n",
       "      <td>595.223181</td>\n",
       "      <td>240.015809</td>\n",
       "      <td>930.285971</td>\n",
       "      <td>818.073557</td>\n",
       "      <td>680.710089</td>\n",
       "      <td>630.786332</td>\n",
       "      <td>584.672502</td>\n",
       "      <td>474.50611</td>\n",
       "      <td>666.91485</td>\n",
       "      <td>1044.133286</td>\n",
       "      <td>613.075184</td>\n",
       "      <td>125.703947</td>\n",
       "      <td>554.297154</td>\n",
       "      <td>746.865359</td>\n",
       "      <td>178.077688</td>\n",
       "      <td>530.26023</td>\n",
       "      <td>828.379786</td>\n",
       "      <td>1128.825755</td>\n",
       "      <td>183.379652</td>\n",
       "      <td>585.733726</td>\n",
       "      <td>597.075869</td>\n",
       "      <td>1426.644534</td>\n",
       "      <td>609.430123</td>\n",
       "      <td>1230.096169</td>\n",
       "      <td>752.683404</td>\n",
       "      <td>631.860825</td>\n",
       "      <td>1124.918904</td>\n",
       "      <td>107.580307</td>\n",
       "      <td>964.896948</td>\n",
       "      <td>845.433359</td>\n",
       "      <td>932.529908</td>\n",
       "      <td>828.393201</td>\n",
       "      <td>542.674179</td>\n",
       "      <td>8418.778745</td>\n",
       "      <td>514.075478</td>\n",
       "      <td>614.212687</td>\n",
       "      <td>750.69982</td>\n",
       "      <td>1677.981438</td>\n",
       "      <td>1200.855005</td>\n",
       "      <td>1023.46107</td>\n",
       "      <td>641.739565</td>\n",
       "      <td>1551.207321</td>\n",
       "      <td>1448.743478</td>\n",
       "      <td>1485.262123</td>\n",
       "      <td>1274.904466</td>\n",
       "      <td>562.538789</td>\n",
       "      <td>795.553393</td>\n",
       "      <td>708.789737</td>\n",
       "      <td>196.533552</td>\n",
       "      <td>940.007732</td>\n",
       "      <td>659.73285</td>\n",
       "      <td>881.419378</td>\n",
       "      <td>2203.211476</td>\n",
       "      <td>1662.575306</td>\n",
       "      <td>646.021091</td>\n",
       "      <td>1518.139929</td>\n",
       "      <td>708.204415</td>\n",
       "      <td>772.734927</td>\n",
       "      <td>143.466911</td>\n",
       "      <td>1234.326235</td>\n",
       "      <td>1127.987867</td>\n",
       "      <td>1259.214409</td>\n",
       "      <td>390.099748</td>\n",
       "      <td>534.115213</td>\n",
       "      <td>685.047901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_avg</th>\n",
       "      <td>0.701849</td>\n",
       "      <td>0.678551</td>\n",
       "      <td>0.667915</td>\n",
       "      <td>0.665473</td>\n",
       "      <td>0.656015</td>\n",
       "      <td>0.661594</td>\n",
       "      <td>0.663938</td>\n",
       "      <td>0.66558</td>\n",
       "      <td>0.666628</td>\n",
       "      <td>0.661934</td>\n",
       "      <td>0.662724</td>\n",
       "      <td>0.663733</td>\n",
       "      <td>0.916395</td>\n",
       "      <td>0.979554</td>\n",
       "      <td>0.96273</td>\n",
       "      <td>0.643025</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.661822</td>\n",
       "      <td>0.667078</td>\n",
       "      <td>0.663048</td>\n",
       "      <td>0.661945</td>\n",
       "      <td>0.666487</td>\n",
       "      <td>0.642038</td>\n",
       "      <td>0.635867</td>\n",
       "      <td>0.641261</td>\n",
       "      <td>0.640277</td>\n",
       "      <td>0.645682</td>\n",
       "      <td>0.677652</td>\n",
       "      <td>0.676869</td>\n",
       "      <td>0.677398</td>\n",
       "      <td>0.67482</td>\n",
       "      <td>0.673987</td>\n",
       "      <td>0.677596</td>\n",
       "      <td>0.677137</td>\n",
       "      <td>0.677181</td>\n",
       "      <td>0.67413</td>\n",
       "      <td>0.676264</td>\n",
       "      <td>0.67676</td>\n",
       "      <td>0.675836</td>\n",
       "      <td>0.675833</td>\n",
       "      <td>0.678728</td>\n",
       "      <td>0.67486</td>\n",
       "      <td>0.68033</td>\n",
       "      <td>0.673824</td>\n",
       "      <td>0.676639</td>\n",
       "      <td>0.676245</td>\n",
       "      <td>0.677293</td>\n",
       "      <td>0.676872</td>\n",
       "      <td>0.676701</td>\n",
       "      <td>0.675662</td>\n",
       "      <td>0.678458</td>\n",
       "      <td>0.68434</td>\n",
       "      <td>0.680158</td>\n",
       "      <td>0.673759</td>\n",
       "      <td>0.674298</td>\n",
       "      <td>0.674014</td>\n",
       "      <td>0.677866</td>\n",
       "      <td>0.639024</td>\n",
       "      <td>0.648004</td>\n",
       "      <td>0.646411</td>\n",
       "      <td>0.641967</td>\n",
       "      <td>0.666498</td>\n",
       "      <td>0.665195</td>\n",
       "      <td>0.665195</td>\n",
       "      <td>0.66469</td>\n",
       "      <td>0.664462</td>\n",
       "      <td>0.6631</td>\n",
       "      <td>0.665169</td>\n",
       "      <td>0.665225</td>\n",
       "      <td>0.663432</td>\n",
       "      <td>0.664345</td>\n",
       "      <td>0.663654</td>\n",
       "      <td>0.663628</td>\n",
       "      <td>0.666584</td>\n",
       "      <td>0.665578</td>\n",
       "      <td>0.666098</td>\n",
       "      <td>0.664872</td>\n",
       "      <td>0.665559</td>\n",
       "      <td>0.66279</td>\n",
       "      <td>0.662914</td>\n",
       "      <td>0.665464</td>\n",
       "      <td>0.663001</td>\n",
       "      <td>0.664455</td>\n",
       "      <td>0.664685</td>\n",
       "      <td>0.667894</td>\n",
       "      <td>0.664632</td>\n",
       "      <td>0.664354</td>\n",
       "      <td>0.664819</td>\n",
       "      <td>0.665937</td>\n",
       "      <td>0.669801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_total</th>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>0.025233</td>\n",
       "      <td>0.012236</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.002276</td>\n",
       "      <td>0.001837</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.014701</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.003388</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>0.07694</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.00312</td>\n",
       "      <td>0.003128</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.00314</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.002895</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.00268</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.002875</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.00268</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.003897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_total</th>\n",
       "      <td>0.003779</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>0.017862</td>\n",
       "      <td>0.026681</td>\n",
       "      <td>0.207629</td>\n",
       "      <td>0.147622</td>\n",
       "      <td>0.068254</td>\n",
       "      <td>0.040386</td>\n",
       "      <td>0.026493</td>\n",
       "      <td>0.017452</td>\n",
       "      <td>0.014974</td>\n",
       "      <td>0.026718</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>0.067042</td>\n",
       "      <td>0.021821</td>\n",
       "      <td>0.023035</td>\n",
       "      <td>0.023758</td>\n",
       "      <td>0.023654</td>\n",
       "      <td>0.024483</td>\n",
       "      <td>0.024152</td>\n",
       "      <td>0.350275</td>\n",
       "      <td>0.023799</td>\n",
       "      <td>0.02048</td>\n",
       "      <td>0.019082</td>\n",
       "      <td>0.01901</td>\n",
       "      <td>0.018871</td>\n",
       "      <td>0.019023</td>\n",
       "      <td>0.019471</td>\n",
       "      <td>0.019529</td>\n",
       "      <td>0.019418</td>\n",
       "      <td>0.019424</td>\n",
       "      <td>0.019407</td>\n",
       "      <td>0.01934</td>\n",
       "      <td>0.01934</td>\n",
       "      <td>0.019476</td>\n",
       "      <td>0.019473</td>\n",
       "      <td>0.019409</td>\n",
       "      <td>0.019406</td>\n",
       "      <td>0.019202</td>\n",
       "      <td>0.019364</td>\n",
       "      <td>0.019419</td>\n",
       "      <td>0.019331</td>\n",
       "      <td>0.01935</td>\n",
       "      <td>0.019335</td>\n",
       "      <td>0.019402</td>\n",
       "      <td>0.019153</td>\n",
       "      <td>0.019325</td>\n",
       "      <td>0.019215</td>\n",
       "      <td>0.01906</td>\n",
       "      <td>0.01937</td>\n",
       "      <td>0.019145</td>\n",
       "      <td>0.019339</td>\n",
       "      <td>0.019341</td>\n",
       "      <td>0.019328</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>0.019412</td>\n",
       "      <td>0.019263</td>\n",
       "      <td>0.018977</td>\n",
       "      <td>0.018983</td>\n",
       "      <td>0.018902</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>0.019227</td>\n",
       "      <td>0.019343</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.019264</td>\n",
       "      <td>0.019155</td>\n",
       "      <td>0.01933</td>\n",
       "      <td>0.019281</td>\n",
       "      <td>0.019313</td>\n",
       "      <td>0.01934</td>\n",
       "      <td>0.019118</td>\n",
       "      <td>0.019204</td>\n",
       "      <td>0.019342</td>\n",
       "      <td>0.019341</td>\n",
       "      <td>0.019185</td>\n",
       "      <td>0.019223</td>\n",
       "      <td>0.019287</td>\n",
       "      <td>0.019089</td>\n",
       "      <td>0.019325</td>\n",
       "      <td>0.019196</td>\n",
       "      <td>0.019312</td>\n",
       "      <td>0.019087</td>\n",
       "      <td>0.019164</td>\n",
       "      <td>0.019385</td>\n",
       "      <td>0.01928</td>\n",
       "      <td>0.019101</td>\n",
       "      <td>0.019622</td>\n",
       "      <td>0.020156</td>\n",
       "      <td>0.020624</td>\n",
       "      <td>0.02156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_total</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_0</th>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.00187</td>\n",
       "      <td>0.003019</td>\n",
       "      <td>0.002293</td>\n",
       "      <td>0.025159</td>\n",
       "      <td>0.01659</td>\n",
       "      <td>0.006945</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.002275</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.001918</td>\n",
       "      <td>0.010057</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.041064</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.00213</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.002251</td>\n",
       "      <td>0.002135</td>\n",
       "      <td>0.002281</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.002123</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.002124</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.002277</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.002179</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002231</td>\n",
       "      <td>0.00201</td>\n",
       "      <td>0.002224</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.00207</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.00204</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.00221</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.002249</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>0.002423</td>\n",
       "      <td>0.002415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>0.021467</td>\n",
       "      <td>0.017284</td>\n",
       "      <td>0.006975</td>\n",
       "      <td>0.005176</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.00144</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.002248</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.002496</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.002972</td>\n",
       "      <td>0.04064</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>0.002116</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.002245</td>\n",
       "      <td>0.002129</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>0.00206</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.002207</td>\n",
       "      <td>0.00212</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.00205</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.002225</td>\n",
       "      <td>0.00205</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.00203</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.002217</td>\n",
       "      <td>0.00207</td>\n",
       "      <td>0.00206</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.002209</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>0.002247</td>\n",
       "      <td>0.002335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>0.003302</td>\n",
       "      <td>0.023721</td>\n",
       "      <td>0.013913</td>\n",
       "      <td>0.008739</td>\n",
       "      <td>0.00417</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.007263</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.002689</td>\n",
       "      <td>0.002704</td>\n",
       "      <td>0.002358</td>\n",
       "      <td>0.040248</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.00208</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.002128</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.00205</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.002091</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>0.002092</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.002063</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.002057</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.00204</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.002214</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>0.00206</td>\n",
       "      <td>0.002082</td>\n",
       "      <td>0.00207</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.00205</td>\n",
       "      <td>0.00208</td>\n",
       "      <td>0.002203</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.002094</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.00204</td>\n",
       "      <td>0.002111</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.002238</td>\n",
       "      <td>0.002548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002918</td>\n",
       "      <td>0.024417</td>\n",
       "      <td>0.018111</td>\n",
       "      <td>0.008027</td>\n",
       "      <td>0.00383</td>\n",
       "      <td>0.00326</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.001871</td>\n",
       "      <td>0.003263</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>0.004866</td>\n",
       "      <td>0.002453</td>\n",
       "      <td>0.002434</td>\n",
       "      <td>0.002481</td>\n",
       "      <td>0.002211</td>\n",
       "      <td>0.002952</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.040966</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>0.002114</td>\n",
       "      <td>0.002213</td>\n",
       "      <td>0.002201</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.002212</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.002086</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.00211</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.002089</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.002095</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.002061</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.002073</td>\n",
       "      <td>0.00224</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>0.002093</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.002241</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.002202</td>\n",
       "      <td>0.00221</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.002236</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.002226</td>\n",
       "      <td>0.002101</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.002222</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>0.002069</td>\n",
       "      <td>0.00205</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>0.002075</td>\n",
       "      <td>0.002055</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.002096</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.002079</td>\n",
       "      <td>0.002088</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>0.002109</td>\n",
       "      <td>0.002076</td>\n",
       "      <td>0.002253</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.00206</td>\n",
       "      <td>0.00229</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.00222</td>\n",
       "      <td>0.002407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_generated_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>14722</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_config_decoding_mode</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            0   \\\n",
       "config_name                                                                    num_processes_1   \n",
       "experiment_id                                                                              109   \n",
       "date_time                                                        April 11, 2025 at 01:21:09 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                1   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.004499   \n",
       "total_energy_joules                                                                16195.77922   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      1.011622   \n",
       "joules_per_token                                                                      0.988512   \n",
       "flops_per_joule                                                              1046567180.461082   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.226318   \n",
       "average_latency_ms_per_batch                                                       2903.289808   \n",
       "throughput_queries_per_sec                                                             5.51099   \n",
       "throughput_tokens_per_sec                                                           705.406671   \n",
       "cpu_usage_percent                                                                          3.8   \n",
       "cpu_memory_usage_bytes                                                              2013147136   \n",
       "gpu_utilization_percent_0                                                                  2.0   \n",
       "gpu_utilization_percent_1                                                                 67.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                 89.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  12016680960   \n",
       "gpu_max_memory_reserved_bytes                                                      12016680960   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                        NaN   \n",
       "cpu_power_process_2                                                                        NaN   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                 696.175445   \n",
       "gpu_power_process_1                                                                        NaN   \n",
       "gpu_power_process_2                                                                        NaN   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   0.701849   \n",
       "ram_power_process_1                                                                        NaN   \n",
       "ram_power_process_2                                                                        NaN   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                  0.000716   \n",
       "cpu_energy_process_1                                                                       NaN   \n",
       "cpu_energy_process_2                                                                       NaN   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                  0.003779   \n",
       "gpu_energy_process_1                                                                       NaN   \n",
       "gpu_energy_process_2                                                                       NaN   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                       NaN   \n",
       "ram_energy_process_2                                                                       NaN   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.004499   \n",
       "total_energy_kwh_process_1                                                                 NaN   \n",
       "total_energy_kwh_process_2                                                                 NaN   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                      16195.77922   \n",
       "total_energy_joules_process_1                                                              NaN   \n",
       "total_energy_joules_process_2                                                              NaN   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       696.175445   \n",
       "ram_power_avg                                                                         0.701849   \n",
       "cpu_energy_total                                                                      0.000716   \n",
       "gpu_energy_total                                                                      0.003779   \n",
       "ram_energy_total                                                                      0.000004   \n",
       "per-process_emissions_0                                                               0.001714   \n",
       "per-process_emissions_1                                                                    NaN   \n",
       "per-process_emissions_2                                                                    NaN   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            1   \\\n",
       "config_name                                                                    num_processes_2   \n",
       "experiment_id                                                                              110   \n",
       "date_time                                                        April 11, 2025 at 01:22:13 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                2   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.011983   \n",
       "total_energy_joules                                                               43137.499279   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.379809   \n",
       "joules_per_token                                                                      2.632904   \n",
       "flops_per_joule                                                               392928919.763817   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.264916   \n",
       "average_latency_ms_per_batch                                                       2908.114499   \n",
       "throughput_queries_per_sec                                                            5.501847   \n",
       "throughput_tokens_per_sec                                                           704.236371   \n",
       "cpu_usage_percent                                                                          4.4   \n",
       "cpu_memory_usage_bytes                                                              2011279360   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                        NaN   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                 473.285169   \n",
       "gpu_power_process_1                                                                 852.283653   \n",
       "gpu_power_process_2                                                                        NaN   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                    0.70122   \n",
       "ram_power_process_1                                                                   0.655882   \n",
       "ram_power_process_2                                                                        NaN   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                  0.000716   \n",
       "cpu_energy_process_1                                                                  0.001084   \n",
       "cpu_energy_process_2                                                                       NaN   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                  0.004188   \n",
       "gpu_energy_process_1                                                                  0.005985   \n",
       "gpu_energy_process_2                                                                       NaN   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000006   \n",
       "ram_energy_process_2                                                                       NaN   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.004908   \n",
       "total_energy_kwh_process_1                                                            0.007075   \n",
       "total_energy_kwh_process_2                                                                 NaN   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                     17668.558761   \n",
       "total_energy_joules_process_1                                                     25468.940519   \n",
       "total_energy_joules_process_2                                                              NaN   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       662.784411   \n",
       "ram_power_avg                                                                         0.678551   \n",
       "cpu_energy_total                                                                        0.0018   \n",
       "gpu_energy_total                                                                      0.010173   \n",
       "ram_energy_total                                                                      0.000009   \n",
       "per-process_emissions_0                                                                0.00187   \n",
       "per-process_emissions_1                                                               0.002695   \n",
       "per-process_emissions_2                                                                    NaN   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            2   \\\n",
       "config_name                                                                    num_processes_3   \n",
       "experiment_id                                                                              111   \n",
       "date_time                                                        April 11, 2025 at 01:23:18 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                3   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                       0.02077   \n",
       "total_energy_joules                                                               74772.641025   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.219118   \n",
       "joules_per_token                                                                       4.56376   \n",
       "flops_per_joule                                                                226686803.63326   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.683534   \n",
       "average_latency_ms_per_batch                                                       2960.441788   \n",
       "throughput_queries_per_sec                                                            5.404599   \n",
       "throughput_tokens_per_sec                                                           691.788641   \n",
       "cpu_usage_percent                                                                          4.7   \n",
       "cpu_memory_usage_bytes                                                              2011983872   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                 748.448174   \n",
       "gpu_power_process_1                                                                        0.0   \n",
       "gpu_power_process_2                                                                 934.252033   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   0.701178   \n",
       "ram_power_process_1                                                                   0.650575   \n",
       "ram_power_process_2                                                                   0.651993   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                  0.000731   \n",
       "cpu_energy_process_1                                                                  0.001142   \n",
       "cpu_energy_process_2                                                                   0.00102   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                  0.004743   \n",
       "gpu_energy_process_1                                                                  0.006776   \n",
       "gpu_energy_process_2                                                                  0.006343   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000006   \n",
       "ram_energy_process_2                                                                  0.000005   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.005478   \n",
       "total_energy_kwh_process_1                                                            0.007924   \n",
       "total_energy_kwh_process_2                                                            0.007368   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                     19719.790245   \n",
       "total_energy_joules_process_1                                                      28527.65535   \n",
       "total_energy_joules_process_2                                                      26525.19543   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       560.900069   \n",
       "ram_power_avg                                                                         0.667915   \n",
       "cpu_energy_total                                                                      0.002893   \n",
       "gpu_energy_total                                                                      0.017862   \n",
       "ram_energy_total                                                                      0.000015   \n",
       "per-process_emissions_0                                                               0.003019   \n",
       "per-process_emissions_1                                                               0.002087   \n",
       "per-process_emissions_2                                                               0.002807   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            3   \\\n",
       "config_name                                                                    num_processes_4   \n",
       "experiment_id                                                                              112   \n",
       "date_time                                                        April 11, 2025 at 01:24:25 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                       0.03052   \n",
       "total_energy_joules                                                              109872.192307   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.149119   \n",
       "joules_per_token                                                                      6.706066   \n",
       "flops_per_joule                                                               154269889.744024   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.531789   \n",
       "average_latency_ms_per_batch                                                       2941.473608   \n",
       "throughput_queries_per_sec                                                             5.43945   \n",
       "throughput_tokens_per_sec                                                            696.24966   \n",
       "cpu_usage_percent                                                                          4.7   \n",
       "cpu_memory_usage_bytes                                                              2012934144   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 840.551156   \n",
       "gpu_power_process_1                                                                  770.76088   \n",
       "gpu_power_process_2                                                                 590.523284   \n",
       "gpu_power_process_3                                                                 702.522995   \n",
       "ram_power_process_0                                                                   0.701102   \n",
       "ram_power_process_1                                                                   0.651967   \n",
       "ram_power_process_2                                                                   0.652677   \n",
       "ram_power_process_3                                                                   0.656146   \n",
       "cpu_energy_process_0                                                                  0.000728   \n",
       "cpu_energy_process_1                                                                  0.001116   \n",
       "cpu_energy_process_2                                                                  0.001028   \n",
       "cpu_energy_process_3                                                                  0.000947   \n",
       "gpu_energy_process_0                                                                  0.005287   \n",
       "gpu_energy_process_1                                                                  0.007545   \n",
       "gpu_energy_process_2                                                                  0.007143   \n",
       "gpu_energy_process_3                                                                  0.006707   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000006   \n",
       "ram_energy_process_2                                                                  0.000005   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.006019   \n",
       "total_energy_kwh_process_1                                                            0.008667   \n",
       "total_energy_kwh_process_2                                                            0.008176   \n",
       "total_energy_kwh_process_3                                                            0.007659   \n",
       "total_energy_joules_process_0                                                     21668.390967   \n",
       "total_energy_joules_process_1                                                     31199.538263   \n",
       "total_energy_joules_process_2                                                     29432.232638   \n",
       "total_energy_joules_process_3                                                     27572.030439   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       726.089579   \n",
       "ram_power_avg                                                                         0.665473   \n",
       "cpu_energy_total                                                                      0.003819   \n",
       "gpu_energy_total                                                                      0.026681   \n",
       "ram_energy_total                                                                       0.00002   \n",
       "per-process_emissions_0                                                               0.002293   \n",
       "per-process_emissions_1                                                               0.003115   \n",
       "per-process_emissions_2                                                               0.003302   \n",
       "per-process_emissions_3                                                               0.002918   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            4   \\\n",
       "config_name                                                                         batching_1   \n",
       "experiment_id                                                                              113   \n",
       "date_time                                                        April 11, 2025 at 01:30:52 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                  1   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.248756   \n",
       "total_energy_joules                                                              895521.470895   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                       0.01644   \n",
       "joules_per_token                                                                     60.828792   \n",
       "flops_per_joule                                                                18927486.993933   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                            300.517251   \n",
       "average_latency_ms_per_batch                                                       2347.791025   \n",
       "throughput_queries_per_sec                                                            0.425932   \n",
       "throughput_tokens_per_sec                                                            48.988868   \n",
       "cpu_usage_percent                                                                          6.8   \n",
       "cpu_memory_usage_bytes                                                              1982603264   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818202112   \n",
       "gpu_max_memory_allocated_bytes                                                      8818202112   \n",
       "gpu_current_memory_reserved_bytes                                                  13214154752   \n",
       "gpu_max_memory_reserved_bytes                                                      13214154752   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 627.691201   \n",
       "gpu_power_process_1                                                                 587.868011   \n",
       "gpu_power_process_2                                                                 530.446613   \n",
       "gpu_power_process_3                                                                 464.528704   \n",
       "ram_power_process_0                                                                   0.690853   \n",
       "ram_power_process_1                                                                   0.645085   \n",
       "ram_power_process_2                                                                   0.644468   \n",
       "ram_power_process_3                                                                   0.643654   \n",
       "cpu_energy_process_0                                                                  0.009208   \n",
       "cpu_energy_process_1                                                                  0.010928   \n",
       "cpu_energy_process_2                                                                  0.010551   \n",
       "cpu_energy_process_3                                                                  0.010234   \n",
       "gpu_energy_process_0                                                                  0.047094   \n",
       "gpu_energy_process_1                                                                  0.055061   \n",
       "gpu_energy_process_2                                                                  0.053492   \n",
       "gpu_energy_process_3                                                                  0.051983   \n",
       "ram_energy_process_0                                                                  0.000048   \n",
       "ram_energy_process_1                                                                  0.000054   \n",
       "ram_energy_process_2                                                                  0.000052   \n",
       "ram_energy_process_3                                                                   0.00005   \n",
       "total_energy_kwh_process_0                                                            0.056351   \n",
       "total_energy_kwh_process_1                                                            0.066043   \n",
       "total_energy_kwh_process_2                                                            0.064095   \n",
       "total_energy_kwh_process_3                                                            0.062268   \n",
       "total_energy_joules_process_0                                                    202862.159538   \n",
       "total_energy_joules_process_1                                                    237753.201148   \n",
       "total_energy_joules_process_2                                                    230742.699366   \n",
       "total_energy_joules_process_3                                                    224163.410843   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       552.633632   \n",
       "ram_power_avg                                                                         0.656015   \n",
       "cpu_energy_total                                                                      0.040921   \n",
       "gpu_energy_total                                                                      0.207629   \n",
       "ram_energy_total                                                                      0.000206   \n",
       "per-process_emissions_0                                                               0.025159   \n",
       "per-process_emissions_1                                                               0.021467   \n",
       "per-process_emissions_2                                                               0.023721   \n",
       "per-process_emissions_3                                                               0.024417   \n",
       "total_generated_tokens                                                                   14722   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            5   \\\n",
       "config_name                                                                         batching_2   \n",
       "experiment_id                                                                              114   \n",
       "date_time                                                        April 11, 2025 at 01:35:11 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                  2   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.172983   \n",
       "total_energy_joules                                                              622739.187387   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                       0.02631   \n",
       "joules_per_token                                                                     38.008984   \n",
       "flops_per_joule                                                                27218410.751168   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                            170.672749   \n",
       "average_latency_ms_per_batch                                                       2666.761703   \n",
       "throughput_queries_per_sec                                                            0.749973   \n",
       "throughput_tokens_per_sec                                                            95.996579   \n",
       "cpu_usage_percent                                                                          5.4   \n",
       "cpu_memory_usage_bytes                                                              2007461888   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13220446208   \n",
       "gpu_max_memory_reserved_bytes                                                      13220446208   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 607.851348   \n",
       "gpu_power_process_1                                                                 443.862459   \n",
       "gpu_power_process_2                                                                 494.305105   \n",
       "gpu_power_process_3                                                                 700.458985   \n",
       "ram_power_process_0                                                                     0.6996   \n",
       "ram_power_process_1                                                                    0.65001   \n",
       "ram_power_process_2                                                                   0.648281   \n",
       "ram_power_process_3                                                                   0.648484   \n",
       "cpu_energy_process_0                                                                  0.005241   \n",
       "cpu_energy_process_1                                                                   0.00703   \n",
       "cpu_energy_process_2                                                                  0.006642   \n",
       "cpu_energy_process_3                                                                   0.00632   \n",
       "gpu_energy_process_0                                                                  0.031252   \n",
       "gpu_energy_process_1                                                                  0.040477   \n",
       "gpu_energy_process_2                                                                  0.038695   \n",
       "gpu_energy_process_3                                                                  0.037198   \n",
       "ram_energy_process_0                                                                  0.000028   \n",
       "ram_energy_process_1                                                                  0.000035   \n",
       "ram_energy_process_2                                                                  0.000033   \n",
       "ram_energy_process_3                                                                  0.000032   \n",
       "total_energy_kwh_process_0                                                            0.036521   \n",
       "total_energy_kwh_process_1                                                            0.047542   \n",
       "total_energy_kwh_process_2                                                            0.045371   \n",
       "total_energy_kwh_process_3                                                            0.043549   \n",
       "total_energy_joules_process_0                                                    131476.777867   \n",
       "total_energy_joules_process_1                                                    171150.795772   \n",
       "total_energy_joules_process_2                                                    163334.776383   \n",
       "total_energy_joules_process_3                                                    156776.837365   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       561.619474   \n",
       "ram_power_avg                                                                         0.661594   \n",
       "cpu_energy_total                                                                      0.025233   \n",
       "gpu_energy_total                                                                      0.147622   \n",
       "ram_energy_total                                                                      0.000128   \n",
       "per-process_emissions_0                                                                0.01659   \n",
       "per-process_emissions_1                                                               0.017284   \n",
       "per-process_emissions_2                                                               0.013913   \n",
       "per-process_emissions_3                                                               0.018111   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            6   \\\n",
       "config_name                                                                         batching_4   \n",
       "experiment_id                                                                              115   \n",
       "date_time                                                        April 11, 2025 at 01:37:39 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                  4   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.080552   \n",
       "total_energy_joules                                                              289987.598049   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.056499   \n",
       "joules_per_token                                                                     17.699438   \n",
       "flops_per_joule                                                                58450675.502025   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             89.149648   \n",
       "average_latency_ms_per_batch                                                       2785.926509   \n",
       "throughput_queries_per_sec                                                            1.435788   \n",
       "throughput_tokens_per_sec                                                           183.780871   \n",
       "cpu_usage_percent                                                                          5.2   \n",
       "cpu_memory_usage_bytes                                                              2008850432   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13230931968   \n",
       "gpu_max_memory_reserved_bytes                                                      13230931968   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1115.441822   \n",
       "gpu_power_process_1                                                                 472.776999   \n",
       "gpu_power_process_2                                                                 652.840459   \n",
       "gpu_power_process_3                                                                 495.692987   \n",
       "ram_power_process_0                                                                   0.699941   \n",
       "ram_power_process_1                                                                   0.651295   \n",
       "ram_power_process_2                                                                   0.651762   \n",
       "ram_power_process_3                                                                   0.652755   \n",
       "cpu_energy_process_0                                                                  0.002727   \n",
       "cpu_energy_process_1                                                                  0.003583   \n",
       "cpu_energy_process_2                                                                  0.002716   \n",
       "cpu_energy_process_3                                                                   0.00321   \n",
       "gpu_energy_process_0                                                                  0.015568   \n",
       "gpu_energy_process_1                                                                   0.01934   \n",
       "gpu_energy_process_2                                                                  0.015501   \n",
       "gpu_energy_process_3                                                                  0.017845   \n",
       "ram_energy_process_0                                                                  0.000014   \n",
       "ram_energy_process_1                                                                  0.000018   \n",
       "ram_energy_process_2                                                                  0.000013   \n",
       "ram_energy_process_3                                                                  0.000016   \n",
       "total_energy_kwh_process_0                                                            0.018309   \n",
       "total_energy_kwh_process_1                                                            0.022941   \n",
       "total_energy_kwh_process_2                                                            0.018231   \n",
       "total_energy_kwh_process_3                                                            0.021071   \n",
       "total_energy_joules_process_0                                                     65913.936327   \n",
       "total_energy_joules_process_1                                                     82587.666717   \n",
       "total_energy_joules_process_2                                                     65629.995914   \n",
       "total_energy_joules_process_3                                                     75855.999091   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       684.188067   \n",
       "ram_power_avg                                                                         0.663938   \n",
       "cpu_energy_total                                                                      0.012236   \n",
       "gpu_energy_total                                                                      0.068254   \n",
       "ram_energy_total                                                                      0.000062   \n",
       "per-process_emissions_0                                                               0.006945   \n",
       "per-process_emissions_1                                                               0.006975   \n",
       "per-process_emissions_2                                                               0.008739   \n",
       "per-process_emissions_3                                                               0.008027   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            7   \\\n",
       "config_name                                                                         batching_8   \n",
       "experiment_id                                                                              116   \n",
       "date_time                                                        April 11, 2025 at 01:39:15 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                  8   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.046927   \n",
       "total_energy_joules                                                              168938.609749   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.096982   \n",
       "joules_per_token                                                                     10.311194   \n",
       "flops_per_joule                                                               100332132.591523   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             44.280597   \n",
       "average_latency_ms_per_batch                                                       2767.537316   \n",
       "throughput_queries_per_sec                                                            2.890657   \n",
       "throughput_tokens_per_sec                                                           370.004044   \n",
       "cpu_usage_percent                                                                          5.5   \n",
       "cpu_memory_usage_bytes                                                              2010365952   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  737.23032   \n",
       "gpu_power_process_1                                                                 503.533111   \n",
       "gpu_power_process_2                                                                 630.901716   \n",
       "gpu_power_process_3                                                                 646.758341   \n",
       "ram_power_process_0                                                                   0.700879   \n",
       "ram_power_process_1                                                                    0.65122   \n",
       "ram_power_process_2                                                                   0.653661   \n",
       "ram_power_process_3                                                                   0.656559   \n",
       "cpu_energy_process_0                                                                  0.001364   \n",
       "cpu_energy_process_1                                                                  0.001937   \n",
       "cpu_energy_process_2                                                                  0.001494   \n",
       "cpu_energy_process_3                                                                  0.001712   \n",
       "gpu_energy_process_0                                                                  0.008683   \n",
       "gpu_energy_process_1                                                                  0.011641   \n",
       "gpu_energy_process_2                                                                  0.009446   \n",
       "gpu_energy_process_3                                                                  0.010616   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                   0.00001   \n",
       "ram_energy_process_2                                                                  0.000007   \n",
       "ram_energy_process_3                                                                  0.000009   \n",
       "total_energy_kwh_process_0                                                            0.010055   \n",
       "total_energy_kwh_process_1                                                            0.013588   \n",
       "total_energy_kwh_process_2                                                            0.010947   \n",
       "total_energy_kwh_process_3                                                            0.012337   \n",
       "total_energy_joules_process_0                                                     36197.325349   \n",
       "total_energy_joules_process_1                                                     48917.600616   \n",
       "total_energy_joules_process_2                                                     39410.051212   \n",
       "total_energy_joules_process_3                                                     44413.632572   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       629.605872   \n",
       "ram_power_avg                                                                          0.66558   \n",
       "cpu_energy_total                                                                      0.006508   \n",
       "gpu_energy_total                                                                      0.040386   \n",
       "ram_energy_total                                                                      0.000033   \n",
       "per-process_emissions_0                                                                 0.0047   \n",
       "per-process_emissions_1                                                               0.005176   \n",
       "per-process_emissions_2                                                                0.00417   \n",
       "per-process_emissions_3                                                                0.00383   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            8   \\\n",
       "config_name                                                                        batching_16   \n",
       "experiment_id                                                                              117   \n",
       "date_time                                                        April 11, 2025 at 01:40:22 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.030332   \n",
       "total_energy_joules                                                               109195.59459   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.150043   \n",
       "joules_per_token                                                                       6.66477   \n",
       "flops_per_joule                                                               155225776.798502   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.435158   \n",
       "average_latency_ms_per_batch                                                       2929.394723   \n",
       "throughput_queries_per_sec                                                            5.461879   \n",
       "throughput_tokens_per_sec                                                           699.120533   \n",
       "cpu_usage_percent                                                                          4.7   \n",
       "cpu_memory_usage_bytes                                                              2011435008   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 860.575376   \n",
       "gpu_power_process_1                                                                 451.594338   \n",
       "gpu_power_process_2                                                                 606.900655   \n",
       "gpu_power_process_3                                                                 682.779136   \n",
       "ram_power_process_0                                                                   0.700577   \n",
       "ram_power_process_1                                                                   0.660244   \n",
       "ram_power_process_2                                                                   0.651913   \n",
       "ram_power_process_3                                                                    0.65378   \n",
       "cpu_energy_process_0                                                                  0.000726   \n",
       "cpu_energy_process_1                                                                  0.001107   \n",
       "cpu_energy_process_2                                                                  0.001045   \n",
       "cpu_energy_process_3                                                                  0.000942   \n",
       "gpu_energy_process_0                                                                  0.005243   \n",
       "gpu_energy_process_1                                                                  0.007444   \n",
       "gpu_energy_process_2                                                                  0.007182   \n",
       "gpu_energy_process_3                                                                  0.006623   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000006   \n",
       "ram_energy_process_2                                                                  0.000005   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005972   \n",
       "total_energy_kwh_process_1                                                            0.008557   \n",
       "total_energy_kwh_process_2                                                            0.008233   \n",
       "total_energy_kwh_process_3                                                             0.00757   \n",
       "total_energy_joules_process_0                                                     21500.760054   \n",
       "total_energy_joules_process_1                                                     30805.085856   \n",
       "total_energy_joules_process_2                                                     29637.863397   \n",
       "total_energy_joules_process_3                                                     27251.885283   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       650.462376   \n",
       "ram_power_avg                                                                         0.666628   \n",
       "cpu_energy_total                                                                      0.003819   \n",
       "gpu_energy_total                                                                      0.026493   \n",
       "ram_energy_total                                                                       0.00002   \n",
       "per-process_emissions_0                                                               0.002275   \n",
       "per-process_emissions_1                                                               0.002884   \n",
       "per-process_emissions_2                                                               0.003136   \n",
       "per-process_emissions_3                                                                0.00326   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            9   \\\n",
       "config_name                                                                        batching_32   \n",
       "experiment_id                                                                              118   \n",
       "date_time                                                        April 11, 2025 at 01:41:15 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 32   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                       0.01974   \n",
       "total_energy_joules                                                               71065.052609   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.230549   \n",
       "joules_per_token                                                                      4.337467   \n",
       "flops_per_joule                                                               238513451.700919   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              13.35417   \n",
       "average_latency_ms_per_batch                                                        3338.54239   \n",
       "throughput_queries_per_sec                                                            9.585021   \n",
       "throughput_tokens_per_sec                                                           1226.88273   \n",
       "cpu_usage_percent                                                                          4.8   \n",
       "cpu_memory_usage_bytes                                                              2011807744   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 898.907868   \n",
       "gpu_power_process_1                                                                 528.622622   \n",
       "gpu_power_process_2                                                                 545.227387   \n",
       "gpu_power_process_3                                                                 741.472606   \n",
       "ram_power_process_0                                                                   0.700729   \n",
       "ram_power_process_1                                                                   0.650459   \n",
       "ram_power_process_2                                                                   0.648046   \n",
       "ram_power_process_3                                                                   0.648501   \n",
       "cpu_energy_process_0                                                                  0.000414   \n",
       "cpu_energy_process_1                                                                  0.000677   \n",
       "cpu_energy_process_2                                                                  0.000632   \n",
       "cpu_energy_process_3                                                                  0.000553   \n",
       "gpu_energy_process_0                                                                  0.003364   \n",
       "gpu_energy_process_1                                                                  0.004993   \n",
       "gpu_energy_process_2                                                                  0.004775   \n",
       "gpu_energy_process_3                                                                   0.00432   \n",
       "ram_energy_process_0                                                                  0.000002   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000003   \n",
       "ram_energy_process_3                                                                  0.000003   \n",
       "total_energy_kwh_process_0                                                             0.00378   \n",
       "total_energy_kwh_process_1                                                            0.005674   \n",
       "total_energy_kwh_process_2                                                            0.005409   \n",
       "total_energy_kwh_process_3                                                            0.004876   \n",
       "total_energy_joules_process_0                                                     13609.237095   \n",
       "total_energy_joules_process_1                                                     20427.345729   \n",
       "total_energy_joules_process_2                                                     19474.082681   \n",
       "total_energy_joules_process_3                                                     17554.387104   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       678.557621   \n",
       "ram_power_avg                                                                         0.661934   \n",
       "cpu_energy_total                                                                      0.002276   \n",
       "gpu_energy_total                                                                      0.017452   \n",
       "ram_energy_total                                                                      0.000012   \n",
       "per-process_emissions_0                                                               0.002061   \n",
       "per-process_emissions_1                                                                0.00144   \n",
       "per-process_emissions_2                                                               0.002162   \n",
       "per-process_emissions_3                                                               0.001858   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            10  \\\n",
       "config_name                                                                        batching_64   \n",
       "experiment_id                                                                              119   \n",
       "date_time                                                        April 11, 2025 at 01:42:03 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 64   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.016821   \n",
       "total_energy_joules                                                                 60554.5696   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.270566   \n",
       "joules_per_token                                                                      3.695958   \n",
       "flops_per_joule                                                               279912335.355367   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             10.367802   \n",
       "average_latency_ms_per_batch                                                       5183.901025   \n",
       "throughput_queries_per_sec                                                           12.345915   \n",
       "throughput_tokens_per_sec                                                          1580.277085   \n",
       "cpu_usage_percent                                                                          4.7   \n",
       "cpu_memory_usage_bytes                                                              2015821824   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1099.618651   \n",
       "gpu_power_process_1                                                                 471.735827   \n",
       "gpu_power_process_2                                                                 624.886759   \n",
       "gpu_power_process_3                                                                 807.625618   \n",
       "ram_power_process_0                                                                   0.702344   \n",
       "ram_power_process_1                                                                    0.64562   \n",
       "ram_power_process_2                                                                   0.649797   \n",
       "ram_power_process_3                                                                   0.653134   \n",
       "cpu_energy_process_0                                                                  0.000321   \n",
       "cpu_energy_process_1                                                                  0.000564   \n",
       "cpu_energy_process_2                                                                  0.000507   \n",
       "cpu_energy_process_3                                                                  0.000446   \n",
       "gpu_energy_process_0                                                                  0.002828   \n",
       "gpu_energy_process_1                                                                  0.004346   \n",
       "gpu_energy_process_2                                                                  0.004082   \n",
       "gpu_energy_process_3                                                                  0.003718   \n",
       "ram_energy_process_0                                                                  0.000002   \n",
       "ram_energy_process_1                                                                  0.000003   \n",
       "ram_energy_process_2                                                                  0.000003   \n",
       "ram_energy_process_3                                                                  0.000002   \n",
       "total_energy_kwh_process_0                                                            0.003151   \n",
       "total_energy_kwh_process_1                                                            0.004913   \n",
       "total_energy_kwh_process_2                                                            0.004591   \n",
       "total_energy_kwh_process_3                                                            0.004166   \n",
       "total_energy_joules_process_0                                                     11342.227859   \n",
       "total_energy_joules_process_1                                                     17685.400324   \n",
       "total_energy_joules_process_2                                                     16529.155674   \n",
       "total_energy_joules_process_3                                                     14997.785742   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       750.966714   \n",
       "ram_power_avg                                                                         0.662724   \n",
       "cpu_energy_total                                                                      0.001837   \n",
       "gpu_energy_total                                                                      0.014974   \n",
       "ram_energy_total                                                                       0.00001   \n",
       "per-process_emissions_0                                                               0.001749   \n",
       "per-process_emissions_1                                                               0.001587   \n",
       "per-process_emissions_2                                                                 0.0012   \n",
       "per-process_emissions_3                                                               0.001871   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            11  \\\n",
       "config_name                                  precis_float32_quant_False_quant8_False_quant4...   \n",
       "experiment_id                                                                              120   \n",
       "date_time                                                        April 11, 2025 at 01:43:09 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.030563   \n",
       "total_energy_joules                                                              110026.388974   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                       0.14891   \n",
       "joules_per_token                                                                      6.715478   \n",
       "flops_per_joule                                                               154053687.949614   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.777636   \n",
       "average_latency_ms_per_batch                                                        2972.20455   \n",
       "throughput_queries_per_sec                                                             5.38321   \n",
       "throughput_tokens_per_sec                                                           689.050826   \n",
       "cpu_usage_percent                                                                          5.5   \n",
       "cpu_memory_usage_bytes                                                              2011570176   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 845.522618   \n",
       "gpu_power_process_1                                                                 528.434789   \n",
       "gpu_power_process_2                                                                 486.615792   \n",
       "gpu_power_process_3                                                                 672.966642   \n",
       "ram_power_process_0                                                                   0.700822   \n",
       "ram_power_process_1                                                                   0.656609   \n",
       "ram_power_process_2                                                                   0.647584   \n",
       "ram_power_process_3                                                                   0.649917   \n",
       "cpu_energy_process_0                                                                  0.000736   \n",
       "cpu_energy_process_1                                                                  0.001098   \n",
       "cpu_energy_process_2                                                                  0.001053   \n",
       "cpu_energy_process_3                                                                  0.000938   \n",
       "gpu_energy_process_0                                                                  0.005347   \n",
       "gpu_energy_process_1                                                                  0.007461   \n",
       "gpu_energy_process_2                                                                  0.007275   \n",
       "gpu_energy_process_3                                                                  0.006634   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000006   \n",
       "ram_energy_process_2                                                                  0.000005   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.006087   \n",
       "total_energy_kwh_process_1                                                            0.008565   \n",
       "total_energy_kwh_process_2                                                            0.008334   \n",
       "total_energy_kwh_process_3                                                            0.007577   \n",
       "total_energy_joules_process_0                                                      21913.93914   \n",
       "total_energy_joules_process_1                                                     30832.795448   \n",
       "total_energy_joules_process_2                                                     30001.084447   \n",
       "total_energy_joules_process_3                                                     27278.569938   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        633.38496   \n",
       "ram_power_avg                                                                         0.663733   \n",
       "cpu_energy_total                                                                      0.003825   \n",
       "gpu_energy_total                                                                      0.026718   \n",
       "ram_energy_total                                                                       0.00002   \n",
       "per-process_emissions_0                                                               0.003175   \n",
       "per-process_emissions_1                                                               0.002887   \n",
       "per-process_emissions_2                                                               0.002319   \n",
       "per-process_emissions_3                                                               0.003263   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            12  \\\n",
       "config_name                                  precis_float16_quant_False_quant8_False_quant4...   \n",
       "experiment_id                                                                              121   \n",
       "date_time                                                        April 11, 2025 at 01:44:07 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.020205   \n",
       "total_energy_joules                                                               72739.613361   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.225242   \n",
       "joules_per_token                                                                      4.439674   \n",
       "flops_per_joule                                                               233022561.022627   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.518978   \n",
       "average_latency_ms_per_batch                                                       2939.872271   \n",
       "throughput_queries_per_sec                                                            5.442413   \n",
       "throughput_tokens_per_sec                                                           696.628905   \n",
       "cpu_usage_percent                                                                          5.5   \n",
       "cpu_memory_usage_bytes                                                              3105521664   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  4419853312   \n",
       "gpu_max_memory_allocated_bytes                                                      4419853312   \n",
       "gpu_current_memory_reserved_bytes                                                   6870269952   \n",
       "gpu_max_memory_reserved_bytes                                                       6870269952   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 590.607143   \n",
       "gpu_power_process_1                                                                 498.917158   \n",
       "gpu_power_process_2                                                                 494.106489   \n",
       "gpu_power_process_3                                                                 722.912342   \n",
       "ram_power_process_0                                                                   1.083248   \n",
       "ram_power_process_1                                                                   0.852912   \n",
       "ram_power_process_2                                                                   0.857015   \n",
       "ram_power_process_3                                                                   0.872403   \n",
       "cpu_energy_process_0                                                                  0.000727   \n",
       "cpu_energy_process_1                                                                  0.000837   \n",
       "cpu_energy_process_2                                                                  0.000838   \n",
       "cpu_energy_process_3                                                                  0.000794   \n",
       "gpu_energy_process_0                                                                   0.00388   \n",
       "gpu_energy_process_1                                                                  0.004443   \n",
       "gpu_energy_process_2                                                                  0.004428   \n",
       "gpu_energy_process_3                                                                  0.004237   \n",
       "ram_energy_process_0                                                                  0.000006   \n",
       "ram_energy_process_1                                                                  0.000006   \n",
       "ram_energy_process_2                                                                  0.000006   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.004613   \n",
       "total_energy_kwh_process_1                                                            0.005285   \n",
       "total_energy_kwh_process_2                                                            0.005271   \n",
       "total_energy_kwh_process_3                                                            0.005036   \n",
       "total_energy_joules_process_0                                                     16607.154641   \n",
       "total_energy_joules_process_1                                                     19027.674647   \n",
       "total_energy_joules_process_2                                                     18976.248512   \n",
       "total_energy_joules_process_3                                                     18128.535561   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       576.635783   \n",
       "ram_power_avg                                                                         0.916395   \n",
       "cpu_energy_total                                                                      0.003195   \n",
       "gpu_energy_total                                                                      0.016988   \n",
       "ram_energy_total                                                                      0.000022   \n",
       "per-process_emissions_0                                                               0.001918   \n",
       "per-process_emissions_1                                                               0.002013   \n",
       "per-process_emissions_2                                                               0.002008   \n",
       "per-process_emissions_3                                                               0.001757   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            13  \\\n",
       "config_name                                  precis_float16_quant_True_quant8_True_quant4_F...   \n",
       "experiment_id                                                                              122   \n",
       "date_time                                                        April 11, 2025 at 01:47:13 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                              True   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.081855   \n",
       "total_energy_joules                                                              294677.860311   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                        0.0556   \n",
       "joules_per_token                                                                     17.985709   \n",
       "flops_per_joule                                                                 3510762.996944   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             74.511461   \n",
       "average_latency_ms_per_batch                                                       9313.932569   \n",
       "throughput_queries_per_sec                                                            1.717857   \n",
       "throughput_tokens_per_sec                                                           219.885637   \n",
       "cpu_usage_percent                                                                         32.9   \n",
       "cpu_memory_usage_bytes                                                              2712805376   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1576560640   \n",
       "gpu_max_memory_allocated_bytes                                                      1576560640   \n",
       "gpu_current_memory_reserved_bytes                                                   2883584000   \n",
       "gpu_max_memory_reserved_bytes                                                       2883584000   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 566.735261   \n",
       "gpu_power_process_1                                                                  328.13377   \n",
       "gpu_power_process_2                                                                  541.83233   \n",
       "gpu_power_process_3                                                                 504.428324   \n",
       "ram_power_process_0                                                                    0.94703   \n",
       "ram_power_process_1                                                                   0.991452   \n",
       "ram_power_process_2                                                                   0.990413   \n",
       "ram_power_process_3                                                                   0.989322   \n",
       "cpu_energy_process_0                                                                  0.002289   \n",
       "cpu_energy_process_1                                                                  0.004794   \n",
       "cpu_energy_process_2                                                                  0.004221   \n",
       "cpu_energy_process_3                                                                  0.003397   \n",
       "gpu_energy_process_0                                                                  0.010467   \n",
       "gpu_energy_process_1                                                                   0.02157   \n",
       "gpu_energy_process_2                                                                  0.019362   \n",
       "gpu_energy_process_3                                                                  0.015643   \n",
       "ram_energy_process_0                                                                  0.000016   \n",
       "ram_energy_process_1                                                                  0.000038   \n",
       "ram_energy_process_2                                                                  0.000033   \n",
       "ram_energy_process_3                                                                  0.000026   \n",
       "total_energy_kwh_process_0                                                            0.012772   \n",
       "total_energy_kwh_process_1                                                            0.026401   \n",
       "total_energy_kwh_process_2                                                            0.023616   \n",
       "total_energy_kwh_process_3                                                            0.019066   \n",
       "total_energy_joules_process_0                                                       45979.8298   \n",
       "total_energy_joules_process_1                                                     95043.394452   \n",
       "total_energy_joules_process_2                                                     85017.263054   \n",
       "total_energy_joules_process_3                                                     68637.373006   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       485.282421   \n",
       "ram_power_avg                                                                         0.979554   \n",
       "cpu_energy_total                                                                      0.014701   \n",
       "gpu_energy_total                                                                      0.067042   \n",
       "ram_energy_total                                                                      0.000112   \n",
       "per-process_emissions_0                                                               0.010057   \n",
       "per-process_emissions_1                                                               0.008996   \n",
       "per-process_emissions_2                                                               0.007263   \n",
       "per-process_emissions_3                                                               0.004866   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            14  \\\n",
       "config_name                                  precis_float16_quant_True_quant8_False_quant4_...   \n",
       "experiment_id                                                                              123   \n",
       "date_time                                                        April 11, 2025 at 01:48:28 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.026513   \n",
       "total_energy_joules                                                               95445.437568   \n",
       "flops                                                                            1034544128000   \n",
       "tokens_per_joule                                                                      0.171658   \n",
       "joules_per_token                                                                      5.825527   \n",
       "flops_per_joule                                                                10839115.565521   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.632226   \n",
       "average_latency_ms_per_batch                                                        4704.02822   \n",
       "throughput_queries_per_sec                                                             3.40134   \n",
       "throughput_tokens_per_sec                                                           435.371538   \n",
       "cpu_usage_percent                                                                          6.0   \n",
       "cpu_memory_usage_bytes                                                              2653773824   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 487.388971   \n",
       "gpu_power_process_1                                                                 506.209779   \n",
       "gpu_power_process_2                                                                 715.638517   \n",
       "gpu_power_process_3                                                                 676.823883   \n",
       "ram_power_process_0                                                                   0.926631   \n",
       "ram_power_process_1                                                                   0.980135   \n",
       "ram_power_process_2                                                                   0.976652   \n",
       "ram_power_process_3                                                                   0.967501   \n",
       "cpu_energy_process_0                                                                  0.001135   \n",
       "cpu_energy_process_1                                                                  0.001127   \n",
       "cpu_energy_process_2                                                                  0.001221   \n",
       "cpu_energy_process_3                                                                  0.001175   \n",
       "gpu_energy_process_0                                                                  0.005307   \n",
       "gpu_energy_process_1                                                                  0.005304   \n",
       "gpu_energy_process_2                                                                  0.005697   \n",
       "gpu_energy_process_3                                                                  0.005513   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000009   \n",
       "ram_energy_process_3                                                                  0.000009   \n",
       "total_energy_kwh_process_0                                                            0.006449   \n",
       "total_energy_kwh_process_1                                                            0.006439   \n",
       "total_energy_kwh_process_2                                                            0.006927   \n",
       "total_energy_kwh_process_3                                                            0.006697   \n",
       "total_energy_joules_process_0                                                     23217.853073   \n",
       "total_energy_joules_process_1                                                     23181.478029   \n",
       "total_energy_joules_process_2                                                     24938.418016   \n",
       "total_energy_joules_process_3                                                      24107.68845   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       596.515287   \n",
       "ram_power_avg                                                                          0.96273   \n",
       "cpu_energy_total                                                                      0.004657   \n",
       "gpu_energy_total                                                                      0.021821   \n",
       "ram_energy_total                                                                      0.000034   \n",
       "per-process_emissions_0                                                               0.002457   \n",
       "per-process_emissions_1                                                               0.002639   \n",
       "per-process_emissions_2                                                               0.002551   \n",
       "per-process_emissions_3                                                               0.002453   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            15  \\\n",
       "config_name                                              decoding_greedy_decoder_temperature_0   \n",
       "experiment_id                                                                              124   \n",
       "date_time                                                        April 11, 2025 at 01:49:39 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.026726   \n",
       "total_energy_joules                                                               96214.326055   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.170286   \n",
       "joules_per_token                                                                      5.872456   \n",
       "flops_per_joule                                                               176168889.687912   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.034822   \n",
       "average_latency_ms_per_batch                                                       2879.352748   \n",
       "throughput_queries_per_sec                                                            5.556804   \n",
       "throughput_tokens_per_sec                                                           711.270962   \n",
       "cpu_usage_percent                                                                          4.9   \n",
       "cpu_memory_usage_bytes                                                              1998827520   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  12016680960   \n",
       "gpu_max_memory_reserved_bytes                                                      12016680960   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                        0.0   \n",
       "gpu_power_process_1                                                                 452.225727   \n",
       "gpu_power_process_2                                                                 532.356597   \n",
       "gpu_power_process_3                                                                  11.318237   \n",
       "ram_power_process_0                                                                   0.695679   \n",
       "ram_power_process_1                                                                   0.619613   \n",
       "ram_power_process_2                                                                   0.617517   \n",
       "ram_power_process_3                                                                   0.639288   \n",
       "cpu_energy_process_0                                                                  0.000839   \n",
       "cpu_energy_process_1                                                                  0.001033   \n",
       "cpu_energy_process_2                                                                  0.000938   \n",
       "cpu_energy_process_3                                                                  0.000863   \n",
       "gpu_energy_process_0                                                                  0.005058   \n",
       "gpu_energy_process_1                                                                  0.006462   \n",
       "gpu_energy_process_2                                                                  0.005994   \n",
       "gpu_energy_process_3                                                                  0.005521   \n",
       "ram_energy_process_0                                                                  0.000005   \n",
       "ram_energy_process_1                                                                  0.000005   \n",
       "ram_energy_process_2                                                                  0.000005   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005901   \n",
       "total_energy_kwh_process_1                                                              0.0075   \n",
       "total_energy_kwh_process_2                                                            0.006936   \n",
       "total_energy_kwh_process_3                                                            0.006388   \n",
       "total_energy_joules_process_0                                                     21244.910513   \n",
       "total_energy_joules_process_1                                                       27001.2951   \n",
       "total_energy_joules_process_2                                                     24971.072064   \n",
       "total_energy_joules_process_3                                                     22997.048378   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        248.97514   \n",
       "ram_power_avg                                                                         0.643025   \n",
       "cpu_energy_total                                                                      0.003673   \n",
       "gpu_energy_total                                                                      0.023035   \n",
       "ram_energy_total                                                                      0.000018   \n",
       "per-process_emissions_0                                                               0.002857   \n",
       "per-process_emissions_1                                                               0.002248   \n",
       "per-process_emissions_2                                                               0.002642   \n",
       "per-process_emissions_3                                                               0.002434   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            16  \\\n",
       "config_name                                            decoding_greedy_decoder_temperature_0.2   \n",
       "experiment_id                                                                              125   \n",
       "date_time                                                        April 11, 2025 at 01:50:49 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.027081   \n",
       "total_energy_joules                                                               97493.121231   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.168053   \n",
       "joules_per_token                                                                      5.950508   \n",
       "flops_per_joule                                                               173858122.288034   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.574361   \n",
       "average_latency_ms_per_batch                                                       2946.795177   \n",
       "throughput_queries_per_sec                                                            5.429627   \n",
       "throughput_tokens_per_sec                                                           694.992314   \n",
       "cpu_usage_percent                                                                          5.2   \n",
       "cpu_memory_usage_bytes                                                              2012307456   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                2132.583275   \n",
       "gpu_power_process_1                                                                   9.292454   \n",
       "gpu_power_process_2                                                                   5.057341   \n",
       "gpu_power_process_3                                                                 136.944676   \n",
       "ram_power_process_0                                                                   0.701025   \n",
       "ram_power_process_1                                                                   0.650712   \n",
       "ram_power_process_2                                                                   0.651804   \n",
       "ram_power_process_3                                                                   0.652708   \n",
       "cpu_energy_process_0                                                                  0.000672   \n",
       "cpu_energy_process_1                                                                  0.000965   \n",
       "cpu_energy_process_2                                                                   0.00089   \n",
       "cpu_energy_process_3                                                                  0.000778   \n",
       "gpu_energy_process_0                                                                  0.005266   \n",
       "gpu_energy_process_1                                                                  0.006656   \n",
       "gpu_energy_process_2                                                                  0.006106   \n",
       "gpu_energy_process_3                                                                   0.00573   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000005   \n",
       "ram_energy_process_2                                                                  0.000005   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005942   \n",
       "total_energy_kwh_process_1                                                            0.007626   \n",
       "total_energy_kwh_process_2                                                            0.007001   \n",
       "total_energy_kwh_process_3                                                            0.006512   \n",
       "total_energy_joules_process_0                                                      21391.50582   \n",
       "total_energy_joules_process_1                                                     27453.434216   \n",
       "total_energy_joules_process_2                                                     25203.596025   \n",
       "total_energy_joules_process_3                                                      23444.58517   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       570.969436   \n",
       "ram_power_avg                                                                         0.664062   \n",
       "cpu_energy_total                                                                      0.003304   \n",
       "gpu_energy_total                                                                      0.023758   \n",
       "ram_energy_total                                                                      0.000019   \n",
       "per-process_emissions_0                                                               0.002905   \n",
       "per-process_emissions_1                                                               0.002264   \n",
       "per-process_emissions_2                                                               0.002667   \n",
       "per-process_emissions_3                                                               0.002481   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            17  \\\n",
       "config_name                                            decoding_greedy_decoder_temperature_0.4   \n",
       "experiment_id                                                                              126   \n",
       "date_time                                                        April 11, 2025 at 01:52:03 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                       0.02731   \n",
       "total_energy_joules                                                               98315.389425   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.166647   \n",
       "joules_per_token                                                                      6.000695   \n",
       "flops_per_joule                                                               172404046.735283   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.302189   \n",
       "average_latency_ms_per_batch                                                       2912.773661   \n",
       "throughput_queries_per_sec                                                            5.493046   \n",
       "throughput_tokens_per_sec                                                           703.109901   \n",
       "cpu_usage_percent                                                                          5.1   \n",
       "cpu_memory_usage_bytes                                                              1992527872   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                        0.0   \n",
       "gpu_power_process_1                                                                  11.212884   \n",
       "gpu_power_process_2                                                                 752.568957   \n",
       "gpu_power_process_3                                                                   675.2677   \n",
       "ram_power_process_0                                                                   0.693811   \n",
       "ram_power_process_1                                                                    0.65329   \n",
       "ram_power_process_2                                                                   0.647007   \n",
       "ram_power_process_3                                                                   0.653179   \n",
       "cpu_energy_process_0                                                                   0.00076   \n",
       "cpu_energy_process_1                                                                  0.001088   \n",
       "cpu_energy_process_2                                                                  0.000947   \n",
       "cpu_energy_process_3                                                                  0.000842   \n",
       "gpu_energy_process_0                                                                   0.00504   \n",
       "gpu_energy_process_1                                                                  0.006801   \n",
       "gpu_energy_process_2                                                                  0.006108   \n",
       "gpu_energy_process_3                                                                  0.005705   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000006   \n",
       "ram_energy_process_2                                                                  0.000005   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005805   \n",
       "total_energy_kwh_process_1                                                            0.007895   \n",
       "total_energy_kwh_process_2                                                            0.007059   \n",
       "total_energy_kwh_process_3                                                            0.006551   \n",
       "total_energy_joules_process_0                                                     20897.349946   \n",
       "total_energy_joules_process_1                                                     28421.287345   \n",
       "total_energy_joules_process_2                                                     25414.024573   \n",
       "total_energy_joules_process_3                                                      23582.72756   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       359.762385   \n",
       "ram_power_avg                                                                         0.661822   \n",
       "cpu_energy_total                                                                      0.003637   \n",
       "gpu_energy_total                                                                      0.023654   \n",
       "ram_energy_total                                                                      0.000019   \n",
       "per-process_emissions_0                                                               0.003008   \n",
       "per-process_emissions_1                                                               0.002496   \n",
       "per-process_emissions_2                                                               0.002689   \n",
       "per-process_emissions_3                                                               0.002211   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            18  \\\n",
       "config_name                                            decoding_greedy_decoder_temperature_0.6   \n",
       "experiment_id                                                                              127   \n",
       "date_time                                                        April 11, 2025 at 01:53:15 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.027891   \n",
       "total_energy_joules                                                              100406.566327   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.163177   \n",
       "joules_per_token                                                                       6.12833   \n",
       "flops_per_joule                                                               168813371.607248   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             24.047179   \n",
       "average_latency_ms_per_batch                                                       3005.897323   \n",
       "throughput_queries_per_sec                                                             5.32287   \n",
       "throughput_tokens_per_sec                                                           681.327331   \n",
       "cpu_usage_percent                                                                          4.1   \n",
       "cpu_memory_usage_bytes                                                              2027139072   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                   15.27566   \n",
       "gpu_power_process_1                                                                 597.724199   \n",
       "gpu_power_process_2                                                                  27.024433   \n",
       "gpu_power_process_3                                                                  23.198432   \n",
       "ram_power_process_0                                                                   0.705604   \n",
       "ram_power_process_1                                                                   0.653501   \n",
       "ram_power_process_2                                                                   0.651778   \n",
       "ram_power_process_3                                                                   0.657429   \n",
       "cpu_energy_process_0                                                                   0.00067   \n",
       "cpu_energy_process_1                                                                  0.000909   \n",
       "cpu_energy_process_2                                                                    0.0009   \n",
       "cpu_energy_process_3                                                                  0.000907   \n",
       "gpu_energy_process_0                                                                  0.005266   \n",
       "gpu_energy_process_1                                                                  0.006834   \n",
       "gpu_energy_process_2                                                                  0.006199   \n",
       "gpu_energy_process_3                                                                  0.006184   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000005   \n",
       "ram_energy_process_2                                                                  0.000005   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                             0.00594   \n",
       "total_energy_kwh_process_1                                                            0.007748   \n",
       "total_energy_kwh_process_2                                                            0.007105   \n",
       "total_energy_kwh_process_3                                                            0.007097   \n",
       "total_energy_joules_process_0                                                     21385.706475   \n",
       "total_energy_joules_process_1                                                     27894.212444   \n",
       "total_energy_joules_process_2                                                     25578.007751   \n",
       "total_energy_joules_process_3                                                     25548.639657   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       165.805681   \n",
       "ram_power_avg                                                                         0.667078   \n",
       "cpu_energy_total                                                                      0.003388   \n",
       "gpu_energy_total                                                                      0.024483   \n",
       "ram_energy_total                                                                       0.00002   \n",
       "per-process_emissions_0                                                               0.002707   \n",
       "per-process_emissions_1                                                               0.002263   \n",
       "per-process_emissions_2                                                               0.002704   \n",
       "per-process_emissions_3                                                               0.002952   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            19  \\\n",
       "config_name                                            decoding_greedy_decoder_temperature_0.8   \n",
       "experiment_id                                                                              128   \n",
       "date_time                                                        April 11, 2025 at 01:54:27 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.027698   \n",
       "total_energy_joules                                                               99714.129356   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                       0.16431   \n",
       "joules_per_token                                                                      6.086067   \n",
       "flops_per_joule                                                                169985649.00098   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                               24.1225   \n",
       "average_latency_ms_per_batch                                                       3015.312471   \n",
       "throughput_queries_per_sec                                                            5.306249   \n",
       "throughput_tokens_per_sec                                                           679.199924   \n",
       "cpu_usage_percent                                                                          4.5   \n",
       "cpu_memory_usage_bytes                                                              1993207808   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                        0.0   \n",
       "gpu_power_process_1                                                                 498.848218   \n",
       "gpu_power_process_2                                                                        0.0   \n",
       "gpu_power_process_3                                                                 1029.13102   \n",
       "ram_power_process_0                                                                   0.693814   \n",
       "ram_power_process_1                                                                   0.653257   \n",
       "ram_power_process_2                                                                   0.654561   \n",
       "ram_power_process_3                                                                   0.650559   \n",
       "cpu_energy_process_0                                                                   0.00082   \n",
       "cpu_energy_process_1                                                                  0.000965   \n",
       "cpu_energy_process_2                                                                  0.000896   \n",
       "cpu_energy_process_3                                                                  0.000847   \n",
       "gpu_energy_process_0                                                                  0.005365   \n",
       "gpu_energy_process_1                                                                   0.00683   \n",
       "gpu_energy_process_2                                                                  0.006156   \n",
       "gpu_energy_process_3                                                                  0.005801   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000006   \n",
       "ram_energy_process_2                                                                  0.000005   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.006189   \n",
       "total_energy_kwh_process_1                                                              0.0078   \n",
       "total_energy_kwh_process_2                                                            0.007057   \n",
       "total_energy_kwh_process_3                                                            0.006653   \n",
       "total_energy_joules_process_0                                                     22279.676289   \n",
       "total_energy_joules_process_1                                                      28081.37419   \n",
       "total_energy_joules_process_2                                                     25403.402722   \n",
       "total_energy_joules_process_3                                                     23949.676155   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        381.99481   \n",
       "ram_power_avg                                                                         0.663048   \n",
       "cpu_energy_total                                                                      0.003528   \n",
       "gpu_energy_total                                                                      0.024152   \n",
       "ram_energy_total                                                                      0.000019   \n",
       "per-process_emissions_0                                                               0.002688   \n",
       "per-process_emissions_1                                                               0.002972   \n",
       "per-process_emissions_2                                                               0.002358   \n",
       "per-process_emissions_3                                                               0.002534   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            20  \\\n",
       "config_name                                            decoding_greedy_decoder_temperature_1.0   \n",
       "experiment_id                                                                              129   \n",
       "date_time                                                        April 11, 2025 at 02:07:40 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.427662   \n",
       "total_energy_joules                                                             1539584.096019   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.010642   \n",
       "joules_per_token                                                                     93.968756   \n",
       "flops_per_joule                                                                11009447.965185   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.358511   \n",
       "average_latency_ms_per_batch                                                        2919.81393   \n",
       "throughput_queries_per_sec                                                            5.479801   \n",
       "throughput_tokens_per_sec                                                           701.414559   \n",
       "cpu_usage_percent                                                                          5.6   \n",
       "cpu_memory_usage_bytes                                                              2013167616   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1009.128141   \n",
       "gpu_power_process_1                                                                 451.682352   \n",
       "gpu_power_process_2                                                                  62.157545   \n",
       "gpu_power_process_3                                                                 773.054232   \n",
       "ram_power_process_0                                                                   0.701212   \n",
       "ram_power_process_1                                                                   0.650597   \n",
       "ram_power_process_2                                                                   0.647645   \n",
       "ram_power_process_3                                                                   0.648325   \n",
       "cpu_energy_process_0                                                                  0.018917   \n",
       "cpu_energy_process_1                                                                  0.019204   \n",
       "cpu_energy_process_2                                                                  0.019364   \n",
       "cpu_energy_process_3                                                                  0.019455   \n",
       "gpu_energy_process_0                                                                  0.086619   \n",
       "gpu_energy_process_1                                                                  0.088478   \n",
       "gpu_energy_process_2                                                                  0.088062   \n",
       "gpu_energy_process_3                                                                  0.087116   \n",
       "ram_energy_process_0                                                                  0.000116   \n",
       "ram_energy_process_1                                                                  0.000111   \n",
       "ram_energy_process_2                                                                   0.00011   \n",
       "ram_energy_process_3                                                                  0.000111   \n",
       "total_energy_kwh_process_0                                                            0.105652   \n",
       "total_energy_kwh_process_1                                                            0.107793   \n",
       "total_energy_kwh_process_2                                                            0.107536   \n",
       "total_energy_kwh_process_3                                                            0.106682   \n",
       "total_energy_joules_process_0                                                     380347.64895   \n",
       "total_energy_joules_process_1                                                    388054.628298   \n",
       "total_energy_joules_process_2                                                    387128.374374   \n",
       "total_energy_joules_process_3                                                    384053.444398   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       574.005568   \n",
       "ram_power_avg                                                                         0.661945   \n",
       "cpu_energy_total                                                                       0.07694   \n",
       "gpu_energy_total                                                                      0.350275   \n",
       "ram_energy_total                                                                      0.000447   \n",
       "per-process_emissions_0                                                               0.041064   \n",
       "per-process_emissions_1                                                                0.04064   \n",
       "per-process_emissions_2                                                               0.040248   \n",
       "per-process_emissions_3                                                               0.040966   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            21  \\\n",
       "config_name                                            decoding_greedy_decoder_temperature_1.2   \n",
       "experiment_id                                                                              130   \n",
       "date_time                                                        April 11, 2025 at 02:08:53 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.027378   \n",
       "total_energy_joules                                                               98560.641388   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.166233   \n",
       "joules_per_token                                                                      6.015664   \n",
       "flops_per_joule                                                               171975047.589829   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              23.30423   \n",
       "average_latency_ms_per_batch                                                       2913.028805   \n",
       "throughput_queries_per_sec                                                            5.492565   \n",
       "throughput_tokens_per_sec                                                           703.048317   \n",
       "cpu_usage_percent                                                                          5.9   \n",
       "cpu_memory_usage_bytes                                                              2011959296   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1201.700986   \n",
       "gpu_power_process_1                                                                  13.321082   \n",
       "gpu_power_process_2                                                                1290.999517   \n",
       "gpu_power_process_3                                                                 840.642824   \n",
       "ram_power_process_0                                                                   0.700521   \n",
       "ram_power_process_1                                                                   0.655446   \n",
       "ram_power_process_2                                                                    0.65005   \n",
       "ram_power_process_3                                                                   0.659932   \n",
       "cpu_energy_process_0                                                                  0.000753   \n",
       "cpu_energy_process_1                                                                  0.001071   \n",
       "cpu_energy_process_2                                                                  0.000889   \n",
       "cpu_energy_process_3                                                                  0.000846   \n",
       "gpu_energy_process_0                                                                  0.005063   \n",
       "gpu_energy_process_1                                                                  0.006818   \n",
       "gpu_energy_process_2                                                                  0.006171   \n",
       "gpu_energy_process_3                                                                  0.005748   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000006   \n",
       "ram_energy_process_2                                                                  0.000005   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                             0.00582   \n",
       "total_energy_kwh_process_1                                                            0.007895   \n",
       "total_energy_kwh_process_2                                                            0.007065   \n",
       "total_energy_kwh_process_3                                                            0.006599   \n",
       "total_energy_joules_process_0                                                      20951.19653   \n",
       "total_energy_joules_process_1                                                     28420.579544   \n",
       "total_energy_joules_process_2                                                     25433.114077   \n",
       "total_energy_joules_process_3                                                     23755.751237   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       836.666102   \n",
       "ram_power_avg                                                                         0.666487   \n",
       "cpu_energy_total                                                                      0.003559   \n",
       "gpu_energy_total                                                                      0.023799   \n",
       "ram_energy_total                                                                       0.00002   \n",
       "per-process_emissions_0                                                               0.002514   \n",
       "per-process_emissions_1                                                               0.002217   \n",
       "per-process_emissions_2                                                               0.003007   \n",
       "per-process_emissions_3                                                               0.002691   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            22  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                              132   \n",
       "date_time                                                        April 11, 2025 at 02:10:30 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                               20   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.023482   \n",
       "total_energy_joules                                                               84535.873444   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.193811   \n",
       "joules_per_token                                                                       5.15966   \n",
       "flops_per_joule                                                                200506250.21828   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                               23.1588   \n",
       "average_latency_ms_per_batch                                                       2894.850059   \n",
       "throughput_queries_per_sec                                                            5.527057   \n",
       "throughput_tokens_per_sec                                                           707.463239   \n",
       "cpu_usage_percent                                                                          3.8   \n",
       "cpu_memory_usage_bytes                                                              2001289216   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1061.801104   \n",
       "gpu_power_process_1                                                                1252.829711   \n",
       "gpu_power_process_2                                                                 418.061063   \n",
       "gpu_power_process_3                                                                  57.254406   \n",
       "ram_power_process_0                                                                   0.697287   \n",
       "ram_power_process_1                                                                   0.608936   \n",
       "ram_power_process_2                                                                   0.628262   \n",
       "ram_power_process_3                                                                   0.633667   \n",
       "cpu_energy_process_0                                                                  0.000722   \n",
       "cpu_energy_process_1                                                                  0.000632   \n",
       "cpu_energy_process_2                                                                  0.000836   \n",
       "cpu_energy_process_3                                                                  0.000796   \n",
       "gpu_energy_process_0                                                                  0.004825   \n",
       "gpu_energy_process_1                                                                  0.004956   \n",
       "gpu_energy_process_2                                                                  0.005388   \n",
       "gpu_energy_process_3                                                                  0.005312   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000003   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                             0.00555   \n",
       "total_energy_kwh_process_1                                                            0.005592   \n",
       "total_energy_kwh_process_2                                                            0.006228   \n",
       "total_energy_kwh_process_3                                                            0.006112   \n",
       "total_energy_joules_process_0                                                     19980.710479   \n",
       "total_energy_joules_process_1                                                     20131.056243   \n",
       "total_energy_joules_process_2                                                     22421.505866   \n",
       "total_energy_joules_process_3                                                     22002.600855   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       697.486571   \n",
       "ram_power_avg                                                                         0.642038   \n",
       "cpu_energy_total                                                                      0.002986   \n",
       "gpu_energy_total                                                                       0.02048   \n",
       "ram_energy_total                                                                      0.000015   \n",
       "per-process_emissions_0                                                                0.00213   \n",
       "per-process_emissions_1                                                               0.002328   \n",
       "per-process_emissions_2                                                               0.002373   \n",
       "per-process_emissions_3                                                               0.002114   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            23  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                              133   \n",
       "date_time                                                        April 11, 2025 at 02:11:31 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021907   \n",
       "total_energy_joules                                                               78864.369793   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.207749   \n",
       "joules_per_token                                                                      4.813499   \n",
       "flops_per_joule                                                               214925587.277855   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.033007   \n",
       "average_latency_ms_per_batch                                                       2879.125936   \n",
       "throughput_queries_per_sec                                                            5.557242   \n",
       "throughput_tokens_per_sec                                                           711.326995   \n",
       "cpu_usage_percent                                                                          3.3   \n",
       "cpu_memory_usage_bytes                                                              1999810560   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                2092.393511   \n",
       "gpu_power_process_1                                                                  19.490862   \n",
       "gpu_power_process_2                                                                1856.549041   \n",
       "gpu_power_process_3                                                                   13.16597   \n",
       "ram_power_process_0                                                                   0.697085   \n",
       "ram_power_process_1                                                                   0.620072   \n",
       "ram_power_process_2                                                                   0.605607   \n",
       "ram_power_process_3                                                                   0.620702   \n",
       "cpu_energy_process_0                                                                  0.000659   \n",
       "cpu_energy_process_1                                                                  0.000692   \n",
       "cpu_energy_process_2                                                                  0.000671   \n",
       "cpu_energy_process_3                                                                  0.000787   \n",
       "gpu_energy_process_0                                                                  0.004661   \n",
       "gpu_energy_process_1                                                                  0.004656   \n",
       "gpu_energy_process_2                                                                  0.004748   \n",
       "gpu_energy_process_3                                                                  0.005018   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000003   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005324   \n",
       "total_energy_kwh_process_1                                                            0.005352   \n",
       "total_energy_kwh_process_2                                                            0.005422   \n",
       "total_energy_kwh_process_3                                                            0.005809   \n",
       "total_energy_joules_process_0                                                     19165.613535   \n",
       "total_energy_joules_process_1                                                      19266.66597   \n",
       "total_energy_joules_process_2                                                     19518.685871   \n",
       "total_energy_joules_process_3                                                     20913.404418   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       995.399846   \n",
       "ram_power_avg                                                                         0.635867   \n",
       "cpu_energy_total                                                                      0.002809   \n",
       "gpu_energy_total                                                                      0.019082   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002039   \n",
       "per-process_emissions_1                                                               0.002065   \n",
       "per-process_emissions_2                                                               0.002028   \n",
       "per-process_emissions_3                                                               0.002213   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            24  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                              134   \n",
       "date_time                                                        April 11, 2025 at 02:12:30 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                              100   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021951   \n",
       "total_energy_joules                                                               79024.314526   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.207329   \n",
       "joules_per_token                                                                      4.823261   \n",
       "flops_per_joule                                                               214490579.195115   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                               22.6648   \n",
       "average_latency_ms_per_batch                                                        2833.09999   \n",
       "throughput_queries_per_sec                                                            5.647524   \n",
       "throughput_tokens_per_sec                                                           722.883064   \n",
       "cpu_usage_percent                                                                          4.1   \n",
       "cpu_memory_usage_bytes                                                              1995395072   \n",
       "gpu_utilization_percent_0                                                                 10.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  74.899727   \n",
       "gpu_power_process_1                                                                  72.494017   \n",
       "gpu_power_process_2                                                                  69.415483   \n",
       "gpu_power_process_3                                                                 349.193143   \n",
       "ram_power_process_0                                                                   0.695669   \n",
       "ram_power_process_1                                                                    0.63238   \n",
       "ram_power_process_2                                                                   0.618293   \n",
       "ram_power_process_3                                                                   0.618702   \n",
       "cpu_energy_process_0                                                                  0.000719   \n",
       "cpu_energy_process_1                                                                  0.000721   \n",
       "cpu_energy_process_2                                                                  0.000723   \n",
       "cpu_energy_process_3                                                                  0.000763   \n",
       "gpu_energy_process_0                                                                  0.004668   \n",
       "gpu_energy_process_1                                                                  0.004665   \n",
       "gpu_energy_process_2                                                                  0.004667   \n",
       "gpu_energy_process_3                                                                   0.00501   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005392   \n",
       "total_energy_kwh_process_1                                                             0.00539   \n",
       "total_energy_kwh_process_2                                                            0.005394   \n",
       "total_energy_kwh_process_3                                                            0.005776   \n",
       "total_energy_joules_process_0                                                     19409.412202   \n",
       "total_energy_joules_process_1                                                     19402.612843   \n",
       "total_energy_joules_process_2                                                     19417.424063   \n",
       "total_energy_joules_process_3                                                     20794.865417   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       141.500592   \n",
       "ram_power_avg                                                                         0.641261   \n",
       "cpu_energy_total                                                                      0.002925   \n",
       "gpu_energy_total                                                                       0.01901   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002053   \n",
       "per-process_emissions_1                                                               0.002055   \n",
       "per-process_emissions_2                                                               0.002054   \n",
       "per-process_emissions_3                                                               0.002201   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            25  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                              135   \n",
       "date_time                                                        April 11, 2025 at 02:13:34 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                              200   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021558   \n",
       "total_energy_joules                                                               77607.069182   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.211115   \n",
       "joules_per_token                                                                       4.73676   \n",
       "flops_per_joule                                                               218407564.824574   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             22.773879   \n",
       "average_latency_ms_per_batch                                                       2846.734851   \n",
       "throughput_queries_per_sec                                                            5.620474   \n",
       "throughput_tokens_per_sec                                                           719.420707   \n",
       "cpu_usage_percent                                                                          3.3   \n",
       "cpu_memory_usage_bytes                                                              1999060992   \n",
       "gpu_utilization_percent_0                                                                  5.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  784.54132   \n",
       "gpu_power_process_1                                                                 788.841356   \n",
       "gpu_power_process_2                                                                 793.997062   \n",
       "gpu_power_process_3                                                                  13.512987   \n",
       "ram_power_process_0                                                                   0.696043   \n",
       "ram_power_process_1                                                                   0.625219   \n",
       "ram_power_process_2                                                                   0.619406   \n",
       "ram_power_process_3                                                                    0.62044   \n",
       "cpu_energy_process_0                                                                  0.000604   \n",
       "cpu_energy_process_1                                                                  0.000659   \n",
       "cpu_energy_process_2                                                                  0.000605   \n",
       "cpu_energy_process_3                                                                  0.000803   \n",
       "gpu_energy_process_0                                                                  0.004608   \n",
       "gpu_energy_process_1                                                                  0.004635   \n",
       "gpu_energy_process_2                                                                  0.004625   \n",
       "gpu_energy_process_3                                                                  0.005004   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000003   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005215   \n",
       "total_energy_kwh_process_1                                                            0.005297   \n",
       "total_energy_kwh_process_2                                                            0.005234   \n",
       "total_energy_kwh_process_3                                                            0.005811   \n",
       "total_energy_joules_process_0                                                     18774.637131   \n",
       "total_energy_joules_process_1                                                     19070.647317   \n",
       "total_energy_joules_process_2                                                     18842.209127   \n",
       "total_energy_joules_process_3                                                     20919.575607   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       595.223181   \n",
       "ram_power_avg                                                                         0.640277   \n",
       "cpu_energy_total                                                                      0.002671   \n",
       "gpu_energy_total                                                                      0.018871   \n",
       "ram_energy_total                                                                      0.000015   \n",
       "per-process_emissions_0                                                               0.001987   \n",
       "per-process_emissions_1                                                               0.002214   \n",
       "per-process_emissions_2                                                               0.001994   \n",
       "per-process_emissions_3                                                               0.002018   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            26  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                              136   \n",
       "date_time                                                        April 11, 2025 at 02:14:36 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                              500   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022163   \n",
       "total_energy_joules                                                               79785.192564   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.205351   \n",
       "joules_per_token                                                                      4.869702   \n",
       "flops_per_joule                                                               212445072.179372   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             22.606347   \n",
       "average_latency_ms_per_batch                                                       2825.793395   \n",
       "throughput_queries_per_sec                                                            5.662127   \n",
       "throughput_tokens_per_sec                                                           724.752207   \n",
       "cpu_usage_percent                                                                          4.0   \n",
       "cpu_memory_usage_bytes                                                              1997430784   \n",
       "gpu_utilization_percent_0                                                                  8.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 151.414568   \n",
       "gpu_power_process_1                                                                 157.860419   \n",
       "gpu_power_process_2                                                                        0.0   \n",
       "gpu_power_process_3                                                                  650.78825   \n",
       "ram_power_process_0                                                                   0.695559   \n",
       "ram_power_process_1                                                                   0.631578   \n",
       "ram_power_process_2                                                                   0.638065   \n",
       "ram_power_process_3                                                                   0.617527   \n",
       "cpu_energy_process_0                                                                  0.000736   \n",
       "cpu_energy_process_1                                                                  0.000747   \n",
       "cpu_energy_process_2                                                                  0.000822   \n",
       "cpu_energy_process_3                                                                  0.000819   \n",
       "gpu_energy_process_0                                                                  0.004679   \n",
       "gpu_energy_process_1                                                                  0.004679   \n",
       "gpu_energy_process_2                                                                  0.004679   \n",
       "gpu_energy_process_3                                                                  0.004984   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                             0.00542   \n",
       "total_energy_kwh_process_1                                                             0.00543   \n",
       "total_energy_kwh_process_2                                                            0.005505   \n",
       "total_energy_kwh_process_3                                                            0.005808   \n",
       "total_energy_joules_process_0                                                     19510.974742   \n",
       "total_energy_joules_process_1                                                      19548.20066   \n",
       "total_energy_joules_process_2                                                      19818.57431   \n",
       "total_energy_joules_process_3                                                     20907.442853   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       240.015809   \n",
       "ram_power_avg                                                                         0.645682   \n",
       "cpu_energy_total                                                                      0.003124   \n",
       "gpu_energy_total                                                                      0.019023   \n",
       "ram_energy_total                                                                      0.000015   \n",
       "per-process_emissions_0                                                               0.002069   \n",
       "per-process_emissions_1                                                               0.002065   \n",
       "per-process_emissions_2                                                               0.002097   \n",
       "per-process_emissions_3                                                               0.002212   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            27  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                              137   \n",
       "date_time                                                        April 11, 2025 at 02:15:38 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                               20   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022313   \n",
       "total_energy_joules                                                                80326.29213   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.203968   \n",
       "joules_per_token                                                                      4.902728   \n",
       "flops_per_joule                                                               211013984.881239   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              23.66417   \n",
       "average_latency_ms_per_batch                                                       2958.021251   \n",
       "throughput_queries_per_sec                                                            5.409021   \n",
       "throughput_tokens_per_sec                                                           692.354728   \n",
       "cpu_usage_percent                                                                          3.5   \n",
       "cpu_memory_usage_bytes                                                              2021974016   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1161.348553   \n",
       "gpu_power_process_1                                                                 998.434903   \n",
       "gpu_power_process_2                                                                1060.037074   \n",
       "gpu_power_process_3                                                                 501.323353   \n",
       "ram_power_process_0                                                                   0.704543   \n",
       "ram_power_process_1                                                                   0.659151   \n",
       "ram_power_process_2                                                                   0.677509   \n",
       "ram_power_process_3                                                                   0.669405   \n",
       "cpu_energy_process_0                                                                  0.000691   \n",
       "cpu_energy_process_1                                                                  0.000688   \n",
       "cpu_energy_process_2                                                                  0.000674   \n",
       "cpu_energy_process_3                                                                  0.000772   \n",
       "gpu_energy_process_0                                                                   0.00479   \n",
       "gpu_energy_process_1                                                                  0.004807   \n",
       "gpu_energy_process_2                                                                  0.004744   \n",
       "gpu_energy_process_3                                                                  0.005131   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005484   \n",
       "total_energy_kwh_process_1                                                            0.005499   \n",
       "total_energy_kwh_process_2                                                            0.005422   \n",
       "total_energy_kwh_process_3                                                            0.005908   \n",
       "total_energy_joules_process_0                                                     19743.540879   \n",
       "total_energy_joules_process_1                                                     19796.753943   \n",
       "total_energy_joules_process_2                                                     19518.158547   \n",
       "total_energy_joules_process_3                                                     21267.838761   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       930.285971   \n",
       "ram_power_avg                                                                         0.677652   \n",
       "cpu_energy_total                                                                      0.002825   \n",
       "gpu_energy_total                                                                      0.019471   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002251   \n",
       "per-process_emissions_1                                                               0.002089   \n",
       "per-process_emissions_2                                                               0.002095   \n",
       "per-process_emissions_3                                                               0.002065   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            28  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                              138   \n",
       "date_time                                                        April 11, 2025 at 02:16:46 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022607   \n",
       "total_energy_joules                                                                81385.43303   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.201314   \n",
       "joules_per_token                                                                      4.967373   \n",
       "flops_per_joule                                                               208267872.541956   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.907777   \n",
       "average_latency_ms_per_batch                                                       2988.472176   \n",
       "throughput_queries_per_sec                                                            5.353906   \n",
       "throughput_tokens_per_sec                                                           685.300006   \n",
       "cpu_usage_percent                                                                          3.0   \n",
       "cpu_memory_usage_bytes                                                              2016477184   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 850.569025   \n",
       "gpu_power_process_1                                                                1979.221778   \n",
       "gpu_power_process_2                                                                        0.0   \n",
       "gpu_power_process_3                                                                 442.503424   \n",
       "ram_power_process_0                                                                   0.701859   \n",
       "ram_power_process_1                                                                     0.6666   \n",
       "ram_power_process_2                                                                   0.669771   \n",
       "ram_power_process_3                                                                   0.669248   \n",
       "cpu_energy_process_0                                                                  0.000745   \n",
       "cpu_energy_process_1                                                                   0.00072   \n",
       "cpu_energy_process_2                                                                  0.000781   \n",
       "cpu_energy_process_3                                                                  0.000816   \n",
       "gpu_energy_process_0                                                                  0.004794   \n",
       "gpu_energy_process_1                                                                  0.004797   \n",
       "gpu_energy_process_2                                                                   0.00482   \n",
       "gpu_energy_process_3                                                                  0.005118   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005543   \n",
       "total_energy_kwh_process_1                                                            0.005521   \n",
       "total_energy_kwh_process_2                                                            0.005605   \n",
       "total_energy_kwh_process_3                                                            0.005938   \n",
       "total_energy_joules_process_0                                                     19954.737589   \n",
       "total_energy_joules_process_1                                                     19875.208052   \n",
       "total_energy_joules_process_2                                                     20178.213571   \n",
       "total_energy_joules_process_3                                                     21377.273819   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       818.073557   \n",
       "ram_power_avg                                                                         0.676869   \n",
       "cpu_energy_total                                                                      0.003062   \n",
       "gpu_energy_total                                                                      0.019529   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002135   \n",
       "per-process_emissions_1                                                               0.002103   \n",
       "per-process_emissions_2                                                               0.002262   \n",
       "per-process_emissions_3                                                               0.002112   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            29  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                              139   \n",
       "date_time                                                        April 11, 2025 at 02:17:47 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                              100   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022371   \n",
       "total_energy_joules                                                               80534.828637   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                       0.20344   \n",
       "joules_per_token                                                                      4.915456   \n",
       "flops_per_joule                                                               210467586.260611   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.561953   \n",
       "average_latency_ms_per_batch                                                       2945.244112   \n",
       "throughput_queries_per_sec                                                            5.432487   \n",
       "throughput_tokens_per_sec                                                           695.358321   \n",
       "cpu_usage_percent                                                                          3.4   \n",
       "cpu_memory_usage_bytes                                                              2019176448   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 823.337213   \n",
       "gpu_power_process_1                                                                  730.47263   \n",
       "gpu_power_process_2                                                                 702.759521   \n",
       "gpu_power_process_3                                                                 466.270994   \n",
       "ram_power_process_0                                                                   0.703181   \n",
       "ram_power_process_1                                                                   0.668215   \n",
       "ram_power_process_2                                                                   0.662082   \n",
       "ram_power_process_3                                                                   0.676116   \n",
       "cpu_energy_process_0                                                                  0.000691   \n",
       "cpu_energy_process_1                                                                  0.000696   \n",
       "cpu_energy_process_2                                                                  0.000701   \n",
       "cpu_energy_process_3                                                                  0.000847   \n",
       "gpu_energy_process_0                                                                  0.004743   \n",
       "gpu_energy_process_1                                                                  0.004751   \n",
       "gpu_energy_process_2                                                                   0.00479   \n",
       "gpu_energy_process_3                                                                  0.005135   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005438   \n",
       "total_energy_kwh_process_1                                                            0.005451   \n",
       "total_energy_kwh_process_2                                                            0.005495   \n",
       "total_energy_kwh_process_3                                                            0.005987   \n",
       "total_energy_joules_process_0                                                      19576.73708   \n",
       "total_energy_joules_process_1                                                     19622.485468   \n",
       "total_energy_joules_process_2                                                     19782.550376   \n",
       "total_energy_joules_process_3                                                     21553.055713   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       680.710089   \n",
       "ram_power_avg                                                                         0.677398   \n",
       "cpu_energy_total                                                                      0.002935   \n",
       "gpu_energy_total                                                                      0.019418   \n",
       "ram_energy_total                                                                      0.000018   \n",
       "per-process_emissions_0                                                               0.002281   \n",
       "per-process_emissions_1                                                               0.002076   \n",
       "per-process_emissions_2                                                               0.002072   \n",
       "per-process_emissions_3                                                               0.002093   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            30  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                              140   \n",
       "date_time                                                        April 11, 2025 at 02:18:50 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                              200   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022527   \n",
       "total_energy_joules                                                               81096.772114   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                       0.20203   \n",
       "joules_per_token                                                                      4.949754   \n",
       "flops_per_joule                                                               209009194.217265   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.840143   \n",
       "average_latency_ms_per_batch                                                       2980.017825   \n",
       "throughput_queries_per_sec                                                            5.369095   \n",
       "throughput_tokens_per_sec                                                           687.244211   \n",
       "cpu_usage_percent                                                                          3.3   \n",
       "cpu_memory_usage_bytes                                                              2020286464   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 865.194509   \n",
       "gpu_power_process_1                                                                 805.794565   \n",
       "gpu_power_process_2                                                                 799.459307   \n",
       "gpu_power_process_3                                                                  52.696948   \n",
       "ram_power_process_0                                                                   0.703116   \n",
       "ram_power_process_1                                                                   0.663158   \n",
       "ram_power_process_2                                                                   0.669469   \n",
       "ram_power_process_3                                                                   0.663536   \n",
       "cpu_energy_process_0                                                                  0.000711   \n",
       "cpu_energy_process_1                                                                  0.000774   \n",
       "cpu_energy_process_2                                                                  0.000713   \n",
       "cpu_energy_process_3                                                                  0.000889   \n",
       "gpu_energy_process_0                                                                   0.00476   \n",
       "gpu_energy_process_1                                                                   0.00476   \n",
       "gpu_energy_process_2                                                                   0.00476   \n",
       "gpu_energy_process_3                                                                  0.005145   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005475   \n",
       "total_energy_kwh_process_1                                                            0.005537   \n",
       "total_energy_kwh_process_2                                                            0.005476   \n",
       "total_energy_kwh_process_3                                                            0.006038   \n",
       "total_energy_joules_process_0                                                     19709.793915   \n",
       "total_energy_joules_process_1                                                     19934.468602   \n",
       "total_energy_joules_process_2                                                     19714.900987   \n",
       "total_energy_joules_process_3                                                     21737.608609   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       630.786332   \n",
       "ram_power_avg                                                                          0.67482   \n",
       "cpu_energy_total                                                                      0.003087   \n",
       "gpu_energy_total                                                                      0.019424   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                                 0.0023   \n",
       "per-process_emissions_1                                                               0.002109   \n",
       "per-process_emissions_2                                                               0.002086   \n",
       "per-process_emissions_3                                                               0.002086   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            31  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                              141   \n",
       "date_time                                                        April 11, 2025 at 02:19:51 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                              500   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022292   \n",
       "total_energy_joules                                                               80252.705575   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.204155   \n",
       "joules_per_token                                                                      4.898236   \n",
       "flops_per_joule                                                               211207471.096386   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.885973   \n",
       "average_latency_ms_per_batch                                                       2985.746645   \n",
       "throughput_queries_per_sec                                                            5.358794   \n",
       "throughput_tokens_per_sec                                                            685.92558   \n",
       "cpu_usage_percent                                                                          3.4   \n",
       "cpu_memory_usage_bytes                                                              2017255424   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  932.97171   \n",
       "gpu_power_process_1                                                                        0.0   \n",
       "gpu_power_process_2                                                                 933.957899   \n",
       "gpu_power_process_3                                                                   471.7604   \n",
       "ram_power_process_0                                                                   0.702168   \n",
       "ram_power_process_1                                                                   0.664437   \n",
       "ram_power_process_2                                                                   0.665169   \n",
       "ram_power_process_3                                                                   0.664172   \n",
       "cpu_energy_process_0                                                                  0.000684   \n",
       "cpu_energy_process_1                                                                  0.000729   \n",
       "cpu_energy_process_2                                                                  0.000685   \n",
       "cpu_energy_process_3                                                                   0.00077   \n",
       "gpu_energy_process_0                                                                  0.004773   \n",
       "gpu_energy_process_1                                                                  0.004787   \n",
       "gpu_energy_process_2                                                                  0.004749   \n",
       "gpu_energy_process_3                                                                  0.005098   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005461   \n",
       "total_energy_kwh_process_1                                                            0.005521   \n",
       "total_energy_kwh_process_2                                                            0.005438   \n",
       "total_energy_kwh_process_3                                                            0.005872   \n",
       "total_energy_joules_process_0                                                      19659.79529   \n",
       "total_energy_joules_process_1                                                     19874.875654   \n",
       "total_energy_joules_process_2                                                     19578.297702   \n",
       "total_energy_joules_process_3                                                     21139.736929   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       584.672502   \n",
       "ram_power_avg                                                                         0.673987   \n",
       "cpu_energy_total                                                                      0.002869   \n",
       "gpu_energy_total                                                                      0.019407   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002103   \n",
       "per-process_emissions_1                                                               0.002072   \n",
       "per-process_emissions_2                                                                0.00208   \n",
       "per-process_emissions_3                                                               0.002237   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            32  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                              142   \n",
       "date_time                                                        April 11, 2025 at 02:20:54 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                               20   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022349   \n",
       "total_energy_joules                                                               80457.547565   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.203635   \n",
       "joules_per_token                                                                      4.910739   \n",
       "flops_per_joule                                                                210669744.55767   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.299355   \n",
       "average_latency_ms_per_batch                                                       2912.419385   \n",
       "throughput_queries_per_sec                                                            5.493714   \n",
       "throughput_tokens_per_sec                                                           703.195429   \n",
       "cpu_usage_percent                                                                          3.8   \n",
       "cpu_memory_usage_bytes                                                              2019057664   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 737.530858   \n",
       "gpu_power_process_1                                                                  24.604144   \n",
       "gpu_power_process_2                                                                 655.269069   \n",
       "gpu_power_process_3                                                                  480.62037   \n",
       "ram_power_process_0                                                                   0.703071   \n",
       "ram_power_process_1                                                                   0.670727   \n",
       "ram_power_process_2                                                                   0.667106   \n",
       "ram_power_process_3                                                                   0.669482   \n",
       "cpu_energy_process_0                                                                  0.000691   \n",
       "cpu_energy_process_1                                                                  0.000765   \n",
       "cpu_energy_process_2                                                                  0.000742   \n",
       "cpu_energy_process_3                                                                  0.000795   \n",
       "gpu_energy_process_0                                                                  0.004655   \n",
       "gpu_energy_process_1                                                                  0.004785   \n",
       "gpu_energy_process_2                                                                  0.004796   \n",
       "gpu_energy_process_3                                                                  0.005104   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                             0.00535   \n",
       "total_energy_kwh_process_1                                                            0.005554   \n",
       "total_energy_kwh_process_2                                                            0.005542   \n",
       "total_energy_kwh_process_3                                                            0.005903   \n",
       "total_energy_joules_process_0                                                     19260.021787   \n",
       "total_energy_joules_process_1                                                     19995.542592   \n",
       "total_energy_joules_process_2                                                     19949.876927   \n",
       "total_energy_joules_process_3                                                     21252.106258   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        474.50611   \n",
       "ram_power_avg                                                                         0.677596   \n",
       "cpu_energy_total                                                                      0.002992   \n",
       "gpu_energy_total                                                                       0.01934   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002249   \n",
       "per-process_emissions_1                                                               0.002116   \n",
       "per-process_emissions_2                                                               0.002111   \n",
       "per-process_emissions_3                                                               0.002038   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            33  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                              143   \n",
       "date_time                                                        April 11, 2025 at 02:21:57 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                       0.02246   \n",
       "total_energy_joules                                                                 80855.2652   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.202634   \n",
       "joules_per_token                                                                      4.935014   \n",
       "flops_per_joule                                                               209633484.611915   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.477822   \n",
       "average_latency_ms_per_batch                                                       2934.727713   \n",
       "throughput_queries_per_sec                                                            5.451954   \n",
       "throughput_tokens_per_sec                                                            697.85009   \n",
       "cpu_usage_percent                                                                          3.8   \n",
       "cpu_memory_usage_bytes                                                              2020814848   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 833.971863   \n",
       "gpu_power_process_1                                                                 721.532522   \n",
       "gpu_power_process_2                                                                 613.832213   \n",
       "gpu_power_process_3                                                                 498.322801   \n",
       "ram_power_process_0                                                                   0.704103   \n",
       "ram_power_process_1                                                                   0.667624   \n",
       "ram_power_process_2                                                                    0.67189   \n",
       "ram_power_process_3                                                                   0.664929   \n",
       "cpu_energy_process_0                                                                  0.000754   \n",
       "cpu_energy_process_1                                                                  0.000775   \n",
       "cpu_energy_process_2                                                                  0.000784   \n",
       "cpu_energy_process_3                                                                   0.00079   \n",
       "gpu_energy_process_0                                                                  0.004696   \n",
       "gpu_energy_process_1                                                                  0.004759   \n",
       "gpu_energy_process_2                                                                  0.004792   \n",
       "gpu_energy_process_3                                                                  0.005093   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005454   \n",
       "total_energy_kwh_process_1                                                            0.005538   \n",
       "total_energy_kwh_process_2                                                             0.00558   \n",
       "total_energy_kwh_process_3                                                            0.005887   \n",
       "total_energy_joules_process_0                                                     19635.156896   \n",
       "total_energy_joules_process_1                                                     19937.843552   \n",
       "total_energy_joules_process_2                                                     20087.509267   \n",
       "total_energy_joules_process_3                                                     21194.755485   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        666.91485   \n",
       "ram_power_avg                                                                         0.677137   \n",
       "cpu_energy_total                                                                      0.003103   \n",
       "gpu_energy_total                                                                       0.01934   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002078   \n",
       "per-process_emissions_1                                                               0.002243   \n",
       "per-process_emissions_2                                                               0.002126   \n",
       "per-process_emissions_3                                                                0.00211   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            34  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                              144   \n",
       "date_time                                                        April 11, 2025 at 02:22:59 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                              100   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022236   \n",
       "total_energy_joules                                                                80049.35023   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.204674   \n",
       "joules_per_token                                                                      4.885825   \n",
       "flops_per_joule                                                               211744017.213695   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.895986   \n",
       "average_latency_ms_per_batch                                                       2986.998288   \n",
       "throughput_queries_per_sec                                                            5.356548   \n",
       "throughput_tokens_per_sec                                                           685.638157   \n",
       "cpu_usage_percent                                                                          3.7   \n",
       "cpu_memory_usage_bytes                                                              2017898496   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  12633243648   \n",
       "gpu_max_memory_reserved_bytes                                                      12633243648   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 840.144888   \n",
       "gpu_power_process_1                                                                 1161.29246   \n",
       "gpu_power_process_2                                                                1723.878013   \n",
       "gpu_power_process_3                                                                 451.217783   \n",
       "ram_power_process_0                                                                   0.703332   \n",
       "ram_power_process_1                                                                   0.668508   \n",
       "ram_power_process_2                                                                   0.668924   \n",
       "ram_power_process_3                                                                   0.667959   \n",
       "cpu_energy_process_0                                                                  0.000685   \n",
       "cpu_energy_process_1                                                                  0.000632   \n",
       "cpu_energy_process_2                                                                  0.000663   \n",
       "cpu_energy_process_3                                                                  0.000764   \n",
       "gpu_energy_process_0                                                                  0.004805   \n",
       "gpu_energy_process_1                                                                  0.004775   \n",
       "gpu_energy_process_2                                                                  0.004775   \n",
       "gpu_energy_process_3                                                                  0.005121   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005495   \n",
       "total_energy_kwh_process_1                                                             0.00541   \n",
       "total_energy_kwh_process_2                                                            0.005442   \n",
       "total_energy_kwh_process_3                                                            0.005889   \n",
       "total_energy_joules_process_0                                                     19781.212377   \n",
       "total_energy_joules_process_1                                                     19477.738854   \n",
       "total_energy_joules_process_2                                                     19590.509753   \n",
       "total_energy_joules_process_3                                                     21199.889247   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1044.133286   \n",
       "ram_power_avg                                                                         0.677181   \n",
       "cpu_energy_total                                                                      0.002743   \n",
       "gpu_energy_total                                                                      0.019476   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002093   \n",
       "per-process_emissions_1                                                               0.002073   \n",
       "per-process_emissions_2                                                               0.002061   \n",
       "per-process_emissions_3                                                               0.002243   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            35  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                              145   \n",
       "date_time                                                        April 11, 2025 at 02:24:04 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                              200   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022204   \n",
       "total_energy_joules                                                               79935.142249   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.204966   \n",
       "joules_per_token                                                                      4.878854   \n",
       "flops_per_joule                                                               212046548.191128   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              23.82698   \n",
       "average_latency_ms_per_batch                                                       2978.372542   \n",
       "throughput_queries_per_sec                                                            5.372061   \n",
       "throughput_tokens_per_sec                                                           687.623852   \n",
       "cpu_usage_percent                                                                          3.9   \n",
       "cpu_memory_usage_bytes                                                              2019971072   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1024.973746   \n",
       "gpu_power_process_1                                                                        0.0   \n",
       "gpu_power_process_2                                                                1029.978916   \n",
       "gpu_power_process_3                                                                 397.348075   \n",
       "ram_power_process_0                                                                   0.703428   \n",
       "ram_power_process_1                                                                   0.663785   \n",
       "ram_power_process_2                                                                   0.664714   \n",
       "ram_power_process_3                                                                   0.664591   \n",
       "cpu_energy_process_0                                                                  0.000646   \n",
       "cpu_energy_process_1                                                                  0.000687   \n",
       "cpu_energy_process_2                                                                  0.000647   \n",
       "cpu_energy_process_3                                                                  0.000736   \n",
       "gpu_energy_process_0                                                                   0.00478   \n",
       "gpu_energy_process_1                                                                  0.004793   \n",
       "gpu_energy_process_2                                                                   0.00478   \n",
       "gpu_energy_process_3                                                                  0.005121   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005429   \n",
       "total_energy_kwh_process_1                                                            0.005483   \n",
       "total_energy_kwh_process_2                                                             0.00543   \n",
       "total_energy_kwh_process_3                                                            0.005861   \n",
       "total_energy_joules_process_0                                                     19545.438086   \n",
       "total_energy_joules_process_1                                                     19739.917487   \n",
       "total_energy_joules_process_2                                                     19548.685151   \n",
       "total_energy_joules_process_3                                                     21101.101525   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       613.075184   \n",
       "ram_power_avg                                                                          0.67413   \n",
       "cpu_energy_total                                                                      0.002715   \n",
       "gpu_energy_total                                                                      0.019473   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002068   \n",
       "per-process_emissions_1                                                               0.002233   \n",
       "per-process_emissions_2                                                               0.002069   \n",
       "per-process_emissions_3                                                               0.002089   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            36  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                              146   \n",
       "date_time                                                        April 11, 2025 at 02:25:08 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                              500   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022546   \n",
       "total_energy_joules                                                               81165.046053   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                       0.20186   \n",
       "joules_per_token                                                                      4.953921   \n",
       "flops_per_joule                                                               208833381.085398   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             24.004103   \n",
       "average_latency_ms_per_batch                                                       3000.512829   \n",
       "throughput_queries_per_sec                                                            5.332422   \n",
       "throughput_tokens_per_sec                                                            682.54999   \n",
       "cpu_usage_percent                                                                          2.9   \n",
       "cpu_memory_usage_bytes                                                              2018074624   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                        0.0   \n",
       "gpu_power_process_1                                                                  98.379849   \n",
       "gpu_power_process_2                                                                   8.759803   \n",
       "gpu_power_process_3                                                                 395.676137   \n",
       "ram_power_process_0                                                                   0.703474   \n",
       "ram_power_process_1                                                                   0.671883   \n",
       "ram_power_process_2                                                                   0.664699   \n",
       "ram_power_process_3                                                                   0.665002   \n",
       "cpu_energy_process_0                                                                   0.00079   \n",
       "cpu_energy_process_1                                                                  0.000716   \n",
       "cpu_energy_process_2                                                                  0.000798   \n",
       "cpu_energy_process_3                                                                  0.000817   \n",
       "gpu_energy_process_0                                                                   0.00478   \n",
       "gpu_energy_process_1                                                                  0.004774   \n",
       "gpu_energy_process_2                                                                  0.004784   \n",
       "gpu_energy_process_3                                                                  0.005072   \n",
       "ram_energy_process_0                                                                  0.000005   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005574   \n",
       "total_energy_kwh_process_1                                                            0.005493   \n",
       "total_energy_kwh_process_2                                                            0.005586   \n",
       "total_energy_kwh_process_3                                                            0.005893   \n",
       "total_energy_joules_process_0                                                     20066.680423   \n",
       "total_energy_joules_process_1                                                     19775.650822   \n",
       "total_energy_joules_process_2                                                     20108.210403   \n",
       "total_energy_joules_process_3                                                     21214.504404   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       125.703947   \n",
       "ram_power_avg                                                                         0.676264   \n",
       "cpu_energy_total                                                                       0.00312   \n",
       "gpu_energy_total                                                                      0.019409   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002123   \n",
       "per-process_emissions_1                                                               0.002245   \n",
       "per-process_emissions_2                                                               0.002128   \n",
       "per-process_emissions_3                                                               0.002093   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            37  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                              147   \n",
       "date_time                                                        April 11, 2025 at 02:26:16 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                               20   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                       0.02255   \n",
       "total_energy_joules                                                               81180.686997   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.201821   \n",
       "joules_per_token                                                                      4.954876   \n",
       "flops_per_joule                                                               208793145.515737   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             24.247811   \n",
       "average_latency_ms_per_batch                                                       3030.976345   \n",
       "throughput_queries_per_sec                                                            5.278827   \n",
       "throughput_tokens_per_sec                                                           675.689866   \n",
       "cpu_usage_percent                                                                          3.8   \n",
       "cpu_memory_usage_bytes                                                              2020343808   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 1702.06151   \n",
       "gpu_power_process_1                                                                 101.913394   \n",
       "gpu_power_process_2                                                                        0.0   \n",
       "gpu_power_process_3                                                                 413.213713   \n",
       "ram_power_process_0                                                                   0.704278   \n",
       "ram_power_process_1                                                                   0.663054   \n",
       "ram_power_process_2                                                                   0.668273   \n",
       "ram_power_process_3                                                                   0.671436   \n",
       "cpu_energy_process_0                                                                  0.000744   \n",
       "cpu_energy_process_1                                                                  0.000745   \n",
       "cpu_energy_process_2                                                                  0.000815   \n",
       "cpu_energy_process_3                                                                  0.000824   \n",
       "gpu_energy_process_0                                                                  0.004769   \n",
       "gpu_energy_process_1                                                                  0.004752   \n",
       "gpu_energy_process_2                                                                  0.004769   \n",
       "gpu_energy_process_3                                                                  0.005115   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005518   \n",
       "total_energy_kwh_process_1                                                            0.005501   \n",
       "total_energy_kwh_process_2                                                            0.005588   \n",
       "total_energy_kwh_process_3                                                            0.005943   \n",
       "total_energy_joules_process_0                                                     19864.754521   \n",
       "total_energy_joules_process_1                                                     19802.264827   \n",
       "total_energy_joules_process_2                                                     20117.896841   \n",
       "total_energy_joules_process_3                                                     21395.770807   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       554.297154   \n",
       "ram_power_avg                                                                          0.67676   \n",
       "cpu_energy_total                                                                      0.003128   \n",
       "gpu_energy_total                                                                      0.019406   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002102   \n",
       "per-process_emissions_1                                                               0.002129   \n",
       "per-process_emissions_2                                                               0.002095   \n",
       "per-process_emissions_3                                                               0.002264   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            38  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                              148   \n",
       "date_time                                                        April 11, 2025 at 02:27:18 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022035   \n",
       "total_energy_joules                                                                79326.35121   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.206539   \n",
       "joules_per_token                                                                      4.841696   \n",
       "flops_per_joule                                                               213673901.983323   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              23.55748   \n",
       "average_latency_ms_per_batch                                                       2944.685004   \n",
       "throughput_queries_per_sec                                                            5.433518   \n",
       "throughput_tokens_per_sec                                                           695.490349   \n",
       "cpu_usage_percent                                                                          3.7   \n",
       "cpu_memory_usage_bytes                                                              2019336192   \n",
       "gpu_utilization_percent_0                                                                  4.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 907.576366   \n",
       "gpu_power_process_1                                                                1262.458064   \n",
       "gpu_power_process_2                                                                 806.913317   \n",
       "gpu_power_process_3                                                                  10.513689   \n",
       "ram_power_process_0                                                                   0.702796   \n",
       "ram_power_process_1                                                                    0.66352   \n",
       "ram_power_process_2                                                                   0.667314   \n",
       "ram_power_process_3                                                                   0.669714   \n",
       "cpu_energy_process_0                                                                  0.000674   \n",
       "cpu_energy_process_1                                                                  0.000676   \n",
       "cpu_energy_process_2                                                                  0.000677   \n",
       "cpu_energy_process_3                                                                   0.00079   \n",
       "gpu_energy_process_0                                                                  0.004719   \n",
       "gpu_energy_process_1                                                                  0.004714   \n",
       "gpu_energy_process_2                                                                  0.004702   \n",
       "gpu_energy_process_3                                                                  0.005067   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005397   \n",
       "total_energy_kwh_process_1                                                            0.005394   \n",
       "total_energy_kwh_process_2                                                            0.005382   \n",
       "total_energy_kwh_process_3                                                            0.005862   \n",
       "total_energy_joules_process_0                                                     19429.101109   \n",
       "total_energy_joules_process_1                                                     19418.099808   \n",
       "total_energy_joules_process_2                                                     19376.997128   \n",
       "total_energy_joules_process_3                                                     21102.153165   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       746.865359   \n",
       "ram_power_avg                                                                         0.675836   \n",
       "cpu_energy_total                                                                      0.002817   \n",
       "gpu_energy_total                                                                      0.019202   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002056   \n",
       "per-process_emissions_1                                                               0.002055   \n",
       "per-process_emissions_2                                                                0.00205   \n",
       "per-process_emissions_3                                                               0.002233   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            39  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                              149   \n",
       "date_time                                                        April 11, 2025 at 02:28:19 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                              100   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022381   \n",
       "total_energy_joules                                                               80571.964142   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.203346   \n",
       "joules_per_token                                                                      4.917722   \n",
       "flops_per_joule                                                               210370582.046835   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             24.153399   \n",
       "average_latency_ms_per_batch                                                       3019.174914   \n",
       "throughput_queries_per_sec                                                            5.299461   \n",
       "throughput_tokens_per_sec                                                            678.33102   \n",
       "cpu_usage_percent                                                                          3.2   \n",
       "cpu_memory_usage_bytes                                                              2019917824   \n",
       "gpu_utilization_percent_0                                                                  4.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                        0.0   \n",
       "gpu_power_process_1                                                                 113.351432   \n",
       "gpu_power_process_2                                                                 124.546594   \n",
       "gpu_power_process_3                                                                 474.412727   \n",
       "ram_power_process_0                                                                   0.704071   \n",
       "ram_power_process_1                                                                   0.662325   \n",
       "ram_power_process_2                                                                   0.666161   \n",
       "ram_power_process_3                                                                   0.670774   \n",
       "cpu_energy_process_0                                                                  0.000796   \n",
       "cpu_energy_process_1                                                                   0.00072   \n",
       "cpu_energy_process_2                                                                   0.00072   \n",
       "cpu_energy_process_3                                                                  0.000764   \n",
       "gpu_energy_process_0                                                                  0.004774   \n",
       "gpu_energy_process_1                                                                  0.004776   \n",
       "gpu_energy_process_2                                                                  0.004774   \n",
       "gpu_energy_process_3                                                                  0.005039   \n",
       "ram_energy_process_0                                                                  0.000005   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005575   \n",
       "total_energy_kwh_process_1                                                              0.0055   \n",
       "total_energy_kwh_process_2                                                            0.005498   \n",
       "total_energy_kwh_process_3                                                            0.005807   \n",
       "total_energy_joules_process_0                                                     20071.427558   \n",
       "total_energy_joules_process_1                                                     19800.535796   \n",
       "total_energy_joules_process_2                                                     19793.391684   \n",
       "total_energy_joules_process_3                                                     20906.609104   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       178.077688   \n",
       "ram_power_avg                                                                         0.675833   \n",
       "cpu_energy_total                                                                         0.003   \n",
       "gpu_energy_total                                                                      0.019364   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002124   \n",
       "per-process_emissions_1                                                               0.002095   \n",
       "per-process_emissions_2                                                               0.002212   \n",
       "per-process_emissions_3                                                               0.002095   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            40  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                              150   \n",
       "date_time                                                        April 11, 2025 at 02:29:23 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                              200   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022374   \n",
       "total_energy_joules                                                               80546.838823   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                       0.20341   \n",
       "joules_per_token                                                                      4.916189   \n",
       "flops_per_joule                                                               210436203.840162   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              24.07616   \n",
       "average_latency_ms_per_batch                                                       3009.520001   \n",
       "throughput_queries_per_sec                                                            5.316462   \n",
       "throughput_tokens_per_sec                                                            680.50719   \n",
       "cpu_usage_percent                                                                          3.5   \n",
       "cpu_memory_usage_bytes                                                              2017144832   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                        0.0   \n",
       "gpu_power_process_1                                                                  94.053829   \n",
       "gpu_power_process_2                                                                1490.421123   \n",
       "gpu_power_process_3                                                                  536.56597   \n",
       "ram_power_process_0                                                                   0.703132   \n",
       "ram_power_process_1                                                                   0.669359   \n",
       "ram_power_process_2                                                                   0.661823   \n",
       "ram_power_process_3                                                                   0.680599   \n",
       "cpu_energy_process_0                                                                  0.000804   \n",
       "cpu_energy_process_1                                                                  0.000726   \n",
       "cpu_energy_process_2                                                                   0.00061   \n",
       "cpu_energy_process_3                                                                  0.000798   \n",
       "gpu_energy_process_0                                                                  0.004762   \n",
       "gpu_energy_process_1                                                                  0.004768   \n",
       "gpu_energy_process_2                                                                  0.004713   \n",
       "gpu_energy_process_3                                                                  0.005175   \n",
       "ram_energy_process_0                                                                  0.000005   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005571   \n",
       "total_energy_kwh_process_1                                                            0.005498   \n",
       "total_energy_kwh_process_2                                                            0.005327   \n",
       "total_energy_kwh_process_3                                                            0.005978   \n",
       "total_energy_joules_process_0                                                     20054.398769   \n",
       "total_energy_joules_process_1                                                     19792.426539   \n",
       "total_energy_joules_process_2                                                     19178.647159   \n",
       "total_energy_joules_process_3                                                     21521.366357   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        530.26023   \n",
       "ram_power_avg                                                                         0.678728   \n",
       "cpu_energy_total                                                                      0.002939   \n",
       "gpu_energy_total                                                                      0.019419   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002277   \n",
       "per-process_emissions_1                                                               0.002122   \n",
       "per-process_emissions_2                                                               0.002094   \n",
       "per-process_emissions_3                                                               0.002029   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            41  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                              151   \n",
       "date_time                                                        April 11, 2025 at 02:30:26 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                              500   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022143   \n",
       "total_energy_joules                                                               79714.965563   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.205532   \n",
       "joules_per_token                                                                      4.865415   \n",
       "flops_per_joule                                                               212632231.269686   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.535471   \n",
       "average_latency_ms_per_batch                                                       2941.933847   \n",
       "throughput_queries_per_sec                                                              5.4386   \n",
       "throughput_tokens_per_sec                                                           696.140738   \n",
       "cpu_usage_percent                                                                          3.3   \n",
       "cpu_memory_usage_bytes                                                              2019106816   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1296.061967   \n",
       "gpu_power_process_1                                                                1646.512799   \n",
       "gpu_power_process_2                                                                  47.808284   \n",
       "gpu_power_process_3                                                                 323.136095   \n",
       "ram_power_process_0                                                                   0.703952   \n",
       "ram_power_process_1                                                                   0.663025   \n",
       "ram_power_process_2                                                                   0.668996   \n",
       "ram_power_process_3                                                                   0.663465   \n",
       "cpu_energy_process_0                                                                  0.000639   \n",
       "cpu_energy_process_1                                                                  0.000669   \n",
       "cpu_energy_process_2                                                                  0.000723   \n",
       "cpu_energy_process_3                                                                  0.000764   \n",
       "gpu_energy_process_0                                                                  0.004764   \n",
       "gpu_energy_process_1                                                                  0.004736   \n",
       "gpu_energy_process_2                                                                  0.004761   \n",
       "gpu_energy_process_3                                                                  0.005069   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005407   \n",
       "total_energy_kwh_process_1                                                            0.005409   \n",
       "total_energy_kwh_process_2                                                            0.005488   \n",
       "total_energy_kwh_process_3                                                            0.005838   \n",
       "total_energy_joules_process_0                                                     19466.226544   \n",
       "total_energy_joules_process_1                                                     19473.943975   \n",
       "total_energy_joules_process_2                                                     19758.447455   \n",
       "total_energy_joules_process_3                                                     21016.347588   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       828.379786   \n",
       "ram_power_avg                                                                          0.67486   \n",
       "cpu_energy_total                                                                      0.002796   \n",
       "gpu_energy_total                                                                      0.019331   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002224   \n",
       "per-process_emissions_1                                                                0.00206   \n",
       "per-process_emissions_2                                                               0.002091   \n",
       "per-process_emissions_3                                                               0.002061   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            42  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                              152   \n",
       "date_time                                                        April 11, 2025 at 02:31:29 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                               20   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022079   \n",
       "total_energy_joules                                                               79485.169526   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.206127   \n",
       "joules_per_token                                                                       4.85139   \n",
       "flops_per_joule                                                               213246962.851946   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.584799   \n",
       "average_latency_ms_per_batch                                                       2948.099845   \n",
       "throughput_queries_per_sec                                                            5.427225   \n",
       "throughput_tokens_per_sec                                                           694.684749   \n",
       "cpu_usage_percent                                                                          3.2   \n",
       "cpu_memory_usage_bytes                                                              2018009088   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                 94.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1246.937856   \n",
       "gpu_power_process_1                                                                1950.269423   \n",
       "gpu_power_process_2                                                                 875.249088   \n",
       "gpu_power_process_3                                                                 442.846654   \n",
       "ram_power_process_0                                                                   0.703468   \n",
       "ram_power_process_1                                                                   0.674951   \n",
       "ram_power_process_2                                                                   0.673327   \n",
       "ram_power_process_3                                                                   0.669574   \n",
       "cpu_energy_process_0                                                                  0.000628   \n",
       "cpu_energy_process_1                                                                  0.000662   \n",
       "cpu_energy_process_2                                                                  0.000673   \n",
       "cpu_energy_process_3                                                                   0.00075   \n",
       "gpu_energy_process_0                                                                  0.004759   \n",
       "gpu_energy_process_1                                                                  0.004747   \n",
       "gpu_energy_process_2                                                                  0.004767   \n",
       "gpu_energy_process_3                                                                  0.005076   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005391   \n",
       "total_energy_kwh_process_1                                                            0.005413   \n",
       "total_energy_kwh_process_2                                                            0.005444   \n",
       "total_energy_kwh_process_3                                                            0.005831   \n",
       "total_energy_joules_process_0                                                     19408.237514   \n",
       "total_energy_joules_process_1                                                     19485.442064   \n",
       "total_energy_joules_process_2                                                     19599.244853   \n",
       "total_energy_joules_process_3                                                     20992.245094   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1128.825755   \n",
       "ram_power_avg                                                                          0.68033   \n",
       "cpu_energy_total                                                                      0.002713   \n",
       "gpu_energy_total                                                                       0.01935   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002062   \n",
       "per-process_emissions_1                                                               0.002054   \n",
       "per-process_emissions_2                                                               0.002221   \n",
       "per-process_emissions_3                                                               0.002074   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            43  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                              153   \n",
       "date_time                                                        April 11, 2025 at 02:32:31 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022215   \n",
       "total_energy_joules                                                               79973.120837   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.204869   \n",
       "joules_per_token                                                                      4.881172   \n",
       "flops_per_joule                                                               211945849.002445   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             24.044567   \n",
       "average_latency_ms_per_batch                                                       3005.570872   \n",
       "throughput_queries_per_sec                                                            5.323448   \n",
       "throughput_tokens_per_sec                                                           681.401333   \n",
       "cpu_usage_percent                                                                          3.2   \n",
       "cpu_memory_usage_bytes                                                              2020339712   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                        0.0   \n",
       "gpu_power_process_1                                                                 129.714284   \n",
       "gpu_power_process_2                                                                 136.960885   \n",
       "gpu_power_process_3                                                                 466.843438   \n",
       "ram_power_process_0                                                                   0.704178   \n",
       "ram_power_process_1                                                                   0.662604   \n",
       "ram_power_process_2                                                                   0.663998   \n",
       "ram_power_process_3                                                                   0.664515   \n",
       "cpu_energy_process_0                                                                  0.000756   \n",
       "cpu_energy_process_1                                                                  0.000672   \n",
       "cpu_energy_process_2                                                                   0.00068   \n",
       "cpu_energy_process_3                                                                  0.000755   \n",
       "gpu_energy_process_0                                                                  0.004766   \n",
       "gpu_energy_process_1                                                                  0.004766   \n",
       "gpu_energy_process_2                                                                  0.004766   \n",
       "gpu_energy_process_3                                                                  0.005035   \n",
       "ram_energy_process_0                                                                  0.000005   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005528   \n",
       "total_energy_kwh_process_1                                                            0.005443   \n",
       "total_energy_kwh_process_2                                                             0.00545   \n",
       "total_energy_kwh_process_3                                                            0.005795   \n",
       "total_energy_joules_process_0                                                     19899.119422   \n",
       "total_energy_joules_process_1                                                     19593.949878   \n",
       "total_energy_joules_process_2                                                     19619.519138   \n",
       "total_energy_joules_process_3                                                     20860.532399   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       183.379652   \n",
       "ram_power_avg                                                                         0.673824   \n",
       "cpu_energy_total                                                                      0.002863   \n",
       "gpu_energy_total                                                                      0.019335   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002076   \n",
       "per-process_emissions_1                                                               0.002207   \n",
       "per-process_emissions_2                                                               0.002106   \n",
       "per-process_emissions_3                                                               0.002073   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            44  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                              154   \n",
       "date_time                                                        April 11, 2025 at 02:33:34 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                              100   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022313   \n",
       "total_energy_joules                                                               80327.286164   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.203966   \n",
       "joules_per_token                                                                      4.902788   \n",
       "flops_per_joule                                                                211011373.62713   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.701611   \n",
       "average_latency_ms_per_batch                                                       2962.701374   \n",
       "throughput_queries_per_sec                                                            5.400477   \n",
       "throughput_tokens_per_sec                                                           691.261029   \n",
       "cpu_usage_percent                                                                          3.7   \n",
       "cpu_memory_usage_bytes                                                              2021003264   \n",
       "gpu_utilization_percent_0                                                                  2.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 774.142548   \n",
       "gpu_power_process_1                                                                1568.792356   \n",
       "gpu_power_process_2                                                                        0.0   \n",
       "gpu_power_process_3                                                                        0.0   \n",
       "ram_power_process_0                                                                   0.703823   \n",
       "ram_power_process_1                                                                   0.669487   \n",
       "ram_power_process_2                                                                    0.66809   \n",
       "ram_power_process_3                                                                   0.665158   \n",
       "cpu_energy_process_0                                                                  0.000684   \n",
       "cpu_energy_process_1                                                                  0.000706   \n",
       "cpu_energy_process_2                                                                  0.000729   \n",
       "cpu_energy_process_3                                                                  0.000775   \n",
       "gpu_energy_process_0                                                                  0.004689   \n",
       "gpu_energy_process_1                                                                  0.004855   \n",
       "gpu_energy_process_2                                                                  0.004758   \n",
       "gpu_energy_process_3                                                                    0.0051   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005377   \n",
       "total_energy_kwh_process_1                                                            0.005564   \n",
       "total_energy_kwh_process_2                                                            0.005492   \n",
       "total_energy_kwh_process_3                                                             0.00588   \n",
       "total_energy_joules_process_0                                                     19357.213437   \n",
       "total_energy_joules_process_1                                                     20032.110287   \n",
       "total_energy_joules_process_2                                                     19770.177135   \n",
       "total_energy_joules_process_3                                                     21167.785305   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       585.733726   \n",
       "ram_power_avg                                                                         0.676639   \n",
       "cpu_energy_total                                                                      0.002894   \n",
       "gpu_energy_total                                                                      0.019402   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002048   \n",
       "per-process_emissions_1                                                                0.00212   \n",
       "per-process_emissions_2                                                               0.002092   \n",
       "per-process_emissions_3                                                                0.00224   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            45  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                              155   \n",
       "date_time                                                        April 11, 2025 at 02:34:37 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                              200   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022003   \n",
       "total_energy_joules                                                               79212.479066   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.206836   \n",
       "joules_per_token                                                                      4.834746   \n",
       "flops_per_joule                                                               213981069.562596   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.352319   \n",
       "average_latency_ms_per_batch                                                       2919.039935   \n",
       "throughput_queries_per_sec                                                            5.481254   \n",
       "throughput_tokens_per_sec                                                           701.600542   \n",
       "cpu_usage_percent                                                                          3.5   \n",
       "cpu_memory_usage_bytes                                                              2019926016   \n",
       "gpu_utilization_percent_0                                                                  5.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 915.912752   \n",
       "gpu_power_process_1                                                                 738.719496   \n",
       "gpu_power_process_2                                                                 722.772005   \n",
       "gpu_power_process_3                                                                  10.899224   \n",
       "ram_power_process_0                                                                   0.704059   \n",
       "ram_power_process_1                                                                   0.668499   \n",
       "ram_power_process_2                                                                   0.668465   \n",
       "ram_power_process_3                                                                   0.663956   \n",
       "cpu_energy_process_0                                                                  0.000687   \n",
       "cpu_energy_process_1                                                                  0.000699   \n",
       "cpu_energy_process_2                                                                  0.000649   \n",
       "cpu_energy_process_3                                                                  0.000798   \n",
       "gpu_energy_process_0                                                                  0.004647   \n",
       "gpu_energy_process_1                                                                  0.004702   \n",
       "gpu_energy_process_2                                                                  0.004716   \n",
       "gpu_energy_process_3                                                                  0.005088   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005338   \n",
       "total_energy_kwh_process_1                                                            0.005405   \n",
       "total_energy_kwh_process_2                                                            0.005369   \n",
       "total_energy_kwh_process_3                                                            0.005892   \n",
       "total_energy_joules_process_0                                                     19216.994373   \n",
       "total_energy_joules_process_1                                                     19458.184584   \n",
       "total_energy_joules_process_2                                                     19327.673077   \n",
       "total_energy_joules_process_3                                                     21209.627033   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       597.075869   \n",
       "ram_power_avg                                                                         0.676245   \n",
       "cpu_energy_total                                                                      0.002834   \n",
       "gpu_energy_total                                                                      0.019153   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002034   \n",
       "per-process_emissions_1                                                               0.002045   \n",
       "per-process_emissions_2                                                               0.002244   \n",
       "per-process_emissions_3                                                               0.002059   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            46  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                              156   \n",
       "date_time                                                        April 11, 2025 at 02:35:41 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                              500   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021963   \n",
       "total_energy_joules                                                               79067.881421   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.207214   \n",
       "joules_per_token                                                                       4.82592   \n",
       "flops_per_joule                                                               214372393.548913   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.586959   \n",
       "average_latency_ms_per_batch                                                        2948.36993   \n",
       "throughput_queries_per_sec                                                            5.426727   \n",
       "throughput_tokens_per_sec                                                           694.621112   \n",
       "cpu_usage_percent                                                                          3.2   \n",
       "cpu_memory_usage_bytes                                                              2000257024   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1168.832823   \n",
       "gpu_power_process_1                                                                 1283.37675   \n",
       "gpu_power_process_2                                                                 928.259069   \n",
       "gpu_power_process_3                                                                2326.109494   \n",
       "ram_power_process_0                                                                   0.697381   \n",
       "ram_power_process_1                                                                   0.669037   \n",
       "ram_power_process_2                                                                   0.671003   \n",
       "ram_power_process_3                                                                    0.67175   \n",
       "cpu_energy_process_0                                                                  0.000642   \n",
       "cpu_energy_process_1                                                                  0.000691   \n",
       "cpu_energy_process_2                                                                  0.000638   \n",
       "cpu_energy_process_3                                                                  0.000652   \n",
       "gpu_energy_process_0                                                                  0.004751   \n",
       "gpu_energy_process_1                                                                  0.004753   \n",
       "gpu_energy_process_2                                                                  0.004761   \n",
       "gpu_energy_process_3                                                                  0.005061   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005397   \n",
       "total_energy_kwh_process_1                                                            0.005448   \n",
       "total_energy_kwh_process_2                                                            0.005403   \n",
       "total_energy_kwh_process_3                                                            0.005716   \n",
       "total_energy_joules_process_0                                                     19428.084537   \n",
       "total_energy_joules_process_1                                                     19611.249515   \n",
       "total_energy_joules_process_2                                                     19449.798175   \n",
       "total_energy_joules_process_3                                                     20578.749194   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1426.644534   \n",
       "ram_power_avg                                                                         0.677293   \n",
       "cpu_energy_total                                                                      0.002622   \n",
       "gpu_energy_total                                                                      0.019325   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002058   \n",
       "per-process_emissions_1                                                               0.002056   \n",
       "per-process_emissions_2                                                               0.002075   \n",
       "per-process_emissions_3                                                               0.002178   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            47  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                              157   \n",
       "date_time                                                        April 11, 2025 at 02:36:45 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                               20   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022372   \n",
       "total_energy_joules                                                               80539.640657   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.203428   \n",
       "joules_per_token                                                                       4.91575   \n",
       "flops_per_joule                                                               210455011.407237   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.279665   \n",
       "average_latency_ms_per_batch                                                       2909.958078   \n",
       "throughput_queries_per_sec                                                            5.498361   \n",
       "throughput_tokens_per_sec                                                           703.790208   \n",
       "cpu_usage_percent                                                                          3.3   \n",
       "cpu_memory_usage_bytes                                                              2020048896   \n",
       "gpu_utilization_percent_0                                                                  7.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 882.692097   \n",
       "gpu_power_process_1                                                                 737.945279   \n",
       "gpu_power_process_2                                                                 762.663717   \n",
       "gpu_power_process_3                                                                  54.419399   \n",
       "ram_power_process_0                                                                   0.703574   \n",
       "ram_power_process_1                                                                   0.664238   \n",
       "ram_power_process_2                                                                   0.675021   \n",
       "ram_power_process_3                                                                   0.664653   \n",
       "cpu_energy_process_0                                                                  0.000754   \n",
       "cpu_energy_process_1                                                                  0.000775   \n",
       "cpu_energy_process_2                                                                   0.00077   \n",
       "cpu_energy_process_3                                                                  0.000841   \n",
       "gpu_energy_process_0                                                                  0.004654   \n",
       "gpu_energy_process_1                                                                  0.004711   \n",
       "gpu_energy_process_2                                                                   0.00472   \n",
       "gpu_energy_process_3                                                                   0.00513   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005412   \n",
       "total_energy_kwh_process_1                                                             0.00549   \n",
       "total_energy_kwh_process_2                                                            0.005495   \n",
       "total_energy_kwh_process_3                                                            0.005976   \n",
       "total_energy_joules_process_0                                                     19482.245789   \n",
       "total_energy_joules_process_1                                                     19763.311386   \n",
       "total_energy_joules_process_2                                                     19780.777175   \n",
       "total_energy_joules_process_3                                                     21513.306307   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       609.430123   \n",
       "ram_power_avg                                                                         0.676872   \n",
       "cpu_energy_total                                                                       0.00314   \n",
       "gpu_energy_total                                                                      0.019215   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002277   \n",
       "per-process_emissions_1                                                               0.002091   \n",
       "per-process_emissions_2                                                               0.002062   \n",
       "per-process_emissions_3                                                               0.002093   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            48  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                              158   \n",
       "date_time                                                        April 11, 2025 at 02:37:48 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021898   \n",
       "total_energy_joules                                                               78832.359919   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.207833   \n",
       "joules_per_token                                                                      4.811545   \n",
       "flops_per_joule                                                               215012857.796897   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.328102   \n",
       "average_latency_ms_per_batch                                                       2916.012712   \n",
       "throughput_queries_per_sec                                                            5.486945   \n",
       "throughput_tokens_per_sec                                                             702.3289   \n",
       "cpu_usage_percent                                                                          3.5   \n",
       "cpu_memory_usage_bytes                                                              2019524608   \n",
       "gpu_utilization_percent_0                                                                  9.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 603.259737   \n",
       "gpu_power_process_1                                                                 660.254699   \n",
       "gpu_power_process_2                                                                3150.571004   \n",
       "gpu_power_process_3                                                                 506.299235   \n",
       "ram_power_process_0                                                                   0.703661   \n",
       "ram_power_process_1                                                                   0.662991   \n",
       "ram_power_process_2                                                                   0.670984   \n",
       "ram_power_process_3                                                                   0.669169   \n",
       "cpu_energy_process_0                                                                  0.000696   \n",
       "cpu_energy_process_1                                                                  0.000694   \n",
       "cpu_energy_process_2                                                                  0.000694   \n",
       "cpu_energy_process_3                                                                  0.000738   \n",
       "gpu_energy_process_0                                                                  0.004672   \n",
       "gpu_energy_process_1                                                                  0.004672   \n",
       "gpu_energy_process_2                                                                  0.004633   \n",
       "gpu_energy_process_3                                                                  0.005083   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005372   \n",
       "total_energy_kwh_process_1                                                             0.00537   \n",
       "total_energy_kwh_process_2                                                            0.005331   \n",
       "total_energy_kwh_process_3                                                            0.005825   \n",
       "total_energy_joules_process_0                                                     19338.889712   \n",
       "total_energy_joules_process_1                                                     19332.564397   \n",
       "total_energy_joules_process_2                                                     19191.822488   \n",
       "total_energy_joules_process_3                                                     20969.083323   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1230.096169   \n",
       "ram_power_avg                                                                         0.676701   \n",
       "cpu_energy_total                                                                      0.002822   \n",
       "gpu_energy_total                                                                       0.01906   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002031   \n",
       "per-process_emissions_1                                                               0.002046   \n",
       "per-process_emissions_2                                                               0.002219   \n",
       "per-process_emissions_3                                                               0.002046   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            49  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                              159   \n",
       "date_time                                                        April 11, 2025 at 02:38:49 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                              100   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022286   \n",
       "total_energy_joules                                                               80229.360539   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.204215   \n",
       "joules_per_token                                                                      4.896812   \n",
       "flops_per_joule                                                               211268927.975691   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.584234   \n",
       "average_latency_ms_per_batch                                                       2948.029216   \n",
       "throughput_queries_per_sec                                                            5.427355   \n",
       "throughput_tokens_per_sec                                                           694.701392   \n",
       "cpu_usage_percent                                                                          3.0   \n",
       "cpu_memory_usage_bytes                                                              2017579008   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1374.787363   \n",
       "gpu_power_process_1                                                                        0.0   \n",
       "gpu_power_process_2                                                                1010.700407   \n",
       "gpu_power_process_3                                                                 625.245845   \n",
       "ram_power_process_0                                                                   0.703328   \n",
       "ram_power_process_1                                                                   0.669341   \n",
       "ram_power_process_2                                                                   0.664939   \n",
       "ram_power_process_3                                                                   0.665042   \n",
       "cpu_energy_process_0                                                                  0.000691   \n",
       "cpu_energy_process_1                                                                  0.000738   \n",
       "cpu_energy_process_2                                                                  0.000697   \n",
       "cpu_energy_process_3                                                                  0.000774   \n",
       "gpu_energy_process_0                                                                  0.004762   \n",
       "gpu_energy_process_1                                                                  0.004779   \n",
       "gpu_energy_process_2                                                                  0.004779   \n",
       "gpu_energy_process_3                                                                   0.00505   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005457   \n",
       "total_energy_kwh_process_1                                                             0.00552   \n",
       "total_energy_kwh_process_2                                                             0.00548   \n",
       "total_energy_kwh_process_3                                                            0.005828   \n",
       "total_energy_joules_process_0                                                     19646.964429   \n",
       "total_energy_joules_process_1                                                      19873.58322   \n",
       "total_energy_joules_process_2                                                     19726.637947   \n",
       "total_energy_joules_process_3                                                     20982.174943   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       752.683404   \n",
       "ram_power_avg                                                                         0.675662   \n",
       "cpu_energy_total                                                                        0.0029   \n",
       "gpu_energy_total                                                                       0.01937   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002087   \n",
       "per-process_emissions_1                                                               0.002079   \n",
       "per-process_emissions_2                                                                0.00222   \n",
       "per-process_emissions_3                                                               0.002103   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            50  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                              160   \n",
       "date_time                                                        April 11, 2025 at 02:39:50 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                              200   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022056   \n",
       "total_energy_joules                                                               79403.040972   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                       0.20634   \n",
       "joules_per_token                                                                      4.846377   \n",
       "flops_per_joule                                                               213467529.525458   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.233562   \n",
       "average_latency_ms_per_batch                                                       2904.195222   \n",
       "throughput_queries_per_sec                                                            5.509272   \n",
       "throughput_tokens_per_sec                                                           705.186753   \n",
       "cpu_usage_percent                                                                          3.4   \n",
       "cpu_memory_usage_bytes                                                              2031259648   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 784.969026   \n",
       "gpu_power_process_1                                                                1069.004617   \n",
       "gpu_power_process_2                                                                        0.0   \n",
       "gpu_power_process_3                                                                 673.469657   \n",
       "ram_power_process_0                                                                   0.708203   \n",
       "ram_power_process_1                                                                   0.671711   \n",
       "ram_power_process_2                                                                   0.665657   \n",
       "ram_power_process_3                                                                   0.668261   \n",
       "cpu_energy_process_0                                                                  0.000743   \n",
       "cpu_energy_process_1                                                                  0.000675   \n",
       "cpu_energy_process_2                                                                   0.00079   \n",
       "cpu_energy_process_3                                                                  0.000688   \n",
       "gpu_energy_process_0                                                                   0.00463   \n",
       "gpu_energy_process_1                                                                  0.004702   \n",
       "gpu_energy_process_2                                                                  0.004786   \n",
       "gpu_energy_process_3                                                                  0.005027   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005377   \n",
       "total_energy_kwh_process_1                                                             0.00538   \n",
       "total_energy_kwh_process_2                                                             0.00558   \n",
       "total_energy_kwh_process_3                                                            0.005719   \n",
       "total_energy_joules_process_0                                                     19356.784252   \n",
       "total_energy_joules_process_1                                                     19369.401268   \n",
       "total_energy_joules_process_2                                                     20088.689768   \n",
       "total_energy_joules_process_3                                                     20588.165683   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       631.860825   \n",
       "ram_power_avg                                                                         0.678458   \n",
       "cpu_energy_total                                                                      0.002895   \n",
       "gpu_energy_total                                                                      0.019145   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002179   \n",
       "per-process_emissions_1                                                                0.00205   \n",
       "per-process_emissions_2                                                               0.002048   \n",
       "per-process_emissions_3                                                               0.002126   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            51  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                              161   \n",
       "date_time                                                        April 11, 2025 at 02:40:54 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                              500   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022172   \n",
       "total_energy_joules                                                               79820.968883   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.205259   \n",
       "joules_per_token                                                                      4.871885   \n",
       "flops_per_joule                                                               212349852.805032   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.687913   \n",
       "average_latency_ms_per_batch                                                       2960.989152   \n",
       "throughput_queries_per_sec                                                              5.4036   \n",
       "throughput_tokens_per_sec                                                           691.660758   \n",
       "cpu_usage_percent                                                                          3.3   \n",
       "cpu_memory_usage_bytes                                                              2020073472   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1038.966873   \n",
       "gpu_power_process_1                                                                2230.731714   \n",
       "gpu_power_process_2                                                                 909.304739   \n",
       "gpu_power_process_3                                                                 320.672289   \n",
       "ram_power_process_0                                                                   0.704255   \n",
       "ram_power_process_1                                                                   0.676709   \n",
       "ram_power_process_2                                                                   0.674967   \n",
       "ram_power_process_3                                                                   0.681427   \n",
       "cpu_energy_process_0                                                                  0.000689   \n",
       "cpu_energy_process_1                                                                  0.000716   \n",
       "cpu_energy_process_2                                                                  0.000644   \n",
       "cpu_energy_process_3                                                                  0.000768   \n",
       "gpu_energy_process_0                                                                  0.004763   \n",
       "gpu_energy_process_1                                                                  0.004734   \n",
       "gpu_energy_process_2                                                                  0.004767   \n",
       "gpu_energy_process_3                                                                  0.005074   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005456   \n",
       "total_energy_kwh_process_1                                                            0.005454   \n",
       "total_energy_kwh_process_2                                                            0.005415   \n",
       "total_energy_kwh_process_3                                                            0.005847   \n",
       "total_energy_joules_process_0                                                     19642.590894   \n",
       "total_energy_joules_process_1                                                     19635.139756   \n",
       "total_energy_joules_process_2                                                     19494.728512   \n",
       "total_energy_joules_process_3                                                     21048.509722   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1124.918904   \n",
       "ram_power_avg                                                                          0.68434   \n",
       "cpu_energy_total                                                                      0.002817   \n",
       "gpu_energy_total                                                                      0.019339   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002063   \n",
       "per-process_emissions_1                                                               0.002079   \n",
       "per-process_emissions_2                                                               0.002078   \n",
       "per-process_emissions_3                                                               0.002227   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            52  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                              162   \n",
       "date_time                                                        April 11, 2025 at 02:41:56 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                               20   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022241   \n",
       "total_energy_joules                                                               80066.319146   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                       0.20463   \n",
       "joules_per_token                                                                       4.88686   \n",
       "flops_per_joule                                                               211699141.086514   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.430406   \n",
       "average_latency_ms_per_batch                                                       2928.800693   \n",
       "throughput_queries_per_sec                                                            5.462987   \n",
       "throughput_tokens_per_sec                                                           699.262331   \n",
       "cpu_usage_percent                                                                          3.0   \n",
       "cpu_memory_usage_bytes                                                              2023170048   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  53.497819   \n",
       "gpu_power_process_1                                                                  45.508511   \n",
       "gpu_power_process_2                                                                  71.437712   \n",
       "gpu_power_process_3                                                                 259.877186   \n",
       "ram_power_process_0                                                                   0.704736   \n",
       "ram_power_process_1                                                                    0.67122   \n",
       "ram_power_process_2                                                                   0.668265   \n",
       "ram_power_process_3                                                                   0.676413   \n",
       "cpu_energy_process_0                                                                  0.000721   \n",
       "cpu_energy_process_1                                                                   0.00067   \n",
       "cpu_energy_process_2                                                                  0.000679   \n",
       "cpu_energy_process_3                                                                  0.000813   \n",
       "gpu_energy_process_0                                                                  0.004759   \n",
       "gpu_energy_process_1                                                                  0.004757   \n",
       "gpu_energy_process_2                                                                  0.004759   \n",
       "gpu_energy_process_3                                                                  0.005066   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005484   \n",
       "total_energy_kwh_process_1                                                            0.005431   \n",
       "total_energy_kwh_process_2                                                            0.005442   \n",
       "total_energy_kwh_process_3                                                            0.005884   \n",
       "total_energy_joules_process_0                                                     19742.001207   \n",
       "total_energy_joules_process_1                                                     19552.473979   \n",
       "total_energy_joules_process_2                                                     19590.352354   \n",
       "total_energy_joules_process_3                                                     21181.491607   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       107.580307   \n",
       "ram_power_avg                                                                         0.680158   \n",
       "cpu_energy_total                                                                      0.002883   \n",
       "gpu_energy_total                                                                      0.019341   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002089   \n",
       "per-process_emissions_1                                                               0.002069   \n",
       "per-process_emissions_2                                                               0.002073   \n",
       "per-process_emissions_3                                                               0.002241   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            53  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                              163   \n",
       "date_time                                                        April 11, 2025 at 02:42:58 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022124   \n",
       "total_energy_joules                                                               79646.128042   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                       0.20571   \n",
       "joules_per_token                                                                      4.861214   \n",
       "flops_per_joule                                                               212816007.631856   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.540169   \n",
       "average_latency_ms_per_batch                                                       2942.521106   \n",
       "throughput_queries_per_sec                                                            5.437514   \n",
       "throughput_tokens_per_sec                                                           696.001805   \n",
       "cpu_usage_percent                                                                          3.0   \n",
       "cpu_memory_usage_bytes                                                              2024202240   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1303.029478   \n",
       "gpu_power_process_1                                                                 930.694166   \n",
       "gpu_power_process_2                                                                1187.409604   \n",
       "gpu_power_process_3                                                                 438.454544   \n",
       "ram_power_process_0                                                                   0.705005   \n",
       "ram_power_process_1                                                                   0.664392   \n",
       "ram_power_process_2                                                                   0.664093   \n",
       "ram_power_process_3                                                                   0.661546   \n",
       "cpu_energy_process_0                                                                  0.000632   \n",
       "cpu_energy_process_1                                                                  0.000695   \n",
       "cpu_energy_process_2                                                                  0.000681   \n",
       "cpu_energy_process_3                                                                  0.000771   \n",
       "gpu_energy_process_0                                                                  0.004749   \n",
       "gpu_energy_process_1                                                                  0.004763   \n",
       "gpu_energy_process_2                                                                  0.004751   \n",
       "gpu_energy_process_3                                                                  0.005064   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005385   \n",
       "total_energy_kwh_process_1                                                            0.005462   \n",
       "total_energy_kwh_process_2                                                            0.005437   \n",
       "total_energy_kwh_process_3                                                             0.00584   \n",
       "total_energy_joules_process_0                                                     19385.208812   \n",
       "total_energy_joules_process_1                                                     19664.751299   \n",
       "total_energy_joules_process_2                                                     19572.514176   \n",
       "total_energy_joules_process_3                                                     21023.653755   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       964.896948   \n",
       "ram_power_avg                                                                         0.673759   \n",
       "cpu_energy_total                                                                      0.002779   \n",
       "gpu_energy_total                                                                      0.019328   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002081   \n",
       "per-process_emissions_1                                                               0.002225   \n",
       "per-process_emissions_2                                                               0.002051   \n",
       "per-process_emissions_3                                                               0.002071   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            54  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                              164   \n",
       "date_time                                                        April 11, 2025 at 02:44:00 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                              100   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021905   \n",
       "total_energy_joules                                                                78857.96964   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.207766   \n",
       "joules_per_token                                                                      4.813108   \n",
       "flops_per_joule                                                               214943030.749142   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.653556   \n",
       "average_latency_ms_per_batch                                                       2956.694525   \n",
       "throughput_queries_per_sec                                                            5.411448   \n",
       "throughput_tokens_per_sec                                                           692.665401   \n",
       "cpu_usage_percent                                                                          3.2   \n",
       "cpu_memory_usage_bytes                                                              2019373056   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1022.695962   \n",
       "gpu_power_process_1                                                                1180.326923   \n",
       "gpu_power_process_2                                                                1178.710549   \n",
       "gpu_power_process_3                                                                        0.0   \n",
       "ram_power_process_0                                                                   0.702986   \n",
       "ram_power_process_1                                                                   0.664045   \n",
       "ram_power_process_2                                                                   0.665493   \n",
       "ram_power_process_3                                                                   0.664669   \n",
       "cpu_energy_process_0                                                                  0.000628   \n",
       "cpu_energy_process_1                                                                  0.000636   \n",
       "cpu_energy_process_2                                                                  0.000628   \n",
       "cpu_energy_process_3                                                                  0.000719   \n",
       "gpu_energy_process_0                                                                  0.004742   \n",
       "gpu_energy_process_1                                                                   0.00474   \n",
       "gpu_energy_process_2                                                                  0.004739   \n",
       "gpu_energy_process_3                                                                  0.005057   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005373   \n",
       "total_energy_kwh_process_1                                                             0.00538   \n",
       "total_energy_kwh_process_2                                                            0.005371   \n",
       "total_energy_kwh_process_3                                                            0.005781   \n",
       "total_energy_joules_process_0                                                     19344.183745   \n",
       "total_energy_joules_process_1                                                     19368.892861   \n",
       "total_energy_joules_process_2                                                     19334.277519   \n",
       "total_energy_joules_process_3                                                     20810.615515   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       845.433359   \n",
       "ram_power_avg                                                                         0.674298   \n",
       "cpu_energy_total                                                                      0.002611   \n",
       "gpu_energy_total                                                                      0.019278   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002046   \n",
       "per-process_emissions_1                                                                0.00205   \n",
       "per-process_emissions_2                                                               0.002047   \n",
       "per-process_emissions_3                                                               0.002202   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            55  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                              165   \n",
       "date_time                                                        April 11, 2025 at 02:45:01 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                              200   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022108   \n",
       "total_energy_joules                                                               79588.547839   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.205859   \n",
       "joules_per_token                                                                      4.857699   \n",
       "flops_per_joule                                                               212969974.366801   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.883228   \n",
       "average_latency_ms_per_batch                                                        2985.40352   \n",
       "throughput_queries_per_sec                                                             5.35941   \n",
       "throughput_tokens_per_sec                                                           686.004416   \n",
       "cpu_usage_percent                                                                          3.2   \n",
       "cpu_memory_usage_bytes                                                              2017050624   \n",
       "gpu_utilization_percent_0                                                                 10.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 989.992263   \n",
       "gpu_power_process_1                                                                 958.975708   \n",
       "gpu_power_process_2                                                                1408.042542   \n",
       "gpu_power_process_3                                                                 373.109119   \n",
       "ram_power_process_0                                                                   0.702569   \n",
       "ram_power_process_1                                                                    0.66287   \n",
       "ram_power_process_2                                                                   0.662753   \n",
       "ram_power_process_3                                                                   0.667863   \n",
       "cpu_energy_process_0                                                                  0.000642   \n",
       "cpu_energy_process_1                                                                  0.000679   \n",
       "cpu_energy_process_2                                                                  0.000638   \n",
       "cpu_energy_process_3                                                                  0.000722   \n",
       "gpu_energy_process_0                                                                  0.004782   \n",
       "gpu_energy_process_1                                                                  0.004782   \n",
       "gpu_energy_process_2                                                                  0.004773   \n",
       "gpu_energy_process_3                                                                  0.005074   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005428   \n",
       "total_energy_kwh_process_1                                                            0.005465   \n",
       "total_energy_kwh_process_2                                                            0.005415   \n",
       "total_energy_kwh_process_3                                                              0.0058   \n",
       "total_energy_joules_process_0                                                       19540.1874   \n",
       "total_energy_joules_process_1                                                     19673.500442   \n",
       "total_energy_joules_process_2                                                     19494.502688   \n",
       "total_energy_joules_process_3                                                     20880.357309   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       932.529908   \n",
       "ram_power_avg                                                                         0.674014   \n",
       "cpu_energy_total                                                                       0.00268   \n",
       "gpu_energy_total                                                                      0.019412   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002082   \n",
       "per-process_emissions_1                                                               0.002068   \n",
       "per-process_emissions_2                                                               0.002063   \n",
       "per-process_emissions_3                                                                0.00221   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            56  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                              166   \n",
       "date_time                                                        April 11, 2025 at 02:46:03 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                              500   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022015   \n",
       "total_energy_joules                                                               79254.830096   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.206726   \n",
       "joules_per_token                                                                      4.837331   \n",
       "flops_per_joule                                                               213866725.505504   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.846678   \n",
       "average_latency_ms_per_batch                                                       2980.834787   \n",
       "throughput_queries_per_sec                                                            5.367624   \n",
       "throughput_tokens_per_sec                                                           687.055857   \n",
       "cpu_usage_percent                                                                          3.3   \n",
       "cpu_memory_usage_bytes                                                              2018820096   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 933.383914   \n",
       "gpu_power_process_1                                                                1006.102423   \n",
       "gpu_power_process_2                                                                 961.608002   \n",
       "gpu_power_process_3                                                                 412.478468   \n",
       "ram_power_process_0                                                                   0.703385   \n",
       "ram_power_process_1                                                                   0.671908   \n",
       "ram_power_process_2                                                                   0.665819   \n",
       "ram_power_process_3                                                                   0.670351   \n",
       "cpu_energy_process_0                                                                  0.000679   \n",
       "cpu_energy_process_1                                                                  0.000669   \n",
       "cpu_energy_process_2                                                                  0.000633   \n",
       "cpu_energy_process_3                                                                  0.000754   \n",
       "gpu_energy_process_0                                                                  0.004762   \n",
       "gpu_energy_process_1                                                                  0.004754   \n",
       "gpu_energy_process_2                                                                  0.004688   \n",
       "gpu_energy_process_3                                                                   0.00506   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005445   \n",
       "total_energy_kwh_process_1                                                            0.005427   \n",
       "total_energy_kwh_process_2                                                            0.005325   \n",
       "total_energy_kwh_process_3                                                            0.005818   \n",
       "total_energy_joules_process_0                                                     19603.726781   \n",
       "total_energy_joules_process_1                                                     19538.016199   \n",
       "total_energy_joules_process_2                                                     19168.708825   \n",
       "total_energy_joules_process_3                                                     20944.378291   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       828.393201   \n",
       "ram_power_avg                                                                         0.677866   \n",
       "cpu_energy_total                                                                      0.002735   \n",
       "gpu_energy_total                                                                      0.019263   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002074   \n",
       "per-process_emissions_1                                                               0.002068   \n",
       "per-process_emissions_2                                                               0.002216   \n",
       "per-process_emissions_3                                                               0.002028   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            57  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                              172   \n",
       "date_time                                                        April 11, 2025 at 02:50:00 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.7   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022108   \n",
       "total_energy_joules                                                                79588.27778   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.205859   \n",
       "joules_per_token                                                                      4.857683   \n",
       "flops_per_joule                                                               212970697.015842   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             22.873191   \n",
       "average_latency_ms_per_batch                                                       2859.148891   \n",
       "throughput_queries_per_sec                                                            5.596071   \n",
       "throughput_tokens_per_sec                                                           716.297079   \n",
       "cpu_usage_percent                                                                          3.4   \n",
       "cpu_memory_usage_bytes                                                              1976737792   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  38.689285   \n",
       "gpu_power_process_1                                                                 949.219255   \n",
       "gpu_power_process_2                                                                 577.740962   \n",
       "gpu_power_process_3                                                                 605.047216   \n",
       "ram_power_process_0                                                                   0.689136   \n",
       "ram_power_process_1                                                                   0.619919   \n",
       "ram_power_process_2                                                                   0.626741   \n",
       "ram_power_process_3                                                                   0.620301   \n",
       "cpu_energy_process_0                                                                  0.000777   \n",
       "cpu_energy_process_1                                                                  0.000731   \n",
       "cpu_energy_process_2                                                                  0.000729   \n",
       "cpu_energy_process_3                                                                  0.000878   \n",
       "gpu_energy_process_0                                                                  0.004655   \n",
       "gpu_energy_process_1                                                                  0.004667   \n",
       "gpu_energy_process_2                                                                  0.004667   \n",
       "gpu_energy_process_3                                                                  0.004987   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005437   \n",
       "total_energy_kwh_process_1                                                            0.005402   \n",
       "total_energy_kwh_process_2                                                              0.0054   \n",
       "total_energy_kwh_process_3                                                             0.00587   \n",
       "total_energy_joules_process_0                                                     19571.459222   \n",
       "total_energy_joules_process_1                                                      19446.50456   \n",
       "total_energy_joules_process_2                                                      19439.31524   \n",
       "total_energy_joules_process_3                                                     21130.998758   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       542.674179   \n",
       "ram_power_avg                                                                         0.639024   \n",
       "cpu_energy_total                                                                      0.003115   \n",
       "gpu_energy_total                                                                      0.018977   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002057   \n",
       "per-process_emissions_1                                                               0.002058   \n",
       "per-process_emissions_2                                                               0.002071   \n",
       "per-process_emissions_3                                                               0.002236   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            58  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                              173   \n",
       "date_time                                                        April 11, 2025 at 02:51:04 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.8   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021896   \n",
       "total_energy_joules                                                               78825.275361   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.207852   \n",
       "joules_per_token                                                                      4.811113   \n",
       "flops_per_joule                                                               215032182.449385   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              23.07682   \n",
       "average_latency_ms_per_batch                                                       2884.602521   \n",
       "throughput_queries_per_sec                                                            5.546691   \n",
       "throughput_tokens_per_sec                                                           709.976499   \n",
       "cpu_usage_percent                                                                          3.8   \n",
       "cpu_memory_usage_bytes                                                              1998172160   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1465.047114   \n",
       "gpu_power_process_1                                                                31000.47471   \n",
       "gpu_power_process_2                                                                 147.942848   \n",
       "gpu_power_process_3                                                                1061.650308   \n",
       "ram_power_process_0                                                                   0.696061   \n",
       "ram_power_process_1                                                                   0.631253   \n",
       "ram_power_process_2                                                                   0.619699   \n",
       "ram_power_process_3                                                                   0.645003   \n",
       "cpu_energy_process_0                                                                  0.000713   \n",
       "cpu_energy_process_1                                                                  0.000719   \n",
       "cpu_energy_process_2                                                                   0.00076   \n",
       "cpu_energy_process_3                                                                  0.000705   \n",
       "gpu_energy_process_0                                                                  0.004666   \n",
       "gpu_energy_process_1                                                                  0.004635   \n",
       "gpu_energy_process_2                                                                  0.004635   \n",
       "gpu_energy_process_3                                                                  0.005046   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005383   \n",
       "total_energy_kwh_process_1                                                            0.005358   \n",
       "total_energy_kwh_process_2                                                            0.005399   \n",
       "total_energy_kwh_process_3                                                            0.005756   \n",
       "total_energy_joules_process_0                                                     19379.295512   \n",
       "total_energy_joules_process_1                                                     19288.685838   \n",
       "total_energy_joules_process_2                                                     19437.420432   \n",
       "total_energy_joules_process_3                                                     20719.873579   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      8418.778745   \n",
       "ram_power_avg                                                                         0.648004   \n",
       "cpu_energy_total                                                                      0.002897   \n",
       "gpu_energy_total                                                                      0.018983   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002041   \n",
       "per-process_emissions_1                                                               0.002193   \n",
       "per-process_emissions_2                                                               0.002057   \n",
       "per-process_emissions_3                                                               0.002051   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            59  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                              174   \n",
       "date_time                                                        April 11, 2025 at 02:52:05 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022016   \n",
       "total_energy_joules                                                               79257.538412   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.206719   \n",
       "joules_per_token                                                                      4.837496   \n",
       "flops_per_joule                                                               213859417.447935   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             22.701395   \n",
       "average_latency_ms_per_batch                                                       2837.674381   \n",
       "throughput_queries_per_sec                                                             5.63842   \n",
       "throughput_tokens_per_sec                                                           721.717761   \n",
       "cpu_usage_percent                                                                          3.5   \n",
       "cpu_memory_usage_bytes                                                              2010185728   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  12903776256   \n",
       "gpu_max_memory_reserved_bytes                                                      12903776256   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 771.424644   \n",
       "gpu_power_process_1                                                                  796.74593   \n",
       "gpu_power_process_2                                                                 488.131338   \n",
       "gpu_power_process_3                                                                        0.0   \n",
       "ram_power_process_0                                                                   0.700212   \n",
       "ram_power_process_1                                                                    0.63298   \n",
       "ram_power_process_2                                                                   0.632026   \n",
       "ram_power_process_3                                                                   0.620424   \n",
       "cpu_energy_process_0                                                                  0.000755   \n",
       "cpu_energy_process_1                                                                  0.000754   \n",
       "cpu_energy_process_2                                                                  0.000762   \n",
       "cpu_energy_process_3                                                                  0.000827   \n",
       "gpu_energy_process_0                                                                  0.004615   \n",
       "gpu_energy_process_1                                                                  0.004588   \n",
       "gpu_energy_process_2                                                                  0.004676   \n",
       "gpu_energy_process_3                                                                  0.005023   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005373   \n",
       "total_energy_kwh_process_1                                                            0.005345   \n",
       "total_energy_kwh_process_2                                                            0.005442   \n",
       "total_energy_kwh_process_3                                                            0.005855   \n",
       "total_energy_joules_process_0                                                     19344.231032   \n",
       "total_energy_joules_process_1                                                     19243.742947   \n",
       "total_energy_joules_process_2                                                     19590.965548   \n",
       "total_energy_joules_process_3                                                     21078.598885   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       514.075478   \n",
       "ram_power_avg                                                                         0.646411   \n",
       "cpu_energy_total                                                                      0.003098   \n",
       "gpu_energy_total                                                                      0.018902   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002231   \n",
       "per-process_emissions_1                                                               0.002047   \n",
       "per-process_emissions_2                                                               0.002073   \n",
       "per-process_emissions_3                                                               0.002036   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            60  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                              175   \n",
       "date_time                                                        April 11, 2025 at 02:53:06 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                             0.98   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021579   \n",
       "total_energy_joules                                                               77685.286425   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.210902   \n",
       "joules_per_token                                                                      4.741534   \n",
       "flops_per_joule                                                               218187661.693502   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              22.59848   \n",
       "average_latency_ms_per_batch                                                       2824.809944   \n",
       "throughput_queries_per_sec                                                            5.664098   \n",
       "throughput_tokens_per_sec                                                           725.004528   \n",
       "cpu_usage_percent                                                                          3.5   \n",
       "cpu_memory_usage_bytes                                                              1999220736   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 886.299478   \n",
       "gpu_power_process_1                                                                  773.40502   \n",
       "gpu_power_process_2                                                                 797.146251   \n",
       "gpu_power_process_3                                                                        0.0   \n",
       "ram_power_process_0                                                                   0.697014   \n",
       "ram_power_process_1                                                                   0.630647   \n",
       "ram_power_process_2                                                                   0.620356   \n",
       "ram_power_process_3                                                                   0.619853   \n",
       "cpu_energy_process_0                                                                  0.000629   \n",
       "cpu_energy_process_1                                                                   0.00064   \n",
       "cpu_energy_process_2                                                                  0.000635   \n",
       "cpu_energy_process_3                                                                  0.000741   \n",
       "gpu_energy_process_0                                                                  0.004611   \n",
       "gpu_energy_process_1                                                                  0.004648   \n",
       "gpu_energy_process_2                                                                  0.004639   \n",
       "gpu_energy_process_3                                                                  0.005021   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005244   \n",
       "total_energy_kwh_process_1                                                            0.005292   \n",
       "total_energy_kwh_process_2                                                            0.005277   \n",
       "total_energy_kwh_process_3                                                            0.005766   \n",
       "total_energy_joules_process_0                                                     18879.317824   \n",
       "total_energy_joules_process_1                                                     19050.339474   \n",
       "total_energy_joules_process_2                                                     18998.701454   \n",
       "total_energy_joules_process_3                                                     20756.927673   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       614.212687   \n",
       "ram_power_avg                                                                         0.641967   \n",
       "cpu_energy_total                                                                      0.002645   \n",
       "gpu_energy_total                                                                      0.018919   \n",
       "ram_energy_total                                                                      0.000015   \n",
       "per-process_emissions_0                                                                0.00201   \n",
       "per-process_emissions_1                                                               0.002196   \n",
       "per-process_emissions_2                                                               0.001998   \n",
       "per-process_emissions_3                                                               0.002016   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            61  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                              176   \n",
       "date_time                                                        April 11, 2025 at 02:54:09 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.7   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021987   \n",
       "total_energy_joules                                                               79153.299519   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.206991   \n",
       "joules_per_token                                                                      4.831134   \n",
       "flops_per_joule                                                               214141054.083154   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.286571   \n",
       "average_latency_ms_per_batch                                                       2910.821429   \n",
       "throughput_queries_per_sec                                                             5.49673   \n",
       "throughput_tokens_per_sec                                                           703.581463   \n",
       "cpu_usage_percent                                                                          3.8   \n",
       "cpu_memory_usage_bytes                                                              2013782016   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 807.718125   \n",
       "gpu_power_process_1                                                                 820.306382   \n",
       "gpu_power_process_2                                                                 646.442067   \n",
       "gpu_power_process_3                                                                 728.332708   \n",
       "ram_power_process_0                                                                   0.701321   \n",
       "ram_power_process_1                                                                   0.658552   \n",
       "ram_power_process_2                                                                   0.650073   \n",
       "ram_power_process_3                                                                   0.656045   \n",
       "cpu_energy_process_0                                                                  0.000662   \n",
       "cpu_energy_process_1                                                                  0.000662   \n",
       "cpu_energy_process_2                                                                  0.000671   \n",
       "cpu_energy_process_3                                                                  0.000749   \n",
       "gpu_energy_process_0                                                                  0.004712   \n",
       "gpu_energy_process_1                                                                  0.004691   \n",
       "gpu_energy_process_2                                                                  0.004739   \n",
       "gpu_energy_process_3                                                                  0.005085   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005378   \n",
       "total_energy_kwh_process_1                                                            0.005357   \n",
       "total_energy_kwh_process_2                                                            0.005414   \n",
       "total_energy_kwh_process_3                                                            0.005839   \n",
       "total_energy_joules_process_0                                                     19360.743744   \n",
       "total_energy_joules_process_1                                                     19283.922536   \n",
       "total_energy_joules_process_2                                                     19489.292961   \n",
       "total_energy_joules_process_3                                                     21019.340278   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        750.69982   \n",
       "ram_power_avg                                                                         0.666498   \n",
       "cpu_energy_total                                                                      0.002744   \n",
       "gpu_energy_total                                                                      0.019227   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002224   \n",
       "per-process_emissions_1                                                               0.002049   \n",
       "per-process_emissions_2                                                               0.002062   \n",
       "per-process_emissions_3                                                               0.002041   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            62  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                              177   \n",
       "date_time                                                        April 11, 2025 at 02:55:09 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.8   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022174   \n",
       "total_energy_joules                                                               79827.530634   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.205242   \n",
       "joules_per_token                                                                      4.872286   \n",
       "flops_per_joule                                                               212332397.841176   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.371715   \n",
       "average_latency_ms_per_batch                                                       2921.464402   \n",
       "throughput_queries_per_sec                                                            5.476705   \n",
       "throughput_tokens_per_sec                                                           701.018297   \n",
       "cpu_usage_percent                                                                          3.6   \n",
       "cpu_memory_usage_bytes                                                              2015571968   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1507.774547   \n",
       "gpu_power_process_1                                                                2644.588979   \n",
       "gpu_power_process_2                                                                2546.422016   \n",
       "gpu_power_process_3                                                                   13.14021   \n",
       "ram_power_process_0                                                                   0.702457   \n",
       "ram_power_process_1                                                                   0.656791   \n",
       "ram_power_process_2                                                                   0.650618   \n",
       "ram_power_process_3                                                                   0.650914   \n",
       "cpu_energy_process_0                                                                  0.000674   \n",
       "cpu_energy_process_1                                                                  0.000668   \n",
       "cpu_energy_process_2                                                                  0.000672   \n",
       "cpu_energy_process_3                                                                  0.000801   \n",
       "gpu_energy_process_0                                                                  0.004775   \n",
       "gpu_energy_process_1                                                                  0.004777   \n",
       "gpu_energy_process_2                                                                  0.004769   \n",
       "gpu_energy_process_3                                                                  0.005021   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005453   \n",
       "total_energy_kwh_process_1                                                            0.005449   \n",
       "total_energy_kwh_process_2                                                            0.005446   \n",
       "total_energy_kwh_process_3                                                            0.005826   \n",
       "total_energy_joules_process_0                                                      19632.01464   \n",
       "total_energy_joules_process_1                                                     19616.766383   \n",
       "total_energy_joules_process_2                                                     19603.913342   \n",
       "total_energy_joules_process_3                                                     20974.836269   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1677.981438   \n",
       "ram_power_avg                                                                         0.665195   \n",
       "cpu_energy_total                                                                      0.002815   \n",
       "gpu_energy_total                                                                      0.019343   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002077   \n",
       "per-process_emissions_1                                                               0.002076   \n",
       "per-process_emissions_2                                                                0.00222   \n",
       "per-process_emissions_3                                                               0.002074   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            63  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                              178   \n",
       "date_time                                                        April 11, 2025 at 02:56:10 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022161   \n",
       "total_energy_joules                                                               79778.964695   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.205367   \n",
       "joules_per_token                                                                      4.869322   \n",
       "flops_per_joule                                                               212461656.501568   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.444686   \n",
       "average_latency_ms_per_batch                                                       2930.585798   \n",
       "throughput_queries_per_sec                                                            5.459659   \n",
       "throughput_tokens_per_sec                                                            698.83639   \n",
       "cpu_usage_percent                                                                          3.0   \n",
       "cpu_memory_usage_bytes                                                              2014027776   \n",
       "gpu_utilization_percent_0                                                                  3.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  52.111428   \n",
       "gpu_power_process_1                                                                1049.926673   \n",
       "gpu_power_process_2                                                                3250.966224   \n",
       "gpu_power_process_3                                                                 450.415693   \n",
       "ram_power_process_0                                                                   0.701925   \n",
       "ram_power_process_1                                                                   0.652162   \n",
       "ram_power_process_2                                                                   0.655918   \n",
       "ram_power_process_3                                                                   0.650775   \n",
       "cpu_energy_process_0                                                                  0.000666   \n",
       "cpu_energy_process_1                                                                  0.000633   \n",
       "cpu_energy_process_2                                                                  0.000666   \n",
       "cpu_energy_process_3                                                                  0.000764   \n",
       "gpu_energy_process_0                                                                  0.004796   \n",
       "gpu_energy_process_1                                                                  0.004781   \n",
       "gpu_energy_process_2                                                                  0.004766   \n",
       "gpu_energy_process_3                                                                  0.005075   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005466   \n",
       "total_energy_kwh_process_1                                                            0.005417   \n",
       "total_energy_kwh_process_2                                                            0.005435   \n",
       "total_energy_kwh_process_3                                                            0.005843   \n",
       "total_energy_joules_process_0                                                      19676.94247   \n",
       "total_energy_joules_process_1                                                     19502.288836   \n",
       "total_energy_joules_process_2                                                     19566.135723   \n",
       "total_energy_joules_process_3                                                     21033.597667   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1200.855005   \n",
       "ram_power_avg                                                                         0.665195   \n",
       "cpu_energy_total                                                                      0.002728   \n",
       "gpu_energy_total                                                                      0.019417   \n",
       "ram_energy_total                                                                      0.000015   \n",
       "per-process_emissions_0                                                                0.00207   \n",
       "per-process_emissions_1                                                               0.002082   \n",
       "per-process_emissions_2                                                               0.002064   \n",
       "per-process_emissions_3                                                               0.002226   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            64  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                              179   \n",
       "date_time                                                        April 11, 2025 at 02:57:12 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                             0.98   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022225   \n",
       "total_energy_joules                                                               80008.879377   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.204777   \n",
       "joules_per_token                                                                      4.883354   \n",
       "flops_per_joule                                                               211851123.589203   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.232562   \n",
       "average_latency_ms_per_batch                                                       2904.070252   \n",
       "throughput_queries_per_sec                                                            5.509509   \n",
       "throughput_tokens_per_sec                                                             705.2171   \n",
       "cpu_usage_percent                                                                          3.4   \n",
       "cpu_memory_usage_bytes                                                              2016215040   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 853.994754   \n",
       "gpu_power_process_1                                                                 1769.71848   \n",
       "gpu_power_process_2                                                                 833.875722   \n",
       "gpu_power_process_3                                                                 636.255324   \n",
       "ram_power_process_0                                                                   0.702041   \n",
       "ram_power_process_1                                                                   0.653923   \n",
       "ram_power_process_2                                                                   0.654596   \n",
       "ram_power_process_3                                                                   0.648202   \n",
       "cpu_energy_process_0                                                                  0.000663   \n",
       "cpu_energy_process_1                                                                  0.000737   \n",
       "cpu_energy_process_2                                                                  0.000737   \n",
       "cpu_energy_process_3                                                                  0.000808   \n",
       "gpu_energy_process_0                                                                  0.004661   \n",
       "gpu_energy_process_1                                                                  0.004775   \n",
       "gpu_energy_process_2                                                                  0.004778   \n",
       "gpu_energy_process_3                                                                  0.005049   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005328   \n",
       "total_energy_kwh_process_1                                                            0.005516   \n",
       "total_energy_kwh_process_2                                                            0.005519   \n",
       "total_energy_kwh_process_3                                                            0.005862   \n",
       "total_energy_joules_process_0                                                     19180.363871   \n",
       "total_energy_joules_process_1                                                     19856.752377   \n",
       "total_energy_joules_process_2                                                     19869.082842   \n",
       "total_energy_joules_process_3                                                     21102.680287   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       1023.46107   \n",
       "ram_power_avg                                                                          0.66469   \n",
       "cpu_energy_total                                                                      0.002945   \n",
       "gpu_energy_total                                                                      0.019264   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002233   \n",
       "per-process_emissions_1                                                                0.00203   \n",
       "per-process_emissions_2                                                               0.002103   \n",
       "per-process_emissions_3                                                               0.002101   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            65  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                              180   \n",
       "date_time                                                        April 11, 2025 at 02:58:15 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.7   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022037   \n",
       "total_energy_joules                                                               79332.316652   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.206524   \n",
       "joules_per_token                                                                       4.84206   \n",
       "flops_per_joule                                                               213657834.643894   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.270355   \n",
       "average_latency_ms_per_batch                                                       2908.794437   \n",
       "throughput_queries_per_sec                                                            5.500561   \n",
       "throughput_tokens_per_sec                                                           704.071754   \n",
       "cpu_usage_percent                                                                          3.6   \n",
       "cpu_memory_usage_bytes                                                              2011607040   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 657.723019   \n",
       "gpu_power_process_1                                                                 637.201177   \n",
       "gpu_power_process_2                                                                 733.064031   \n",
       "gpu_power_process_3                                                                 538.970033   \n",
       "ram_power_process_0                                                                   0.701194   \n",
       "ram_power_process_1                                                                   0.650873   \n",
       "ram_power_process_2                                                                   0.649035   \n",
       "ram_power_process_3                                                                   0.656748   \n",
       "cpu_energy_process_0                                                                  0.000675   \n",
       "cpu_energy_process_1                                                                  0.000696   \n",
       "cpu_energy_process_2                                                                  0.000726   \n",
       "cpu_energy_process_3                                                                  0.000769   \n",
       "gpu_energy_process_0                                                                  0.004675   \n",
       "gpu_energy_process_1                                                                  0.004718   \n",
       "gpu_energy_process_2                                                                  0.004675   \n",
       "gpu_energy_process_3                                                                  0.005087   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005354   \n",
       "total_energy_kwh_process_1                                                            0.005417   \n",
       "total_energy_kwh_process_2                                                            0.005404   \n",
       "total_energy_kwh_process_3                                                            0.005861   \n",
       "total_energy_joules_process_0                                                      19273.79627   \n",
       "total_energy_joules_process_1                                                     19501.893728   \n",
       "total_energy_joules_process_2                                                      19456.16731   \n",
       "total_energy_joules_process_3                                                     21100.459344   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       641.739565   \n",
       "ram_power_avg                                                                         0.664462   \n",
       "cpu_energy_total                                                                      0.002866   \n",
       "gpu_energy_total                                                                      0.019155   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                                0.00204   \n",
       "per-process_emissions_1                                                               0.002064   \n",
       "per-process_emissions_2                                                               0.002059   \n",
       "per-process_emissions_3                                                               0.002233   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            66  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                              181   \n",
       "date_time                                                        April 11, 2025 at 02:59:16 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.8   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022071   \n",
       "total_energy_joules                                                               79455.767743   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.206203   \n",
       "joules_per_token                                                                      4.849595   \n",
       "flops_per_joule                                                                213325872.67883   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.287194   \n",
       "average_latency_ms_per_batch                                                       2910.899296   \n",
       "throughput_queries_per_sec                                                            5.496583   \n",
       "throughput_tokens_per_sec                                                           703.562642   \n",
       "cpu_usage_percent                                                                          2.9   \n",
       "cpu_memory_usage_bytes                                                              2015203328   \n",
       "gpu_utilization_percent_0                                                                  5.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                2089.517058   \n",
       "gpu_power_process_1                                                                2148.794721   \n",
       "gpu_power_process_2                                                                1534.052834   \n",
       "gpu_power_process_3                                                                 432.464672   \n",
       "ram_power_process_0                                                                   0.701341   \n",
       "ram_power_process_1                                                                   0.645194   \n",
       "ram_power_process_2                                                                   0.653472   \n",
       "ram_power_process_3                                                                   0.652392   \n",
       "cpu_energy_process_0                                                                  0.000675   \n",
       "cpu_energy_process_1                                                                  0.000671   \n",
       "cpu_energy_process_2                                                                  0.000617   \n",
       "cpu_energy_process_3                                                                  0.000763   \n",
       "gpu_energy_process_0                                                                  0.004759   \n",
       "gpu_energy_process_1                                                                  0.004753   \n",
       "gpu_energy_process_2                                                                  0.004753   \n",
       "gpu_energy_process_3                                                                  0.005065   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005438   \n",
       "total_energy_kwh_process_1                                                            0.005428   \n",
       "total_energy_kwh_process_2                                                            0.005373   \n",
       "total_energy_kwh_process_3                                                            0.005832   \n",
       "total_energy_joules_process_0                                                     19577.395899   \n",
       "total_energy_joules_process_1                                                     19539.781334   \n",
       "total_energy_joules_process_2                                                     19342.955539   \n",
       "total_energy_joules_process_3                                                     20995.634972   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1551.207321   \n",
       "ram_power_avg                                                                           0.6631   \n",
       "cpu_energy_total                                                                      0.002726   \n",
       "gpu_energy_total                                                                       0.01933   \n",
       "ram_energy_total                                                                      0.000015   \n",
       "per-process_emissions_0                                                               0.002068   \n",
       "per-process_emissions_1                                                               0.002047   \n",
       "per-process_emissions_2                                                               0.002072   \n",
       "per-process_emissions_3                                                               0.002222   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            67  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                              182   \n",
       "date_time                                                        April 11, 2025 at 03:00:18 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                       0.02212   \n",
       "total_energy_joules                                                               79631.713062   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.205747   \n",
       "joules_per_token                                                                      4.860334   \n",
       "flops_per_joule                                                               212854531.709691   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.249351   \n",
       "average_latency_ms_per_batch                                                       2906.168873   \n",
       "throughput_queries_per_sec                                                             5.50553   \n",
       "throughput_tokens_per_sec                                                           704.707844   \n",
       "cpu_usage_percent                                                                          2.9   \n",
       "cpu_memory_usage_bytes                                                              2009636864   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                2453.755831   \n",
       "gpu_power_process_1                                                                1967.273382   \n",
       "gpu_power_process_2                                                                 985.508568   \n",
       "gpu_power_process_3                                                                  388.43613   \n",
       "ram_power_process_0                                                                   0.699768   \n",
       "ram_power_process_1                                                                   0.656291   \n",
       "ram_power_process_2                                                                   0.653499   \n",
       "ram_power_process_3                                                                   0.651119   \n",
       "cpu_energy_process_0                                                                   0.00068   \n",
       "cpu_energy_process_1                                                                  0.000681   \n",
       "cpu_energy_process_2                                                                  0.000687   \n",
       "cpu_energy_process_3                                                                  0.000774   \n",
       "gpu_energy_process_0                                                                  0.004743   \n",
       "gpu_energy_process_1                                                                  0.004745   \n",
       "gpu_energy_process_2                                                                  0.004753   \n",
       "gpu_energy_process_3                                                                   0.00504   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005428   \n",
       "total_energy_kwh_process_1                                                            0.005429   \n",
       "total_energy_kwh_process_2                                                            0.005444   \n",
       "total_energy_kwh_process_3                                                            0.005819   \n",
       "total_energy_joules_process_0                                                      19539.27857   \n",
       "total_energy_joules_process_1                                                     19545.829242   \n",
       "total_energy_joules_process_2                                                     19597.151085   \n",
       "total_energy_joules_process_3                                                     20949.454166   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1448.743478   \n",
       "ram_power_avg                                                                         0.665169   \n",
       "cpu_energy_total                                                                      0.002823   \n",
       "gpu_energy_total                                                                      0.019281   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002074   \n",
       "per-process_emissions_1                                                               0.002217   \n",
       "per-process_emissions_2                                                               0.002068   \n",
       "per-process_emissions_3                                                               0.002068   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            68  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                              183   \n",
       "date_time                                                        April 11, 2025 at 03:01:19 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                             0.98   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022105   \n",
       "total_energy_joules                                                               79576.984984   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.205889   \n",
       "joules_per_token                                                                      4.856994   \n",
       "flops_per_joule                                                               213000919.759229   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.336429   \n",
       "average_latency_ms_per_batch                                                        2917.05359   \n",
       "throughput_queries_per_sec                                                            5.484987   \n",
       "throughput_tokens_per_sec                                                           702.078291   \n",
       "cpu_usage_percent                                                                          3.4   \n",
       "cpu_memory_usage_bytes                                                              2014113792   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1847.083723   \n",
       "gpu_power_process_1                                                                 940.532198   \n",
       "gpu_power_process_2                                                                2485.634033   \n",
       "gpu_power_process_3                                                                  667.79854   \n",
       "ram_power_process_0                                                                   0.702147   \n",
       "ram_power_process_1                                                                   0.645009   \n",
       "ram_power_process_2                                                                   0.656103   \n",
       "ram_power_process_3                                                                    0.65764   \n",
       "cpu_energy_process_0                                                                  0.000677   \n",
       "cpu_energy_process_1                                                                  0.000687   \n",
       "cpu_energy_process_2                                                                  0.000668   \n",
       "cpu_energy_process_3                                                                  0.000744   \n",
       "gpu_energy_process_0                                                                  0.004751   \n",
       "gpu_energy_process_1                                                                  0.004775   \n",
       "gpu_energy_process_2                                                                  0.004762   \n",
       "gpu_energy_process_3                                                                  0.005026   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005432   \n",
       "total_energy_kwh_process_1                                                            0.005465   \n",
       "total_energy_kwh_process_2                                                            0.005434   \n",
       "total_energy_kwh_process_3                                                            0.005774   \n",
       "total_energy_joules_process_0                                                     19554.073109   \n",
       "total_energy_joules_process_1                                                     19674.885567   \n",
       "total_energy_joules_process_2                                                      19561.48776   \n",
       "total_energy_joules_process_3                                                     20786.538548   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1485.262123   \n",
       "ram_power_avg                                                                         0.665225   \n",
       "cpu_energy_total                                                                      0.002775   \n",
       "gpu_energy_total                                                                      0.019313   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                                 0.0022   \n",
       "per-process_emissions_1                                                                0.00207   \n",
       "per-process_emissions_2                                                               0.002082   \n",
       "per-process_emissions_3                                                               0.002069   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            69  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                              184   \n",
       "date_time                                                        April 11, 2025 at 03:02:21 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.7   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021988   \n",
       "total_energy_joules                                                               79156.588699   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.206982   \n",
       "joules_per_token                                                                      4.831335   \n",
       "flops_per_joule                                                               214132155.916694   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.317205   \n",
       "average_latency_ms_per_batch                                                       2914.650578   \n",
       "throughput_queries_per_sec                                                            5.489509   \n",
       "throughput_tokens_per_sec                                                           702.657127   \n",
       "cpu_usage_percent                                                                          3.6   \n",
       "cpu_memory_usage_bytes                                                              2011889664   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  12903776256   \n",
       "gpu_max_memory_reserved_bytes                                                      12903776256   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                2041.919549   \n",
       "gpu_power_process_1                                                                1400.781667   \n",
       "gpu_power_process_2                                                                1137.646687   \n",
       "gpu_power_process_3                                                                 519.269961   \n",
       "ram_power_process_0                                                                   0.700899   \n",
       "ram_power_process_1                                                                   0.649162   \n",
       "ram_power_process_2                                                                   0.654551   \n",
       "ram_power_process_3                                                                   0.649116   \n",
       "cpu_energy_process_0                                                                  0.000614   \n",
       "cpu_energy_process_1                                                                  0.000626   \n",
       "cpu_energy_process_2                                                                  0.000642   \n",
       "cpu_energy_process_3                                                                   0.00075   \n",
       "gpu_energy_process_0                                                                  0.004762   \n",
       "gpu_energy_process_1                                                                  0.004768   \n",
       "gpu_energy_process_2                                                                  0.004762   \n",
       "gpu_energy_process_3                                                                  0.005047   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                             0.00538   \n",
       "total_energy_kwh_process_1                                                            0.005398   \n",
       "total_energy_kwh_process_2                                                            0.005408   \n",
       "total_energy_kwh_process_3                                                            0.005802   \n",
       "total_energy_joules_process_0                                                     19368.197392   \n",
       "total_energy_joules_process_1                                                     19431.327363   \n",
       "total_energy_joules_process_2                                                     19470.194454   \n",
       "total_energy_joules_process_3                                                      20886.86949   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1274.904466   \n",
       "ram_power_avg                                                                         0.663432   \n",
       "cpu_energy_total                                                                      0.002632   \n",
       "gpu_energy_total                                                                       0.01934   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                                0.00221   \n",
       "per-process_emissions_1                                                                0.00206   \n",
       "per-process_emissions_2                                                               0.002056   \n",
       "per-process_emissions_3                                                                0.00205   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            70  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                              185   \n",
       "date_time                                                        April 11, 2025 at 03:03:22 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.8   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                       0.02195   \n",
       "total_energy_joules                                                               79021.660488   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.207336   \n",
       "joules_per_token                                                                      4.823099   \n",
       "flops_per_joule                                                               214497783.119962   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.158494   \n",
       "average_latency_ms_per_batch                                                       2894.811798   \n",
       "throughput_queries_per_sec                                                             5.52713   \n",
       "throughput_tokens_per_sec                                                            707.47259   \n",
       "cpu_usage_percent                                                                          3.3   \n",
       "cpu_memory_usage_bytes                                                              1994887168   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 580.657842   \n",
       "gpu_power_process_1                                                                 671.272318   \n",
       "gpu_power_process_2                                                                 537.766222   \n",
       "gpu_power_process_3                                                                 460.458775   \n",
       "ram_power_process_0                                                                   0.695443   \n",
       "ram_power_process_1                                                                   0.655895   \n",
       "ram_power_process_2                                                                   0.655081   \n",
       "ram_power_process_3                                                                   0.650961   \n",
       "cpu_energy_process_0                                                                  0.000687   \n",
       "cpu_energy_process_1                                                                  0.000689   \n",
       "cpu_energy_process_2                                                                  0.000703   \n",
       "cpu_energy_process_3                                                                  0.000737   \n",
       "gpu_energy_process_0                                                                  0.004664   \n",
       "gpu_energy_process_1                                                                  0.004664   \n",
       "gpu_energy_process_2                                                                  0.004708   \n",
       "gpu_energy_process_3                                                                  0.005081   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005356   \n",
       "total_energy_kwh_process_1                                                            0.005357   \n",
       "total_energy_kwh_process_2                                                            0.005415   \n",
       "total_energy_kwh_process_3                                                            0.005823   \n",
       "total_energy_joules_process_0                                                     19280.720576   \n",
       "total_energy_joules_process_1                                                     19285.441213   \n",
       "total_energy_joules_process_2                                                     19493.519826   \n",
       "total_energy_joules_process_3                                                     20961.978873   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       562.538789   \n",
       "ram_power_avg                                                                         0.664345   \n",
       "cpu_energy_total                                                                      0.002817   \n",
       "gpu_energy_total                                                                      0.019118   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002041   \n",
       "per-process_emissions_1                                                               0.002063   \n",
       "per-process_emissions_2                                                                0.00204   \n",
       "per-process_emissions_3                                                               0.002218   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            71  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                              186   \n",
       "date_time                                                        April 11, 2025 at 03:04:26 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022064   \n",
       "total_energy_joules                                                               79431.609675   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.206265   \n",
       "joules_per_token                                                                      4.848121   \n",
       "flops_per_joule                                                               213390752.907894   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.202428   \n",
       "average_latency_ms_per_batch                                                       2900.303453   \n",
       "throughput_queries_per_sec                                                            5.516664   \n",
       "throughput_tokens_per_sec                                                           706.133007   \n",
       "cpu_usage_percent                                                                          3.6   \n",
       "cpu_memory_usage_bytes                                                              1993248768   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 481.238339   \n",
       "gpu_power_process_1                                                                1468.601516   \n",
       "gpu_power_process_2                                                                 676.799436   \n",
       "gpu_power_process_3                                                                 555.574279   \n",
       "ram_power_process_0                                                                   0.694356   \n",
       "ram_power_process_1                                                                   0.661739   \n",
       "ram_power_process_2                                                                   0.648881   \n",
       "ram_power_process_3                                                                   0.649638   \n",
       "cpu_energy_process_0                                                                  0.000672   \n",
       "cpu_energy_process_1                                                                  0.000734   \n",
       "cpu_energy_process_2                                                                  0.000672   \n",
       "cpu_energy_process_3                                                                  0.000765   \n",
       "gpu_energy_process_0                                                                  0.004691   \n",
       "gpu_energy_process_1                                                                  0.004709   \n",
       "gpu_energy_process_2                                                                  0.004706   \n",
       "gpu_energy_process_3                                                                  0.005097   \n",
       "ram_energy_process_0                                                                  0.000005   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005368   \n",
       "total_energy_kwh_process_1                                                            0.005447   \n",
       "total_energy_kwh_process_2                                                            0.005383   \n",
       "total_energy_kwh_process_3                                                            0.005867   \n",
       "total_energy_joules_process_0                                                     19324.221231   \n",
       "total_energy_joules_process_1                                                      19608.47229   \n",
       "total_energy_joules_process_2                                                     19377.659263   \n",
       "total_energy_joules_process_3                                                     21121.256891   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       795.553393   \n",
       "ram_power_avg                                                                         0.663654   \n",
       "cpu_energy_total                                                                      0.002844   \n",
       "gpu_energy_total                                                                      0.019204   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002051   \n",
       "per-process_emissions_1                                                               0.002235   \n",
       "per-process_emissions_2                                                               0.002045   \n",
       "per-process_emissions_3                                                               0.002075   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            72  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                              187   \n",
       "date_time                                                        April 11, 2025 at 03:05:27 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                             0.98   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022212   \n",
       "total_energy_joules                                                               79963.061299   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.204895   \n",
       "joules_per_token                                                                      4.880558   \n",
       "flops_per_joule                                                               211972512.280364   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.640073   \n",
       "average_latency_ms_per_batch                                                       2955.009096   \n",
       "throughput_queries_per_sec                                                            5.414535   \n",
       "throughput_tokens_per_sec                                                           693.060472   \n",
       "cpu_usage_percent                                                                          2.9   \n",
       "cpu_memory_usage_bytes                                                              2012434432   \n",
       "gpu_utilization_percent_0                                                                  5.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  59.540126   \n",
       "gpu_power_process_1                                                                2311.788445   \n",
       "gpu_power_process_2                                                                        0.0   \n",
       "gpu_power_process_3                                                                 463.830376   \n",
       "ram_power_process_0                                                                   0.700981   \n",
       "ram_power_process_1                                                                   0.649854   \n",
       "ram_power_process_2                                                                    0.65436   \n",
       "ram_power_process_3                                                                   0.649316   \n",
       "cpu_energy_process_0                                                                  0.000708   \n",
       "cpu_energy_process_1                                                                  0.000714   \n",
       "cpu_energy_process_2                                                                  0.000633   \n",
       "cpu_energy_process_3                                                                  0.000799   \n",
       "gpu_energy_process_0                                                                  0.004769   \n",
       "gpu_energy_process_1                                                                  0.004754   \n",
       "gpu_energy_process_2                                                                  0.004757   \n",
       "gpu_energy_process_3                                                                  0.005062   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005481   \n",
       "total_energy_kwh_process_1                                                            0.005472   \n",
       "total_energy_kwh_process_2                                                            0.005394   \n",
       "total_energy_kwh_process_3                                                            0.005865   \n",
       "total_energy_joules_process_0                                                     19731.312537   \n",
       "total_energy_joules_process_1                                                     19698.507808   \n",
       "total_energy_joules_process_2                                                     19419.411241   \n",
       "total_energy_joules_process_3                                                     21113.829712   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       708.789737   \n",
       "ram_power_avg                                                                         0.663628   \n",
       "cpu_energy_total                                                                      0.002854   \n",
       "gpu_energy_total                                                                      0.019342   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002084   \n",
       "per-process_emissions_1                                                               0.002088   \n",
       "per-process_emissions_2                                                               0.002234   \n",
       "per-process_emissions_3                                                               0.002055   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            73  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                              188   \n",
       "date_time                                                        April 11, 2025 at 03:06:29 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.7   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022266   \n",
       "total_energy_joules                                                               80159.040345   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.204394   \n",
       "joules_per_token                                                                       4.89252   \n",
       "flops_per_joule                                                               211454265.422914   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.725851   \n",
       "average_latency_ms_per_batch                                                       2965.731396   \n",
       "throughput_queries_per_sec                                                            5.394959   \n",
       "throughput_tokens_per_sec                                                           690.554783   \n",
       "cpu_usage_percent                                                                          3.7   \n",
       "cpu_memory_usage_bytes                                                              2016657408   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  84.025257   \n",
       "gpu_power_process_1                                                                  85.133778   \n",
       "gpu_power_process_2                                                                  82.865532   \n",
       "gpu_power_process_3                                                                 534.109641   \n",
       "ram_power_process_0                                                                   0.703035   \n",
       "ram_power_process_1                                                                   0.652764   \n",
       "ram_power_process_2                                                                    0.65512   \n",
       "ram_power_process_3                                                                   0.655417   \n",
       "cpu_energy_process_0                                                                   0.00072   \n",
       "cpu_energy_process_1                                                                  0.000714   \n",
       "cpu_energy_process_2                                                                  0.000713   \n",
       "cpu_energy_process_3                                                                  0.000762   \n",
       "gpu_energy_process_0                                                                  0.004769   \n",
       "gpu_energy_process_1                                                                  0.004763   \n",
       "gpu_energy_process_2                                                                  0.004762   \n",
       "gpu_energy_process_3                                                                  0.005047   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005493   \n",
       "total_energy_kwh_process_1                                                            0.005481   \n",
       "total_energy_kwh_process_2                                                            0.005479   \n",
       "total_energy_kwh_process_3                                                            0.005813   \n",
       "total_energy_joules_process_0                                                     19775.897441   \n",
       "total_energy_joules_process_1                                                      19731.83366   \n",
       "total_energy_joules_process_2                                                     19725.122126   \n",
       "total_energy_joules_process_3                                                     20926.187117   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       196.533552   \n",
       "ram_power_avg                                                                         0.666584   \n",
       "cpu_energy_total                                                                      0.002909   \n",
       "gpu_energy_total                                                                      0.019341   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002087   \n",
       "per-process_emissions_1                                                               0.002093   \n",
       "per-process_emissions_2                                                               0.002214   \n",
       "per-process_emissions_3                                                               0.002088   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            74  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                              189   \n",
       "date_time                                                        April 11, 2025 at 03:07:33 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.8   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022171   \n",
       "total_energy_joules                                                               79813.883435   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.205278   \n",
       "joules_per_token                                                                      4.871453   \n",
       "flops_per_joule                                                               212368704.085806   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.440052   \n",
       "average_latency_ms_per_batch                                                       2930.006438   \n",
       "throughput_queries_per_sec                                                            5.460739   \n",
       "throughput_tokens_per_sec                                                           698.974573   \n",
       "cpu_usage_percent                                                                          3.8   \n",
       "cpu_memory_usage_bytes                                                              2012508160   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1280.226382   \n",
       "gpu_power_process_1                                                                 918.583448   \n",
       "gpu_power_process_2                                                                 724.683427   \n",
       "gpu_power_process_3                                                                  836.53767   \n",
       "ram_power_process_0                                                                   0.700842   \n",
       "ram_power_process_1                                                                   0.653312   \n",
       "ram_power_process_2                                                                   0.653895   \n",
       "ram_power_process_3                                                                   0.654262   \n",
       "cpu_energy_process_0                                                                  0.000726   \n",
       "cpu_energy_process_1                                                                  0.000715   \n",
       "cpu_energy_process_2                                                                  0.000719   \n",
       "cpu_energy_process_3                                                                  0.000808   \n",
       "gpu_energy_process_0                                                                  0.004772   \n",
       "gpu_energy_process_1                                                                  0.004669   \n",
       "gpu_energy_process_2                                                                  0.004683   \n",
       "gpu_energy_process_3                                                                  0.005061   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005503   \n",
       "total_energy_kwh_process_1                                                            0.005389   \n",
       "total_energy_kwh_process_2                                                            0.005406   \n",
       "total_energy_kwh_process_3                                                            0.005873   \n",
       "total_energy_joules_process_0                                                     19810.010381   \n",
       "total_energy_joules_process_1                                                     19399.541191   \n",
       "total_energy_joules_process_2                                                     19460.265624   \n",
       "total_energy_joules_process_3                                                     21144.066239   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       940.007732   \n",
       "ram_power_avg                                                                         0.665578   \n",
       "cpu_energy_total                                                                      0.002969   \n",
       "gpu_energy_total                                                                      0.019185   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002096   \n",
       "per-process_emissions_1                                                               0.002237   \n",
       "per-process_emissions_2                                                               0.002053   \n",
       "per-process_emissions_3                                                               0.002059   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            75  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                              190   \n",
       "date_time                                                        April 11, 2025 at 03:08:35 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022127   \n",
       "total_energy_joules                                                               79658.584807   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.205678   \n",
       "joules_per_token                                                                      4.861974   \n",
       "flops_per_joule                                                                212782728.11799   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.257695   \n",
       "average_latency_ms_per_batch                                                       2907.211887   \n",
       "throughput_queries_per_sec                                                            5.503555   \n",
       "throughput_tokens_per_sec                                                           704.455017   \n",
       "cpu_usage_percent                                                                          3.4   \n",
       "cpu_memory_usage_bytes                                                              2015485952   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 854.465019   \n",
       "gpu_power_process_1                                                                 786.069152   \n",
       "gpu_power_process_2                                                                 623.092399   \n",
       "gpu_power_process_3                                                                 375.304828   \n",
       "ram_power_process_0                                                                   0.702211   \n",
       "ram_power_process_1                                                                   0.659035   \n",
       "ram_power_process_2                                                                   0.650888   \n",
       "ram_power_process_3                                                                   0.652259   \n",
       "cpu_energy_process_0                                                                   0.00072   \n",
       "cpu_energy_process_1                                                                  0.000731   \n",
       "cpu_energy_process_2                                                                  0.000687   \n",
       "cpu_energy_process_3                                                                  0.000749   \n",
       "gpu_energy_process_0                                                                  0.004673   \n",
       "gpu_energy_process_1                                                                  0.004673   \n",
       "gpu_energy_process_2                                                                  0.004754   \n",
       "gpu_energy_process_3                                                                  0.005122   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005398   \n",
       "total_energy_kwh_process_1                                                            0.005409   \n",
       "total_energy_kwh_process_2                                                            0.005445   \n",
       "total_energy_kwh_process_3                                                            0.005876   \n",
       "total_energy_joules_process_0                                                     19431.796821   \n",
       "total_energy_joules_process_1                                                     19471.061498   \n",
       "total_energy_joules_process_2                                                     19601.278114   \n",
       "total_energy_joules_process_3                                                     21154.448374   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        659.73285   \n",
       "ram_power_avg                                                                         0.666098   \n",
       "cpu_energy_total                                                                      0.002887   \n",
       "gpu_energy_total                                                                      0.019223   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002056   \n",
       "per-process_emissions_1                                                               0.002074   \n",
       "per-process_emissions_2                                                                0.00206   \n",
       "per-process_emissions_3                                                               0.002239   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            76  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                              191   \n",
       "date_time                                                        April 11, 2025 at 03:09:37 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                             0.98   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022127   \n",
       "total_energy_joules                                                               79655.924763   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.205685   \n",
       "joules_per_token                                                                      4.861812   \n",
       "flops_per_joule                                                               212789833.821877   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.409533   \n",
       "average_latency_ms_per_batch                                                       2926.191577   \n",
       "throughput_queries_per_sec                                                            5.467858   \n",
       "throughput_tokens_per_sec                                                           699.885823   \n",
       "cpu_usage_percent                                                                          3.4   \n",
       "cpu_memory_usage_bytes                                                              2012946432   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 800.847829   \n",
       "gpu_power_process_1                                                                 851.971445   \n",
       "gpu_power_process_2                                                                1469.001199   \n",
       "gpu_power_process_3                                                                 403.857038   \n",
       "ram_power_process_0                                                                   0.701301   \n",
       "ram_power_process_1                                                                    0.65507   \n",
       "ram_power_process_2                                                                   0.650066   \n",
       "ram_power_process_3                                                                    0.65305   \n",
       "cpu_energy_process_0                                                                   0.00067   \n",
       "cpu_energy_process_1                                                                    0.0007   \n",
       "cpu_energy_process_2                                                                  0.000686   \n",
       "cpu_energy_process_3                                                                  0.000767   \n",
       "gpu_energy_process_0                                                                  0.004663   \n",
       "gpu_energy_process_1                                                                  0.004798   \n",
       "gpu_energy_process_2                                                                  0.004774   \n",
       "gpu_energy_process_3                                                                  0.005052   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005337   \n",
       "total_energy_kwh_process_1                                                            0.005502   \n",
       "total_energy_kwh_process_2                                                            0.005464   \n",
       "total_energy_kwh_process_3                                                            0.005824   \n",
       "total_energy_joules_process_0                                                     19214.426719   \n",
       "total_energy_joules_process_1                                                     19805.983148   \n",
       "total_energy_joules_process_2                                                     19670.382157   \n",
       "total_energy_joules_process_3                                                     20965.132739   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       881.419378   \n",
       "ram_power_avg                                                                         0.664872   \n",
       "cpu_energy_total                                                                      0.002823   \n",
       "gpu_energy_total                                                                      0.019287   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002219   \n",
       "per-process_emissions_1                                                               0.002033   \n",
       "per-process_emissions_2                                                               0.002082   \n",
       "per-process_emissions_3                                                               0.002096   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            77  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                              192   \n",
       "date_time                                                        April 11, 2025 at 03:10:39 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.7   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021753   \n",
       "total_energy_joules                                                               78312.258436   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.209214   \n",
       "joules_per_token                                                                      4.779801   \n",
       "flops_per_joule                                                               216440839.935347   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.339891   \n",
       "average_latency_ms_per_batch                                                       2917.486425   \n",
       "throughput_queries_per_sec                                                            5.484173   \n",
       "throughput_tokens_per_sec                                                           701.974132   \n",
       "cpu_usage_percent                                                                          3.5   \n",
       "cpu_memory_usage_bytes                                                              2011414528   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1573.157176   \n",
       "gpu_power_process_1                                                                 944.440022   \n",
       "gpu_power_process_2                                                                 908.342508   \n",
       "gpu_power_process_3                                                                5386.906198   \n",
       "ram_power_process_0                                                                   0.700839   \n",
       "ram_power_process_1                                                                   0.649684   \n",
       "ram_power_process_2                                                                   0.654472   \n",
       "ram_power_process_3                                                                   0.657243   \n",
       "cpu_energy_process_0                                                                  0.000677   \n",
       "cpu_energy_process_1                                                                  0.000671   \n",
       "cpu_energy_process_2                                                                  0.000609   \n",
       "cpu_energy_process_3                                                                  0.000692   \n",
       "gpu_energy_process_0                                                                  0.004753   \n",
       "gpu_energy_process_1                                                                  0.004663   \n",
       "gpu_energy_process_2                                                                  0.004657   \n",
       "gpu_energy_process_3                                                                  0.005015   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005434   \n",
       "total_energy_kwh_process_1                                                            0.005338   \n",
       "total_energy_kwh_process_2                                                             0.00527   \n",
       "total_energy_kwh_process_3                                                            0.005711   \n",
       "total_energy_joules_process_0                                                     19563.896959   \n",
       "total_energy_joules_process_1                                                     19217.148449   \n",
       "total_energy_joules_process_2                                                      18972.36206   \n",
       "total_energy_joules_process_3                                                     20558.850968   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      2203.211476   \n",
       "ram_power_avg                                                                         0.665559   \n",
       "cpu_energy_total                                                                      0.002649   \n",
       "gpu_energy_total                                                                      0.019089   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002008   \n",
       "per-process_emissions_1                                                               0.002176   \n",
       "per-process_emissions_2                                                                0.00207   \n",
       "per-process_emissions_3                                                               0.002034   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            78  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                              193   \n",
       "date_time                                                        April 11, 2025 at 03:11:41 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.8   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022035   \n",
       "total_energy_joules                                                               79324.468177   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.206544   \n",
       "joules_per_token                                                                      4.841581   \n",
       "flops_per_joule                                                               213678974.252386   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.370914   \n",
       "average_latency_ms_per_batch                                                       2921.364236   \n",
       "throughput_queries_per_sec                                                            5.476893   \n",
       "throughput_tokens_per_sec                                                           701.042333   \n",
       "cpu_usage_percent                                                                          3.5   \n",
       "cpu_memory_usage_bytes                                                              2013650944   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1695.250619   \n",
       "gpu_power_process_1                                                                  985.85255   \n",
       "gpu_power_process_2                                                                1872.834769   \n",
       "gpu_power_process_3                                                                2096.363286   \n",
       "ram_power_process_0                                                                   0.701915   \n",
       "ram_power_process_1                                                                    0.64994   \n",
       "ram_power_process_2                                                                   0.652318   \n",
       "ram_power_process_3                                                                   0.646987   \n",
       "cpu_energy_process_0                                                                   0.00063   \n",
       "cpu_energy_process_1                                                                  0.000685   \n",
       "cpu_energy_process_2                                                                  0.000681   \n",
       "cpu_energy_process_3                                                                  0.000698   \n",
       "gpu_energy_process_0                                                                  0.004762   \n",
       "gpu_energy_process_1                                                                  0.004769   \n",
       "gpu_energy_process_2                                                                  0.004768   \n",
       "gpu_energy_process_3                                                                  0.005026   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005396   \n",
       "total_energy_kwh_process_1                                                            0.005458   \n",
       "total_energy_kwh_process_2                                                            0.005452   \n",
       "total_energy_kwh_process_3                                                            0.005728   \n",
       "total_energy_joules_process_0                                                     19425.262245   \n",
       "total_energy_joules_process_1                                                      19650.38001   \n",
       "total_energy_joules_process_2                                                     19628.091002   \n",
       "total_energy_joules_process_3                                                      20620.73492   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1662.575306   \n",
       "ram_power_avg                                                                          0.66279   \n",
       "cpu_energy_total                                                                      0.002694   \n",
       "gpu_energy_total                                                                      0.019325   \n",
       "ram_energy_total                                                                      0.000015   \n",
       "per-process_emissions_0                                                               0.002077   \n",
       "per-process_emissions_1                                                               0.002056   \n",
       "per-process_emissions_2                                                               0.002182   \n",
       "per-process_emissions_3                                                               0.002079   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            79  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                              194   \n",
       "date_time                                                        April 11, 2025 at 03:12:44 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022129   \n",
       "total_energy_joules                                                               79663.168096   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.205666   \n",
       "joules_per_token                                                                      4.862254   \n",
       "flops_per_joule                                                               212770486.013364   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              23.21867   \n",
       "average_latency_ms_per_batch                                                       2902.333711   \n",
       "throughput_queries_per_sec                                                            5.512805   \n",
       "throughput_tokens_per_sec                                                           705.639049   \n",
       "cpu_usage_percent                                                                          3.8   \n",
       "cpu_memory_usage_bytes                                                              2017865728   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 829.361042   \n",
       "gpu_power_process_1                                                                 639.712444   \n",
       "gpu_power_process_2                                                                 596.254414   \n",
       "gpu_power_process_3                                                                 518.756464   \n",
       "ram_power_process_0                                                                   0.703132   \n",
       "ram_power_process_1                                                                   0.649459   \n",
       "ram_power_process_2                                                                   0.648336   \n",
       "ram_power_process_3                                                                    0.65073   \n",
       "cpu_energy_process_0                                                                  0.000699   \n",
       "cpu_energy_process_1                                                                  0.000697   \n",
       "cpu_energy_process_2                                                                  0.000717   \n",
       "cpu_energy_process_3                                                                  0.000801   \n",
       "gpu_energy_process_0                                                                   0.00466   \n",
       "gpu_energy_process_1                                                                   0.00468   \n",
       "gpu_energy_process_2                                                                  0.004758   \n",
       "gpu_energy_process_3                                                                  0.005098   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005364   \n",
       "total_energy_kwh_process_1                                                            0.005381   \n",
       "total_energy_kwh_process_2                                                             0.00548   \n",
       "total_energy_kwh_process_3                                                            0.005904   \n",
       "total_energy_joules_process_0                                                     19309.538146   \n",
       "total_energy_joules_process_1                                                     19373.245152   \n",
       "total_energy_joules_process_2                                                     19727.307429   \n",
       "total_energy_joules_process_3                                                     21253.077369   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       646.021091   \n",
       "ram_power_avg                                                                         0.662914   \n",
       "cpu_energy_total                                                                      0.002915   \n",
       "gpu_energy_total                                                                      0.019196   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002249   \n",
       "per-process_emissions_1                                                               0.002043   \n",
       "per-process_emissions_2                                                                0.00205   \n",
       "per-process_emissions_3                                                               0.002088   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            80  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                              195   \n",
       "date_time                                                        April 11, 2025 at 03:13:47 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                             0.98   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022042   \n",
       "total_energy_joules                                                               79350.575857   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.206476   \n",
       "joules_per_token                                                                      4.843175   \n",
       "flops_per_joule                                                                213608670.26088   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.554853   \n",
       "average_latency_ms_per_batch                                                        2944.35657   \n",
       "throughput_queries_per_sec                                                            5.434124   \n",
       "throughput_tokens_per_sec                                                           695.567928   \n",
       "cpu_usage_percent                                                                          3.6   \n",
       "cpu_memory_usage_bytes                                                              2012020736   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1183.427842   \n",
       "gpu_power_process_1                                                                2603.764889   \n",
       "gpu_power_process_2                                                                1863.487297   \n",
       "gpu_power_process_3                                                                  421.87969   \n",
       "ram_power_process_0                                                                   0.700809   \n",
       "ram_power_process_1                                                                   0.651531   \n",
       "ram_power_process_2                                                                   0.656616   \n",
       "ram_power_process_3                                                                     0.6529   \n",
       "cpu_energy_process_0                                                                  0.000684   \n",
       "cpu_energy_process_1                                                                  0.000654   \n",
       "cpu_energy_process_2                                                                  0.000656   \n",
       "cpu_energy_process_3                                                                  0.000719   \n",
       "gpu_energy_process_0                                                                  0.004771   \n",
       "gpu_energy_process_1                                                                  0.004741   \n",
       "gpu_energy_process_2                                                                  0.004759   \n",
       "gpu_energy_process_3                                                                  0.005041   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005459   \n",
       "total_energy_kwh_process_1                                                            0.005399   \n",
       "total_energy_kwh_process_2                                                            0.005419   \n",
       "total_energy_kwh_process_3                                                            0.005764   \n",
       "total_energy_joules_process_0                                                     19653.176769   \n",
       "total_energy_joules_process_1                                                     19436.980272   \n",
       "total_energy_joules_process_2                                                     19508.364726   \n",
       "total_energy_joules_process_3                                                      20752.05409   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1518.139929   \n",
       "ram_power_avg                                                                         0.665464   \n",
       "cpu_energy_total                                                                      0.002714   \n",
       "gpu_energy_total                                                                      0.019312   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002196   \n",
       "per-process_emissions_1                                                               0.002057   \n",
       "per-process_emissions_2                                                                0.00208   \n",
       "per-process_emissions_3                                                               0.002064   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            81  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                              196   \n",
       "date_time                                                        April 11, 2025 at 03:14:49 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.7   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022019   \n",
       "total_energy_joules                                                               79267.089003   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.206694   \n",
       "joules_per_token                                                                      4.838079   \n",
       "flops_per_joule                                                               213833650.338204   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.547086   \n",
       "average_latency_ms_per_batch                                                       2943.385782   \n",
       "throughput_queries_per_sec                                                            5.435917   \n",
       "throughput_tokens_per_sec                                                           695.797341   \n",
       "cpu_usage_percent                                                                          3.6   \n",
       "cpu_memory_usage_bytes                                                              2017513472   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                   1252.424   \n",
       "gpu_power_process_1                                                                 793.987273   \n",
       "gpu_power_process_2                                                                 758.812641   \n",
       "gpu_power_process_3                                                                  27.593747   \n",
       "ram_power_process_0                                                                   0.703116   \n",
       "ram_power_process_1                                                                   0.648321   \n",
       "ram_power_process_2                                                                   0.650671   \n",
       "ram_power_process_3                                                                   0.649894   \n",
       "cpu_energy_process_0                                                                  0.000754   \n",
       "cpu_energy_process_1                                                                  0.000704   \n",
       "cpu_energy_process_2                                                                  0.000699   \n",
       "cpu_energy_process_3                                                                  0.000761   \n",
       "gpu_energy_process_0                                                                  0.004779   \n",
       "gpu_energy_process_1                                                                  0.004635   \n",
       "gpu_energy_process_2                                                                  0.004655   \n",
       "gpu_energy_process_3                                                                  0.005018   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000003   \n",
       "ram_energy_process_2                                                                  0.000003   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005537   \n",
       "total_energy_kwh_process_1                                                            0.005342   \n",
       "total_energy_kwh_process_2                                                            0.005357   \n",
       "total_energy_kwh_process_3                                                            0.005783   \n",
       "total_energy_joules_process_0                                                     19932.519983   \n",
       "total_energy_joules_process_1                                                     19231.370819   \n",
       "total_energy_joules_process_2                                                     19284.058732   \n",
       "total_energy_joules_process_3                                                     20819.139469   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       708.204415   \n",
       "ram_power_avg                                                                         0.663001   \n",
       "cpu_energy_total                                                                      0.002917   \n",
       "gpu_energy_total                                                                      0.019087   \n",
       "ram_energy_total                                                                      0.000015   \n",
       "per-process_emissions_0                                                               0.002041   \n",
       "per-process_emissions_1                                                               0.002035   \n",
       "per-process_emissions_2                                                               0.002203   \n",
       "per-process_emissions_3                                                               0.002109   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            82  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                              197   \n",
       "date_time                                                        April 11, 2025 at 03:15:52 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.8   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022055   \n",
       "total_energy_joules                                                               79399.139493   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                       0.20635   \n",
       "joules_per_token                                                                      4.846139   \n",
       "flops_per_joule                                                               213478018.796583   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              23.34714   \n",
       "average_latency_ms_per_batch                                                       2918.392557   \n",
       "throughput_queries_per_sec                                                             5.48247   \n",
       "throughput_tokens_per_sec                                                           701.756176   \n",
       "cpu_usage_percent                                                                          3.4   \n",
       "cpu_memory_usage_bytes                                                              2031509504   \n",
       "gpu_utilization_percent_0                                                                  9.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 758.319875   \n",
       "gpu_power_process_1                                                                 590.211571   \n",
       "gpu_power_process_2                                                                1208.611625   \n",
       "gpu_power_process_3                                                                 533.796635   \n",
       "ram_power_process_0                                                                   0.708105   \n",
       "ram_power_process_1                                                                   0.651007   \n",
       "ram_power_process_2                                                                   0.649127   \n",
       "ram_power_process_3                                                                   0.649582   \n",
       "cpu_energy_process_0                                                                  0.000689   \n",
       "cpu_energy_process_1                                                                  0.000703   \n",
       "cpu_energy_process_2                                                                  0.000738   \n",
       "cpu_energy_process_3                                                                  0.000746   \n",
       "gpu_energy_process_0                                                                  0.004672   \n",
       "gpu_energy_process_1                                                                  0.004741   \n",
       "gpu_energy_process_2                                                                  0.004656   \n",
       "gpu_energy_process_3                                                                  0.005094   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005364   \n",
       "total_energy_kwh_process_1                                                            0.005449   \n",
       "total_energy_kwh_process_2                                                            0.005398   \n",
       "total_energy_kwh_process_3                                                            0.005844   \n",
       "total_energy_joules_process_0                                                     19312.169634   \n",
       "total_energy_joules_process_1                                                     19616.363117   \n",
       "total_energy_joules_process_2                                                     19432.082105   \n",
       "total_energy_joules_process_3                                                     21038.524638   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       772.734927   \n",
       "ram_power_avg                                                                         0.664455   \n",
       "cpu_energy_total                                                                      0.002875   \n",
       "gpu_energy_total                                                                      0.019164   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002044   \n",
       "per-process_emissions_1                                                               0.002226   \n",
       "per-process_emissions_2                                                               0.002056   \n",
       "per-process_emissions_3                                                               0.002076   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            83  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                              198   \n",
       "date_time                                                        April 11, 2025 at 03:16:56 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022409   \n",
       "total_energy_joules                                                               80672.664643   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.203092   \n",
       "joules_per_token                                                                      4.923869   \n",
       "flops_per_joule                                                               210107984.757064   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.360484   \n",
       "average_latency_ms_per_batch                                                       2920.060557   \n",
       "throughput_queries_per_sec                                                            5.479338   \n",
       "throughput_tokens_per_sec                                                           701.355318   \n",
       "cpu_usage_percent                                                                          3.2   \n",
       "cpu_memory_usage_bytes                                                              2011983872   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  91.654937   \n",
       "gpu_power_process_1                                                                  72.911802   \n",
       "gpu_power_process_2                                                                  51.069227   \n",
       "gpu_power_process_3                                                                 358.231676   \n",
       "ram_power_process_0                                                                    0.70079   \n",
       "ram_power_process_1                                                                   0.658836   \n",
       "ram_power_process_2                                                                   0.649784   \n",
       "ram_power_process_3                                                                   0.649331   \n",
       "cpu_energy_process_0                                                                  0.000727   \n",
       "cpu_energy_process_1                                                                  0.000724   \n",
       "cpu_energy_process_2                                                                  0.000731   \n",
       "cpu_energy_process_3                                                                  0.000825   \n",
       "gpu_energy_process_0                                                                  0.004767   \n",
       "gpu_energy_process_1                                                                  0.004768   \n",
       "gpu_energy_process_2                                                                  0.004766   \n",
       "gpu_energy_process_3                                                                  0.005085   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005498   \n",
       "total_energy_kwh_process_1                                                            0.005496   \n",
       "total_energy_kwh_process_2                                                              0.0055   \n",
       "total_energy_kwh_process_3                                                            0.005915   \n",
       "total_energy_joules_process_0                                                      19791.57957   \n",
       "total_energy_joules_process_1                                                     19787.304955   \n",
       "total_energy_joules_process_2                                                     19801.364976   \n",
       "total_energy_joules_process_3                                                     21292.415142   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       143.466911   \n",
       "ram_power_avg                                                                         0.664685   \n",
       "cpu_energy_total                                                                      0.003007   \n",
       "gpu_energy_total                                                                      0.019385   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002095   \n",
       "per-process_emissions_1                                                               0.002094   \n",
       "per-process_emissions_2                                                               0.002094   \n",
       "per-process_emissions_3                                                               0.002253   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            84  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                              199   \n",
       "date_time                                                        April 11, 2025 at 03:18:00 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                             0.98   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021976   \n",
       "total_energy_joules                                                               79114.439184   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.207092   \n",
       "joules_per_token                                                                      4.828762   \n",
       "flops_per_joule                                                               214246238.335844   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.647899   \n",
       "average_latency_ms_per_batch                                                       2955.987344   \n",
       "throughput_queries_per_sec                                                            5.412743   \n",
       "throughput_tokens_per_sec                                                           692.831113   \n",
       "cpu_usage_percent                                                                          3.8   \n",
       "cpu_memory_usage_bytes                                                              2016174080   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  963.58932   \n",
       "gpu_power_process_1                                                                2278.488365   \n",
       "gpu_power_process_2                                                                1156.969416   \n",
       "gpu_power_process_3                                                                 538.257839   \n",
       "ram_power_process_0                                                                   0.702488   \n",
       "ram_power_process_1                                                                   0.653818   \n",
       "ram_power_process_2                                                                   0.653021   \n",
       "ram_power_process_3                                                                   0.662247   \n",
       "cpu_energy_process_0                                                                  0.000632   \n",
       "cpu_energy_process_1                                                                  0.000662   \n",
       "cpu_energy_process_2                                                                  0.000636   \n",
       "cpu_energy_process_3                                                                  0.000751   \n",
       "gpu_energy_process_0                                                                  0.004759   \n",
       "gpu_energy_process_1                                                                  0.004747   \n",
       "gpu_energy_process_2                                                                  0.004752   \n",
       "gpu_energy_process_3                                                                  0.005021   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005395   \n",
       "total_energy_kwh_process_1                                                            0.005413   \n",
       "total_energy_kwh_process_2                                                            0.005392   \n",
       "total_energy_kwh_process_3                                                            0.005776   \n",
       "total_energy_joules_process_0                                                     19420.498608   \n",
       "total_energy_joules_process_1                                                     19488.021992   \n",
       "total_energy_joules_process_2                                                     19411.705308   \n",
       "total_energy_joules_process_3                                                     20794.213276   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1234.326235   \n",
       "ram_power_avg                                                                         0.667894   \n",
       "cpu_energy_total                                                                       0.00268   \n",
       "gpu_energy_total                                                                       0.01928   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002054   \n",
       "per-process_emissions_1                                                               0.002062   \n",
       "per-process_emissions_2                                                               0.002055   \n",
       "per-process_emissions_3                                                                 0.0022   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            85  \\\n",
       "config_name                                                                      latency_False   \n",
       "experiment_id                                                                              204   \n",
       "date_time                                                        April 11, 2025 at 03:21:23 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021932   \n",
       "total_energy_joules                                                               78954.196131   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.207513   \n",
       "joules_per_token                                                                      4.818982   \n",
       "flops_per_joule                                                               214681066.031948   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.879527   \n",
       "average_latency_ms_per_batch                                                       2984.940937   \n",
       "throughput_queries_per_sec                                                             5.36024   \n",
       "throughput_tokens_per_sec                                                           686.110728   \n",
       "cpu_usage_percent                                                                          3.1   \n",
       "cpu_memory_usage_bytes                                                              2015072256   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 761.124153   \n",
       "gpu_power_process_1                                                                 1793.70006   \n",
       "gpu_power_process_2                                                                1501.975819   \n",
       "gpu_power_process_3                                                                 455.151437   \n",
       "ram_power_process_0                                                                   0.702219   \n",
       "ram_power_process_1                                                                   0.648634   \n",
       "ram_power_process_2                                                                   0.650369   \n",
       "ram_power_process_3                                                                   0.657304   \n",
       "cpu_energy_process_0                                                                  0.000682   \n",
       "cpu_energy_process_1                                                                  0.000672   \n",
       "cpu_energy_process_2                                                                  0.000681   \n",
       "cpu_energy_process_3                                                                  0.000779   \n",
       "gpu_energy_process_0                                                                  0.004722   \n",
       "gpu_energy_process_1                                                                  0.004679   \n",
       "gpu_energy_process_2                                                                  0.004684   \n",
       "gpu_energy_process_3                                                                  0.005016   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005409   \n",
       "total_energy_kwh_process_1                                                            0.005355   \n",
       "total_energy_kwh_process_2                                                            0.005368   \n",
       "total_energy_kwh_process_3                                                              0.0058   \n",
       "total_energy_joules_process_0                                                     19470.767844   \n",
       "total_energy_joules_process_1                                                     19279.221639   \n",
       "total_energy_joules_process_2                                                     19325.854143   \n",
       "total_energy_joules_process_3                                                     20878.352506   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1127.987867   \n",
       "ram_power_avg                                                                         0.664632   \n",
       "cpu_energy_total                                                                      0.002814   \n",
       "gpu_energy_total                                                                      0.019101   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.002045   \n",
       "per-process_emissions_1                                                               0.002209   \n",
       "per-process_emissions_2                                                                0.00204   \n",
       "per-process_emissions_3                                                                0.00206   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "latency_simulation_simulate                                                              False   \n",
       "\n",
       "                                                                                            86  \\\n",
       "config_name                                  latency_True_latency_0.05_latency_0.2_latency_...   \n",
       "experiment_id                                                                              205   \n",
       "date_time                                                        April 11, 2025 at 03:22:26 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                              0.05   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022573   \n",
       "total_energy_joules                                                               81263.371943   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.201616   \n",
       "joules_per_token                                                                      4.959923   \n",
       "flops_per_joule                                                                208580699.86403   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             24.329177   \n",
       "average_latency_ms_per_batch                                                       3041.147076   \n",
       "throughput_queries_per_sec                                                            5.261173   \n",
       "throughput_tokens_per_sec                                                           673.430107   \n",
       "cpu_usage_percent                                                                          3.6   \n",
       "cpu_memory_usage_bytes                                                              2015412224   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1618.269712   \n",
       "gpu_power_process_1                                                                1120.309099   \n",
       "gpu_power_process_2                                                                1624.941628   \n",
       "gpu_power_process_3                                                                 673.337196   \n",
       "ram_power_process_0                                                                     0.7016   \n",
       "ram_power_process_1                                                                   0.650595   \n",
       "ram_power_process_2                                                                   0.655666   \n",
       "ram_power_process_3                                                                   0.649555   \n",
       "cpu_energy_process_0                                                                  0.000732   \n",
       "cpu_energy_process_1                                                                  0.000739   \n",
       "cpu_energy_process_2                                                                  0.000674   \n",
       "cpu_energy_process_3                                                                   0.00079   \n",
       "gpu_energy_process_0                                                                  0.004804   \n",
       "gpu_energy_process_1                                                                  0.004802   \n",
       "gpu_energy_process_2                                                                    0.0048   \n",
       "gpu_energy_process_3                                                                  0.005216   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005541   \n",
       "total_energy_kwh_process_1                                                            0.005544   \n",
       "total_energy_kwh_process_2                                                            0.005478   \n",
       "total_energy_kwh_process_3                                                            0.006011   \n",
       "total_energy_joules_process_0                                                     19946.301969   \n",
       "total_energy_joules_process_1                                                     19959.656226   \n",
       "total_energy_joules_process_2                                                     19719.588713   \n",
       "total_energy_joules_process_3                                                     21637.825035   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1259.214409   \n",
       "ram_power_avg                                                                         0.664354   \n",
       "cpu_energy_total                                                                      0.002935   \n",
       "gpu_energy_total                                                                      0.019622   \n",
       "ram_energy_total                                                                      0.000017   \n",
       "per-process_emissions_0                                                               0.002087   \n",
       "per-process_emissions_1                                                               0.002112   \n",
       "per-process_emissions_2                                                               0.002111   \n",
       "per-process_emissions_3                                                                0.00229   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_delay_max                                                               0.2   \n",
       "latency_simulation_simulate                                                               True   \n",
       "\n",
       "                                                                                            87  \\\n",
       "config_name                                  latency_True_latency_0.2_latency_0.6_latency_F...   \n",
       "experiment_id                                                                              206   \n",
       "date_time                                                        April 11, 2025 at 03:23:31 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.2   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.023598   \n",
       "total_energy_joules                                                               84951.709741   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.192863   \n",
       "joules_per_token                                                                      5.185041   \n",
       "flops_per_joule                                                               199524777.604627   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             27.506127   \n",
       "average_latency_ms_per_batch                                                       3438.265927   \n",
       "throughput_queries_per_sec                                                            4.653509   \n",
       "throughput_tokens_per_sec                                                           595.649098   \n",
       "cpu_usage_percent                                                                          3.5   \n",
       "cpu_memory_usage_bytes                                                              2012401664   \n",
       "gpu_utilization_percent_0                                                                 11.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 592.348564   \n",
       "gpu_power_process_1                                                                 864.480963   \n",
       "gpu_power_process_2                                                                   52.79913   \n",
       "gpu_power_process_3                                                                  50.770336   \n",
       "ram_power_process_0                                                                   0.701571   \n",
       "ram_power_process_1                                                                   0.651967   \n",
       "ram_power_process_2                                                                   0.646347   \n",
       "ram_power_process_3                                                                   0.659393   \n",
       "cpu_energy_process_0                                                                  0.000828   \n",
       "cpu_energy_process_1                                                                  0.000803   \n",
       "cpu_energy_process_2                                                                  0.000861   \n",
       "cpu_energy_process_3                                                                  0.000932   \n",
       "gpu_energy_process_0                                                                  0.004947   \n",
       "gpu_energy_process_1                                                                  0.005075   \n",
       "gpu_energy_process_2                                                                  0.004816   \n",
       "gpu_energy_process_3                                                                  0.005317   \n",
       "ram_energy_process_0                                                                  0.000005   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005781   \n",
       "total_energy_kwh_process_1                                                            0.005882   \n",
       "total_energy_kwh_process_2                                                            0.005681   \n",
       "total_energy_kwh_process_3                                                            0.006254   \n",
       "total_energy_joules_process_0                                                     20810.618516   \n",
       "total_energy_joules_process_1                                                     21175.184379   \n",
       "total_energy_joules_process_2                                                     20453.258785   \n",
       "total_energy_joules_process_3                                                      22512.64806   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       390.099748   \n",
       "ram_power_avg                                                                         0.664819   \n",
       "cpu_energy_total                                                                      0.003424   \n",
       "gpu_energy_total                                                                      0.020156   \n",
       "ram_energy_total                                                                      0.000018   \n",
       "per-process_emissions_0                                                               0.002382   \n",
       "per-process_emissions_1                                                               0.002241   \n",
       "per-process_emissions_2                                                               0.002202   \n",
       "per-process_emissions_3                                                               0.002164   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_delay_max                                                               0.6   \n",
       "latency_simulation_simulate                                                               True   \n",
       "\n",
       "                                                                                            88  \\\n",
       "config_name                                  latency_True_latency_0.05_latency_0.2_latency_...   \n",
       "experiment_id                                                                              207   \n",
       "date_time                                                        April 11, 2025 at 03:24:40 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                              0.05   \n",
       "latency_simulation_simulate_burst                                                         True   \n",
       "latency_simulation_burst_size                                                                5   \n",
       "latency_simulation_burst_interval                                                          4.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                       0.02396   \n",
       "total_energy_joules                                                               86256.402501   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.189945   \n",
       "joules_per_token                                                                      5.264673   \n",
       "flops_per_joule                                                               196506815.746624   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             28.595749   \n",
       "average_latency_ms_per_batch                                                       3574.468596   \n",
       "throughput_queries_per_sec                                                             4.47619   \n",
       "throughput_tokens_per_sec                                                           572.952299   \n",
       "cpu_usage_percent                                                                          3.4   \n",
       "cpu_memory_usage_bytes                                                              2018140160   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  24.472879   \n",
       "gpu_power_process_1                                                                 987.103513   \n",
       "gpu_power_process_2                                                                 635.873796   \n",
       "gpu_power_process_3                                                                 489.010663   \n",
       "ram_power_process_0                                                                   0.703331   \n",
       "ram_power_process_1                                                                   0.654479   \n",
       "ram_power_process_2                                                                   0.652483   \n",
       "ram_power_process_3                                                                   0.653455   \n",
       "cpu_energy_process_0                                                                  0.000871   \n",
       "cpu_energy_process_1                                                                  0.000776   \n",
       "cpu_energy_process_2                                                                  0.000792   \n",
       "cpu_energy_process_3                                                                  0.000879   \n",
       "gpu_energy_process_0                                                                  0.005022   \n",
       "gpu_energy_process_1                                                                  0.005047   \n",
       "gpu_energy_process_2                                                                  0.005078   \n",
       "gpu_energy_process_3                                                                  0.005476   \n",
       "ram_energy_process_0                                                                  0.000005   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000005   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.005898   \n",
       "total_energy_kwh_process_1                                                            0.005827   \n",
       "total_energy_kwh_process_2                                                            0.005875   \n",
       "total_energy_kwh_process_3                                                             0.00636   \n",
       "total_energy_joules_process_0                                                     21232.057477   \n",
       "total_energy_joules_process_1                                                     20978.666577   \n",
       "total_energy_joules_process_2                                                     21149.179568   \n",
       "total_energy_joules_process_3                                                     22896.498879   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       534.115213   \n",
       "ram_power_avg                                                                         0.665937   \n",
       "cpu_energy_total                                                                      0.003318   \n",
       "gpu_energy_total                                                                      0.020624   \n",
       "ram_energy_total                                                                      0.000019   \n",
       "per-process_emissions_0                                                               0.002423   \n",
       "per-process_emissions_1                                                               0.002247   \n",
       "per-process_emissions_2                                                               0.002238   \n",
       "per-process_emissions_3                                                                0.00222   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                           1034544128000   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_delay_max                                                               0.2   \n",
       "latency_simulation_simulate                                                               True   \n",
       "\n",
       "                                                                                            89  \n",
       "config_name                                  latency_True_latency_0.2_latency_0.6_latency_T...  \n",
       "experiment_id                                                                              208  \n",
       "date_time                                                        April 11, 2025 at 03:25:52 PM  \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0  \n",
       "num_processes                                                                                4  \n",
       "batch_size___fixed_batching                                                                 16  \n",
       "decoder_temperature                                                                        1.0  \n",
       "decoder_top_k                                                                                0  \n",
       "decoder_top_p                                                                              0.0  \n",
       "latency_simulation_delay_min                                                               0.2  \n",
       "latency_simulation_simulate_burst                                                         True  \n",
       "latency_simulation_burst_size                                                                8  \n",
       "latency_simulation_burst_interval                                                          5.0  \n",
       "fp_precision                                                                     torch.float32  \n",
       "quantization                                                                             False  \n",
       "load_in_8bit                                                                             False  \n",
       "load_in_4bit                                                                             False  \n",
       "sharding_strategy                                                                     NO_SHARD  \n",
       "sharding_config_fsdp_config_use_orig_params                                              False  \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False  \n",
       "adaptive_batching                                                                        False  \n",
       "adaptive_max_tokens                                                                          0  \n",
       "query_rate                                                                                 1.0  \n",
       "total_input_tokens                                                                       16384  \n",
       "is_encoder_decoder                                                                       False  \n",
       "task_type                                                                      text_generation  \n",
       "available_gpu_count                                                                          4  \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB  \n",
       "available_cpu_count                                                                        128  \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor  \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31  \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]  \n",
       "country                                                                                Germany  \n",
       "region                                                                                  saxony  \n",
       "distributed_type                                                     DistributedType.MULTI_GPU  \n",
       "decode_token_to_text                                                                      True  \n",
       "inference_type                                                                 pure_generative  \n",
       "backend                                                                                pytorch  \n",
       "total_params                                                                        1100048384  \n",
       "model_arch                                                       Unknown (no config attribute)  \n",
       "max_input_tokens                                                                           128  \n",
       "max_output_tokens                                                                          128  \n",
       "number_input_prompts                                                                       128  \n",
       "total_energy_kwh                                                                      0.025477  \n",
       "total_energy_joules                                                               91716.993714  \n",
       "flops                                                                           16949970993152  \n",
       "tokens_per_joule                                                                      0.178636  \n",
       "joules_per_token                                                                      5.597961  \n",
       "flops_per_joule                                                               184807311.129298  \n",
       "joules_per_flop                                                                            0.0  \n",
       "total_inference_time_sec                                                             32.414388  \n",
       "average_latency_ms_per_batch                                                       4051.798498  \n",
       "throughput_queries_per_sec                                                            3.948864  \n",
       "throughput_tokens_per_sec                                                           505.454553  \n",
       "cpu_usage_percent                                                                          3.3  \n",
       "cpu_memory_usage_bytes                                                              2025857024  \n",
       "gpu_utilization_percent_0                                                                  0.0  \n",
       "gpu_utilization_percent_1                                                                100.0  \n",
       "gpu_utilization_percent_2                                                                100.0  \n",
       "gpu_utilization_percent_3                                                                100.0  \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280  \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280  \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600  \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600  \n",
       "cpu_power_process_0                                                                      112.5  \n",
       "cpu_power_process_1                                                                      112.5  \n",
       "cpu_power_process_2                                                                      112.5  \n",
       "cpu_power_process_3                                                                      112.5  \n",
       "gpu_power_process_0                                                                  696.29275  \n",
       "gpu_power_process_1                                                                 674.736579  \n",
       "gpu_power_process_2                                                                 836.395045  \n",
       "gpu_power_process_3                                                                 532.767231  \n",
       "ram_power_process_0                                                                   0.705437  \n",
       "ram_power_process_1                                                                   0.658193  \n",
       "ram_power_process_2                                                                   0.657608  \n",
       "ram_power_process_3                                                                   0.657968  \n",
       "cpu_energy_process_0                                                                  0.000994  \n",
       "cpu_energy_process_1                                                                  0.000973  \n",
       "cpu_energy_process_2                                                                  0.000926  \n",
       "cpu_energy_process_3                                                                  0.001004  \n",
       "gpu_energy_process_0                                                                   0.00534  \n",
       "gpu_energy_process_1                                                                  0.005341  \n",
       "gpu_energy_process_2                                                                  0.005198  \n",
       "gpu_energy_process_3                                                                   0.00568  \n",
       "ram_energy_process_0                                                                  0.000005  \n",
       "ram_energy_process_1                                                                  0.000005  \n",
       "ram_energy_process_2                                                                  0.000005  \n",
       "ram_energy_process_3                                                                  0.000005  \n",
       "total_energy_kwh_process_0                                                            0.006339  \n",
       "total_energy_kwh_process_1                                                            0.006319  \n",
       "total_energy_kwh_process_2                                                            0.006129  \n",
       "total_energy_kwh_process_3                                                            0.006689  \n",
       "total_energy_joules_process_0                                                     22819.901136  \n",
       "total_energy_joules_process_1                                                     22750.185158  \n",
       "total_energy_joules_process_2                                                     22065.413117  \n",
       "total_energy_joules_process_3                                                     24081.494303  \n",
       "cpu_power_avg                                                                            112.5  \n",
       "gpu_power_avg                                                                       685.047901  \n",
       "ram_power_avg                                                                         0.669801  \n",
       "cpu_energy_total                                                                      0.003897  \n",
       "gpu_energy_total                                                                       0.02156  \n",
       "ram_energy_total                                                                       0.00002  \n",
       "per-process_emissions_0                                                               0.002415  \n",
       "per-process_emissions_1                                                               0.002335  \n",
       "per-process_emissions_2                                                               0.002548  \n",
       "per-process_emissions_3                                                               0.002407  \n",
       "total_generated_tokens                                                                   16384  \n",
       "models                                                                           1034544128000  \n",
       "decoder_config_decoding_mode                                                               NaN  \n",
       "latency_simulation_delay_max                                                               0.6  \n",
       "latency_simulation_simulate                                                               True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scenarios did not exist: [Errno 2] No such file or directory: 'scenarios_results.csv'\n",
      "grid did not exist: [Errno 2] No such file or directory: 'grid_results.csv'\n",
      "text_generation did not exist: [Errno 2] No such file or directory: 'text_generation_results.csv'\n"
     ]
    }
   ],
   "source": [
    "def inspect_results(name, desired_order):\n",
    "    input_file = f\"{name}_results.csv\"\n",
    "    \n",
    "    df = pd.read_csv(input_file)\n",
    "    df_cleaned = clean_and_reorder_columns(df, desired_order)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "possible_files = [\"controlled\", \"scenarios\", \"grid\", \"text_generation\"]\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "for file in possible_files:\n",
    "    try:\n",
    "        var_name = f\"df_{file}_cleaned\"\n",
    "        globals()[var_name] = inspect_results(file, desired_order)  # dynamically create variable\n",
    "        print(f\"Found & inspecting: {var_name}\")\n",
    "        display(globals()[var_name].T)\n",
    "    except Exception as e:\n",
    "        print(f\"{file} did not exist: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found & inspecting dropped version: df_controlled_dropped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>config_name</th>\n",
       "      <td>num_processes_1</td>\n",
       "      <td>num_processes_2</td>\n",
       "      <td>num_processes_3</td>\n",
       "      <td>num_processes_4</td>\n",
       "      <td>batching_1</td>\n",
       "      <td>batching_2</td>\n",
       "      <td>batching_4</td>\n",
       "      <td>batching_8</td>\n",
       "      <td>batching_16</td>\n",
       "      <td>batching_32</td>\n",
       "      <td>batching_64</td>\n",
       "      <td>precis_float32_quant_False_quant8_False_quant4...</td>\n",
       "      <td>precis_float16_quant_False_quant8_False_quant4...</td>\n",
       "      <td>precis_float16_quant_True_quant8_True_quant4_F...</td>\n",
       "      <td>precis_float16_quant_True_quant8_False_quant4_...</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.2</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.4</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.6</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.8</td>\n",
       "      <td>decoding_greedy_decoder_temperature_1.0</td>\n",
       "      <td>decoding_greedy_decoder_temperature_1.2</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>latency_False</td>\n",
       "      <td>latency_True_latency_0.05_latency_0.2_latency_...</td>\n",
       "      <td>latency_True_latency_0.2_latency_0.6_latency_F...</td>\n",
       "      <td>latency_True_latency_0.05_latency_0.2_latency_...</td>\n",
       "      <td>latency_True_latency_0.2_latency_0.6_latency_T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <td>109</td>\n",
       "      <td>110</td>\n",
       "      <td>111</td>\n",
       "      <td>112</td>\n",
       "      <td>113</td>\n",
       "      <td>114</td>\n",
       "      <td>115</td>\n",
       "      <td>116</td>\n",
       "      <td>117</td>\n",
       "      <td>118</td>\n",
       "      <td>119</td>\n",
       "      <td>120</td>\n",
       "      <td>121</td>\n",
       "      <td>122</td>\n",
       "      <td>123</td>\n",
       "      <td>124</td>\n",
       "      <td>125</td>\n",
       "      <td>126</td>\n",
       "      <td>127</td>\n",
       "      <td>128</td>\n",
       "      <td>129</td>\n",
       "      <td>130</td>\n",
       "      <td>132</td>\n",
       "      <td>133</td>\n",
       "      <td>134</td>\n",
       "      <td>135</td>\n",
       "      <td>136</td>\n",
       "      <td>137</td>\n",
       "      <td>138</td>\n",
       "      <td>139</td>\n",
       "      <td>140</td>\n",
       "      <td>141</td>\n",
       "      <td>142</td>\n",
       "      <td>143</td>\n",
       "      <td>144</td>\n",
       "      <td>145</td>\n",
       "      <td>146</td>\n",
       "      <td>147</td>\n",
       "      <td>148</td>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>152</td>\n",
       "      <td>153</td>\n",
       "      <td>154</td>\n",
       "      <td>155</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "      <td>160</td>\n",
       "      <td>161</td>\n",
       "      <td>162</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>165</td>\n",
       "      <td>166</td>\n",
       "      <td>172</td>\n",
       "      <td>173</td>\n",
       "      <td>174</td>\n",
       "      <td>175</td>\n",
       "      <td>176</td>\n",
       "      <td>177</td>\n",
       "      <td>178</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>192</td>\n",
       "      <td>193</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "      <td>196</td>\n",
       "      <td>197</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>204</td>\n",
       "      <td>205</td>\n",
       "      <td>206</td>\n",
       "      <td>207</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <td>April 11, 2025 at 01:21:09 PM</td>\n",
       "      <td>April 11, 2025 at 01:22:13 PM</td>\n",
       "      <td>April 11, 2025 at 01:23:18 PM</td>\n",
       "      <td>April 11, 2025 at 01:24:25 PM</td>\n",
       "      <td>April 11, 2025 at 01:30:52 PM</td>\n",
       "      <td>April 11, 2025 at 01:35:11 PM</td>\n",
       "      <td>April 11, 2025 at 01:37:39 PM</td>\n",
       "      <td>April 11, 2025 at 01:39:15 PM</td>\n",
       "      <td>April 11, 2025 at 01:40:22 PM</td>\n",
       "      <td>April 11, 2025 at 01:41:15 PM</td>\n",
       "      <td>April 11, 2025 at 01:42:03 PM</td>\n",
       "      <td>April 11, 2025 at 01:43:09 PM</td>\n",
       "      <td>April 11, 2025 at 01:44:07 PM</td>\n",
       "      <td>April 11, 2025 at 01:47:13 PM</td>\n",
       "      <td>April 11, 2025 at 01:48:28 PM</td>\n",
       "      <td>April 11, 2025 at 01:49:39 PM</td>\n",
       "      <td>April 11, 2025 at 01:50:49 PM</td>\n",
       "      <td>April 11, 2025 at 01:52:03 PM</td>\n",
       "      <td>April 11, 2025 at 01:53:15 PM</td>\n",
       "      <td>April 11, 2025 at 01:54:27 PM</td>\n",
       "      <td>April 11, 2025 at 02:07:40 PM</td>\n",
       "      <td>April 11, 2025 at 02:08:53 PM</td>\n",
       "      <td>April 11, 2025 at 02:10:30 PM</td>\n",
       "      <td>April 11, 2025 at 02:11:31 PM</td>\n",
       "      <td>April 11, 2025 at 02:12:30 PM</td>\n",
       "      <td>April 11, 2025 at 02:13:34 PM</td>\n",
       "      <td>April 11, 2025 at 02:14:36 PM</td>\n",
       "      <td>April 11, 2025 at 02:15:38 PM</td>\n",
       "      <td>April 11, 2025 at 02:16:46 PM</td>\n",
       "      <td>April 11, 2025 at 02:17:47 PM</td>\n",
       "      <td>April 11, 2025 at 02:18:50 PM</td>\n",
       "      <td>April 11, 2025 at 02:19:51 PM</td>\n",
       "      <td>April 11, 2025 at 02:20:54 PM</td>\n",
       "      <td>April 11, 2025 at 02:21:57 PM</td>\n",
       "      <td>April 11, 2025 at 02:22:59 PM</td>\n",
       "      <td>April 11, 2025 at 02:24:04 PM</td>\n",
       "      <td>April 11, 2025 at 02:25:08 PM</td>\n",
       "      <td>April 11, 2025 at 02:26:16 PM</td>\n",
       "      <td>April 11, 2025 at 02:27:18 PM</td>\n",
       "      <td>April 11, 2025 at 02:28:19 PM</td>\n",
       "      <td>April 11, 2025 at 02:29:23 PM</td>\n",
       "      <td>April 11, 2025 at 02:30:26 PM</td>\n",
       "      <td>April 11, 2025 at 02:31:29 PM</td>\n",
       "      <td>April 11, 2025 at 02:32:31 PM</td>\n",
       "      <td>April 11, 2025 at 02:33:34 PM</td>\n",
       "      <td>April 11, 2025 at 02:34:37 PM</td>\n",
       "      <td>April 11, 2025 at 02:35:41 PM</td>\n",
       "      <td>April 11, 2025 at 02:36:45 PM</td>\n",
       "      <td>April 11, 2025 at 02:37:48 PM</td>\n",
       "      <td>April 11, 2025 at 02:38:49 PM</td>\n",
       "      <td>April 11, 2025 at 02:39:50 PM</td>\n",
       "      <td>April 11, 2025 at 02:40:54 PM</td>\n",
       "      <td>April 11, 2025 at 02:41:56 PM</td>\n",
       "      <td>April 11, 2025 at 02:42:58 PM</td>\n",
       "      <td>April 11, 2025 at 02:44:00 PM</td>\n",
       "      <td>April 11, 2025 at 02:45:01 PM</td>\n",
       "      <td>April 11, 2025 at 02:46:03 PM</td>\n",
       "      <td>April 11, 2025 at 02:50:00 PM</td>\n",
       "      <td>April 11, 2025 at 02:51:04 PM</td>\n",
       "      <td>April 11, 2025 at 02:52:05 PM</td>\n",
       "      <td>April 11, 2025 at 02:53:06 PM</td>\n",
       "      <td>April 11, 2025 at 02:54:09 PM</td>\n",
       "      <td>April 11, 2025 at 02:55:09 PM</td>\n",
       "      <td>April 11, 2025 at 02:56:10 PM</td>\n",
       "      <td>April 11, 2025 at 02:57:12 PM</td>\n",
       "      <td>April 11, 2025 at 02:58:15 PM</td>\n",
       "      <td>April 11, 2025 at 02:59:16 PM</td>\n",
       "      <td>April 11, 2025 at 03:00:18 PM</td>\n",
       "      <td>April 11, 2025 at 03:01:19 PM</td>\n",
       "      <td>April 11, 2025 at 03:02:21 PM</td>\n",
       "      <td>April 11, 2025 at 03:03:22 PM</td>\n",
       "      <td>April 11, 2025 at 03:04:26 PM</td>\n",
       "      <td>April 11, 2025 at 03:05:27 PM</td>\n",
       "      <td>April 11, 2025 at 03:06:29 PM</td>\n",
       "      <td>April 11, 2025 at 03:07:33 PM</td>\n",
       "      <td>April 11, 2025 at 03:08:35 PM</td>\n",
       "      <td>April 11, 2025 at 03:09:37 PM</td>\n",
       "      <td>April 11, 2025 at 03:10:39 PM</td>\n",
       "      <td>April 11, 2025 at 03:11:41 PM</td>\n",
       "      <td>April 11, 2025 at 03:12:44 PM</td>\n",
       "      <td>April 11, 2025 at 03:13:47 PM</td>\n",
       "      <td>April 11, 2025 at 03:14:49 PM</td>\n",
       "      <td>April 11, 2025 at 03:15:52 PM</td>\n",
       "      <td>April 11, 2025 at 03:16:56 PM</td>\n",
       "      <td>April 11, 2025 at 03:18:00 PM</td>\n",
       "      <td>April 11, 2025 at 03:21:23 PM</td>\n",
       "      <td>April 11, 2025 at 03:22:26 PM</td>\n",
       "      <td>April 11, 2025 at 03:23:31 PM</td>\n",
       "      <td>April 11, 2025 at 03:24:40 PM</td>\n",
       "      <td>April 11, 2025 at 03:25:52 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_processes</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size___fixed_batching</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_temperature</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_k</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_p</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate_burst</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_size</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_interval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp_precision</th>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantization</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_8bit</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_4bit</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_input_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_params</th>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>615606272</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_input_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_output_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_input_prompts</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh</th>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.011983</td>\n",
       "      <td>0.02077</td>\n",
       "      <td>0.03052</td>\n",
       "      <td>0.248756</td>\n",
       "      <td>0.172983</td>\n",
       "      <td>0.080552</td>\n",
       "      <td>0.046927</td>\n",
       "      <td>0.030332</td>\n",
       "      <td>0.01974</td>\n",
       "      <td>0.016821</td>\n",
       "      <td>0.030563</td>\n",
       "      <td>0.020205</td>\n",
       "      <td>0.081855</td>\n",
       "      <td>0.026513</td>\n",
       "      <td>0.026726</td>\n",
       "      <td>0.027081</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.027891</td>\n",
       "      <td>0.027698</td>\n",
       "      <td>0.427662</td>\n",
       "      <td>0.027378</td>\n",
       "      <td>0.023482</td>\n",
       "      <td>0.021907</td>\n",
       "      <td>0.021951</td>\n",
       "      <td>0.021558</td>\n",
       "      <td>0.022163</td>\n",
       "      <td>0.022313</td>\n",
       "      <td>0.022607</td>\n",
       "      <td>0.022371</td>\n",
       "      <td>0.022527</td>\n",
       "      <td>0.022292</td>\n",
       "      <td>0.022349</td>\n",
       "      <td>0.02246</td>\n",
       "      <td>0.022236</td>\n",
       "      <td>0.022204</td>\n",
       "      <td>0.022546</td>\n",
       "      <td>0.02255</td>\n",
       "      <td>0.022035</td>\n",
       "      <td>0.022381</td>\n",
       "      <td>0.022374</td>\n",
       "      <td>0.022143</td>\n",
       "      <td>0.022079</td>\n",
       "      <td>0.022215</td>\n",
       "      <td>0.022313</td>\n",
       "      <td>0.022003</td>\n",
       "      <td>0.021963</td>\n",
       "      <td>0.022372</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>0.022286</td>\n",
       "      <td>0.022056</td>\n",
       "      <td>0.022172</td>\n",
       "      <td>0.022241</td>\n",
       "      <td>0.022124</td>\n",
       "      <td>0.021905</td>\n",
       "      <td>0.022108</td>\n",
       "      <td>0.022015</td>\n",
       "      <td>0.022108</td>\n",
       "      <td>0.021896</td>\n",
       "      <td>0.022016</td>\n",
       "      <td>0.021579</td>\n",
       "      <td>0.021987</td>\n",
       "      <td>0.022174</td>\n",
       "      <td>0.022161</td>\n",
       "      <td>0.022225</td>\n",
       "      <td>0.022037</td>\n",
       "      <td>0.022071</td>\n",
       "      <td>0.02212</td>\n",
       "      <td>0.022105</td>\n",
       "      <td>0.021988</td>\n",
       "      <td>0.02195</td>\n",
       "      <td>0.022064</td>\n",
       "      <td>0.022212</td>\n",
       "      <td>0.022266</td>\n",
       "      <td>0.022171</td>\n",
       "      <td>0.022127</td>\n",
       "      <td>0.022127</td>\n",
       "      <td>0.021753</td>\n",
       "      <td>0.022035</td>\n",
       "      <td>0.022129</td>\n",
       "      <td>0.022042</td>\n",
       "      <td>0.022019</td>\n",
       "      <td>0.022055</td>\n",
       "      <td>0.022409</td>\n",
       "      <td>0.021976</td>\n",
       "      <td>0.021932</td>\n",
       "      <td>0.022573</td>\n",
       "      <td>0.023598</td>\n",
       "      <td>0.02396</td>\n",
       "      <td>0.025477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules</th>\n",
       "      <td>16195.77922</td>\n",
       "      <td>43137.499279</td>\n",
       "      <td>74772.641025</td>\n",
       "      <td>109872.192307</td>\n",
       "      <td>895521.470895</td>\n",
       "      <td>622739.187387</td>\n",
       "      <td>289987.598049</td>\n",
       "      <td>168938.609749</td>\n",
       "      <td>109195.59459</td>\n",
       "      <td>71065.052609</td>\n",
       "      <td>60554.5696</td>\n",
       "      <td>110026.388974</td>\n",
       "      <td>72739.613361</td>\n",
       "      <td>294677.860311</td>\n",
       "      <td>95445.437568</td>\n",
       "      <td>96214.326055</td>\n",
       "      <td>97493.121231</td>\n",
       "      <td>98315.389425</td>\n",
       "      <td>100406.566327</td>\n",
       "      <td>99714.129356</td>\n",
       "      <td>1539584.096019</td>\n",
       "      <td>98560.641388</td>\n",
       "      <td>84535.873444</td>\n",
       "      <td>78864.369793</td>\n",
       "      <td>79024.314526</td>\n",
       "      <td>77607.069182</td>\n",
       "      <td>79785.192564</td>\n",
       "      <td>80326.29213</td>\n",
       "      <td>81385.43303</td>\n",
       "      <td>80534.828637</td>\n",
       "      <td>81096.772114</td>\n",
       "      <td>80252.705575</td>\n",
       "      <td>80457.547565</td>\n",
       "      <td>80855.2652</td>\n",
       "      <td>80049.35023</td>\n",
       "      <td>79935.142249</td>\n",
       "      <td>81165.046053</td>\n",
       "      <td>81180.686997</td>\n",
       "      <td>79326.35121</td>\n",
       "      <td>80571.964142</td>\n",
       "      <td>80546.838823</td>\n",
       "      <td>79714.965563</td>\n",
       "      <td>79485.169526</td>\n",
       "      <td>79973.120837</td>\n",
       "      <td>80327.286164</td>\n",
       "      <td>79212.479066</td>\n",
       "      <td>79067.881421</td>\n",
       "      <td>80539.640657</td>\n",
       "      <td>78832.359919</td>\n",
       "      <td>80229.360539</td>\n",
       "      <td>79403.040972</td>\n",
       "      <td>79820.968883</td>\n",
       "      <td>80066.319146</td>\n",
       "      <td>79646.128042</td>\n",
       "      <td>78857.96964</td>\n",
       "      <td>79588.547839</td>\n",
       "      <td>79254.830096</td>\n",
       "      <td>79588.27778</td>\n",
       "      <td>78825.275361</td>\n",
       "      <td>79257.538412</td>\n",
       "      <td>77685.286425</td>\n",
       "      <td>79153.299519</td>\n",
       "      <td>79827.530634</td>\n",
       "      <td>79778.964695</td>\n",
       "      <td>80008.879377</td>\n",
       "      <td>79332.316652</td>\n",
       "      <td>79455.767743</td>\n",
       "      <td>79631.713062</td>\n",
       "      <td>79576.984984</td>\n",
       "      <td>79156.588699</td>\n",
       "      <td>79021.660488</td>\n",
       "      <td>79431.609675</td>\n",
       "      <td>79963.061299</td>\n",
       "      <td>80159.040345</td>\n",
       "      <td>79813.883435</td>\n",
       "      <td>79658.584807</td>\n",
       "      <td>79655.924763</td>\n",
       "      <td>78312.258436</td>\n",
       "      <td>79324.468177</td>\n",
       "      <td>79663.168096</td>\n",
       "      <td>79350.575857</td>\n",
       "      <td>79267.089003</td>\n",
       "      <td>79399.139493</td>\n",
       "      <td>80672.664643</td>\n",
       "      <td>79114.439184</td>\n",
       "      <td>78954.196131</td>\n",
       "      <td>81263.371943</td>\n",
       "      <td>84951.709741</td>\n",
       "      <td>86256.402501</td>\n",
       "      <td>91716.993714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops</th>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>1034544128000</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens_per_joule</th>\n",
       "      <td>1.011622</td>\n",
       "      <td>0.379809</td>\n",
       "      <td>0.219118</td>\n",
       "      <td>0.149119</td>\n",
       "      <td>0.01644</td>\n",
       "      <td>0.02631</td>\n",
       "      <td>0.056499</td>\n",
       "      <td>0.096982</td>\n",
       "      <td>0.150043</td>\n",
       "      <td>0.230549</td>\n",
       "      <td>0.270566</td>\n",
       "      <td>0.14891</td>\n",
       "      <td>0.225242</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.171658</td>\n",
       "      <td>0.170286</td>\n",
       "      <td>0.168053</td>\n",
       "      <td>0.166647</td>\n",
       "      <td>0.163177</td>\n",
       "      <td>0.16431</td>\n",
       "      <td>0.010642</td>\n",
       "      <td>0.166233</td>\n",
       "      <td>0.193811</td>\n",
       "      <td>0.207749</td>\n",
       "      <td>0.207329</td>\n",
       "      <td>0.211115</td>\n",
       "      <td>0.205351</td>\n",
       "      <td>0.203968</td>\n",
       "      <td>0.201314</td>\n",
       "      <td>0.20344</td>\n",
       "      <td>0.20203</td>\n",
       "      <td>0.204155</td>\n",
       "      <td>0.203635</td>\n",
       "      <td>0.202634</td>\n",
       "      <td>0.204674</td>\n",
       "      <td>0.204966</td>\n",
       "      <td>0.20186</td>\n",
       "      <td>0.201821</td>\n",
       "      <td>0.206539</td>\n",
       "      <td>0.203346</td>\n",
       "      <td>0.20341</td>\n",
       "      <td>0.205532</td>\n",
       "      <td>0.206127</td>\n",
       "      <td>0.204869</td>\n",
       "      <td>0.203966</td>\n",
       "      <td>0.206836</td>\n",
       "      <td>0.207214</td>\n",
       "      <td>0.203428</td>\n",
       "      <td>0.207833</td>\n",
       "      <td>0.204215</td>\n",
       "      <td>0.20634</td>\n",
       "      <td>0.205259</td>\n",
       "      <td>0.20463</td>\n",
       "      <td>0.20571</td>\n",
       "      <td>0.207766</td>\n",
       "      <td>0.205859</td>\n",
       "      <td>0.206726</td>\n",
       "      <td>0.205859</td>\n",
       "      <td>0.207852</td>\n",
       "      <td>0.206719</td>\n",
       "      <td>0.210902</td>\n",
       "      <td>0.206991</td>\n",
       "      <td>0.205242</td>\n",
       "      <td>0.205367</td>\n",
       "      <td>0.204777</td>\n",
       "      <td>0.206524</td>\n",
       "      <td>0.206203</td>\n",
       "      <td>0.205747</td>\n",
       "      <td>0.205889</td>\n",
       "      <td>0.206982</td>\n",
       "      <td>0.207336</td>\n",
       "      <td>0.206265</td>\n",
       "      <td>0.204895</td>\n",
       "      <td>0.204394</td>\n",
       "      <td>0.205278</td>\n",
       "      <td>0.205678</td>\n",
       "      <td>0.205685</td>\n",
       "      <td>0.209214</td>\n",
       "      <td>0.206544</td>\n",
       "      <td>0.205666</td>\n",
       "      <td>0.206476</td>\n",
       "      <td>0.206694</td>\n",
       "      <td>0.20635</td>\n",
       "      <td>0.203092</td>\n",
       "      <td>0.207092</td>\n",
       "      <td>0.207513</td>\n",
       "      <td>0.201616</td>\n",
       "      <td>0.192863</td>\n",
       "      <td>0.189945</td>\n",
       "      <td>0.178636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_token</th>\n",
       "      <td>0.988512</td>\n",
       "      <td>2.632904</td>\n",
       "      <td>4.56376</td>\n",
       "      <td>6.706066</td>\n",
       "      <td>60.828792</td>\n",
       "      <td>38.008984</td>\n",
       "      <td>17.699438</td>\n",
       "      <td>10.311194</td>\n",
       "      <td>6.66477</td>\n",
       "      <td>4.337467</td>\n",
       "      <td>3.695958</td>\n",
       "      <td>6.715478</td>\n",
       "      <td>4.439674</td>\n",
       "      <td>17.985709</td>\n",
       "      <td>5.825527</td>\n",
       "      <td>5.872456</td>\n",
       "      <td>5.950508</td>\n",
       "      <td>6.000695</td>\n",
       "      <td>6.12833</td>\n",
       "      <td>6.086067</td>\n",
       "      <td>93.968756</td>\n",
       "      <td>6.015664</td>\n",
       "      <td>5.15966</td>\n",
       "      <td>4.813499</td>\n",
       "      <td>4.823261</td>\n",
       "      <td>4.73676</td>\n",
       "      <td>4.869702</td>\n",
       "      <td>4.902728</td>\n",
       "      <td>4.967373</td>\n",
       "      <td>4.915456</td>\n",
       "      <td>4.949754</td>\n",
       "      <td>4.898236</td>\n",
       "      <td>4.910739</td>\n",
       "      <td>4.935014</td>\n",
       "      <td>4.885825</td>\n",
       "      <td>4.878854</td>\n",
       "      <td>4.953921</td>\n",
       "      <td>4.954876</td>\n",
       "      <td>4.841696</td>\n",
       "      <td>4.917722</td>\n",
       "      <td>4.916189</td>\n",
       "      <td>4.865415</td>\n",
       "      <td>4.85139</td>\n",
       "      <td>4.881172</td>\n",
       "      <td>4.902788</td>\n",
       "      <td>4.834746</td>\n",
       "      <td>4.82592</td>\n",
       "      <td>4.91575</td>\n",
       "      <td>4.811545</td>\n",
       "      <td>4.896812</td>\n",
       "      <td>4.846377</td>\n",
       "      <td>4.871885</td>\n",
       "      <td>4.88686</td>\n",
       "      <td>4.861214</td>\n",
       "      <td>4.813108</td>\n",
       "      <td>4.857699</td>\n",
       "      <td>4.837331</td>\n",
       "      <td>4.857683</td>\n",
       "      <td>4.811113</td>\n",
       "      <td>4.837496</td>\n",
       "      <td>4.741534</td>\n",
       "      <td>4.831134</td>\n",
       "      <td>4.872286</td>\n",
       "      <td>4.869322</td>\n",
       "      <td>4.883354</td>\n",
       "      <td>4.84206</td>\n",
       "      <td>4.849595</td>\n",
       "      <td>4.860334</td>\n",
       "      <td>4.856994</td>\n",
       "      <td>4.831335</td>\n",
       "      <td>4.823099</td>\n",
       "      <td>4.848121</td>\n",
       "      <td>4.880558</td>\n",
       "      <td>4.89252</td>\n",
       "      <td>4.871453</td>\n",
       "      <td>4.861974</td>\n",
       "      <td>4.861812</td>\n",
       "      <td>4.779801</td>\n",
       "      <td>4.841581</td>\n",
       "      <td>4.862254</td>\n",
       "      <td>4.843175</td>\n",
       "      <td>4.838079</td>\n",
       "      <td>4.846139</td>\n",
       "      <td>4.923869</td>\n",
       "      <td>4.828762</td>\n",
       "      <td>4.818982</td>\n",
       "      <td>4.959923</td>\n",
       "      <td>5.185041</td>\n",
       "      <td>5.264673</td>\n",
       "      <td>5.597961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops_per_joule</th>\n",
       "      <td>1046567180.461082</td>\n",
       "      <td>392928919.763817</td>\n",
       "      <td>226686803.63326</td>\n",
       "      <td>154269889.744024</td>\n",
       "      <td>18927486.993933</td>\n",
       "      <td>27218410.751168</td>\n",
       "      <td>58450675.502025</td>\n",
       "      <td>100332132.591523</td>\n",
       "      <td>155225776.798502</td>\n",
       "      <td>238513451.700919</td>\n",
       "      <td>279912335.355367</td>\n",
       "      <td>154053687.949614</td>\n",
       "      <td>233022561.022627</td>\n",
       "      <td>3510762.996944</td>\n",
       "      <td>10839115.565521</td>\n",
       "      <td>176168889.687912</td>\n",
       "      <td>173858122.288034</td>\n",
       "      <td>172404046.735283</td>\n",
       "      <td>168813371.607248</td>\n",
       "      <td>169985649.00098</td>\n",
       "      <td>11009447.965185</td>\n",
       "      <td>171975047.589829</td>\n",
       "      <td>200506250.21828</td>\n",
       "      <td>214925587.277855</td>\n",
       "      <td>214490579.195115</td>\n",
       "      <td>218407564.824574</td>\n",
       "      <td>212445072.179372</td>\n",
       "      <td>211013984.881239</td>\n",
       "      <td>208267872.541956</td>\n",
       "      <td>210467586.260611</td>\n",
       "      <td>209009194.217265</td>\n",
       "      <td>211207471.096386</td>\n",
       "      <td>210669744.55767</td>\n",
       "      <td>209633484.611915</td>\n",
       "      <td>211744017.213695</td>\n",
       "      <td>212046548.191128</td>\n",
       "      <td>208833381.085398</td>\n",
       "      <td>208793145.515737</td>\n",
       "      <td>213673901.983323</td>\n",
       "      <td>210370582.046835</td>\n",
       "      <td>210436203.840162</td>\n",
       "      <td>212632231.269686</td>\n",
       "      <td>213246962.851946</td>\n",
       "      <td>211945849.002445</td>\n",
       "      <td>211011373.62713</td>\n",
       "      <td>213981069.562596</td>\n",
       "      <td>214372393.548913</td>\n",
       "      <td>210455011.407237</td>\n",
       "      <td>215012857.796897</td>\n",
       "      <td>211268927.975691</td>\n",
       "      <td>213467529.525458</td>\n",
       "      <td>212349852.805032</td>\n",
       "      <td>211699141.086514</td>\n",
       "      <td>212816007.631856</td>\n",
       "      <td>214943030.749142</td>\n",
       "      <td>212969974.366801</td>\n",
       "      <td>213866725.505504</td>\n",
       "      <td>212970697.015842</td>\n",
       "      <td>215032182.449385</td>\n",
       "      <td>213859417.447935</td>\n",
       "      <td>218187661.693502</td>\n",
       "      <td>214141054.083154</td>\n",
       "      <td>212332397.841176</td>\n",
       "      <td>212461656.501568</td>\n",
       "      <td>211851123.589203</td>\n",
       "      <td>213657834.643894</td>\n",
       "      <td>213325872.67883</td>\n",
       "      <td>212854531.709691</td>\n",
       "      <td>213000919.759229</td>\n",
       "      <td>214132155.916694</td>\n",
       "      <td>214497783.119962</td>\n",
       "      <td>213390752.907894</td>\n",
       "      <td>211972512.280364</td>\n",
       "      <td>211454265.422914</td>\n",
       "      <td>212368704.085806</td>\n",
       "      <td>212782728.11799</td>\n",
       "      <td>212789833.821877</td>\n",
       "      <td>216440839.935347</td>\n",
       "      <td>213678974.252386</td>\n",
       "      <td>212770486.013364</td>\n",
       "      <td>213608670.26088</td>\n",
       "      <td>213833650.338204</td>\n",
       "      <td>213478018.796583</td>\n",
       "      <td>210107984.757064</td>\n",
       "      <td>214246238.335844</td>\n",
       "      <td>214681066.031948</td>\n",
       "      <td>208580699.86403</td>\n",
       "      <td>199524777.604627</td>\n",
       "      <td>196506815.746624</td>\n",
       "      <td>184807311.129298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_flop</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_inference_time_sec</th>\n",
       "      <td>23.226318</td>\n",
       "      <td>23.264916</td>\n",
       "      <td>23.683534</td>\n",
       "      <td>23.531789</td>\n",
       "      <td>300.517251</td>\n",
       "      <td>170.672749</td>\n",
       "      <td>89.149648</td>\n",
       "      <td>44.280597</td>\n",
       "      <td>23.435158</td>\n",
       "      <td>13.35417</td>\n",
       "      <td>10.367802</td>\n",
       "      <td>23.777636</td>\n",
       "      <td>23.518978</td>\n",
       "      <td>74.511461</td>\n",
       "      <td>37.632226</td>\n",
       "      <td>23.034822</td>\n",
       "      <td>23.574361</td>\n",
       "      <td>23.302189</td>\n",
       "      <td>24.047179</td>\n",
       "      <td>24.1225</td>\n",
       "      <td>23.358511</td>\n",
       "      <td>23.30423</td>\n",
       "      <td>23.1588</td>\n",
       "      <td>23.033007</td>\n",
       "      <td>22.6648</td>\n",
       "      <td>22.773879</td>\n",
       "      <td>22.606347</td>\n",
       "      <td>23.66417</td>\n",
       "      <td>23.907777</td>\n",
       "      <td>23.561953</td>\n",
       "      <td>23.840143</td>\n",
       "      <td>23.885973</td>\n",
       "      <td>23.299355</td>\n",
       "      <td>23.477822</td>\n",
       "      <td>23.895986</td>\n",
       "      <td>23.82698</td>\n",
       "      <td>24.004103</td>\n",
       "      <td>24.247811</td>\n",
       "      <td>23.55748</td>\n",
       "      <td>24.153399</td>\n",
       "      <td>24.07616</td>\n",
       "      <td>23.535471</td>\n",
       "      <td>23.584799</td>\n",
       "      <td>24.044567</td>\n",
       "      <td>23.701611</td>\n",
       "      <td>23.352319</td>\n",
       "      <td>23.586959</td>\n",
       "      <td>23.279665</td>\n",
       "      <td>23.328102</td>\n",
       "      <td>23.584234</td>\n",
       "      <td>23.233562</td>\n",
       "      <td>23.687913</td>\n",
       "      <td>23.430406</td>\n",
       "      <td>23.540169</td>\n",
       "      <td>23.653556</td>\n",
       "      <td>23.883228</td>\n",
       "      <td>23.846678</td>\n",
       "      <td>22.873191</td>\n",
       "      <td>23.07682</td>\n",
       "      <td>22.701395</td>\n",
       "      <td>22.59848</td>\n",
       "      <td>23.286571</td>\n",
       "      <td>23.371715</td>\n",
       "      <td>23.444686</td>\n",
       "      <td>23.232562</td>\n",
       "      <td>23.270355</td>\n",
       "      <td>23.287194</td>\n",
       "      <td>23.249351</td>\n",
       "      <td>23.336429</td>\n",
       "      <td>23.317205</td>\n",
       "      <td>23.158494</td>\n",
       "      <td>23.202428</td>\n",
       "      <td>23.640073</td>\n",
       "      <td>23.725851</td>\n",
       "      <td>23.440052</td>\n",
       "      <td>23.257695</td>\n",
       "      <td>23.409533</td>\n",
       "      <td>23.339891</td>\n",
       "      <td>23.370914</td>\n",
       "      <td>23.21867</td>\n",
       "      <td>23.554853</td>\n",
       "      <td>23.547086</td>\n",
       "      <td>23.34714</td>\n",
       "      <td>23.360484</td>\n",
       "      <td>23.647899</td>\n",
       "      <td>23.879527</td>\n",
       "      <td>24.329177</td>\n",
       "      <td>27.506127</td>\n",
       "      <td>28.595749</td>\n",
       "      <td>32.414388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_latency_ms_per_batch</th>\n",
       "      <td>2903.289808</td>\n",
       "      <td>2908.114499</td>\n",
       "      <td>2960.441788</td>\n",
       "      <td>2941.473608</td>\n",
       "      <td>2347.791025</td>\n",
       "      <td>2666.761703</td>\n",
       "      <td>2785.926509</td>\n",
       "      <td>2767.537316</td>\n",
       "      <td>2929.394723</td>\n",
       "      <td>3338.54239</td>\n",
       "      <td>5183.901025</td>\n",
       "      <td>2972.20455</td>\n",
       "      <td>2939.872271</td>\n",
       "      <td>9313.932569</td>\n",
       "      <td>4704.02822</td>\n",
       "      <td>2879.352748</td>\n",
       "      <td>2946.795177</td>\n",
       "      <td>2912.773661</td>\n",
       "      <td>3005.897323</td>\n",
       "      <td>3015.312471</td>\n",
       "      <td>2919.81393</td>\n",
       "      <td>2913.028805</td>\n",
       "      <td>2894.850059</td>\n",
       "      <td>2879.125936</td>\n",
       "      <td>2833.09999</td>\n",
       "      <td>2846.734851</td>\n",
       "      <td>2825.793395</td>\n",
       "      <td>2958.021251</td>\n",
       "      <td>2988.472176</td>\n",
       "      <td>2945.244112</td>\n",
       "      <td>2980.017825</td>\n",
       "      <td>2985.746645</td>\n",
       "      <td>2912.419385</td>\n",
       "      <td>2934.727713</td>\n",
       "      <td>2986.998288</td>\n",
       "      <td>2978.372542</td>\n",
       "      <td>3000.512829</td>\n",
       "      <td>3030.976345</td>\n",
       "      <td>2944.685004</td>\n",
       "      <td>3019.174914</td>\n",
       "      <td>3009.520001</td>\n",
       "      <td>2941.933847</td>\n",
       "      <td>2948.099845</td>\n",
       "      <td>3005.570872</td>\n",
       "      <td>2962.701374</td>\n",
       "      <td>2919.039935</td>\n",
       "      <td>2948.36993</td>\n",
       "      <td>2909.958078</td>\n",
       "      <td>2916.012712</td>\n",
       "      <td>2948.029216</td>\n",
       "      <td>2904.195222</td>\n",
       "      <td>2960.989152</td>\n",
       "      <td>2928.800693</td>\n",
       "      <td>2942.521106</td>\n",
       "      <td>2956.694525</td>\n",
       "      <td>2985.40352</td>\n",
       "      <td>2980.834787</td>\n",
       "      <td>2859.148891</td>\n",
       "      <td>2884.602521</td>\n",
       "      <td>2837.674381</td>\n",
       "      <td>2824.809944</td>\n",
       "      <td>2910.821429</td>\n",
       "      <td>2921.464402</td>\n",
       "      <td>2930.585798</td>\n",
       "      <td>2904.070252</td>\n",
       "      <td>2908.794437</td>\n",
       "      <td>2910.899296</td>\n",
       "      <td>2906.168873</td>\n",
       "      <td>2917.05359</td>\n",
       "      <td>2914.650578</td>\n",
       "      <td>2894.811798</td>\n",
       "      <td>2900.303453</td>\n",
       "      <td>2955.009096</td>\n",
       "      <td>2965.731396</td>\n",
       "      <td>2930.006438</td>\n",
       "      <td>2907.211887</td>\n",
       "      <td>2926.191577</td>\n",
       "      <td>2917.486425</td>\n",
       "      <td>2921.364236</td>\n",
       "      <td>2902.333711</td>\n",
       "      <td>2944.35657</td>\n",
       "      <td>2943.385782</td>\n",
       "      <td>2918.392557</td>\n",
       "      <td>2920.060557</td>\n",
       "      <td>2955.987344</td>\n",
       "      <td>2984.940937</td>\n",
       "      <td>3041.147076</td>\n",
       "      <td>3438.265927</td>\n",
       "      <td>3574.468596</td>\n",
       "      <td>4051.798498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_queries_per_sec</th>\n",
       "      <td>5.51099</td>\n",
       "      <td>5.501847</td>\n",
       "      <td>5.404599</td>\n",
       "      <td>5.43945</td>\n",
       "      <td>0.425932</td>\n",
       "      <td>0.749973</td>\n",
       "      <td>1.435788</td>\n",
       "      <td>2.890657</td>\n",
       "      <td>5.461879</td>\n",
       "      <td>9.585021</td>\n",
       "      <td>12.345915</td>\n",
       "      <td>5.38321</td>\n",
       "      <td>5.442413</td>\n",
       "      <td>1.717857</td>\n",
       "      <td>3.40134</td>\n",
       "      <td>5.556804</td>\n",
       "      <td>5.429627</td>\n",
       "      <td>5.493046</td>\n",
       "      <td>5.32287</td>\n",
       "      <td>5.306249</td>\n",
       "      <td>5.479801</td>\n",
       "      <td>5.492565</td>\n",
       "      <td>5.527057</td>\n",
       "      <td>5.557242</td>\n",
       "      <td>5.647524</td>\n",
       "      <td>5.620474</td>\n",
       "      <td>5.662127</td>\n",
       "      <td>5.409021</td>\n",
       "      <td>5.353906</td>\n",
       "      <td>5.432487</td>\n",
       "      <td>5.369095</td>\n",
       "      <td>5.358794</td>\n",
       "      <td>5.493714</td>\n",
       "      <td>5.451954</td>\n",
       "      <td>5.356548</td>\n",
       "      <td>5.372061</td>\n",
       "      <td>5.332422</td>\n",
       "      <td>5.278827</td>\n",
       "      <td>5.433518</td>\n",
       "      <td>5.299461</td>\n",
       "      <td>5.316462</td>\n",
       "      <td>5.4386</td>\n",
       "      <td>5.427225</td>\n",
       "      <td>5.323448</td>\n",
       "      <td>5.400477</td>\n",
       "      <td>5.481254</td>\n",
       "      <td>5.426727</td>\n",
       "      <td>5.498361</td>\n",
       "      <td>5.486945</td>\n",
       "      <td>5.427355</td>\n",
       "      <td>5.509272</td>\n",
       "      <td>5.4036</td>\n",
       "      <td>5.462987</td>\n",
       "      <td>5.437514</td>\n",
       "      <td>5.411448</td>\n",
       "      <td>5.35941</td>\n",
       "      <td>5.367624</td>\n",
       "      <td>5.596071</td>\n",
       "      <td>5.546691</td>\n",
       "      <td>5.63842</td>\n",
       "      <td>5.664098</td>\n",
       "      <td>5.49673</td>\n",
       "      <td>5.476705</td>\n",
       "      <td>5.459659</td>\n",
       "      <td>5.509509</td>\n",
       "      <td>5.500561</td>\n",
       "      <td>5.496583</td>\n",
       "      <td>5.50553</td>\n",
       "      <td>5.484987</td>\n",
       "      <td>5.489509</td>\n",
       "      <td>5.52713</td>\n",
       "      <td>5.516664</td>\n",
       "      <td>5.414535</td>\n",
       "      <td>5.394959</td>\n",
       "      <td>5.460739</td>\n",
       "      <td>5.503555</td>\n",
       "      <td>5.467858</td>\n",
       "      <td>5.484173</td>\n",
       "      <td>5.476893</td>\n",
       "      <td>5.512805</td>\n",
       "      <td>5.434124</td>\n",
       "      <td>5.435917</td>\n",
       "      <td>5.48247</td>\n",
       "      <td>5.479338</td>\n",
       "      <td>5.412743</td>\n",
       "      <td>5.36024</td>\n",
       "      <td>5.261173</td>\n",
       "      <td>4.653509</td>\n",
       "      <td>4.47619</td>\n",
       "      <td>3.948864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_tokens_per_sec</th>\n",
       "      <td>705.406671</td>\n",
       "      <td>704.236371</td>\n",
       "      <td>691.788641</td>\n",
       "      <td>696.24966</td>\n",
       "      <td>48.988868</td>\n",
       "      <td>95.996579</td>\n",
       "      <td>183.780871</td>\n",
       "      <td>370.004044</td>\n",
       "      <td>699.120533</td>\n",
       "      <td>1226.88273</td>\n",
       "      <td>1580.277085</td>\n",
       "      <td>689.050826</td>\n",
       "      <td>696.628905</td>\n",
       "      <td>219.885637</td>\n",
       "      <td>435.371538</td>\n",
       "      <td>711.270962</td>\n",
       "      <td>694.992314</td>\n",
       "      <td>703.109901</td>\n",
       "      <td>681.327331</td>\n",
       "      <td>679.199924</td>\n",
       "      <td>701.414559</td>\n",
       "      <td>703.048317</td>\n",
       "      <td>707.463239</td>\n",
       "      <td>711.326995</td>\n",
       "      <td>722.883064</td>\n",
       "      <td>719.420707</td>\n",
       "      <td>724.752207</td>\n",
       "      <td>692.354728</td>\n",
       "      <td>685.300006</td>\n",
       "      <td>695.358321</td>\n",
       "      <td>687.244211</td>\n",
       "      <td>685.92558</td>\n",
       "      <td>703.195429</td>\n",
       "      <td>697.85009</td>\n",
       "      <td>685.638157</td>\n",
       "      <td>687.623852</td>\n",
       "      <td>682.54999</td>\n",
       "      <td>675.689866</td>\n",
       "      <td>695.490349</td>\n",
       "      <td>678.33102</td>\n",
       "      <td>680.50719</td>\n",
       "      <td>696.140738</td>\n",
       "      <td>694.684749</td>\n",
       "      <td>681.401333</td>\n",
       "      <td>691.261029</td>\n",
       "      <td>701.600542</td>\n",
       "      <td>694.621112</td>\n",
       "      <td>703.790208</td>\n",
       "      <td>702.3289</td>\n",
       "      <td>694.701392</td>\n",
       "      <td>705.186753</td>\n",
       "      <td>691.660758</td>\n",
       "      <td>699.262331</td>\n",
       "      <td>696.001805</td>\n",
       "      <td>692.665401</td>\n",
       "      <td>686.004416</td>\n",
       "      <td>687.055857</td>\n",
       "      <td>716.297079</td>\n",
       "      <td>709.976499</td>\n",
       "      <td>721.717761</td>\n",
       "      <td>725.004528</td>\n",
       "      <td>703.581463</td>\n",
       "      <td>701.018297</td>\n",
       "      <td>698.83639</td>\n",
       "      <td>705.2171</td>\n",
       "      <td>704.071754</td>\n",
       "      <td>703.562642</td>\n",
       "      <td>704.707844</td>\n",
       "      <td>702.078291</td>\n",
       "      <td>702.657127</td>\n",
       "      <td>707.47259</td>\n",
       "      <td>706.133007</td>\n",
       "      <td>693.060472</td>\n",
       "      <td>690.554783</td>\n",
       "      <td>698.974573</td>\n",
       "      <td>704.455017</td>\n",
       "      <td>699.885823</td>\n",
       "      <td>701.974132</td>\n",
       "      <td>701.042333</td>\n",
       "      <td>705.639049</td>\n",
       "      <td>695.567928</td>\n",
       "      <td>695.797341</td>\n",
       "      <td>701.756176</td>\n",
       "      <td>701.355318</td>\n",
       "      <td>692.831113</td>\n",
       "      <td>686.110728</td>\n",
       "      <td>673.430107</td>\n",
       "      <td>595.649098</td>\n",
       "      <td>572.952299</td>\n",
       "      <td>505.454553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_0</th>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.004908</td>\n",
       "      <td>0.005478</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>0.056351</td>\n",
       "      <td>0.036521</td>\n",
       "      <td>0.018309</td>\n",
       "      <td>0.010055</td>\n",
       "      <td>0.005972</td>\n",
       "      <td>0.00378</td>\n",
       "      <td>0.003151</td>\n",
       "      <td>0.006087</td>\n",
       "      <td>0.004613</td>\n",
       "      <td>0.012772</td>\n",
       "      <td>0.006449</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>0.005942</td>\n",
       "      <td>0.005805</td>\n",
       "      <td>0.00594</td>\n",
       "      <td>0.006189</td>\n",
       "      <td>0.105652</td>\n",
       "      <td>0.00582</td>\n",
       "      <td>0.00555</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.005392</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>0.00542</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.005543</td>\n",
       "      <td>0.005438</td>\n",
       "      <td>0.005475</td>\n",
       "      <td>0.005461</td>\n",
       "      <td>0.00535</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.005429</td>\n",
       "      <td>0.005574</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>0.005571</td>\n",
       "      <td>0.005407</td>\n",
       "      <td>0.005391</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>0.005377</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>0.005412</td>\n",
       "      <td>0.005372</td>\n",
       "      <td>0.005457</td>\n",
       "      <td>0.005377</td>\n",
       "      <td>0.005456</td>\n",
       "      <td>0.005484</td>\n",
       "      <td>0.005385</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.005437</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.005244</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>0.005453</td>\n",
       "      <td>0.005466</td>\n",
       "      <td>0.005328</td>\n",
       "      <td>0.005354</td>\n",
       "      <td>0.005438</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>0.005432</td>\n",
       "      <td>0.00538</td>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>0.005503</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>0.005396</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.005459</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>0.005395</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.005541</td>\n",
       "      <td>0.005781</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.006339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007075</td>\n",
       "      <td>0.007924</td>\n",
       "      <td>0.008667</td>\n",
       "      <td>0.066043</td>\n",
       "      <td>0.047542</td>\n",
       "      <td>0.022941</td>\n",
       "      <td>0.013588</td>\n",
       "      <td>0.008557</td>\n",
       "      <td>0.005674</td>\n",
       "      <td>0.004913</td>\n",
       "      <td>0.008565</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>0.026401</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.007626</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.007748</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.107793</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>0.00539</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.00543</td>\n",
       "      <td>0.005499</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>0.005451</td>\n",
       "      <td>0.005537</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>0.005554</td>\n",
       "      <td>0.005538</td>\n",
       "      <td>0.00541</td>\n",
       "      <td>0.005483</td>\n",
       "      <td>0.005493</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.005394</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>0.005443</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>0.005405</td>\n",
       "      <td>0.005448</td>\n",
       "      <td>0.00549</td>\n",
       "      <td>0.00537</td>\n",
       "      <td>0.00552</td>\n",
       "      <td>0.00538</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>0.005431</td>\n",
       "      <td>0.005462</td>\n",
       "      <td>0.00538</td>\n",
       "      <td>0.005465</td>\n",
       "      <td>0.005427</td>\n",
       "      <td>0.005402</td>\n",
       "      <td>0.005358</td>\n",
       "      <td>0.005345</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.005449</td>\n",
       "      <td>0.005417</td>\n",
       "      <td>0.005516</td>\n",
       "      <td>0.005417</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>0.005429</td>\n",
       "      <td>0.005465</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.005447</td>\n",
       "      <td>0.005472</td>\n",
       "      <td>0.005481</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>0.005458</td>\n",
       "      <td>0.005381</td>\n",
       "      <td>0.005399</td>\n",
       "      <td>0.005342</td>\n",
       "      <td>0.005449</td>\n",
       "      <td>0.005496</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>0.005355</td>\n",
       "      <td>0.005544</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.005827</td>\n",
       "      <td>0.006319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007368</td>\n",
       "      <td>0.008176</td>\n",
       "      <td>0.064095</td>\n",
       "      <td>0.045371</td>\n",
       "      <td>0.018231</td>\n",
       "      <td>0.010947</td>\n",
       "      <td>0.008233</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.008334</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.023616</td>\n",
       "      <td>0.006927</td>\n",
       "      <td>0.006936</td>\n",
       "      <td>0.007001</td>\n",
       "      <td>0.007059</td>\n",
       "      <td>0.007105</td>\n",
       "      <td>0.007057</td>\n",
       "      <td>0.107536</td>\n",
       "      <td>0.007065</td>\n",
       "      <td>0.006228</td>\n",
       "      <td>0.005422</td>\n",
       "      <td>0.005394</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.005505</td>\n",
       "      <td>0.005422</td>\n",
       "      <td>0.005605</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.005476</td>\n",
       "      <td>0.005438</td>\n",
       "      <td>0.005542</td>\n",
       "      <td>0.00558</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.00543</td>\n",
       "      <td>0.005586</td>\n",
       "      <td>0.005588</td>\n",
       "      <td>0.005382</td>\n",
       "      <td>0.005498</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.005488</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.00545</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>0.005369</td>\n",
       "      <td>0.005403</td>\n",
       "      <td>0.005495</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.00548</td>\n",
       "      <td>0.00558</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.005437</td>\n",
       "      <td>0.005371</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.005399</td>\n",
       "      <td>0.005442</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.005414</td>\n",
       "      <td>0.005446</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>0.005404</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>0.005408</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>0.005394</td>\n",
       "      <td>0.005479</td>\n",
       "      <td>0.005406</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.005464</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>0.00548</td>\n",
       "      <td>0.005419</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.005398</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.005392</td>\n",
       "      <td>0.005368</td>\n",
       "      <td>0.005478</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.005875</td>\n",
       "      <td>0.006129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007659</td>\n",
       "      <td>0.062268</td>\n",
       "      <td>0.043549</td>\n",
       "      <td>0.021071</td>\n",
       "      <td>0.012337</td>\n",
       "      <td>0.00757</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>0.004166</td>\n",
       "      <td>0.007577</td>\n",
       "      <td>0.005036</td>\n",
       "      <td>0.019066</td>\n",
       "      <td>0.006697</td>\n",
       "      <td>0.006388</td>\n",
       "      <td>0.006512</td>\n",
       "      <td>0.006551</td>\n",
       "      <td>0.007097</td>\n",
       "      <td>0.006653</td>\n",
       "      <td>0.106682</td>\n",
       "      <td>0.006599</td>\n",
       "      <td>0.006112</td>\n",
       "      <td>0.005809</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.005811</td>\n",
       "      <td>0.005808</td>\n",
       "      <td>0.005908</td>\n",
       "      <td>0.005938</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>0.006038</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.005887</td>\n",
       "      <td>0.005889</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.005893</td>\n",
       "      <td>0.005943</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.005807</td>\n",
       "      <td>0.005978</td>\n",
       "      <td>0.005838</td>\n",
       "      <td>0.005831</td>\n",
       "      <td>0.005795</td>\n",
       "      <td>0.00588</td>\n",
       "      <td>0.005892</td>\n",
       "      <td>0.005716</td>\n",
       "      <td>0.005976</td>\n",
       "      <td>0.005825</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>0.005719</td>\n",
       "      <td>0.005847</td>\n",
       "      <td>0.005884</td>\n",
       "      <td>0.00584</td>\n",
       "      <td>0.005781</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.005818</td>\n",
       "      <td>0.00587</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>0.005855</td>\n",
       "      <td>0.005766</td>\n",
       "      <td>0.005839</td>\n",
       "      <td>0.005826</td>\n",
       "      <td>0.005843</td>\n",
       "      <td>0.005862</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>0.005819</td>\n",
       "      <td>0.005774</td>\n",
       "      <td>0.005802</td>\n",
       "      <td>0.005823</td>\n",
       "      <td>0.005867</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.005813</td>\n",
       "      <td>0.005873</td>\n",
       "      <td>0.005876</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>0.005711</td>\n",
       "      <td>0.005728</td>\n",
       "      <td>0.005904</td>\n",
       "      <td>0.005764</td>\n",
       "      <td>0.005783</td>\n",
       "      <td>0.005844</td>\n",
       "      <td>0.005915</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.006011</td>\n",
       "      <td>0.006254</td>\n",
       "      <td>0.00636</td>\n",
       "      <td>0.006689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_avg</th>\n",
       "      <td>696.175445</td>\n",
       "      <td>662.784411</td>\n",
       "      <td>560.900069</td>\n",
       "      <td>726.089579</td>\n",
       "      <td>552.633632</td>\n",
       "      <td>561.619474</td>\n",
       "      <td>684.188067</td>\n",
       "      <td>629.605872</td>\n",
       "      <td>650.462376</td>\n",
       "      <td>678.557621</td>\n",
       "      <td>750.966714</td>\n",
       "      <td>633.38496</td>\n",
       "      <td>576.635783</td>\n",
       "      <td>485.282421</td>\n",
       "      <td>596.515287</td>\n",
       "      <td>248.97514</td>\n",
       "      <td>570.969436</td>\n",
       "      <td>359.762385</td>\n",
       "      <td>165.805681</td>\n",
       "      <td>381.99481</td>\n",
       "      <td>574.005568</td>\n",
       "      <td>836.666102</td>\n",
       "      <td>697.486571</td>\n",
       "      <td>995.399846</td>\n",
       "      <td>141.500592</td>\n",
       "      <td>595.223181</td>\n",
       "      <td>240.015809</td>\n",
       "      <td>930.285971</td>\n",
       "      <td>818.073557</td>\n",
       "      <td>680.710089</td>\n",
       "      <td>630.786332</td>\n",
       "      <td>584.672502</td>\n",
       "      <td>474.50611</td>\n",
       "      <td>666.91485</td>\n",
       "      <td>1044.133286</td>\n",
       "      <td>613.075184</td>\n",
       "      <td>125.703947</td>\n",
       "      <td>554.297154</td>\n",
       "      <td>746.865359</td>\n",
       "      <td>178.077688</td>\n",
       "      <td>530.26023</td>\n",
       "      <td>828.379786</td>\n",
       "      <td>1128.825755</td>\n",
       "      <td>183.379652</td>\n",
       "      <td>585.733726</td>\n",
       "      <td>597.075869</td>\n",
       "      <td>1426.644534</td>\n",
       "      <td>609.430123</td>\n",
       "      <td>1230.096169</td>\n",
       "      <td>752.683404</td>\n",
       "      <td>631.860825</td>\n",
       "      <td>1124.918904</td>\n",
       "      <td>107.580307</td>\n",
       "      <td>964.896948</td>\n",
       "      <td>845.433359</td>\n",
       "      <td>932.529908</td>\n",
       "      <td>828.393201</td>\n",
       "      <td>542.674179</td>\n",
       "      <td>8418.778745</td>\n",
       "      <td>514.075478</td>\n",
       "      <td>614.212687</td>\n",
       "      <td>750.69982</td>\n",
       "      <td>1677.981438</td>\n",
       "      <td>1200.855005</td>\n",
       "      <td>1023.46107</td>\n",
       "      <td>641.739565</td>\n",
       "      <td>1551.207321</td>\n",
       "      <td>1448.743478</td>\n",
       "      <td>1485.262123</td>\n",
       "      <td>1274.904466</td>\n",
       "      <td>562.538789</td>\n",
       "      <td>795.553393</td>\n",
       "      <td>708.789737</td>\n",
       "      <td>196.533552</td>\n",
       "      <td>940.007732</td>\n",
       "      <td>659.73285</td>\n",
       "      <td>881.419378</td>\n",
       "      <td>2203.211476</td>\n",
       "      <td>1662.575306</td>\n",
       "      <td>646.021091</td>\n",
       "      <td>1518.139929</td>\n",
       "      <td>708.204415</td>\n",
       "      <td>772.734927</td>\n",
       "      <td>143.466911</td>\n",
       "      <td>1234.326235</td>\n",
       "      <td>1127.987867</td>\n",
       "      <td>1259.214409</td>\n",
       "      <td>390.099748</td>\n",
       "      <td>534.115213</td>\n",
       "      <td>685.047901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_avg</th>\n",
       "      <td>0.701849</td>\n",
       "      <td>0.678551</td>\n",
       "      <td>0.667915</td>\n",
       "      <td>0.665473</td>\n",
       "      <td>0.656015</td>\n",
       "      <td>0.661594</td>\n",
       "      <td>0.663938</td>\n",
       "      <td>0.66558</td>\n",
       "      <td>0.666628</td>\n",
       "      <td>0.661934</td>\n",
       "      <td>0.662724</td>\n",
       "      <td>0.663733</td>\n",
       "      <td>0.916395</td>\n",
       "      <td>0.979554</td>\n",
       "      <td>0.96273</td>\n",
       "      <td>0.643025</td>\n",
       "      <td>0.664062</td>\n",
       "      <td>0.661822</td>\n",
       "      <td>0.667078</td>\n",
       "      <td>0.663048</td>\n",
       "      <td>0.661945</td>\n",
       "      <td>0.666487</td>\n",
       "      <td>0.642038</td>\n",
       "      <td>0.635867</td>\n",
       "      <td>0.641261</td>\n",
       "      <td>0.640277</td>\n",
       "      <td>0.645682</td>\n",
       "      <td>0.677652</td>\n",
       "      <td>0.676869</td>\n",
       "      <td>0.677398</td>\n",
       "      <td>0.67482</td>\n",
       "      <td>0.673987</td>\n",
       "      <td>0.677596</td>\n",
       "      <td>0.677137</td>\n",
       "      <td>0.677181</td>\n",
       "      <td>0.67413</td>\n",
       "      <td>0.676264</td>\n",
       "      <td>0.67676</td>\n",
       "      <td>0.675836</td>\n",
       "      <td>0.675833</td>\n",
       "      <td>0.678728</td>\n",
       "      <td>0.67486</td>\n",
       "      <td>0.68033</td>\n",
       "      <td>0.673824</td>\n",
       "      <td>0.676639</td>\n",
       "      <td>0.676245</td>\n",
       "      <td>0.677293</td>\n",
       "      <td>0.676872</td>\n",
       "      <td>0.676701</td>\n",
       "      <td>0.675662</td>\n",
       "      <td>0.678458</td>\n",
       "      <td>0.68434</td>\n",
       "      <td>0.680158</td>\n",
       "      <td>0.673759</td>\n",
       "      <td>0.674298</td>\n",
       "      <td>0.674014</td>\n",
       "      <td>0.677866</td>\n",
       "      <td>0.639024</td>\n",
       "      <td>0.648004</td>\n",
       "      <td>0.646411</td>\n",
       "      <td>0.641967</td>\n",
       "      <td>0.666498</td>\n",
       "      <td>0.665195</td>\n",
       "      <td>0.665195</td>\n",
       "      <td>0.66469</td>\n",
       "      <td>0.664462</td>\n",
       "      <td>0.6631</td>\n",
       "      <td>0.665169</td>\n",
       "      <td>0.665225</td>\n",
       "      <td>0.663432</td>\n",
       "      <td>0.664345</td>\n",
       "      <td>0.663654</td>\n",
       "      <td>0.663628</td>\n",
       "      <td>0.666584</td>\n",
       "      <td>0.665578</td>\n",
       "      <td>0.666098</td>\n",
       "      <td>0.664872</td>\n",
       "      <td>0.665559</td>\n",
       "      <td>0.66279</td>\n",
       "      <td>0.662914</td>\n",
       "      <td>0.665464</td>\n",
       "      <td>0.663001</td>\n",
       "      <td>0.664455</td>\n",
       "      <td>0.664685</td>\n",
       "      <td>0.667894</td>\n",
       "      <td>0.664632</td>\n",
       "      <td>0.664354</td>\n",
       "      <td>0.664819</td>\n",
       "      <td>0.665937</td>\n",
       "      <td>0.669801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_total</th>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.002893</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.040921</td>\n",
       "      <td>0.025233</td>\n",
       "      <td>0.012236</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.002276</td>\n",
       "      <td>0.001837</td>\n",
       "      <td>0.003825</td>\n",
       "      <td>0.003195</td>\n",
       "      <td>0.014701</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>0.003637</td>\n",
       "      <td>0.003388</td>\n",
       "      <td>0.003528</td>\n",
       "      <td>0.07694</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.002925</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.003124</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.002869</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.002743</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.00312</td>\n",
       "      <td>0.003128</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.002796</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002894</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.00314</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.002895</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.002883</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.00268</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>0.003115</td>\n",
       "      <td>0.002897</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.002866</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.002775</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.002817</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.002969</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.002714</td>\n",
       "      <td>0.002917</td>\n",
       "      <td>0.002875</td>\n",
       "      <td>0.003007</td>\n",
       "      <td>0.00268</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.002935</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.003897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_total</th>\n",
       "      <td>0.003779</td>\n",
       "      <td>0.010173</td>\n",
       "      <td>0.017862</td>\n",
       "      <td>0.026681</td>\n",
       "      <td>0.207629</td>\n",
       "      <td>0.147622</td>\n",
       "      <td>0.068254</td>\n",
       "      <td>0.040386</td>\n",
       "      <td>0.026493</td>\n",
       "      <td>0.017452</td>\n",
       "      <td>0.014974</td>\n",
       "      <td>0.026718</td>\n",
       "      <td>0.016988</td>\n",
       "      <td>0.067042</td>\n",
       "      <td>0.021821</td>\n",
       "      <td>0.023035</td>\n",
       "      <td>0.023758</td>\n",
       "      <td>0.023654</td>\n",
       "      <td>0.024483</td>\n",
       "      <td>0.024152</td>\n",
       "      <td>0.350275</td>\n",
       "      <td>0.023799</td>\n",
       "      <td>0.02048</td>\n",
       "      <td>0.019082</td>\n",
       "      <td>0.01901</td>\n",
       "      <td>0.018871</td>\n",
       "      <td>0.019023</td>\n",
       "      <td>0.019471</td>\n",
       "      <td>0.019529</td>\n",
       "      <td>0.019418</td>\n",
       "      <td>0.019424</td>\n",
       "      <td>0.019407</td>\n",
       "      <td>0.01934</td>\n",
       "      <td>0.01934</td>\n",
       "      <td>0.019476</td>\n",
       "      <td>0.019473</td>\n",
       "      <td>0.019409</td>\n",
       "      <td>0.019406</td>\n",
       "      <td>0.019202</td>\n",
       "      <td>0.019364</td>\n",
       "      <td>0.019419</td>\n",
       "      <td>0.019331</td>\n",
       "      <td>0.01935</td>\n",
       "      <td>0.019335</td>\n",
       "      <td>0.019402</td>\n",
       "      <td>0.019153</td>\n",
       "      <td>0.019325</td>\n",
       "      <td>0.019215</td>\n",
       "      <td>0.01906</td>\n",
       "      <td>0.01937</td>\n",
       "      <td>0.019145</td>\n",
       "      <td>0.019339</td>\n",
       "      <td>0.019341</td>\n",
       "      <td>0.019328</td>\n",
       "      <td>0.019278</td>\n",
       "      <td>0.019412</td>\n",
       "      <td>0.019263</td>\n",
       "      <td>0.018977</td>\n",
       "      <td>0.018983</td>\n",
       "      <td>0.018902</td>\n",
       "      <td>0.018919</td>\n",
       "      <td>0.019227</td>\n",
       "      <td>0.019343</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.019264</td>\n",
       "      <td>0.019155</td>\n",
       "      <td>0.01933</td>\n",
       "      <td>0.019281</td>\n",
       "      <td>0.019313</td>\n",
       "      <td>0.01934</td>\n",
       "      <td>0.019118</td>\n",
       "      <td>0.019204</td>\n",
       "      <td>0.019342</td>\n",
       "      <td>0.019341</td>\n",
       "      <td>0.019185</td>\n",
       "      <td>0.019223</td>\n",
       "      <td>0.019287</td>\n",
       "      <td>0.019089</td>\n",
       "      <td>0.019325</td>\n",
       "      <td>0.019196</td>\n",
       "      <td>0.019312</td>\n",
       "      <td>0.019087</td>\n",
       "      <td>0.019164</td>\n",
       "      <td>0.019385</td>\n",
       "      <td>0.01928</td>\n",
       "      <td>0.019101</td>\n",
       "      <td>0.019622</td>\n",
       "      <td>0.020156</td>\n",
       "      <td>0.020624</td>\n",
       "      <td>0.02156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_generated_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>14722</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_config_decoding_mode</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   0   \\\n",
       "config_name                                           num_processes_1   \n",
       "experiment_id                                                     109   \n",
       "date_time                               April 11, 2025 at 01:21:09 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       1   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.004499   \n",
       "total_energy_joules                                       16195.77922   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             1.011622   \n",
       "joules_per_token                                             0.988512   \n",
       "flops_per_joule                                     1046567180.461082   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    23.226318   \n",
       "average_latency_ms_per_batch                              2903.289808   \n",
       "throughput_queries_per_sec                                    5.51099   \n",
       "throughput_tokens_per_sec                                  705.406671   \n",
       "total_energy_kwh_process_0                                   0.004499   \n",
       "total_energy_kwh_process_1                                        NaN   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                              696.175445   \n",
       "ram_power_avg                                                0.701849   \n",
       "cpu_energy_total                                             0.000716   \n",
       "gpu_energy_total                                             0.003779   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "latency_simulation_simulate                                     False   \n",
       "\n",
       "                                                                   1   \\\n",
       "config_name                                           num_processes_2   \n",
       "experiment_id                                                     110   \n",
       "date_time                               April 11, 2025 at 01:22:13 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       2   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.011983   \n",
       "total_energy_joules                                      43137.499279   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.379809   \n",
       "joules_per_token                                             2.632904   \n",
       "flops_per_joule                                      392928919.763817   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    23.264916   \n",
       "average_latency_ms_per_batch                              2908.114499   \n",
       "throughput_queries_per_sec                                   5.501847   \n",
       "throughput_tokens_per_sec                                  704.236371   \n",
       "total_energy_kwh_process_0                                   0.004908   \n",
       "total_energy_kwh_process_1                                   0.007075   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                              662.784411   \n",
       "ram_power_avg                                                0.678551   \n",
       "cpu_energy_total                                               0.0018   \n",
       "gpu_energy_total                                             0.010173   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "latency_simulation_simulate                                     False   \n",
       "\n",
       "                                                                   2   \\\n",
       "config_name                                           num_processes_3   \n",
       "experiment_id                                                     111   \n",
       "date_time                               April 11, 2025 at 01:23:18 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       3   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                              0.02077   \n",
       "total_energy_joules                                      74772.641025   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.219118   \n",
       "joules_per_token                                              4.56376   \n",
       "flops_per_joule                                       226686803.63326   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    23.683534   \n",
       "average_latency_ms_per_batch                              2960.441788   \n",
       "throughput_queries_per_sec                                   5.404599   \n",
       "throughput_tokens_per_sec                                  691.788641   \n",
       "total_energy_kwh_process_0                                   0.005478   \n",
       "total_energy_kwh_process_1                                   0.007924   \n",
       "total_energy_kwh_process_2                                   0.007368   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                              560.900069   \n",
       "ram_power_avg                                                0.667915   \n",
       "cpu_energy_total                                             0.002893   \n",
       "gpu_energy_total                                             0.017862   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "latency_simulation_simulate                                     False   \n",
       "\n",
       "                                                                   3   \\\n",
       "config_name                                           num_processes_4   \n",
       "experiment_id                                                     112   \n",
       "date_time                               April 11, 2025 at 01:24:25 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                              0.03052   \n",
       "total_energy_joules                                     109872.192307   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.149119   \n",
       "joules_per_token                                             6.706066   \n",
       "flops_per_joule                                      154269889.744024   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    23.531789   \n",
       "average_latency_ms_per_batch                              2941.473608   \n",
       "throughput_queries_per_sec                                    5.43945   \n",
       "throughput_tokens_per_sec                                   696.24966   \n",
       "total_energy_kwh_process_0                                   0.006019   \n",
       "total_energy_kwh_process_1                                   0.008667   \n",
       "total_energy_kwh_process_2                                   0.008176   \n",
       "total_energy_kwh_process_3                                   0.007659   \n",
       "gpu_power_avg                                              726.089579   \n",
       "ram_power_avg                                                0.665473   \n",
       "cpu_energy_total                                             0.003819   \n",
       "gpu_energy_total                                             0.026681   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "latency_simulation_simulate                                     False   \n",
       "\n",
       "                                                                   4   \\\n",
       "config_name                                                batching_1   \n",
       "experiment_id                                                     113   \n",
       "date_time                               April 11, 2025 at 01:30:52 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                         1   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.248756   \n",
       "total_energy_joules                                     895521.470895   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                              0.01644   \n",
       "joules_per_token                                            60.828792   \n",
       "flops_per_joule                                       18927486.993933   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                   300.517251   \n",
       "average_latency_ms_per_batch                              2347.791025   \n",
       "throughput_queries_per_sec                                   0.425932   \n",
       "throughput_tokens_per_sec                                   48.988868   \n",
       "total_energy_kwh_process_0                                   0.056351   \n",
       "total_energy_kwh_process_1                                   0.066043   \n",
       "total_energy_kwh_process_2                                   0.064095   \n",
       "total_energy_kwh_process_3                                   0.062268   \n",
       "gpu_power_avg                                              552.633632   \n",
       "ram_power_avg                                                0.656015   \n",
       "cpu_energy_total                                             0.040921   \n",
       "gpu_energy_total                                             0.207629   \n",
       "total_generated_tokens                                          14722   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "latency_simulation_simulate                                     False   \n",
       "\n",
       "                                                                   5   \\\n",
       "config_name                                                batching_2   \n",
       "experiment_id                                                     114   \n",
       "date_time                               April 11, 2025 at 01:35:11 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                         2   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.172983   \n",
       "total_energy_joules                                     622739.187387   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                              0.02631   \n",
       "joules_per_token                                            38.008984   \n",
       "flops_per_joule                                       27218410.751168   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                   170.672749   \n",
       "average_latency_ms_per_batch                              2666.761703   \n",
       "throughput_queries_per_sec                                   0.749973   \n",
       "throughput_tokens_per_sec                                   95.996579   \n",
       "total_energy_kwh_process_0                                   0.036521   \n",
       "total_energy_kwh_process_1                                   0.047542   \n",
       "total_energy_kwh_process_2                                   0.045371   \n",
       "total_energy_kwh_process_3                                   0.043549   \n",
       "gpu_power_avg                                              561.619474   \n",
       "ram_power_avg                                                0.661594   \n",
       "cpu_energy_total                                             0.025233   \n",
       "gpu_energy_total                                             0.147622   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "latency_simulation_simulate                                     False   \n",
       "\n",
       "                                                                   6   \\\n",
       "config_name                                                batching_4   \n",
       "experiment_id                                                     115   \n",
       "date_time                               April 11, 2025 at 01:37:39 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                         4   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.080552   \n",
       "total_energy_joules                                     289987.598049   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.056499   \n",
       "joules_per_token                                            17.699438   \n",
       "flops_per_joule                                       58450675.502025   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    89.149648   \n",
       "average_latency_ms_per_batch                              2785.926509   \n",
       "throughput_queries_per_sec                                   1.435788   \n",
       "throughput_tokens_per_sec                                  183.780871   \n",
       "total_energy_kwh_process_0                                   0.018309   \n",
       "total_energy_kwh_process_1                                   0.022941   \n",
       "total_energy_kwh_process_2                                   0.018231   \n",
       "total_energy_kwh_process_3                                   0.021071   \n",
       "gpu_power_avg                                              684.188067   \n",
       "ram_power_avg                                                0.663938   \n",
       "cpu_energy_total                                             0.012236   \n",
       "gpu_energy_total                                             0.068254   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "latency_simulation_simulate                                     False   \n",
       "\n",
       "                                                                   7   \\\n",
       "config_name                                                batching_8   \n",
       "experiment_id                                                     116   \n",
       "date_time                               April 11, 2025 at 01:39:15 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                         8   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.046927   \n",
       "total_energy_joules                                     168938.609749   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.096982   \n",
       "joules_per_token                                            10.311194   \n",
       "flops_per_joule                                      100332132.591523   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    44.280597   \n",
       "average_latency_ms_per_batch                              2767.537316   \n",
       "throughput_queries_per_sec                                   2.890657   \n",
       "throughput_tokens_per_sec                                  370.004044   \n",
       "total_energy_kwh_process_0                                   0.010055   \n",
       "total_energy_kwh_process_1                                   0.013588   \n",
       "total_energy_kwh_process_2                                   0.010947   \n",
       "total_energy_kwh_process_3                                   0.012337   \n",
       "gpu_power_avg                                              629.605872   \n",
       "ram_power_avg                                                 0.66558   \n",
       "cpu_energy_total                                             0.006508   \n",
       "gpu_energy_total                                             0.040386   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "latency_simulation_simulate                                     False   \n",
       "\n",
       "                                                                   8   \\\n",
       "config_name                                               batching_16   \n",
       "experiment_id                                                     117   \n",
       "date_time                               April 11, 2025 at 01:40:22 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.030332   \n",
       "total_energy_joules                                      109195.59459   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.150043   \n",
       "joules_per_token                                              6.66477   \n",
       "flops_per_joule                                      155225776.798502   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    23.435158   \n",
       "average_latency_ms_per_batch                              2929.394723   \n",
       "throughput_queries_per_sec                                   5.461879   \n",
       "throughput_tokens_per_sec                                  699.120533   \n",
       "total_energy_kwh_process_0                                   0.005972   \n",
       "total_energy_kwh_process_1                                   0.008557   \n",
       "total_energy_kwh_process_2                                   0.008233   \n",
       "total_energy_kwh_process_3                                    0.00757   \n",
       "gpu_power_avg                                              650.462376   \n",
       "ram_power_avg                                                0.666628   \n",
       "cpu_energy_total                                             0.003819   \n",
       "gpu_energy_total                                             0.026493   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "latency_simulation_simulate                                     False   \n",
       "\n",
       "                                                                   9   \\\n",
       "config_name                                               batching_32   \n",
       "experiment_id                                                     118   \n",
       "date_time                               April 11, 2025 at 01:41:15 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        32   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                              0.01974   \n",
       "total_energy_joules                                      71065.052609   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.230549   \n",
       "joules_per_token                                             4.337467   \n",
       "flops_per_joule                                      238513451.700919   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     13.35417   \n",
       "average_latency_ms_per_batch                               3338.54239   \n",
       "throughput_queries_per_sec                                   9.585021   \n",
       "throughput_tokens_per_sec                                  1226.88273   \n",
       "total_energy_kwh_process_0                                    0.00378   \n",
       "total_energy_kwh_process_1                                   0.005674   \n",
       "total_energy_kwh_process_2                                   0.005409   \n",
       "total_energy_kwh_process_3                                   0.004876   \n",
       "gpu_power_avg                                              678.557621   \n",
       "ram_power_avg                                                0.661934   \n",
       "cpu_energy_total                                             0.002276   \n",
       "gpu_energy_total                                             0.017452   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "latency_simulation_simulate                                     False   \n",
       "\n",
       "                                                                   10  \\\n",
       "config_name                                               batching_64   \n",
       "experiment_id                                                     119   \n",
       "date_time                               April 11, 2025 at 01:42:03 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        64   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.016821   \n",
       "total_energy_joules                                        60554.5696   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.270566   \n",
       "joules_per_token                                             3.695958   \n",
       "flops_per_joule                                      279912335.355367   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    10.367802   \n",
       "average_latency_ms_per_batch                              5183.901025   \n",
       "throughput_queries_per_sec                                  12.345915   \n",
       "throughput_tokens_per_sec                                 1580.277085   \n",
       "total_energy_kwh_process_0                                   0.003151   \n",
       "total_energy_kwh_process_1                                   0.004913   \n",
       "total_energy_kwh_process_2                                   0.004591   \n",
       "total_energy_kwh_process_3                                   0.004166   \n",
       "gpu_power_avg                                              750.966714   \n",
       "ram_power_avg                                                0.662724   \n",
       "cpu_energy_total                                             0.001837   \n",
       "gpu_energy_total                                             0.014974   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "latency_simulation_simulate                                     False   \n",
       "\n",
       "                                                                                  11  \\\n",
       "config_name                        precis_float32_quant_False_quant8_False_quant4...   \n",
       "experiment_id                                                                    120   \n",
       "date_time                                              April 11, 2025 at 01:43:09 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.030563   \n",
       "total_energy_joules                                                    110026.388974   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                             0.14891   \n",
       "joules_per_token                                                            6.715478   \n",
       "flops_per_joule                                                     154053687.949614   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.777636   \n",
       "average_latency_ms_per_batch                                              2972.20455   \n",
       "throughput_queries_per_sec                                                   5.38321   \n",
       "throughput_tokens_per_sec                                                 689.050826   \n",
       "total_energy_kwh_process_0                                                  0.006087   \n",
       "total_energy_kwh_process_1                                                  0.008565   \n",
       "total_energy_kwh_process_2                                                  0.008334   \n",
       "total_energy_kwh_process_3                                                  0.007577   \n",
       "gpu_power_avg                                                              633.38496   \n",
       "ram_power_avg                                                               0.663733   \n",
       "cpu_energy_total                                                            0.003825   \n",
       "gpu_energy_total                                                            0.026718   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  12  \\\n",
       "config_name                        precis_float16_quant_False_quant8_False_quant4...   \n",
       "experiment_id                                                                    121   \n",
       "date_time                                              April 11, 2025 at 01:44:07 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.020205   \n",
       "total_energy_joules                                                     72739.613361   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.225242   \n",
       "joules_per_token                                                            4.439674   \n",
       "flops_per_joule                                                     233022561.022627   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.518978   \n",
       "average_latency_ms_per_batch                                             2939.872271   \n",
       "throughput_queries_per_sec                                                  5.442413   \n",
       "throughput_tokens_per_sec                                                 696.628905   \n",
       "total_energy_kwh_process_0                                                  0.004613   \n",
       "total_energy_kwh_process_1                                                  0.005285   \n",
       "total_energy_kwh_process_2                                                  0.005271   \n",
       "total_energy_kwh_process_3                                                  0.005036   \n",
       "gpu_power_avg                                                             576.635783   \n",
       "ram_power_avg                                                               0.916395   \n",
       "cpu_energy_total                                                            0.003195   \n",
       "gpu_energy_total                                                            0.016988   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  13  \\\n",
       "config_name                        precis_float16_quant_True_quant8_True_quant4_F...   \n",
       "experiment_id                                                                    122   \n",
       "date_time                                              April 11, 2025 at 01:47:13 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                    True   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.081855   \n",
       "total_energy_joules                                                    294677.860311   \n",
       "flops                                                                  1034544128000   \n",
       "tokens_per_joule                                                              0.0556   \n",
       "joules_per_token                                                           17.985709   \n",
       "flops_per_joule                                                       3510762.996944   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   74.511461   \n",
       "average_latency_ms_per_batch                                             9313.932569   \n",
       "throughput_queries_per_sec                                                  1.717857   \n",
       "throughput_tokens_per_sec                                                 219.885637   \n",
       "total_energy_kwh_process_0                                                  0.012772   \n",
       "total_energy_kwh_process_1                                                  0.026401   \n",
       "total_energy_kwh_process_2                                                  0.023616   \n",
       "total_energy_kwh_process_3                                                  0.019066   \n",
       "gpu_power_avg                                                             485.282421   \n",
       "ram_power_avg                                                               0.979554   \n",
       "cpu_energy_total                                                            0.014701   \n",
       "gpu_energy_total                                                            0.067042   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  14  \\\n",
       "config_name                        precis_float16_quant_True_quant8_False_quant4_...   \n",
       "experiment_id                                                                    123   \n",
       "date_time                                              April 11, 2025 at 01:48:28 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.026513   \n",
       "total_energy_joules                                                     95445.437568   \n",
       "flops                                                                  1034544128000   \n",
       "tokens_per_joule                                                            0.171658   \n",
       "joules_per_token                                                            5.825527   \n",
       "flops_per_joule                                                      10839115.565521   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.632226   \n",
       "average_latency_ms_per_batch                                              4704.02822   \n",
       "throughput_queries_per_sec                                                   3.40134   \n",
       "throughput_tokens_per_sec                                                 435.371538   \n",
       "total_energy_kwh_process_0                                                  0.006449   \n",
       "total_energy_kwh_process_1                                                  0.006439   \n",
       "total_energy_kwh_process_2                                                  0.006927   \n",
       "total_energy_kwh_process_3                                                  0.006697   \n",
       "gpu_power_avg                                                             596.515287   \n",
       "ram_power_avg                                                                0.96273   \n",
       "cpu_energy_total                                                            0.004657   \n",
       "gpu_energy_total                                                            0.021821   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                      15  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_0   \n",
       "experiment_id                                                        124   \n",
       "date_time                                  April 11, 2025 at 01:49:39 PM   \n",
       "model                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                          4   \n",
       "batch_size___fixed_batching                                           16   \n",
       "decoder_temperature                                                  0.0   \n",
       "decoder_top_k                                                          0   \n",
       "decoder_top_p                                                        0.0   \n",
       "latency_simulation_delay_min                                         0.0   \n",
       "latency_simulation_simulate_burst                                  False   \n",
       "latency_simulation_burst_size                                          0   \n",
       "latency_simulation_burst_interval                                    0.0   \n",
       "fp_precision                                               torch.float32   \n",
       "quantization                                                       False   \n",
       "load_in_8bit                                                       False   \n",
       "load_in_4bit                                                       False   \n",
       "total_input_tokens                                                 16384   \n",
       "total_params                                                  1100048384   \n",
       "max_input_tokens                                                     128   \n",
       "max_output_tokens                                                    128   \n",
       "number_input_prompts                                                 128   \n",
       "total_energy_kwh                                                0.026726   \n",
       "total_energy_joules                                         96214.326055   \n",
       "flops                                                     16949970993152   \n",
       "tokens_per_joule                                                0.170286   \n",
       "joules_per_token                                                5.872456   \n",
       "flops_per_joule                                         176168889.687912   \n",
       "joules_per_flop                                                      0.0   \n",
       "total_inference_time_sec                                       23.034822   \n",
       "average_latency_ms_per_batch                                 2879.352748   \n",
       "throughput_queries_per_sec                                      5.556804   \n",
       "throughput_tokens_per_sec                                     711.270962   \n",
       "total_energy_kwh_process_0                                      0.005901   \n",
       "total_energy_kwh_process_1                                        0.0075   \n",
       "total_energy_kwh_process_2                                      0.006936   \n",
       "total_energy_kwh_process_3                                      0.006388   \n",
       "gpu_power_avg                                                  248.97514   \n",
       "ram_power_avg                                                   0.643025   \n",
       "cpu_energy_total                                                0.003673   \n",
       "gpu_energy_total                                                0.023035   \n",
       "total_generated_tokens                                             16384   \n",
       "decoder_config_decoding_mode                                      greedy   \n",
       "latency_simulation_delay_max                                         0.0   \n",
       "latency_simulation_simulate                                        False   \n",
       "\n",
       "                                                                        16  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_0.2   \n",
       "experiment_id                                                          125   \n",
       "date_time                                    April 11, 2025 at 01:50:49 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    0.2   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float32   \n",
       "quantization                                                         False   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                         False   \n",
       "total_input_tokens                                                   16384   \n",
       "total_params                                                    1100048384   \n",
       "max_input_tokens                                                       128   \n",
       "max_output_tokens                                                      128   \n",
       "number_input_prompts                                                   128   \n",
       "total_energy_kwh                                                  0.027081   \n",
       "total_energy_joules                                           97493.121231   \n",
       "flops                                                       16949970993152   \n",
       "tokens_per_joule                                                  0.168053   \n",
       "joules_per_token                                                  5.950508   \n",
       "flops_per_joule                                           173858122.288034   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                         23.574361   \n",
       "average_latency_ms_per_batch                                   2946.795177   \n",
       "throughput_queries_per_sec                                        5.429627   \n",
       "throughput_tokens_per_sec                                       694.992314   \n",
       "total_energy_kwh_process_0                                        0.005942   \n",
       "total_energy_kwh_process_1                                        0.007626   \n",
       "total_energy_kwh_process_2                                        0.007001   \n",
       "total_energy_kwh_process_3                                        0.006512   \n",
       "gpu_power_avg                                                   570.969436   \n",
       "ram_power_avg                                                     0.664062   \n",
       "cpu_energy_total                                                  0.003304   \n",
       "gpu_energy_total                                                  0.023758   \n",
       "total_generated_tokens                                               16384   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "latency_simulation_simulate                                          False   \n",
       "\n",
       "                                                                        17  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_0.4   \n",
       "experiment_id                                                          126   \n",
       "date_time                                    April 11, 2025 at 01:52:03 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    0.4   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float32   \n",
       "quantization                                                         False   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                         False   \n",
       "total_input_tokens                                                   16384   \n",
       "total_params                                                    1100048384   \n",
       "max_input_tokens                                                       128   \n",
       "max_output_tokens                                                      128   \n",
       "number_input_prompts                                                   128   \n",
       "total_energy_kwh                                                   0.02731   \n",
       "total_energy_joules                                           98315.389425   \n",
       "flops                                                       16949970993152   \n",
       "tokens_per_joule                                                  0.166647   \n",
       "joules_per_token                                                  6.000695   \n",
       "flops_per_joule                                           172404046.735283   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                         23.302189   \n",
       "average_latency_ms_per_batch                                   2912.773661   \n",
       "throughput_queries_per_sec                                        5.493046   \n",
       "throughput_tokens_per_sec                                       703.109901   \n",
       "total_energy_kwh_process_0                                        0.005805   \n",
       "total_energy_kwh_process_1                                        0.007895   \n",
       "total_energy_kwh_process_2                                        0.007059   \n",
       "total_energy_kwh_process_3                                        0.006551   \n",
       "gpu_power_avg                                                   359.762385   \n",
       "ram_power_avg                                                     0.661822   \n",
       "cpu_energy_total                                                  0.003637   \n",
       "gpu_energy_total                                                  0.023654   \n",
       "total_generated_tokens                                               16384   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "latency_simulation_simulate                                          False   \n",
       "\n",
       "                                                                        18  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_0.6   \n",
       "experiment_id                                                          127   \n",
       "date_time                                    April 11, 2025 at 01:53:15 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    0.6   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float32   \n",
       "quantization                                                         False   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                         False   \n",
       "total_input_tokens                                                   16384   \n",
       "total_params                                                    1100048384   \n",
       "max_input_tokens                                                       128   \n",
       "max_output_tokens                                                      128   \n",
       "number_input_prompts                                                   128   \n",
       "total_energy_kwh                                                  0.027891   \n",
       "total_energy_joules                                          100406.566327   \n",
       "flops                                                       16949970993152   \n",
       "tokens_per_joule                                                  0.163177   \n",
       "joules_per_token                                                   6.12833   \n",
       "flops_per_joule                                           168813371.607248   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                         24.047179   \n",
       "average_latency_ms_per_batch                                   3005.897323   \n",
       "throughput_queries_per_sec                                         5.32287   \n",
       "throughput_tokens_per_sec                                       681.327331   \n",
       "total_energy_kwh_process_0                                         0.00594   \n",
       "total_energy_kwh_process_1                                        0.007748   \n",
       "total_energy_kwh_process_2                                        0.007105   \n",
       "total_energy_kwh_process_3                                        0.007097   \n",
       "gpu_power_avg                                                   165.805681   \n",
       "ram_power_avg                                                     0.667078   \n",
       "cpu_energy_total                                                  0.003388   \n",
       "gpu_energy_total                                                  0.024483   \n",
       "total_generated_tokens                                               16384   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "latency_simulation_simulate                                          False   \n",
       "\n",
       "                                                                        19  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_0.8   \n",
       "experiment_id                                                          128   \n",
       "date_time                                    April 11, 2025 at 01:54:27 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    0.8   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float32   \n",
       "quantization                                                         False   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                         False   \n",
       "total_input_tokens                                                   16384   \n",
       "total_params                                                    1100048384   \n",
       "max_input_tokens                                                       128   \n",
       "max_output_tokens                                                      128   \n",
       "number_input_prompts                                                   128   \n",
       "total_energy_kwh                                                  0.027698   \n",
       "total_energy_joules                                           99714.129356   \n",
       "flops                                                       16949970993152   \n",
       "tokens_per_joule                                                   0.16431   \n",
       "joules_per_token                                                  6.086067   \n",
       "flops_per_joule                                            169985649.00098   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                           24.1225   \n",
       "average_latency_ms_per_batch                                   3015.312471   \n",
       "throughput_queries_per_sec                                        5.306249   \n",
       "throughput_tokens_per_sec                                       679.199924   \n",
       "total_energy_kwh_process_0                                        0.006189   \n",
       "total_energy_kwh_process_1                                          0.0078   \n",
       "total_energy_kwh_process_2                                        0.007057   \n",
       "total_energy_kwh_process_3                                        0.006653   \n",
       "gpu_power_avg                                                    381.99481   \n",
       "ram_power_avg                                                     0.663048   \n",
       "cpu_energy_total                                                  0.003528   \n",
       "gpu_energy_total                                                  0.024152   \n",
       "total_generated_tokens                                               16384   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "latency_simulation_simulate                                          False   \n",
       "\n",
       "                                                                        20  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_1.0   \n",
       "experiment_id                                                          129   \n",
       "date_time                                    April 11, 2025 at 02:07:40 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    1.0   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float32   \n",
       "quantization                                                         False   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                         False   \n",
       "total_input_tokens                                                   16384   \n",
       "total_params                                                    1100048384   \n",
       "max_input_tokens                                                       128   \n",
       "max_output_tokens                                                      128   \n",
       "number_input_prompts                                                   128   \n",
       "total_energy_kwh                                                  0.427662   \n",
       "total_energy_joules                                         1539584.096019   \n",
       "flops                                                       16949970993152   \n",
       "tokens_per_joule                                                  0.010642   \n",
       "joules_per_token                                                 93.968756   \n",
       "flops_per_joule                                            11009447.965185   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                         23.358511   \n",
       "average_latency_ms_per_batch                                    2919.81393   \n",
       "throughput_queries_per_sec                                        5.479801   \n",
       "throughput_tokens_per_sec                                       701.414559   \n",
       "total_energy_kwh_process_0                                        0.105652   \n",
       "total_energy_kwh_process_1                                        0.107793   \n",
       "total_energy_kwh_process_2                                        0.107536   \n",
       "total_energy_kwh_process_3                                        0.106682   \n",
       "gpu_power_avg                                                   574.005568   \n",
       "ram_power_avg                                                     0.661945   \n",
       "cpu_energy_total                                                   0.07694   \n",
       "gpu_energy_total                                                  0.350275   \n",
       "total_generated_tokens                                               16384   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "latency_simulation_simulate                                          False   \n",
       "\n",
       "                                                                        21  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_1.2   \n",
       "experiment_id                                                          130   \n",
       "date_time                                    April 11, 2025 at 02:08:53 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    1.2   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float32   \n",
       "quantization                                                         False   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                         False   \n",
       "total_input_tokens                                                   16384   \n",
       "total_params                                                    1100048384   \n",
       "max_input_tokens                                                       128   \n",
       "max_output_tokens                                                      128   \n",
       "number_input_prompts                                                   128   \n",
       "total_energy_kwh                                                  0.027378   \n",
       "total_energy_joules                                           98560.641388   \n",
       "flops                                                       16949970993152   \n",
       "tokens_per_joule                                                  0.166233   \n",
       "joules_per_token                                                  6.015664   \n",
       "flops_per_joule                                           171975047.589829   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                          23.30423   \n",
       "average_latency_ms_per_batch                                   2913.028805   \n",
       "throughput_queries_per_sec                                        5.492565   \n",
       "throughput_tokens_per_sec                                       703.048317   \n",
       "total_energy_kwh_process_0                                         0.00582   \n",
       "total_energy_kwh_process_1                                        0.007895   \n",
       "total_energy_kwh_process_2                                        0.007065   \n",
       "total_energy_kwh_process_3                                        0.006599   \n",
       "gpu_power_avg                                                   836.666102   \n",
       "ram_power_avg                                                     0.666487   \n",
       "cpu_energy_total                                                  0.003559   \n",
       "gpu_energy_total                                                  0.023799   \n",
       "total_generated_tokens                                               16384   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "latency_simulation_simulate                                          False   \n",
       "\n",
       "                                                                                  22  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    132   \n",
       "date_time                                              April 11, 2025 at 02:10:30 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.023482   \n",
       "total_energy_joules                                                     84535.873444   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.193811   \n",
       "joules_per_token                                                             5.15966   \n",
       "flops_per_joule                                                      200506250.21828   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                     23.1588   \n",
       "average_latency_ms_per_batch                                             2894.850059   \n",
       "throughput_queries_per_sec                                                  5.527057   \n",
       "throughput_tokens_per_sec                                                 707.463239   \n",
       "total_energy_kwh_process_0                                                   0.00555   \n",
       "total_energy_kwh_process_1                                                  0.005592   \n",
       "total_energy_kwh_process_2                                                  0.006228   \n",
       "total_energy_kwh_process_3                                                  0.006112   \n",
       "gpu_power_avg                                                             697.486571   \n",
       "ram_power_avg                                                               0.642038   \n",
       "cpu_energy_total                                                            0.002986   \n",
       "gpu_energy_total                                                             0.02048   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  23  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    133   \n",
       "date_time                                              April 11, 2025 at 02:11:31 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021907   \n",
       "total_energy_joules                                                     78864.369793   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.207749   \n",
       "joules_per_token                                                            4.813499   \n",
       "flops_per_joule                                                     214925587.277855   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.033007   \n",
       "average_latency_ms_per_batch                                             2879.125936   \n",
       "throughput_queries_per_sec                                                  5.557242   \n",
       "throughput_tokens_per_sec                                                 711.326995   \n",
       "total_energy_kwh_process_0                                                  0.005324   \n",
       "total_energy_kwh_process_1                                                  0.005352   \n",
       "total_energy_kwh_process_2                                                  0.005422   \n",
       "total_energy_kwh_process_3                                                  0.005809   \n",
       "gpu_power_avg                                                             995.399846   \n",
       "ram_power_avg                                                               0.635867   \n",
       "cpu_energy_total                                                            0.002809   \n",
       "gpu_energy_total                                                            0.019082   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  24  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    134   \n",
       "date_time                                              April 11, 2025 at 02:12:30 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021951   \n",
       "total_energy_joules                                                     79024.314526   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.207329   \n",
       "joules_per_token                                                            4.823261   \n",
       "flops_per_joule                                                     214490579.195115   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                     22.6648   \n",
       "average_latency_ms_per_batch                                              2833.09999   \n",
       "throughput_queries_per_sec                                                  5.647524   \n",
       "throughput_tokens_per_sec                                                 722.883064   \n",
       "total_energy_kwh_process_0                                                  0.005392   \n",
       "total_energy_kwh_process_1                                                   0.00539   \n",
       "total_energy_kwh_process_2                                                  0.005394   \n",
       "total_energy_kwh_process_3                                                  0.005776   \n",
       "gpu_power_avg                                                             141.500592   \n",
       "ram_power_avg                                                               0.641261   \n",
       "cpu_energy_total                                                            0.002925   \n",
       "gpu_energy_total                                                             0.01901   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  25  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    135   \n",
       "date_time                                              April 11, 2025 at 02:13:34 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021558   \n",
       "total_energy_joules                                                     77607.069182   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.211115   \n",
       "joules_per_token                                                             4.73676   \n",
       "flops_per_joule                                                     218407564.824574   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   22.773879   \n",
       "average_latency_ms_per_batch                                             2846.734851   \n",
       "throughput_queries_per_sec                                                  5.620474   \n",
       "throughput_tokens_per_sec                                                 719.420707   \n",
       "total_energy_kwh_process_0                                                  0.005215   \n",
       "total_energy_kwh_process_1                                                  0.005297   \n",
       "total_energy_kwh_process_2                                                  0.005234   \n",
       "total_energy_kwh_process_3                                                  0.005811   \n",
       "gpu_power_avg                                                             595.223181   \n",
       "ram_power_avg                                                               0.640277   \n",
       "cpu_energy_total                                                            0.002671   \n",
       "gpu_energy_total                                                            0.018871   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  26  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    136   \n",
       "date_time                                              April 11, 2025 at 02:14:36 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022163   \n",
       "total_energy_joules                                                     79785.192564   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.205351   \n",
       "joules_per_token                                                            4.869702   \n",
       "flops_per_joule                                                     212445072.179372   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   22.606347   \n",
       "average_latency_ms_per_batch                                             2825.793395   \n",
       "throughput_queries_per_sec                                                  5.662127   \n",
       "throughput_tokens_per_sec                                                 724.752207   \n",
       "total_energy_kwh_process_0                                                   0.00542   \n",
       "total_energy_kwh_process_1                                                   0.00543   \n",
       "total_energy_kwh_process_2                                                  0.005505   \n",
       "total_energy_kwh_process_3                                                  0.005808   \n",
       "gpu_power_avg                                                             240.015809   \n",
       "ram_power_avg                                                               0.645682   \n",
       "cpu_energy_total                                                            0.003124   \n",
       "gpu_energy_total                                                            0.019023   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  27  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    137   \n",
       "date_time                                              April 11, 2025 at 02:15:38 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022313   \n",
       "total_energy_joules                                                      80326.29213   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.203968   \n",
       "joules_per_token                                                            4.902728   \n",
       "flops_per_joule                                                     211013984.881239   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    23.66417   \n",
       "average_latency_ms_per_batch                                             2958.021251   \n",
       "throughput_queries_per_sec                                                  5.409021   \n",
       "throughput_tokens_per_sec                                                 692.354728   \n",
       "total_energy_kwh_process_0                                                  0.005484   \n",
       "total_energy_kwh_process_1                                                  0.005499   \n",
       "total_energy_kwh_process_2                                                  0.005422   \n",
       "total_energy_kwh_process_3                                                  0.005908   \n",
       "gpu_power_avg                                                             930.285971   \n",
       "ram_power_avg                                                               0.677652   \n",
       "cpu_energy_total                                                            0.002825   \n",
       "gpu_energy_total                                                            0.019471   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  28  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    138   \n",
       "date_time                                              April 11, 2025 at 02:16:46 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022607   \n",
       "total_energy_joules                                                      81385.43303   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.201314   \n",
       "joules_per_token                                                            4.967373   \n",
       "flops_per_joule                                                     208267872.541956   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.907777   \n",
       "average_latency_ms_per_batch                                             2988.472176   \n",
       "throughput_queries_per_sec                                                  5.353906   \n",
       "throughput_tokens_per_sec                                                 685.300006   \n",
       "total_energy_kwh_process_0                                                  0.005543   \n",
       "total_energy_kwh_process_1                                                  0.005521   \n",
       "total_energy_kwh_process_2                                                  0.005605   \n",
       "total_energy_kwh_process_3                                                  0.005938   \n",
       "gpu_power_avg                                                             818.073557   \n",
       "ram_power_avg                                                               0.676869   \n",
       "cpu_energy_total                                                            0.003062   \n",
       "gpu_energy_total                                                            0.019529   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  29  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    139   \n",
       "date_time                                              April 11, 2025 at 02:17:47 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022371   \n",
       "total_energy_joules                                                     80534.828637   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                             0.20344   \n",
       "joules_per_token                                                            4.915456   \n",
       "flops_per_joule                                                     210467586.260611   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.561953   \n",
       "average_latency_ms_per_batch                                             2945.244112   \n",
       "throughput_queries_per_sec                                                  5.432487   \n",
       "throughput_tokens_per_sec                                                 695.358321   \n",
       "total_energy_kwh_process_0                                                  0.005438   \n",
       "total_energy_kwh_process_1                                                  0.005451   \n",
       "total_energy_kwh_process_2                                                  0.005495   \n",
       "total_energy_kwh_process_3                                                  0.005987   \n",
       "gpu_power_avg                                                             680.710089   \n",
       "ram_power_avg                                                               0.677398   \n",
       "cpu_energy_total                                                            0.002935   \n",
       "gpu_energy_total                                                            0.019418   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  30  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    140   \n",
       "date_time                                              April 11, 2025 at 02:18:50 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022527   \n",
       "total_energy_joules                                                     81096.772114   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                             0.20203   \n",
       "joules_per_token                                                            4.949754   \n",
       "flops_per_joule                                                     209009194.217265   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.840143   \n",
       "average_latency_ms_per_batch                                             2980.017825   \n",
       "throughput_queries_per_sec                                                  5.369095   \n",
       "throughput_tokens_per_sec                                                 687.244211   \n",
       "total_energy_kwh_process_0                                                  0.005475   \n",
       "total_energy_kwh_process_1                                                  0.005537   \n",
       "total_energy_kwh_process_2                                                  0.005476   \n",
       "total_energy_kwh_process_3                                                  0.006038   \n",
       "gpu_power_avg                                                             630.786332   \n",
       "ram_power_avg                                                                0.67482   \n",
       "cpu_energy_total                                                            0.003087   \n",
       "gpu_energy_total                                                            0.019424   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  31  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    141   \n",
       "date_time                                              April 11, 2025 at 02:19:51 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022292   \n",
       "total_energy_joules                                                     80252.705575   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.204155   \n",
       "joules_per_token                                                            4.898236   \n",
       "flops_per_joule                                                     211207471.096386   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.885973   \n",
       "average_latency_ms_per_batch                                             2985.746645   \n",
       "throughput_queries_per_sec                                                  5.358794   \n",
       "throughput_tokens_per_sec                                                  685.92558   \n",
       "total_energy_kwh_process_0                                                  0.005461   \n",
       "total_energy_kwh_process_1                                                  0.005521   \n",
       "total_energy_kwh_process_2                                                  0.005438   \n",
       "total_energy_kwh_process_3                                                  0.005872   \n",
       "gpu_power_avg                                                             584.672502   \n",
       "ram_power_avg                                                               0.673987   \n",
       "cpu_energy_total                                                            0.002869   \n",
       "gpu_energy_total                                                            0.019407   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  32  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    142   \n",
       "date_time                                              April 11, 2025 at 02:20:54 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022349   \n",
       "total_energy_joules                                                     80457.547565   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.203635   \n",
       "joules_per_token                                                            4.910739   \n",
       "flops_per_joule                                                      210669744.55767   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.299355   \n",
       "average_latency_ms_per_batch                                             2912.419385   \n",
       "throughput_queries_per_sec                                                  5.493714   \n",
       "throughput_tokens_per_sec                                                 703.195429   \n",
       "total_energy_kwh_process_0                                                   0.00535   \n",
       "total_energy_kwh_process_1                                                  0.005554   \n",
       "total_energy_kwh_process_2                                                  0.005542   \n",
       "total_energy_kwh_process_3                                                  0.005903   \n",
       "gpu_power_avg                                                              474.50611   \n",
       "ram_power_avg                                                               0.677596   \n",
       "cpu_energy_total                                                            0.002992   \n",
       "gpu_energy_total                                                             0.01934   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  33  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    143   \n",
       "date_time                                              April 11, 2025 at 02:21:57 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                             0.02246   \n",
       "total_energy_joules                                                       80855.2652   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.202634   \n",
       "joules_per_token                                                            4.935014   \n",
       "flops_per_joule                                                     209633484.611915   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.477822   \n",
       "average_latency_ms_per_batch                                             2934.727713   \n",
       "throughput_queries_per_sec                                                  5.451954   \n",
       "throughput_tokens_per_sec                                                  697.85009   \n",
       "total_energy_kwh_process_0                                                  0.005454   \n",
       "total_energy_kwh_process_1                                                  0.005538   \n",
       "total_energy_kwh_process_2                                                   0.00558   \n",
       "total_energy_kwh_process_3                                                  0.005887   \n",
       "gpu_power_avg                                                              666.91485   \n",
       "ram_power_avg                                                               0.677137   \n",
       "cpu_energy_total                                                            0.003103   \n",
       "gpu_energy_total                                                             0.01934   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  34  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    144   \n",
       "date_time                                              April 11, 2025 at 02:22:59 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022236   \n",
       "total_energy_joules                                                      80049.35023   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.204674   \n",
       "joules_per_token                                                            4.885825   \n",
       "flops_per_joule                                                     211744017.213695   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.895986   \n",
       "average_latency_ms_per_batch                                             2986.998288   \n",
       "throughput_queries_per_sec                                                  5.356548   \n",
       "throughput_tokens_per_sec                                                 685.638157   \n",
       "total_energy_kwh_process_0                                                  0.005495   \n",
       "total_energy_kwh_process_1                                                   0.00541   \n",
       "total_energy_kwh_process_2                                                  0.005442   \n",
       "total_energy_kwh_process_3                                                  0.005889   \n",
       "gpu_power_avg                                                            1044.133286   \n",
       "ram_power_avg                                                               0.677181   \n",
       "cpu_energy_total                                                            0.002743   \n",
       "gpu_energy_total                                                            0.019476   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  35  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    145   \n",
       "date_time                                              April 11, 2025 at 02:24:04 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022204   \n",
       "total_energy_joules                                                     79935.142249   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.204966   \n",
       "joules_per_token                                                            4.878854   \n",
       "flops_per_joule                                                     212046548.191128   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    23.82698   \n",
       "average_latency_ms_per_batch                                             2978.372542   \n",
       "throughput_queries_per_sec                                                  5.372061   \n",
       "throughput_tokens_per_sec                                                 687.623852   \n",
       "total_energy_kwh_process_0                                                  0.005429   \n",
       "total_energy_kwh_process_1                                                  0.005483   \n",
       "total_energy_kwh_process_2                                                   0.00543   \n",
       "total_energy_kwh_process_3                                                  0.005861   \n",
       "gpu_power_avg                                                             613.075184   \n",
       "ram_power_avg                                                                0.67413   \n",
       "cpu_energy_total                                                            0.002715   \n",
       "gpu_energy_total                                                            0.019473   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  36  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    146   \n",
       "date_time                                              April 11, 2025 at 02:25:08 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022546   \n",
       "total_energy_joules                                                     81165.046053   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                             0.20186   \n",
       "joules_per_token                                                            4.953921   \n",
       "flops_per_joule                                                     208833381.085398   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   24.004103   \n",
       "average_latency_ms_per_batch                                             3000.512829   \n",
       "throughput_queries_per_sec                                                  5.332422   \n",
       "throughput_tokens_per_sec                                                  682.54999   \n",
       "total_energy_kwh_process_0                                                  0.005574   \n",
       "total_energy_kwh_process_1                                                  0.005493   \n",
       "total_energy_kwh_process_2                                                  0.005586   \n",
       "total_energy_kwh_process_3                                                  0.005893   \n",
       "gpu_power_avg                                                             125.703947   \n",
       "ram_power_avg                                                               0.676264   \n",
       "cpu_energy_total                                                             0.00312   \n",
       "gpu_energy_total                                                            0.019409   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  37  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    147   \n",
       "date_time                                              April 11, 2025 at 02:26:16 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                             0.02255   \n",
       "total_energy_joules                                                     81180.686997   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.201821   \n",
       "joules_per_token                                                            4.954876   \n",
       "flops_per_joule                                                     208793145.515737   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   24.247811   \n",
       "average_latency_ms_per_batch                                             3030.976345   \n",
       "throughput_queries_per_sec                                                  5.278827   \n",
       "throughput_tokens_per_sec                                                 675.689866   \n",
       "total_energy_kwh_process_0                                                  0.005518   \n",
       "total_energy_kwh_process_1                                                  0.005501   \n",
       "total_energy_kwh_process_2                                                  0.005588   \n",
       "total_energy_kwh_process_3                                                  0.005943   \n",
       "gpu_power_avg                                                             554.297154   \n",
       "ram_power_avg                                                                0.67676   \n",
       "cpu_energy_total                                                            0.003128   \n",
       "gpu_energy_total                                                            0.019406   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  38  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    148   \n",
       "date_time                                              April 11, 2025 at 02:27:18 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022035   \n",
       "total_energy_joules                                                      79326.35121   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.206539   \n",
       "joules_per_token                                                            4.841696   \n",
       "flops_per_joule                                                     213673901.983323   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    23.55748   \n",
       "average_latency_ms_per_batch                                             2944.685004   \n",
       "throughput_queries_per_sec                                                  5.433518   \n",
       "throughput_tokens_per_sec                                                 695.490349   \n",
       "total_energy_kwh_process_0                                                  0.005397   \n",
       "total_energy_kwh_process_1                                                  0.005394   \n",
       "total_energy_kwh_process_2                                                  0.005382   \n",
       "total_energy_kwh_process_3                                                  0.005862   \n",
       "gpu_power_avg                                                             746.865359   \n",
       "ram_power_avg                                                               0.675836   \n",
       "cpu_energy_total                                                            0.002817   \n",
       "gpu_energy_total                                                            0.019202   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  39  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    149   \n",
       "date_time                                              April 11, 2025 at 02:28:19 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022381   \n",
       "total_energy_joules                                                     80571.964142   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.203346   \n",
       "joules_per_token                                                            4.917722   \n",
       "flops_per_joule                                                     210370582.046835   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   24.153399   \n",
       "average_latency_ms_per_batch                                             3019.174914   \n",
       "throughput_queries_per_sec                                                  5.299461   \n",
       "throughput_tokens_per_sec                                                  678.33102   \n",
       "total_energy_kwh_process_0                                                  0.005575   \n",
       "total_energy_kwh_process_1                                                    0.0055   \n",
       "total_energy_kwh_process_2                                                  0.005498   \n",
       "total_energy_kwh_process_3                                                  0.005807   \n",
       "gpu_power_avg                                                             178.077688   \n",
       "ram_power_avg                                                               0.675833   \n",
       "cpu_energy_total                                                               0.003   \n",
       "gpu_energy_total                                                            0.019364   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  40  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    150   \n",
       "date_time                                              April 11, 2025 at 02:29:23 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022374   \n",
       "total_energy_joules                                                     80546.838823   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                             0.20341   \n",
       "joules_per_token                                                            4.916189   \n",
       "flops_per_joule                                                     210436203.840162   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    24.07616   \n",
       "average_latency_ms_per_batch                                             3009.520001   \n",
       "throughput_queries_per_sec                                                  5.316462   \n",
       "throughput_tokens_per_sec                                                  680.50719   \n",
       "total_energy_kwh_process_0                                                  0.005571   \n",
       "total_energy_kwh_process_1                                                  0.005498   \n",
       "total_energy_kwh_process_2                                                  0.005327   \n",
       "total_energy_kwh_process_3                                                  0.005978   \n",
       "gpu_power_avg                                                              530.26023   \n",
       "ram_power_avg                                                               0.678728   \n",
       "cpu_energy_total                                                            0.002939   \n",
       "gpu_energy_total                                                            0.019419   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  41  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    151   \n",
       "date_time                                              April 11, 2025 at 02:30:26 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022143   \n",
       "total_energy_joules                                                     79714.965563   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.205532   \n",
       "joules_per_token                                                            4.865415   \n",
       "flops_per_joule                                                     212632231.269686   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.535471   \n",
       "average_latency_ms_per_batch                                             2941.933847   \n",
       "throughput_queries_per_sec                                                    5.4386   \n",
       "throughput_tokens_per_sec                                                 696.140738   \n",
       "total_energy_kwh_process_0                                                  0.005407   \n",
       "total_energy_kwh_process_1                                                  0.005409   \n",
       "total_energy_kwh_process_2                                                  0.005488   \n",
       "total_energy_kwh_process_3                                                  0.005838   \n",
       "gpu_power_avg                                                             828.379786   \n",
       "ram_power_avg                                                                0.67486   \n",
       "cpu_energy_total                                                            0.002796   \n",
       "gpu_energy_total                                                            0.019331   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  42  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    152   \n",
       "date_time                                              April 11, 2025 at 02:31:29 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022079   \n",
       "total_energy_joules                                                     79485.169526   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.206127   \n",
       "joules_per_token                                                             4.85139   \n",
       "flops_per_joule                                                     213246962.851946   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.584799   \n",
       "average_latency_ms_per_batch                                             2948.099845   \n",
       "throughput_queries_per_sec                                                  5.427225   \n",
       "throughput_tokens_per_sec                                                 694.684749   \n",
       "total_energy_kwh_process_0                                                  0.005391   \n",
       "total_energy_kwh_process_1                                                  0.005413   \n",
       "total_energy_kwh_process_2                                                  0.005444   \n",
       "total_energy_kwh_process_3                                                  0.005831   \n",
       "gpu_power_avg                                                            1128.825755   \n",
       "ram_power_avg                                                                0.68033   \n",
       "cpu_energy_total                                                            0.002713   \n",
       "gpu_energy_total                                                             0.01935   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  43  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    153   \n",
       "date_time                                              April 11, 2025 at 02:32:31 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022215   \n",
       "total_energy_joules                                                     79973.120837   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.204869   \n",
       "joules_per_token                                                            4.881172   \n",
       "flops_per_joule                                                     211945849.002445   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   24.044567   \n",
       "average_latency_ms_per_batch                                             3005.570872   \n",
       "throughput_queries_per_sec                                                  5.323448   \n",
       "throughput_tokens_per_sec                                                 681.401333   \n",
       "total_energy_kwh_process_0                                                  0.005528   \n",
       "total_energy_kwh_process_1                                                  0.005443   \n",
       "total_energy_kwh_process_2                                                   0.00545   \n",
       "total_energy_kwh_process_3                                                  0.005795   \n",
       "gpu_power_avg                                                             183.379652   \n",
       "ram_power_avg                                                               0.673824   \n",
       "cpu_energy_total                                                            0.002863   \n",
       "gpu_energy_total                                                            0.019335   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  44  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    154   \n",
       "date_time                                              April 11, 2025 at 02:33:34 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022313   \n",
       "total_energy_joules                                                     80327.286164   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.203966   \n",
       "joules_per_token                                                            4.902788   \n",
       "flops_per_joule                                                      211011373.62713   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.701611   \n",
       "average_latency_ms_per_batch                                             2962.701374   \n",
       "throughput_queries_per_sec                                                  5.400477   \n",
       "throughput_tokens_per_sec                                                 691.261029   \n",
       "total_energy_kwh_process_0                                                  0.005377   \n",
       "total_energy_kwh_process_1                                                  0.005564   \n",
       "total_energy_kwh_process_2                                                  0.005492   \n",
       "total_energy_kwh_process_3                                                   0.00588   \n",
       "gpu_power_avg                                                             585.733726   \n",
       "ram_power_avg                                                               0.676639   \n",
       "cpu_energy_total                                                            0.002894   \n",
       "gpu_energy_total                                                            0.019402   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  45  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    155   \n",
       "date_time                                              April 11, 2025 at 02:34:37 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022003   \n",
       "total_energy_joules                                                     79212.479066   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.206836   \n",
       "joules_per_token                                                            4.834746   \n",
       "flops_per_joule                                                     213981069.562596   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.352319   \n",
       "average_latency_ms_per_batch                                             2919.039935   \n",
       "throughput_queries_per_sec                                                  5.481254   \n",
       "throughput_tokens_per_sec                                                 701.600542   \n",
       "total_energy_kwh_process_0                                                  0.005338   \n",
       "total_energy_kwh_process_1                                                  0.005405   \n",
       "total_energy_kwh_process_2                                                  0.005369   \n",
       "total_energy_kwh_process_3                                                  0.005892   \n",
       "gpu_power_avg                                                             597.075869   \n",
       "ram_power_avg                                                               0.676245   \n",
       "cpu_energy_total                                                            0.002834   \n",
       "gpu_energy_total                                                            0.019153   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  46  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    156   \n",
       "date_time                                              April 11, 2025 at 02:35:41 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021963   \n",
       "total_energy_joules                                                     79067.881421   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.207214   \n",
       "joules_per_token                                                             4.82592   \n",
       "flops_per_joule                                                     214372393.548913   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.586959   \n",
       "average_latency_ms_per_batch                                              2948.36993   \n",
       "throughput_queries_per_sec                                                  5.426727   \n",
       "throughput_tokens_per_sec                                                 694.621112   \n",
       "total_energy_kwh_process_0                                                  0.005397   \n",
       "total_energy_kwh_process_1                                                  0.005448   \n",
       "total_energy_kwh_process_2                                                  0.005403   \n",
       "total_energy_kwh_process_3                                                  0.005716   \n",
       "gpu_power_avg                                                            1426.644534   \n",
       "ram_power_avg                                                               0.677293   \n",
       "cpu_energy_total                                                            0.002622   \n",
       "gpu_energy_total                                                            0.019325   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  47  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    157   \n",
       "date_time                                              April 11, 2025 at 02:36:45 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022372   \n",
       "total_energy_joules                                                     80539.640657   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.203428   \n",
       "joules_per_token                                                             4.91575   \n",
       "flops_per_joule                                                     210455011.407237   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.279665   \n",
       "average_latency_ms_per_batch                                             2909.958078   \n",
       "throughput_queries_per_sec                                                  5.498361   \n",
       "throughput_tokens_per_sec                                                 703.790208   \n",
       "total_energy_kwh_process_0                                                  0.005412   \n",
       "total_energy_kwh_process_1                                                   0.00549   \n",
       "total_energy_kwh_process_2                                                  0.005495   \n",
       "total_energy_kwh_process_3                                                  0.005976   \n",
       "gpu_power_avg                                                             609.430123   \n",
       "ram_power_avg                                                               0.676872   \n",
       "cpu_energy_total                                                             0.00314   \n",
       "gpu_energy_total                                                            0.019215   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  48  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    158   \n",
       "date_time                                              April 11, 2025 at 02:37:48 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021898   \n",
       "total_energy_joules                                                     78832.359919   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.207833   \n",
       "joules_per_token                                                            4.811545   \n",
       "flops_per_joule                                                     215012857.796897   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.328102   \n",
       "average_latency_ms_per_batch                                             2916.012712   \n",
       "throughput_queries_per_sec                                                  5.486945   \n",
       "throughput_tokens_per_sec                                                   702.3289   \n",
       "total_energy_kwh_process_0                                                  0.005372   \n",
       "total_energy_kwh_process_1                                                   0.00537   \n",
       "total_energy_kwh_process_2                                                  0.005331   \n",
       "total_energy_kwh_process_3                                                  0.005825   \n",
       "gpu_power_avg                                                            1230.096169   \n",
       "ram_power_avg                                                               0.676701   \n",
       "cpu_energy_total                                                            0.002822   \n",
       "gpu_energy_total                                                             0.01906   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  49  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    159   \n",
       "date_time                                              April 11, 2025 at 02:38:49 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022286   \n",
       "total_energy_joules                                                     80229.360539   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.204215   \n",
       "joules_per_token                                                            4.896812   \n",
       "flops_per_joule                                                     211268927.975691   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.584234   \n",
       "average_latency_ms_per_batch                                             2948.029216   \n",
       "throughput_queries_per_sec                                                  5.427355   \n",
       "throughput_tokens_per_sec                                                 694.701392   \n",
       "total_energy_kwh_process_0                                                  0.005457   \n",
       "total_energy_kwh_process_1                                                   0.00552   \n",
       "total_energy_kwh_process_2                                                   0.00548   \n",
       "total_energy_kwh_process_3                                                  0.005828   \n",
       "gpu_power_avg                                                             752.683404   \n",
       "ram_power_avg                                                               0.675662   \n",
       "cpu_energy_total                                                              0.0029   \n",
       "gpu_energy_total                                                             0.01937   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  50  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    160   \n",
       "date_time                                              April 11, 2025 at 02:39:50 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022056   \n",
       "total_energy_joules                                                     79403.040972   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                             0.20634   \n",
       "joules_per_token                                                            4.846377   \n",
       "flops_per_joule                                                     213467529.525458   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.233562   \n",
       "average_latency_ms_per_batch                                             2904.195222   \n",
       "throughput_queries_per_sec                                                  5.509272   \n",
       "throughput_tokens_per_sec                                                 705.186753   \n",
       "total_energy_kwh_process_0                                                  0.005377   \n",
       "total_energy_kwh_process_1                                                   0.00538   \n",
       "total_energy_kwh_process_2                                                   0.00558   \n",
       "total_energy_kwh_process_3                                                  0.005719   \n",
       "gpu_power_avg                                                             631.860825   \n",
       "ram_power_avg                                                               0.678458   \n",
       "cpu_energy_total                                                            0.002895   \n",
       "gpu_energy_total                                                            0.019145   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  51  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    161   \n",
       "date_time                                              April 11, 2025 at 02:40:54 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022172   \n",
       "total_energy_joules                                                     79820.968883   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.205259   \n",
       "joules_per_token                                                            4.871885   \n",
       "flops_per_joule                                                     212349852.805032   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.687913   \n",
       "average_latency_ms_per_batch                                             2960.989152   \n",
       "throughput_queries_per_sec                                                    5.4036   \n",
       "throughput_tokens_per_sec                                                 691.660758   \n",
       "total_energy_kwh_process_0                                                  0.005456   \n",
       "total_energy_kwh_process_1                                                  0.005454   \n",
       "total_energy_kwh_process_2                                                  0.005415   \n",
       "total_energy_kwh_process_3                                                  0.005847   \n",
       "gpu_power_avg                                                            1124.918904   \n",
       "ram_power_avg                                                                0.68434   \n",
       "cpu_energy_total                                                            0.002817   \n",
       "gpu_energy_total                                                            0.019339   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  52  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    162   \n",
       "date_time                                              April 11, 2025 at 02:41:56 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022241   \n",
       "total_energy_joules                                                     80066.319146   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                             0.20463   \n",
       "joules_per_token                                                             4.88686   \n",
       "flops_per_joule                                                     211699141.086514   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.430406   \n",
       "average_latency_ms_per_batch                                             2928.800693   \n",
       "throughput_queries_per_sec                                                  5.462987   \n",
       "throughput_tokens_per_sec                                                 699.262331   \n",
       "total_energy_kwh_process_0                                                  0.005484   \n",
       "total_energy_kwh_process_1                                                  0.005431   \n",
       "total_energy_kwh_process_2                                                  0.005442   \n",
       "total_energy_kwh_process_3                                                  0.005884   \n",
       "gpu_power_avg                                                             107.580307   \n",
       "ram_power_avg                                                               0.680158   \n",
       "cpu_energy_total                                                            0.002883   \n",
       "gpu_energy_total                                                            0.019341   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  53  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    163   \n",
       "date_time                                              April 11, 2025 at 02:42:58 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022124   \n",
       "total_energy_joules                                                     79646.128042   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                             0.20571   \n",
       "joules_per_token                                                            4.861214   \n",
       "flops_per_joule                                                     212816007.631856   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.540169   \n",
       "average_latency_ms_per_batch                                             2942.521106   \n",
       "throughput_queries_per_sec                                                  5.437514   \n",
       "throughput_tokens_per_sec                                                 696.001805   \n",
       "total_energy_kwh_process_0                                                  0.005385   \n",
       "total_energy_kwh_process_1                                                  0.005462   \n",
       "total_energy_kwh_process_2                                                  0.005437   \n",
       "total_energy_kwh_process_3                                                   0.00584   \n",
       "gpu_power_avg                                                             964.896948   \n",
       "ram_power_avg                                                               0.673759   \n",
       "cpu_energy_total                                                            0.002779   \n",
       "gpu_energy_total                                                            0.019328   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  54  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    164   \n",
       "date_time                                              April 11, 2025 at 02:44:00 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021905   \n",
       "total_energy_joules                                                      78857.96964   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.207766   \n",
       "joules_per_token                                                            4.813108   \n",
       "flops_per_joule                                                     214943030.749142   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.653556   \n",
       "average_latency_ms_per_batch                                             2956.694525   \n",
       "throughput_queries_per_sec                                                  5.411448   \n",
       "throughput_tokens_per_sec                                                 692.665401   \n",
       "total_energy_kwh_process_0                                                  0.005373   \n",
       "total_energy_kwh_process_1                                                   0.00538   \n",
       "total_energy_kwh_process_2                                                  0.005371   \n",
       "total_energy_kwh_process_3                                                  0.005781   \n",
       "gpu_power_avg                                                             845.433359   \n",
       "ram_power_avg                                                               0.674298   \n",
       "cpu_energy_total                                                            0.002611   \n",
       "gpu_energy_total                                                            0.019278   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  55  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    165   \n",
       "date_time                                              April 11, 2025 at 02:45:01 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022108   \n",
       "total_energy_joules                                                     79588.547839   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.205859   \n",
       "joules_per_token                                                            4.857699   \n",
       "flops_per_joule                                                     212969974.366801   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.883228   \n",
       "average_latency_ms_per_batch                                              2985.40352   \n",
       "throughput_queries_per_sec                                                   5.35941   \n",
       "throughput_tokens_per_sec                                                 686.004416   \n",
       "total_energy_kwh_process_0                                                  0.005428   \n",
       "total_energy_kwh_process_1                                                  0.005465   \n",
       "total_energy_kwh_process_2                                                  0.005415   \n",
       "total_energy_kwh_process_3                                                    0.0058   \n",
       "gpu_power_avg                                                             932.529908   \n",
       "ram_power_avg                                                               0.674014   \n",
       "cpu_energy_total                                                             0.00268   \n",
       "gpu_energy_total                                                            0.019412   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  56  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    166   \n",
       "date_time                                              April 11, 2025 at 02:46:03 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022015   \n",
       "total_energy_joules                                                     79254.830096   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.206726   \n",
       "joules_per_token                                                            4.837331   \n",
       "flops_per_joule                                                     213866725.505504   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.846678   \n",
       "average_latency_ms_per_batch                                             2980.834787   \n",
       "throughput_queries_per_sec                                                  5.367624   \n",
       "throughput_tokens_per_sec                                                 687.055857   \n",
       "total_energy_kwh_process_0                                                  0.005445   \n",
       "total_energy_kwh_process_1                                                  0.005427   \n",
       "total_energy_kwh_process_2                                                  0.005325   \n",
       "total_energy_kwh_process_3                                                  0.005818   \n",
       "gpu_power_avg                                                             828.393201   \n",
       "ram_power_avg                                                               0.677866   \n",
       "cpu_energy_total                                                            0.002735   \n",
       "gpu_energy_total                                                            0.019263   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  57  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    172   \n",
       "date_time                                              April 11, 2025 at 02:50:00 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022108   \n",
       "total_energy_joules                                                      79588.27778   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.205859   \n",
       "joules_per_token                                                            4.857683   \n",
       "flops_per_joule                                                     212970697.015842   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   22.873191   \n",
       "average_latency_ms_per_batch                                             2859.148891   \n",
       "throughput_queries_per_sec                                                  5.596071   \n",
       "throughput_tokens_per_sec                                                 716.297079   \n",
       "total_energy_kwh_process_0                                                  0.005437   \n",
       "total_energy_kwh_process_1                                                  0.005402   \n",
       "total_energy_kwh_process_2                                                    0.0054   \n",
       "total_energy_kwh_process_3                                                   0.00587   \n",
       "gpu_power_avg                                                             542.674179   \n",
       "ram_power_avg                                                               0.639024   \n",
       "cpu_energy_total                                                            0.003115   \n",
       "gpu_energy_total                                                            0.018977   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  58  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    173   \n",
       "date_time                                              April 11, 2025 at 02:51:04 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021896   \n",
       "total_energy_joules                                                     78825.275361   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.207852   \n",
       "joules_per_token                                                            4.811113   \n",
       "flops_per_joule                                                     215032182.449385   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    23.07682   \n",
       "average_latency_ms_per_batch                                             2884.602521   \n",
       "throughput_queries_per_sec                                                  5.546691   \n",
       "throughput_tokens_per_sec                                                 709.976499   \n",
       "total_energy_kwh_process_0                                                  0.005383   \n",
       "total_energy_kwh_process_1                                                  0.005358   \n",
       "total_energy_kwh_process_2                                                  0.005399   \n",
       "total_energy_kwh_process_3                                                  0.005756   \n",
       "gpu_power_avg                                                            8418.778745   \n",
       "ram_power_avg                                                               0.648004   \n",
       "cpu_energy_total                                                            0.002897   \n",
       "gpu_energy_total                                                            0.018983   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  59  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    174   \n",
       "date_time                                              April 11, 2025 at 02:52:05 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022016   \n",
       "total_energy_joules                                                     79257.538412   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.206719   \n",
       "joules_per_token                                                            4.837496   \n",
       "flops_per_joule                                                     213859417.447935   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   22.701395   \n",
       "average_latency_ms_per_batch                                             2837.674381   \n",
       "throughput_queries_per_sec                                                   5.63842   \n",
       "throughput_tokens_per_sec                                                 721.717761   \n",
       "total_energy_kwh_process_0                                                  0.005373   \n",
       "total_energy_kwh_process_1                                                  0.005345   \n",
       "total_energy_kwh_process_2                                                  0.005442   \n",
       "total_energy_kwh_process_3                                                  0.005855   \n",
       "gpu_power_avg                                                             514.075478   \n",
       "ram_power_avg                                                               0.646411   \n",
       "cpu_energy_total                                                            0.003098   \n",
       "gpu_energy_total                                                            0.018902   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  60  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    175   \n",
       "date_time                                              April 11, 2025 at 02:53:06 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021579   \n",
       "total_energy_joules                                                     77685.286425   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.210902   \n",
       "joules_per_token                                                            4.741534   \n",
       "flops_per_joule                                                     218187661.693502   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    22.59848   \n",
       "average_latency_ms_per_batch                                             2824.809944   \n",
       "throughput_queries_per_sec                                                  5.664098   \n",
       "throughput_tokens_per_sec                                                 725.004528   \n",
       "total_energy_kwh_process_0                                                  0.005244   \n",
       "total_energy_kwh_process_1                                                  0.005292   \n",
       "total_energy_kwh_process_2                                                  0.005277   \n",
       "total_energy_kwh_process_3                                                  0.005766   \n",
       "gpu_power_avg                                                             614.212687   \n",
       "ram_power_avg                                                               0.641967   \n",
       "cpu_energy_total                                                            0.002645   \n",
       "gpu_energy_total                                                            0.018919   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  61  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    176   \n",
       "date_time                                              April 11, 2025 at 02:54:09 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021987   \n",
       "total_energy_joules                                                     79153.299519   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.206991   \n",
       "joules_per_token                                                            4.831134   \n",
       "flops_per_joule                                                     214141054.083154   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.286571   \n",
       "average_latency_ms_per_batch                                             2910.821429   \n",
       "throughput_queries_per_sec                                                   5.49673   \n",
       "throughput_tokens_per_sec                                                 703.581463   \n",
       "total_energy_kwh_process_0                                                  0.005378   \n",
       "total_energy_kwh_process_1                                                  0.005357   \n",
       "total_energy_kwh_process_2                                                  0.005414   \n",
       "total_energy_kwh_process_3                                                  0.005839   \n",
       "gpu_power_avg                                                              750.69982   \n",
       "ram_power_avg                                                               0.666498   \n",
       "cpu_energy_total                                                            0.002744   \n",
       "gpu_energy_total                                                            0.019227   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  62  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    177   \n",
       "date_time                                              April 11, 2025 at 02:55:09 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022174   \n",
       "total_energy_joules                                                     79827.530634   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.205242   \n",
       "joules_per_token                                                            4.872286   \n",
       "flops_per_joule                                                     212332397.841176   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.371715   \n",
       "average_latency_ms_per_batch                                             2921.464402   \n",
       "throughput_queries_per_sec                                                  5.476705   \n",
       "throughput_tokens_per_sec                                                 701.018297   \n",
       "total_energy_kwh_process_0                                                  0.005453   \n",
       "total_energy_kwh_process_1                                                  0.005449   \n",
       "total_energy_kwh_process_2                                                  0.005446   \n",
       "total_energy_kwh_process_3                                                  0.005826   \n",
       "gpu_power_avg                                                            1677.981438   \n",
       "ram_power_avg                                                               0.665195   \n",
       "cpu_energy_total                                                            0.002815   \n",
       "gpu_energy_total                                                            0.019343   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  63  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    178   \n",
       "date_time                                              April 11, 2025 at 02:56:10 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022161   \n",
       "total_energy_joules                                                     79778.964695   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.205367   \n",
       "joules_per_token                                                            4.869322   \n",
       "flops_per_joule                                                     212461656.501568   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.444686   \n",
       "average_latency_ms_per_batch                                             2930.585798   \n",
       "throughput_queries_per_sec                                                  5.459659   \n",
       "throughput_tokens_per_sec                                                  698.83639   \n",
       "total_energy_kwh_process_0                                                  0.005466   \n",
       "total_energy_kwh_process_1                                                  0.005417   \n",
       "total_energy_kwh_process_2                                                  0.005435   \n",
       "total_energy_kwh_process_3                                                  0.005843   \n",
       "gpu_power_avg                                                            1200.855005   \n",
       "ram_power_avg                                                               0.665195   \n",
       "cpu_energy_total                                                            0.002728   \n",
       "gpu_energy_total                                                            0.019417   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  64  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    179   \n",
       "date_time                                              April 11, 2025 at 02:57:12 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022225   \n",
       "total_energy_joules                                                     80008.879377   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.204777   \n",
       "joules_per_token                                                            4.883354   \n",
       "flops_per_joule                                                     211851123.589203   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.232562   \n",
       "average_latency_ms_per_batch                                             2904.070252   \n",
       "throughput_queries_per_sec                                                  5.509509   \n",
       "throughput_tokens_per_sec                                                   705.2171   \n",
       "total_energy_kwh_process_0                                                  0.005328   \n",
       "total_energy_kwh_process_1                                                  0.005516   \n",
       "total_energy_kwh_process_2                                                  0.005519   \n",
       "total_energy_kwh_process_3                                                  0.005862   \n",
       "gpu_power_avg                                                             1023.46107   \n",
       "ram_power_avg                                                                0.66469   \n",
       "cpu_energy_total                                                            0.002945   \n",
       "gpu_energy_total                                                            0.019264   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  65  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    180   \n",
       "date_time                                              April 11, 2025 at 02:58:15 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022037   \n",
       "total_energy_joules                                                     79332.316652   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.206524   \n",
       "joules_per_token                                                             4.84206   \n",
       "flops_per_joule                                                     213657834.643894   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.270355   \n",
       "average_latency_ms_per_batch                                             2908.794437   \n",
       "throughput_queries_per_sec                                                  5.500561   \n",
       "throughput_tokens_per_sec                                                 704.071754   \n",
       "total_energy_kwh_process_0                                                  0.005354   \n",
       "total_energy_kwh_process_1                                                  0.005417   \n",
       "total_energy_kwh_process_2                                                  0.005404   \n",
       "total_energy_kwh_process_3                                                  0.005861   \n",
       "gpu_power_avg                                                             641.739565   \n",
       "ram_power_avg                                                               0.664462   \n",
       "cpu_energy_total                                                            0.002866   \n",
       "gpu_energy_total                                                            0.019155   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  66  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    181   \n",
       "date_time                                              April 11, 2025 at 02:59:16 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022071   \n",
       "total_energy_joules                                                     79455.767743   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.206203   \n",
       "joules_per_token                                                            4.849595   \n",
       "flops_per_joule                                                      213325872.67883   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.287194   \n",
       "average_latency_ms_per_batch                                             2910.899296   \n",
       "throughput_queries_per_sec                                                  5.496583   \n",
       "throughput_tokens_per_sec                                                 703.562642   \n",
       "total_energy_kwh_process_0                                                  0.005438   \n",
       "total_energy_kwh_process_1                                                  0.005428   \n",
       "total_energy_kwh_process_2                                                  0.005373   \n",
       "total_energy_kwh_process_3                                                  0.005832   \n",
       "gpu_power_avg                                                            1551.207321   \n",
       "ram_power_avg                                                                 0.6631   \n",
       "cpu_energy_total                                                            0.002726   \n",
       "gpu_energy_total                                                             0.01933   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  67  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    182   \n",
       "date_time                                              April 11, 2025 at 03:00:18 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                             0.02212   \n",
       "total_energy_joules                                                     79631.713062   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.205747   \n",
       "joules_per_token                                                            4.860334   \n",
       "flops_per_joule                                                     212854531.709691   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.249351   \n",
       "average_latency_ms_per_batch                                             2906.168873   \n",
       "throughput_queries_per_sec                                                   5.50553   \n",
       "throughput_tokens_per_sec                                                 704.707844   \n",
       "total_energy_kwh_process_0                                                  0.005428   \n",
       "total_energy_kwh_process_1                                                  0.005429   \n",
       "total_energy_kwh_process_2                                                  0.005444   \n",
       "total_energy_kwh_process_3                                                  0.005819   \n",
       "gpu_power_avg                                                            1448.743478   \n",
       "ram_power_avg                                                               0.665169   \n",
       "cpu_energy_total                                                            0.002823   \n",
       "gpu_energy_total                                                            0.019281   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  68  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    183   \n",
       "date_time                                              April 11, 2025 at 03:01:19 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022105   \n",
       "total_energy_joules                                                     79576.984984   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.205889   \n",
       "joules_per_token                                                            4.856994   \n",
       "flops_per_joule                                                     213000919.759229   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.336429   \n",
       "average_latency_ms_per_batch                                              2917.05359   \n",
       "throughput_queries_per_sec                                                  5.484987   \n",
       "throughput_tokens_per_sec                                                 702.078291   \n",
       "total_energy_kwh_process_0                                                  0.005432   \n",
       "total_energy_kwh_process_1                                                  0.005465   \n",
       "total_energy_kwh_process_2                                                  0.005434   \n",
       "total_energy_kwh_process_3                                                  0.005774   \n",
       "gpu_power_avg                                                            1485.262123   \n",
       "ram_power_avg                                                               0.665225   \n",
       "cpu_energy_total                                                            0.002775   \n",
       "gpu_energy_total                                                            0.019313   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  69  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    184   \n",
       "date_time                                              April 11, 2025 at 03:02:21 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021988   \n",
       "total_energy_joules                                                     79156.588699   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.206982   \n",
       "joules_per_token                                                            4.831335   \n",
       "flops_per_joule                                                     214132155.916694   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.317205   \n",
       "average_latency_ms_per_batch                                             2914.650578   \n",
       "throughput_queries_per_sec                                                  5.489509   \n",
       "throughput_tokens_per_sec                                                 702.657127   \n",
       "total_energy_kwh_process_0                                                   0.00538   \n",
       "total_energy_kwh_process_1                                                  0.005398   \n",
       "total_energy_kwh_process_2                                                  0.005408   \n",
       "total_energy_kwh_process_3                                                  0.005802   \n",
       "gpu_power_avg                                                            1274.904466   \n",
       "ram_power_avg                                                               0.663432   \n",
       "cpu_energy_total                                                            0.002632   \n",
       "gpu_energy_total                                                             0.01934   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  70  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    185   \n",
       "date_time                                              April 11, 2025 at 03:03:22 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                             0.02195   \n",
       "total_energy_joules                                                     79021.660488   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.207336   \n",
       "joules_per_token                                                            4.823099   \n",
       "flops_per_joule                                                     214497783.119962   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.158494   \n",
       "average_latency_ms_per_batch                                             2894.811798   \n",
       "throughput_queries_per_sec                                                   5.52713   \n",
       "throughput_tokens_per_sec                                                  707.47259   \n",
       "total_energy_kwh_process_0                                                  0.005356   \n",
       "total_energy_kwh_process_1                                                  0.005357   \n",
       "total_energy_kwh_process_2                                                  0.005415   \n",
       "total_energy_kwh_process_3                                                  0.005823   \n",
       "gpu_power_avg                                                             562.538789   \n",
       "ram_power_avg                                                               0.664345   \n",
       "cpu_energy_total                                                            0.002817   \n",
       "gpu_energy_total                                                            0.019118   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  71  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    186   \n",
       "date_time                                              April 11, 2025 at 03:04:26 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022064   \n",
       "total_energy_joules                                                     79431.609675   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.206265   \n",
       "joules_per_token                                                            4.848121   \n",
       "flops_per_joule                                                     213390752.907894   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.202428   \n",
       "average_latency_ms_per_batch                                             2900.303453   \n",
       "throughput_queries_per_sec                                                  5.516664   \n",
       "throughput_tokens_per_sec                                                 706.133007   \n",
       "total_energy_kwh_process_0                                                  0.005368   \n",
       "total_energy_kwh_process_1                                                  0.005447   \n",
       "total_energy_kwh_process_2                                                  0.005383   \n",
       "total_energy_kwh_process_3                                                  0.005867   \n",
       "gpu_power_avg                                                             795.553393   \n",
       "ram_power_avg                                                               0.663654   \n",
       "cpu_energy_total                                                            0.002844   \n",
       "gpu_energy_total                                                            0.019204   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  72  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    187   \n",
       "date_time                                              April 11, 2025 at 03:05:27 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022212   \n",
       "total_energy_joules                                                     79963.061299   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.204895   \n",
       "joules_per_token                                                            4.880558   \n",
       "flops_per_joule                                                     211972512.280364   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.640073   \n",
       "average_latency_ms_per_batch                                             2955.009096   \n",
       "throughput_queries_per_sec                                                  5.414535   \n",
       "throughput_tokens_per_sec                                                 693.060472   \n",
       "total_energy_kwh_process_0                                                  0.005481   \n",
       "total_energy_kwh_process_1                                                  0.005472   \n",
       "total_energy_kwh_process_2                                                  0.005394   \n",
       "total_energy_kwh_process_3                                                  0.005865   \n",
       "gpu_power_avg                                                             708.789737   \n",
       "ram_power_avg                                                               0.663628   \n",
       "cpu_energy_total                                                            0.002854   \n",
       "gpu_energy_total                                                            0.019342   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  73  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    188   \n",
       "date_time                                              April 11, 2025 at 03:06:29 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022266   \n",
       "total_energy_joules                                                     80159.040345   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.204394   \n",
       "joules_per_token                                                             4.89252   \n",
       "flops_per_joule                                                     211454265.422914   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.725851   \n",
       "average_latency_ms_per_batch                                             2965.731396   \n",
       "throughput_queries_per_sec                                                  5.394959   \n",
       "throughput_tokens_per_sec                                                 690.554783   \n",
       "total_energy_kwh_process_0                                                  0.005493   \n",
       "total_energy_kwh_process_1                                                  0.005481   \n",
       "total_energy_kwh_process_2                                                  0.005479   \n",
       "total_energy_kwh_process_3                                                  0.005813   \n",
       "gpu_power_avg                                                             196.533552   \n",
       "ram_power_avg                                                               0.666584   \n",
       "cpu_energy_total                                                            0.002909   \n",
       "gpu_energy_total                                                            0.019341   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  74  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    189   \n",
       "date_time                                              April 11, 2025 at 03:07:33 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022171   \n",
       "total_energy_joules                                                     79813.883435   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.205278   \n",
       "joules_per_token                                                            4.871453   \n",
       "flops_per_joule                                                     212368704.085806   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.440052   \n",
       "average_latency_ms_per_batch                                             2930.006438   \n",
       "throughput_queries_per_sec                                                  5.460739   \n",
       "throughput_tokens_per_sec                                                 698.974573   \n",
       "total_energy_kwh_process_0                                                  0.005503   \n",
       "total_energy_kwh_process_1                                                  0.005389   \n",
       "total_energy_kwh_process_2                                                  0.005406   \n",
       "total_energy_kwh_process_3                                                  0.005873   \n",
       "gpu_power_avg                                                             940.007732   \n",
       "ram_power_avg                                                               0.665578   \n",
       "cpu_energy_total                                                            0.002969   \n",
       "gpu_energy_total                                                            0.019185   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  75  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    190   \n",
       "date_time                                              April 11, 2025 at 03:08:35 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022127   \n",
       "total_energy_joules                                                     79658.584807   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.205678   \n",
       "joules_per_token                                                            4.861974   \n",
       "flops_per_joule                                                      212782728.11799   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.257695   \n",
       "average_latency_ms_per_batch                                             2907.211887   \n",
       "throughput_queries_per_sec                                                  5.503555   \n",
       "throughput_tokens_per_sec                                                 704.455017   \n",
       "total_energy_kwh_process_0                                                  0.005398   \n",
       "total_energy_kwh_process_1                                                  0.005409   \n",
       "total_energy_kwh_process_2                                                  0.005445   \n",
       "total_energy_kwh_process_3                                                  0.005876   \n",
       "gpu_power_avg                                                              659.73285   \n",
       "ram_power_avg                                                               0.666098   \n",
       "cpu_energy_total                                                            0.002887   \n",
       "gpu_energy_total                                                            0.019223   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  76  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    191   \n",
       "date_time                                              April 11, 2025 at 03:09:37 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022127   \n",
       "total_energy_joules                                                     79655.924763   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.205685   \n",
       "joules_per_token                                                            4.861812   \n",
       "flops_per_joule                                                     212789833.821877   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.409533   \n",
       "average_latency_ms_per_batch                                             2926.191577   \n",
       "throughput_queries_per_sec                                                  5.467858   \n",
       "throughput_tokens_per_sec                                                 699.885823   \n",
       "total_energy_kwh_process_0                                                  0.005337   \n",
       "total_energy_kwh_process_1                                                  0.005502   \n",
       "total_energy_kwh_process_2                                                  0.005464   \n",
       "total_energy_kwh_process_3                                                  0.005824   \n",
       "gpu_power_avg                                                             881.419378   \n",
       "ram_power_avg                                                               0.664872   \n",
       "cpu_energy_total                                                            0.002823   \n",
       "gpu_energy_total                                                            0.019287   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  77  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    192   \n",
       "date_time                                              April 11, 2025 at 03:10:39 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021753   \n",
       "total_energy_joules                                                     78312.258436   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.209214   \n",
       "joules_per_token                                                            4.779801   \n",
       "flops_per_joule                                                     216440839.935347   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.339891   \n",
       "average_latency_ms_per_batch                                             2917.486425   \n",
       "throughput_queries_per_sec                                                  5.484173   \n",
       "throughput_tokens_per_sec                                                 701.974132   \n",
       "total_energy_kwh_process_0                                                  0.005434   \n",
       "total_energy_kwh_process_1                                                  0.005338   \n",
       "total_energy_kwh_process_2                                                   0.00527   \n",
       "total_energy_kwh_process_3                                                  0.005711   \n",
       "gpu_power_avg                                                            2203.211476   \n",
       "ram_power_avg                                                               0.665559   \n",
       "cpu_energy_total                                                            0.002649   \n",
       "gpu_energy_total                                                            0.019089   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  78  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    193   \n",
       "date_time                                              April 11, 2025 at 03:11:41 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022035   \n",
       "total_energy_joules                                                     79324.468177   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.206544   \n",
       "joules_per_token                                                            4.841581   \n",
       "flops_per_joule                                                     213678974.252386   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.370914   \n",
       "average_latency_ms_per_batch                                             2921.364236   \n",
       "throughput_queries_per_sec                                                  5.476893   \n",
       "throughput_tokens_per_sec                                                 701.042333   \n",
       "total_energy_kwh_process_0                                                  0.005396   \n",
       "total_energy_kwh_process_1                                                  0.005458   \n",
       "total_energy_kwh_process_2                                                  0.005452   \n",
       "total_energy_kwh_process_3                                                  0.005728   \n",
       "gpu_power_avg                                                            1662.575306   \n",
       "ram_power_avg                                                                0.66279   \n",
       "cpu_energy_total                                                            0.002694   \n",
       "gpu_energy_total                                                            0.019325   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  79  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    194   \n",
       "date_time                                              April 11, 2025 at 03:12:44 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022129   \n",
       "total_energy_joules                                                     79663.168096   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.205666   \n",
       "joules_per_token                                                            4.862254   \n",
       "flops_per_joule                                                     212770486.013364   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    23.21867   \n",
       "average_latency_ms_per_batch                                             2902.333711   \n",
       "throughput_queries_per_sec                                                  5.512805   \n",
       "throughput_tokens_per_sec                                                 705.639049   \n",
       "total_energy_kwh_process_0                                                  0.005364   \n",
       "total_energy_kwh_process_1                                                  0.005381   \n",
       "total_energy_kwh_process_2                                                   0.00548   \n",
       "total_energy_kwh_process_3                                                  0.005904   \n",
       "gpu_power_avg                                                             646.021091   \n",
       "ram_power_avg                                                               0.662914   \n",
       "cpu_energy_total                                                            0.002915   \n",
       "gpu_energy_total                                                            0.019196   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  80  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    195   \n",
       "date_time                                              April 11, 2025 at 03:13:47 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022042   \n",
       "total_energy_joules                                                     79350.575857   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.206476   \n",
       "joules_per_token                                                            4.843175   \n",
       "flops_per_joule                                                      213608670.26088   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.554853   \n",
       "average_latency_ms_per_batch                                              2944.35657   \n",
       "throughput_queries_per_sec                                                  5.434124   \n",
       "throughput_tokens_per_sec                                                 695.567928   \n",
       "total_energy_kwh_process_0                                                  0.005459   \n",
       "total_energy_kwh_process_1                                                  0.005399   \n",
       "total_energy_kwh_process_2                                                  0.005419   \n",
       "total_energy_kwh_process_3                                                  0.005764   \n",
       "gpu_power_avg                                                            1518.139929   \n",
       "ram_power_avg                                                               0.665464   \n",
       "cpu_energy_total                                                            0.002714   \n",
       "gpu_energy_total                                                            0.019312   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  81  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    196   \n",
       "date_time                                              April 11, 2025 at 03:14:49 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022019   \n",
       "total_energy_joules                                                     79267.089003   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.206694   \n",
       "joules_per_token                                                            4.838079   \n",
       "flops_per_joule                                                     213833650.338204   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.547086   \n",
       "average_latency_ms_per_batch                                             2943.385782   \n",
       "throughput_queries_per_sec                                                  5.435917   \n",
       "throughput_tokens_per_sec                                                 695.797341   \n",
       "total_energy_kwh_process_0                                                  0.005537   \n",
       "total_energy_kwh_process_1                                                  0.005342   \n",
       "total_energy_kwh_process_2                                                  0.005357   \n",
       "total_energy_kwh_process_3                                                  0.005783   \n",
       "gpu_power_avg                                                             708.204415   \n",
       "ram_power_avg                                                               0.663001   \n",
       "cpu_energy_total                                                            0.002917   \n",
       "gpu_energy_total                                                            0.019087   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  82  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    197   \n",
       "date_time                                              April 11, 2025 at 03:15:52 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022055   \n",
       "total_energy_joules                                                     79399.139493   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                             0.20635   \n",
       "joules_per_token                                                            4.846139   \n",
       "flops_per_joule                                                     213478018.796583   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    23.34714   \n",
       "average_latency_ms_per_batch                                             2918.392557   \n",
       "throughput_queries_per_sec                                                   5.48247   \n",
       "throughput_tokens_per_sec                                                 701.756176   \n",
       "total_energy_kwh_process_0                                                  0.005364   \n",
       "total_energy_kwh_process_1                                                  0.005449   \n",
       "total_energy_kwh_process_2                                                  0.005398   \n",
       "total_energy_kwh_process_3                                                  0.005844   \n",
       "gpu_power_avg                                                             772.734927   \n",
       "ram_power_avg                                                               0.664455   \n",
       "cpu_energy_total                                                            0.002875   \n",
       "gpu_energy_total                                                            0.019164   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  83  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    198   \n",
       "date_time                                              April 11, 2025 at 03:16:56 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022409   \n",
       "total_energy_joules                                                     80672.664643   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.203092   \n",
       "joules_per_token                                                            4.923869   \n",
       "flops_per_joule                                                     210107984.757064   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.360484   \n",
       "average_latency_ms_per_batch                                             2920.060557   \n",
       "throughput_queries_per_sec                                                  5.479338   \n",
       "throughput_tokens_per_sec                                                 701.355318   \n",
       "total_energy_kwh_process_0                                                  0.005498   \n",
       "total_energy_kwh_process_1                                                  0.005496   \n",
       "total_energy_kwh_process_2                                                    0.0055   \n",
       "total_energy_kwh_process_3                                                  0.005915   \n",
       "gpu_power_avg                                                             143.466911   \n",
       "ram_power_avg                                                               0.664685   \n",
       "cpu_energy_total                                                            0.003007   \n",
       "gpu_energy_total                                                            0.019385   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                                  84  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    199   \n",
       "date_time                                              April 11, 2025 at 03:18:00 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021976   \n",
       "total_energy_joules                                                     79114.439184   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.207092   \n",
       "joules_per_token                                                            4.828762   \n",
       "flops_per_joule                                                     214246238.335844   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.647899   \n",
       "average_latency_ms_per_batch                                             2955.987344   \n",
       "throughput_queries_per_sec                                                  5.412743   \n",
       "throughput_tokens_per_sec                                                 692.831113   \n",
       "total_energy_kwh_process_0                                                  0.005395   \n",
       "total_energy_kwh_process_1                                                  0.005413   \n",
       "total_energy_kwh_process_2                                                  0.005392   \n",
       "total_energy_kwh_process_3                                                  0.005776   \n",
       "gpu_power_avg                                                            1234.326235   \n",
       "ram_power_avg                                                               0.667894   \n",
       "cpu_energy_total                                                             0.00268   \n",
       "gpu_energy_total                                                             0.01928   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "latency_simulation_simulate                                                    False   \n",
       "\n",
       "                                                                   85  \\\n",
       "config_name                                             latency_False   \n",
       "experiment_id                                                     204   \n",
       "date_time                               April 11, 2025 at 03:21:23 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.021932   \n",
       "total_energy_joules                                      78954.196131   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.207513   \n",
       "joules_per_token                                             4.818982   \n",
       "flops_per_joule                                      214681066.031948   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    23.879527   \n",
       "average_latency_ms_per_batch                              2984.940937   \n",
       "throughput_queries_per_sec                                    5.36024   \n",
       "throughput_tokens_per_sec                                  686.110728   \n",
       "total_energy_kwh_process_0                                   0.005409   \n",
       "total_energy_kwh_process_1                                   0.005355   \n",
       "total_energy_kwh_process_2                                   0.005368   \n",
       "total_energy_kwh_process_3                                     0.0058   \n",
       "gpu_power_avg                                             1127.987867   \n",
       "ram_power_avg                                                0.664632   \n",
       "cpu_energy_total                                             0.002814   \n",
       "gpu_energy_total                                             0.019101   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "latency_simulation_simulate                                     False   \n",
       "\n",
       "                                                                                  86  \\\n",
       "config_name                        latency_True_latency_0.05_latency_0.2_latency_...   \n",
       "experiment_id                                                                    205   \n",
       "date_time                                              April 11, 2025 at 03:22:26 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                    0.05   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022573   \n",
       "total_energy_joules                                                     81263.371943   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.201616   \n",
       "joules_per_token                                                            4.959923   \n",
       "flops_per_joule                                                      208580699.86403   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   24.329177   \n",
       "average_latency_ms_per_batch                                             3041.147076   \n",
       "throughput_queries_per_sec                                                  5.261173   \n",
       "throughput_tokens_per_sec                                                 673.430107   \n",
       "total_energy_kwh_process_0                                                  0.005541   \n",
       "total_energy_kwh_process_1                                                  0.005544   \n",
       "total_energy_kwh_process_2                                                  0.005478   \n",
       "total_energy_kwh_process_3                                                  0.006011   \n",
       "gpu_power_avg                                                            1259.214409   \n",
       "ram_power_avg                                                               0.664354   \n",
       "cpu_energy_total                                                            0.002935   \n",
       "gpu_energy_total                                                            0.019622   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "latency_simulation_delay_max                                                     0.2   \n",
       "latency_simulation_simulate                                                     True   \n",
       "\n",
       "                                                                                  87  \\\n",
       "config_name                        latency_True_latency_0.2_latency_0.6_latency_F...   \n",
       "experiment_id                                                                    206   \n",
       "date_time                                              April 11, 2025 at 03:23:31 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.2   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.023598   \n",
       "total_energy_joules                                                     84951.709741   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.192863   \n",
       "joules_per_token                                                            5.185041   \n",
       "flops_per_joule                                                     199524777.604627   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   27.506127   \n",
       "average_latency_ms_per_batch                                             3438.265927   \n",
       "throughput_queries_per_sec                                                  4.653509   \n",
       "throughput_tokens_per_sec                                                 595.649098   \n",
       "total_energy_kwh_process_0                                                  0.005781   \n",
       "total_energy_kwh_process_1                                                  0.005882   \n",
       "total_energy_kwh_process_2                                                  0.005681   \n",
       "total_energy_kwh_process_3                                                  0.006254   \n",
       "gpu_power_avg                                                             390.099748   \n",
       "ram_power_avg                                                               0.664819   \n",
       "cpu_energy_total                                                            0.003424   \n",
       "gpu_energy_total                                                            0.020156   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "latency_simulation_delay_max                                                     0.6   \n",
       "latency_simulation_simulate                                                     True   \n",
       "\n",
       "                                                                                  88  \\\n",
       "config_name                        latency_True_latency_0.05_latency_0.2_latency_...   \n",
       "experiment_id                                                                    207   \n",
       "date_time                                              April 11, 2025 at 03:24:40 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                    0.05   \n",
       "latency_simulation_simulate_burst                                               True   \n",
       "latency_simulation_burst_size                                                      5   \n",
       "latency_simulation_burst_interval                                                4.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                             0.02396   \n",
       "total_energy_joules                                                     86256.402501   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.189945   \n",
       "joules_per_token                                                            5.264673   \n",
       "flops_per_joule                                                     196506815.746624   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   28.595749   \n",
       "average_latency_ms_per_batch                                             3574.468596   \n",
       "throughput_queries_per_sec                                                   4.47619   \n",
       "throughput_tokens_per_sec                                                 572.952299   \n",
       "total_energy_kwh_process_0                                                  0.005898   \n",
       "total_energy_kwh_process_1                                                  0.005827   \n",
       "total_energy_kwh_process_2                                                  0.005875   \n",
       "total_energy_kwh_process_3                                                   0.00636   \n",
       "gpu_power_avg                                                             534.115213   \n",
       "ram_power_avg                                                               0.665937   \n",
       "cpu_energy_total                                                            0.003318   \n",
       "gpu_energy_total                                                            0.020624   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "latency_simulation_delay_max                                                     0.2   \n",
       "latency_simulation_simulate                                                     True   \n",
       "\n",
       "                                                                                  89  \n",
       "config_name                        latency_True_latency_0.2_latency_0.6_latency_T...  \n",
       "experiment_id                                                                    208  \n",
       "date_time                                              April 11, 2025 at 03:25:52 PM  \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0  \n",
       "num_processes                                                                      4  \n",
       "batch_size___fixed_batching                                                       16  \n",
       "decoder_temperature                                                              1.0  \n",
       "decoder_top_k                                                                      0  \n",
       "decoder_top_p                                                                    0.0  \n",
       "latency_simulation_delay_min                                                     0.2  \n",
       "latency_simulation_simulate_burst                                               True  \n",
       "latency_simulation_burst_size                                                      8  \n",
       "latency_simulation_burst_interval                                                5.0  \n",
       "fp_precision                                                           torch.float32  \n",
       "quantization                                                                   False  \n",
       "load_in_8bit                                                                   False  \n",
       "load_in_4bit                                                                   False  \n",
       "total_input_tokens                                                             16384  \n",
       "total_params                                                              1100048384  \n",
       "max_input_tokens                                                                 128  \n",
       "max_output_tokens                                                                128  \n",
       "number_input_prompts                                                             128  \n",
       "total_energy_kwh                                                            0.025477  \n",
       "total_energy_joules                                                     91716.993714  \n",
       "flops                                                                 16949970993152  \n",
       "tokens_per_joule                                                            0.178636  \n",
       "joules_per_token                                                            5.597961  \n",
       "flops_per_joule                                                     184807311.129298  \n",
       "joules_per_flop                                                                  0.0  \n",
       "total_inference_time_sec                                                   32.414388  \n",
       "average_latency_ms_per_batch                                             4051.798498  \n",
       "throughput_queries_per_sec                                                  3.948864  \n",
       "throughput_tokens_per_sec                                                 505.454553  \n",
       "total_energy_kwh_process_0                                                  0.006339  \n",
       "total_energy_kwh_process_1                                                  0.006319  \n",
       "total_energy_kwh_process_2                                                  0.006129  \n",
       "total_energy_kwh_process_3                                                  0.006689  \n",
       "gpu_power_avg                                                             685.047901  \n",
       "ram_power_avg                                                               0.669801  \n",
       "cpu_energy_total                                                            0.003897  \n",
       "gpu_energy_total                                                             0.02156  \n",
       "total_generated_tokens                                                         16384  \n",
       "decoder_config_decoding_mode                                                     NaN  \n",
       "latency_simulation_delay_max                                                     0.6  \n",
       "latency_simulation_simulate                                                     True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing scenarios: 'df_scenarios_cleaned'\n",
      "Error processing grid: 'df_grid_cleaned'\n",
      "Error processing text_generation: 'df_text_generation_cleaned'\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [\n",
    "    \"sharding_strategy\",\n",
    "    \"sharding_config_fsdp_config_use_orig_params\",\n",
    "    \"sharding_config_fsdp_config_cpu_offload\",\n",
    "    \"adaptive_batching\",\n",
    "    \"adaptive_max_tokens\",\n",
    "    \"query_rate\",\n",
    "    \"is_encoder_decoder\",\n",
    "    \"task_type\",\n",
    "    \"available_gpu_count\",\n",
    "    \"gpu_model\",\n",
    "    \"available_cpu_count\",\n",
    "    \"cpu_model\",\n",
    "    \"os\",\n",
    "    \"python_version\",\n",
    "    \"country\",\n",
    "    \"region\",\n",
    "    \"distributed_type\",\n",
    "    \"decode_token_to_text\",\n",
    "    \"inference_type\",\n",
    "    \"backend\",\n",
    "    \"model_arch\",\n",
    "    \"gpu_current_memory_allocated_bytes\",\n",
    "    \"gpu_max_memory_allocated_bytes\",\n",
    "    \"gpu_current_memory_reserved_bytes\",\n",
    "    \"gpu_max_memory_reserved_bytes\",\n",
    "    \"per-process_emissions_0\", \"per-process_emissions_1\", \"per-process_emissions_2\",\"per-process_emissions_3\" # OR IS THIS NICE TO HAVE?\n",
    "]\n",
    "\n",
    "# second round of dropping (at some point come back to these)\n",
    "columns_to_drop_2 = [\n",
    "    \"cpu_usage_percent\",\n",
    "    \"cpu_memory_usage_bytes\",\n",
    "    \"gpu_utilization_percent_0\",\n",
    "    \"gpu_utilization_percent_1\",\n",
    "    \"gpu_utilization_percent_2\",\n",
    "    \"gpu_utilization_percent_3\",\n",
    "    \"gpu_current_memory_allocated_bytes\",\n",
    "    \"gpu_max_memory_allocated_bytes\",\n",
    "    \"cpu_current_memory_allocated_bytes\",\n",
    "    \"cpu_max_memory_allocated_bytes\",\n",
    "    \"cpu_power_process_0\",\n",
    "    \"cpu_power_process_1\",\n",
    "    \"cpu_power_process_2\",\n",
    "    \"cpu_power_process_3\",\n",
    "    \"gpu_power_process_0\",\n",
    "    \"gpu_power_process_1\",\n",
    "    \"gpu_power_process_2\",\n",
    "    \"gpu_power_process_3\",\n",
    "    \"ram_power_process_0\",\n",
    "    \"ram_power_process_1\",\n",
    "    \"ram_power_process_2\",\n",
    "    \"ram_power_process_3\",\n",
    "    \"cpu_energy_process_0\",\n",
    "    \"cpu_energy_process_1\",\n",
    "    \"cpu_energy_process_2\",\n",
    "    \"cpu_energy_process_3\",\n",
    "    \"gpu_energy_process_0\",\n",
    "    \"gpu_energy_process_1\",\n",
    "    \"gpu_energy_process_2\",\n",
    "    \"gpu_energy_process_3\",\n",
    "    \"ram_energy_process_0\",\n",
    "    \"ram_energy_process_1\",\n",
    "    \"ram_energy_process_2\",\n",
    "    \"ram_energy_process_3\",\n",
    "    \"total_energy_joules_process_0\",\n",
    "    \"total_energy_joules_process_1\",\n",
    "    \"total_energy_joules_process_2\",\n",
    "    \"total_energy_joules_process_3\",\n",
    "    \"cpu_power_avg\",\n",
    "    \"ram_energy_total\",\n",
    "    \"models\"\n",
    "]\n",
    "\n",
    "for file in possible_files:\n",
    "    try:\n",
    "        cleaned_var = f\"df_{file}_cleaned\"   # e.g., df_controlled_cleaned\n",
    "        dropped_var = f\"df_{file}_dropped\"     # e.g., df_controlled_dropped\n",
    "        \n",
    "        # Drop the specified columns from the cleaned DataFrame.\n",
    "        globals()[dropped_var] = globals()[cleaned_var].drop(columns=columns_to_drop, errors='ignore')\n",
    "        globals()[dropped_var] = globals()[dropped_var].drop(columns=columns_to_drop_2, errors='ignore')\n",
    "        print(f\"Found & inspecting dropped version: {dropped_var}\")\n",
    "        display(globals()[dropped_var].T)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df_controlled_dropped has multiple FLOP counts:\n",
      "Unique FLOPs: [16949970993152  1034544128000]\n",
      "\n",
      "FLOP value: 16949970993152\n",
      "Associated config_name(s): ['num_processes_1' 'num_processes_2' 'num_processes_3' 'num_processes_4'\n",
      " 'batching_1' 'batching_2' 'batching_4' 'batching_8' 'batching_16'\n",
      " 'batching_32' 'batching_64'\n",
      " 'precis_float32_quant_False_quant8_False_quant4_False'\n",
      " 'precis_float16_quant_False_quant8_False_quant4_False'\n",
      " 'decoding_greedy_decoder_temperature_0'\n",
      " 'decoding_greedy_decoder_temperature_0.2'\n",
      " 'decoding_greedy_decoder_temperature_0.4'\n",
      " 'decoding_greedy_decoder_temperature_0.6'\n",
      " 'decoding_greedy_decoder_temperature_0.8'\n",
      " 'decoding_greedy_decoder_temperature_1.0'\n",
      " 'decoding_greedy_decoder_temperature_1.2'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_0'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_0'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_0'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_0'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_0'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_0.2'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_0.2'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_0.2'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_0.2'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_0.2'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_0.4'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_0.4'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_0.4'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_0.4'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_0.4'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_0.6'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_0.6'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_0.6'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_0.6'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_0.6'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_0.8'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_0.8'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_0.8'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_0.8'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_0.8'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_1.0'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_1.0'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_1.0'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_1.0'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_1.0'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_1.2'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_1.2'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_1.2'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_1.2'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_1.2'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_0'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_0'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_0'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_0.2'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_0.2'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.2'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_0.2'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_0.4'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_0.4'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.4'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_0.4'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_0.6'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_0.6'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.6'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_0.6'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_0.8'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_0.8'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.8'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_0.8'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_1.0'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_1.0'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.0'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_1.0'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_1.2'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_1.2'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.2'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_1.2'\n",
      " 'latency_False' 'latency_True_latency_0.05_latency_0.2_latency_False'\n",
      " 'latency_True_latency_0.2_latency_0.6_latency_False'\n",
      " 'latency_True_latency_0.05_latency_0.2_latency_True_latency_4.0_latency_5'\n",
      " 'latency_True_latency_0.2_latency_0.6_latency_True_latency_5.0_latency_8']\n",
      "\n",
      "FLOP value: 1034544128000\n",
      "Associated config_name(s): ['precis_float16_quant_True_quant8_True_quant4_False'\n",
      " 'precis_float16_quant_True_quant8_False_quant4_True']\n",
      "--------------------------------------------------\n",
      "df_scenarios_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_grid_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_text_generation_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check all flops are constant\n",
    "\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    \n",
    "    if var_dropped in globals():\n",
    "        try:\n",
    "            df = globals()[var_dropped]\n",
    "            \n",
    "            # Check how many unique flops exist\n",
    "            unique_flops = df['flops'].unique()\n",
    "            \n",
    "            if len(unique_flops) > 1:\n",
    "                print(f\"\\n{var_dropped} has multiple FLOP counts:\")\n",
    "                print(f\"Unique FLOPs: {unique_flops}\")\n",
    "                \n",
    "                # Find rows for each different flop value\n",
    "                for flop_val in unique_flops:\n",
    "                    subset = df[df['flops'] == flop_val]\n",
    "                    config_names = subset['config_name'].unique()\n",
    "                    \n",
    "                    print(f\"\\nFLOP value: {flop_val}\")\n",
    "                    print(f\"Associated config_name(s): {config_names}\")\n",
    "                print(\"-\" * 50)\n",
    "            else:\n",
    "                print(f\"\\n{var_dropped} has only one unique FLOP value, skipping.\")\n",
    "                print(\"-\" * 50)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Problem inspecting {var_dropped}: {e}\")\n",
    "    else:\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df_controlled_dropped has multiple FLOP counts:\n",
      "Unique FLOPs: [16949970993152  1034544128000]\n",
      "Differentiating columns:\n",
      "Column: quantization\n",
      "  FLOP 16949970993152: False\n",
      "  FLOP 1034544128000: True\n",
      "--------------------------------------------------\n",
      "df_scenarios_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_grid_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_text_generation_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def identify_flop_differentiators(df, flops_col='flops', exclude_cols=None):\n",
    "    \"\"\"\n",
    "    Identify columns that are constant within each FLOP group but differ between groups.\n",
    "    \n",
    "    Parameters:\n",
    "      df (pd.DataFrame): The DataFrame containing the data.\n",
    "      flops_col (str): Name of the column used for grouping the FLOPs.\n",
    "      exclude_cols (list, optional): List of columns to exclude from the comparison.\n",
    "      \n",
    "    Returns:\n",
    "      dict: A dictionary where keys are the column names that differentiate FLOP groups,\n",
    "            and values are dictionaries mapping each unique FLOP value to the constant value\n",
    "            observed in that group.\n",
    "            \n",
    "    Example output:\n",
    "    {\n",
    "      'config_name': {1034544128000: 'A1_Max_Throughput_Exploit', \n",
    "                      16949970993152: 'A5_Parallel_Overdrive'},\n",
    "      'some_other_col': {1034544128000: 'value1', \n",
    "                         16949970993152: 'value2'}\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Optionally exclude some columns, including the flops column itself.\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = []\n",
    "    exclude_cols = set(exclude_cols + [flops_col])\n",
    "    \n",
    "    differentiators = {}\n",
    "    unique_flops = df[flops_col].unique()\n",
    "    \n",
    "    # Loop over each column in df excluding the ones in exclude_cols.\n",
    "    for col in df.columns:\n",
    "        if col in exclude_cols:\n",
    "            continue\n",
    "        \n",
    "        # For each group (by flops), get the unique values for this column.\n",
    "        group_values = {}\n",
    "        valid = True  # assume column is constant per group unless we find more than one unique value.\n",
    "        for flop in unique_flops:\n",
    "            values = df[df[flops_col] == flop][col].unique()\n",
    "            if len(values) == 1:\n",
    "                group_values[flop] = values[0]\n",
    "            else:\n",
    "                # If any FLOP group has more than one value, then this column doesn't differentiate consistently.\n",
    "                valid = False\n",
    "                break\n",
    "        # Check if the column is valid and if it truly differentiates between groups.\n",
    "        if valid and len(set(group_values.values())) > 1:\n",
    "            differentiators[col] = group_values\n",
    "    \n",
    "    return differentiators\n",
    "\n",
    "\n",
    "\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    if var_dropped in globals():\n",
    "        try:\n",
    "            df = globals()[var_dropped]\n",
    "            \n",
    "            # Check if there is more than one FLOP count.\n",
    "            unique_flops = df['flops'].unique()\n",
    "            if len(unique_flops) > 1:\n",
    "                print(f\"\\n{var_dropped} has multiple FLOP counts:\")\n",
    "                print(f\"Unique FLOPs: {unique_flops}\")\n",
    "                \n",
    "                # Identify columns that differ consistently between FLOP groups.\n",
    "                diff_cols = identify_flop_differentiators(df)\n",
    "                if diff_cols:\n",
    "                    print(\"Differentiating columns:\")\n",
    "                    for col, mapping in diff_cols.items():\n",
    "                        print(f\"Column: {col}\")\n",
    "                        for flop, val in mapping.items():\n",
    "                            print(f\"  FLOP {flop}: {val}\")\n",
    "                else:\n",
    "                    print(\"No consistently differentiating columns were found.\")\n",
    "                print(\"-\" * 50)\n",
    "            else:\n",
    "                print(f\"\\n{var_dropped} has only one unique FLOP value, skipping.\")\n",
    "                print(\"-\" * 50)\n",
    "        except Exception as e:\n",
    "            print(f\"Problem inspecting {var_dropped}: {e}\")\n",
    "    else:\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_scenarios_dropped does not exist, skipping.\n",
      "df_grid_dropped does not exist, skipping.\n",
      "df_text_generation_dropped does not exist, skipping.\n"
     ]
    }
   ],
   "source": [
    "# DEFINE NEW VARS\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    \n",
    "    if var_dropped not in globals():\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df = globals()[var_dropped]\n",
    "        \n",
    "        df['flops_per_token'] = df['flops'] / df['total_generated_tokens']\n",
    "        df['energy_per_token_kwh'] = df['total_energy_kwh'] / df['total_generated_tokens']\n",
    "        df['divergence_energy_flops_per_token'] = df['energy_per_token_kwh'] / df['flops_per_token']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {var_dropped}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['config_name', 'experiment_id', 'date_time', 'model', 'num_processes',\n",
      "       'batch_size___fixed_batching', 'decoder_temperature', 'decoder_top_k',\n",
      "       'decoder_top_p', 'latency_simulation_delay_min',\n",
      "       'latency_simulation_simulate_burst', 'latency_simulation_burst_size',\n",
      "       'latency_simulation_burst_interval', 'fp_precision', 'quantization',\n",
      "       'load_in_8bit', 'load_in_4bit', 'total_input_tokens', 'total_params',\n",
      "       'max_input_tokens', 'max_output_tokens', 'number_input_prompts',\n",
      "       'total_energy_kwh', 'total_energy_joules', 'flops', 'tokens_per_joule',\n",
      "       'joules_per_token', 'flops_per_joule', 'joules_per_flop',\n",
      "       'total_inference_time_sec', 'average_latency_ms_per_batch',\n",
      "       'throughput_queries_per_sec', 'throughput_tokens_per_sec',\n",
      "       'total_energy_kwh_process_0', 'total_energy_kwh_process_1',\n",
      "       'total_energy_kwh_process_2', 'total_energy_kwh_process_3',\n",
      "       'gpu_power_avg', 'ram_power_avg', 'cpu_energy_total',\n",
      "       'gpu_energy_total', 'total_generated_tokens',\n",
      "       'decoder_config_decoding_mode', 'latency_simulation_delay_max',\n",
      "       'latency_simulation_simulate', 'flops_per_token',\n",
      "       'energy_per_token_kwh', 'divergence_energy_flops_per_token'],\n",
      "      dtype='object')\n",
      "--------------------------------------------------\n",
      "df_scenarios_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_grid_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_text_generation_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# CHECK COLUMN NAMES\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    \n",
    "    if var_dropped not in globals():\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        print(\"-\" * 50)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        df = globals()[var_dropped]\n",
    "        print(df.columns)\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {var_dropped}: {e}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num_processes_1' 'num_processes_2' 'num_processes_3' 'num_processes_4'\n",
      " 'batching_1' 'batching_2' 'batching_4' 'batching_8' 'batching_16'\n",
      " 'batching_32' 'batching_64'\n",
      " 'precis_float32_quant_False_quant8_False_quant4_False'\n",
      " 'precis_float16_quant_False_quant8_False_quant4_False'\n",
      " 'precis_float16_quant_True_quant8_True_quant4_False'\n",
      " 'precis_float16_quant_True_quant8_False_quant4_True'\n",
      " 'decoding_greedy_decoder_temperature_0'\n",
      " 'decoding_greedy_decoder_temperature_0.2'\n",
      " 'decoding_greedy_decoder_temperature_0.4'\n",
      " 'decoding_greedy_decoder_temperature_0.6'\n",
      " 'decoding_greedy_decoder_temperature_0.8'\n",
      " 'decoding_greedy_decoder_temperature_1.0'\n",
      " 'decoding_greedy_decoder_temperature_1.2'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_0'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_0'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_0'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_0'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_0'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_0.2'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_0.2'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_0.2'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_0.2'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_0.2'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_0.4'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_0.4'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_0.4'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_0.4'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_0.4'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_0.6'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_0.6'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_0.6'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_0.6'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_0.6'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_0.8'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_0.8'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_0.8'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_0.8'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_0.8'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_1.0'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_1.0'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_1.0'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_1.0'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_1.0'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_1.2'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_1.2'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_1.2'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_1.2'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_1.2'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_0'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_0'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_0'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_0.2'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_0.2'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.2'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_0.2'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_0.4'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_0.4'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.4'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_0.4'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_0.6'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_0.6'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.6'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_0.6'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_0.8'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_0.8'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.8'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_0.8'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_1.0'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_1.0'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.0'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_1.0'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_1.2'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_1.2'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.2'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_1.2'\n",
      " 'latency_False' 'latency_True_latency_0.05_latency_0.2_latency_False'\n",
      " 'latency_True_latency_0.2_latency_0.6_latency_False'\n",
      " 'latency_True_latency_0.05_latency_0.2_latency_True_latency_4.0_latency_5'\n",
      " 'latency_True_latency_0.2_latency_0.6_latency_True_latency_5.0_latency_8']\n",
      "--------------------------------------------------\n",
      "df_scenarios_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_grid_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_text_generation_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# CHECK CONFIG NAMES\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    \n",
    "    if var_dropped not in globals():\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        print(\"-\" * 50)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        df = globals()[var_dropped]\n",
    "        print(df['config_name'].unique())\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {var_dropped}: {e}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxYAAAHpCAYAAAAf5apCAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAvWpJREFUeJzs3XdYU2cbBvA7bJAlKoqiiLj3qtaBSN2rjroH4GpV3LWOtu49qrbu0YKz7tE668JtnVgtigsVKe4JuCDv98f7JRCGhDAO4/5dVy5OTk7ePAknJ+c571IJIQSIiIiIiIhSwUjpAIiIiIiIKOtjYkFERERERKnGxIKIiIiIiFKNiQUREREREaUaEwsiIiIiIko1JhZERERERJRqTCyIiIiIiCjVmFgQEREREVGqMbEgIiIiIqJUY2KRyfn7+0OlUuHu3btKh5IprVmzBqVLl4apqSns7e0BAPXr10f9+vUVjSunKlq0KFq2bKl0GBnq7t27UKlU8Pf3VzoUUojmOH3+/HmlQ9Gh2TfnzJmTLuXXr18f5cuXT5eyM1LRokXh4+OjdBh6yyrxqlQqTJgwQekwKIMxscjG1q9fj/nz5ysdRrq5fv06fHx84ObmhhUrVmD58uVKh5SlnTp1ChMmTMDLly+VDoUoQ02bNg07duxQOgzKJIKCgjBhwgRe0Pu/qKgoTJgwAQEBAQke27NnD5MH0sHEIhvL7olFQEAA1Go1fv75Z/j4+KBjx45Kh5SlnTp1ChMnTmRiQTkOEwuKKygoCBMnTmRi8X9RUVGYOHFikonFxIkTE33e27dv8eOPP6ZzdJTZMLGgLOvx48cAoG0CRYmLiopSOgTKhCIjI5UOIV29e/cOarVa6TCItLL7dy4+CwsLmJiYKB0GZTAmFlnQzp070aJFCxQsWBDm5uZwc3PD5MmTERMTo92mfv362L17N+7duweVSgWVSoWiRYtqH3///j3Gjx+P4sWLw9zcHIULF8bIkSPx/v17nddSqVQYOHAgduzYgfLly8Pc3BzlypXDvn37EsQVFhaG3r17a+NydXVF//798eHDB9y5cwcqlQrz5s1L8LxTp05BpVLh999/R1RUFK5fv46nT59+8jMoWrQoxo8fDwDIly9fsm05Hz9+jN69eyN//vywsLBApUqVsGrVKp1t4rZHnjdvHlxcXGBpaQkPDw9cvXpVZ9uHDx+iZ8+ecHZ2hrm5OZycnNC6desUXeGaMGECVCoVrl+/jo4dO8LW1hZ58uTBkCFD8O7duwTbr127FtWqVYOlpSUcHBzQuXNnhIaG6myjafN84cIF1KtXD1ZWVvj+++/1iuW7774DALi6umr3Gc37iY6OxuTJk+Hm5gZzc3MULVoU33//fYL9JTGrVq2CiYmJtnwA+Pvvv9G0aVPY2dnBysoKHh4eOHnyZKKfz61bt+Dj4wN7e3vY2dmhZ8+eeiVLx48fR4cOHVCkSBHtPj5s2DC8fftWZzsfHx9YW1sjLCwMbdq0gbW1NfLly4cRI0bofKcA4OXLl/Dx8YGdnR3s7e3h7e2dohqely9fYujQoShcuDDMzc1RvHhxzJw5U+cEOO5+uHz5cu1n/tlnn+HcuXMJyrx+/Trat28PBwcHWFhYoHr16vjjjz90ttH0ATh69CgGDBgAR0dHODs7ax9ftGgRihUrBktLS9SoUQPHjx/X6asUERGBXLlyYciQIQle/8GDBzA2Nsb06dP1/hw0x5V169ahVKlSsLCwQLVq1XDs2LEE24aFhaFXr17Inz+/9vjz22+/6WwTEBAAlUqFDRs24Mcff0ShQoVgZWWF169f6xVLZGQkVq1apd3v47Zfv3TpEpo1awZbW1tYW1ujQYMGOHPmTLLlvnjxAjVq1ICzszOCg4MBpM9xN6WEEPj6669hZmaGbdu24eXLlzA2NsYvv/yi3ebp06cwMjJCnjx5IITQru/fvz8KFCiQoMygoCB4enrCysoKhQoVwqxZs5KNo3z58vD09EywXq1Wo1ChQmjfvr123YYNG1CtWjXY2NjA1tYWFSpUwM8//5zsa8yZMwe1a9dGnjx5YGlpiWrVqmHLli2ffI6/vz86dOgAAPD09NTuE3Gv1u/duxfu7u7IlSsXbGxs0KJFC/z777865WiOK7dv30bz5s1hY2ODbt26ad/j/PnzUa5cOVhYWCB//vz45ptv8OLFC50yhBCYMmUKnJ2dYWVlBU9PzwSv8yn6fG7JHZPu3r2LfPnyAQAmTpyo/TwmTJgAHx8fLFq0CAC061Uqlbbs+L/LKTmmv337FoMHD0bevHlhY2ODL7/8EmFhYey3kRUIytT8/PwEABESEqJd16ZNG9GxY0cxe/ZssWTJEtGhQwcBQIwYMUK7zV9//SUqV64s8ubNK9asWSPWrFkjtm/fLoQQIiYmRjRu3FhYWVmJoUOHimXLlomBAwcKExMT0bp1a53XByAqVaoknJycxOTJk8X8+fNFsWLFhJWVlXj69Kl2u7CwMFGwYEFtmUuXLhVjx44VZcqUES9evBBCCFGnTh1RrVq1BO9xwIABwsbGRkRGRoojR44IAGL8+PGf/Fy2b98u2rZtKwCIJUuWiDVr1ojLly8LIYTw8PAQHh4e2m2joqJEmTJlhKmpqRg2bJj45ZdfhLu7uwAg5s+fr90uJCREABAVKlQQRYsWFTNnzhQTJ04UDg4OIl++fOLhw4fabWvXri3s7OzEjz/+KFauXCmmTZsmPD09xdGjRz8Zd1zjx4/Xvl6rVq3EwoULRffu3QUA0aNHD51tp0yZIlQqlejUqZNYvHixmDhxosibN68oWrSo9vPVvPcCBQqIfPnyiUGDBolly5aJHTt2JBvL5cuXRZcuXQQAMW/ePO0+ExERIYQQwtvbWwAQ7du3F4sWLRJeXl4CgGjTpo1OOS4uLqJFixba+8uWLRMqlUr88MMP2nWHDh0SZmZmolatWuKnn34S8+bNExUrVhRmZmbi77//TvD5VKlSRbRr104sXrxY9OnTRwAQI0eOTPY9DRo0SDRv3lxMmzZNLFu2TPTu3VsYGxuL9u3b62zn7e0tLCwsRLly5USvXr3EkiVLxFdffSUAiMWLF2u3U6vVol69esLIyEgMGDBALFiwQHzxxReiYsWKAoDw8/P7ZDyRkZGiYsWKIk+ePOL7778XS5cuFV5eXkKlUokhQ4Zot9Psh1WqVBHFixcXM2fOFLNmzRJ58+YVzs7O4sOHD9ptr169Kuzs7ETZsmXFzJkzxcKFC0W9evWESqUS27Zt026nOY6ULVtWeHh4iAULFogZM2YIIYRYvHixACDc3d3FL7/8IoYPHy4cHByEm5ubzveoW7duIn/+/CI6Olrnfc2aNUuoVCpx7969ZP8nGgBE+fLlRd68ecWkSZPEzJkzhYuLi7C0tBRXrlzRbvfw4UPh7OwsChcuLCZNmiSWLFkivvzyS+1+qqE5bpQtW1ZUrlxZzJ07V0yfPl1ERkYmG8uaNWuEubm5cHd31+73p06d0n6+uXLl0h7/ZsyYIVxdXYW5ubk4c+ZMgs/33LlzQgghnjx5IipXriyKFCkibt26JYRIn+NucjT70uzZs4UQQkRHRwsvLy9hbm4udu3apd2uYsWK4quvvtLe3759uzAyMhIAxNWrV7Xry5Urp/P98fDwEAULFhSFCxcWQ4YMEYsXLxZffPGFACD27NnzydgmTZokjIyMRHh4uM76o0ePCgBi8+bNQgj5WwZANGjQQCxatEgsWrRIDBw4UHTo0CHZ9+/s7CwGDBggFi5cKObOnStq1KghAOi8dyHkccvb21sIIcTt27fF4MGDBQDx/fffa/cJzfF/9erVQqVSiaZNm4oFCxaImTNniqJFiwp7e3ud32lvb29hbm4u3NzchLe3t1i6dKlYvXq1EEKIPn36CBMTE9G3b1+xdOlSMWrUKJErVy7x2Wef6Xy/f/zxRwFANG/eXCxcuFD06tVLFCxYUOTNm1cbb1L0+dz0OSZFRESIJUuWCACibdu22s/j8uXL4tSpU6JRo0YCgHb9mjVrtOXH/y1PyTG9Y8eO2t/CRYsWiY4dO4pKlSrpdX5AymJikcklllhERUUl2O6bb74RVlZW4t27d9p1LVq0EC4uLgm2XbNmjTAyMhLHjx/XWb906VIBQJw8eVK7DoAwMzPT/jgKIU9CAYgFCxZo13l5eQkjIyPtD2tcarVaCCFPMgGIa9euaR/78OGDzkFS38RCiNiD1JMnT3TWx08s5s+fLwCItWvX6rxurVq1hLW1tXj9+rUQIvZH2NLSUjx48EC77d9//y0AiGHDhgkhhHjx4oXOj7WhNPF/+eWXOusHDBggAGgTpbt37wpjY2MxdepUne2uXLkiTExMdNZ7eHgIAGLp0qUpjmf27NkJ9jUhhAgMDBQARJ8+fXTWjxgxQgAQhw8f1q6Lm1j8/PPPQqVSicmTJ2sfV6vVokSJEqJJkyba/UIIuU+7urqKRo0aaddpPp9evXrpvG7btm1Fnjx5kn0/iX1Ppk+fnuAkWJM0TZo0SWfbKlWq6CTCO3bsEADErFmztOuio6O1SWpyicXkyZNFrly5xI0bN3TWjx49WhgbG4v79+8LIWL3wzx58ojnz59rt9u5c6cAIP7880/tugYNGogKFSrofO/VarWoXbu2KFGihHad5jhSt25dncTg/fv3Ik+ePOKzzz4THz9+1K739/cXAHS+R/v37xcAxN69e3Xir1ixos52+gAgAIjz589r1927d09YWFiItm3batf17t1bODk5JTiZ7ty5s7Czs9P+jzXHjWLFiiX6f09Orly5Ej1Ra9OmjTAzMxO3b9/Wrvvvv/+EjY2NqFevnnZd3MQiPDxclCtXThQrVkzcvXtXu016HHeTEzex+Pjxo+jUqZOwtLQU+/fv19nO19dX5M+fX3t/+PDhol69esLR0VEsWbJECCHEs2fPhEqlEj///LN2O83xRnPCLITcpwoUKKCTqCQmODg40fczYMAAYW1trf0/DhkyRNja2iZIaPURf1/48OGDKF++vPjiiy901sdNLIQQYvPmzQKAOHLkiM52b968Efb29qJv37466x8+fCjs7Ox01muOK6NHj9bZ9vjx4wKAWLdunc76ffv26ax//PixMDMzEy1atNA5Vn7//fcCQLKJhT6fm77HpCdPniT5u+zr6yuSukadVGKR3DH9woULAoAYOnSoznY+Pj5MLLIANoXKgiwtLbXLb968wdOnT+Hu7q5tRpSczZs3o0yZMihdujSePn2qvX3xxRcAgCNHjuhs37BhQ7i5uWnvV6xYEba2trhz5w4AWa27Y8cOtGrVCtWrV0/wepqq0Y4dO8LCwgLr1q3TPrZ//348ffoU3bt3ByCb8ggh0rSqc8+ePShQoAC6dOmiXWdqaorBgwcjIiICR48e1dm+TZs2KFSokPZ+jRo1ULNmTezZsweA/PzNzMwQEBCQoOraEL6+vjr3Bw0apI0bALZt2wa1Wo2OHTvq/L8KFCiAEiVKJPh/mZubo2fPnqmOS0MTx/Dhw3XWf/vttwCA3bt3J3jOrFmzMGTIEMycOVOn815gYCBu3ryJrl274tmzZ9r3EhkZiQYNGuDYsWMJ2sX369dP5767uzuePXuWbDOXuN+TyMhIPH36FLVr14YQApcuXUqwfWKvo9nHNZ+DiYkJ+vfvr11nbGys/X8lZ/PmzXB3d0fu3Ll1/o8NGzZETExMgmZAnTp1Qu7cuXXiAaCN6fnz5zh8+DA6duyoPQ48ffoUz549Q5MmTXDz5k2EhYXplNm3b18YGxtr758/fx7Pnj1D3759ddpCd+vWTee1AXkcKFiwoM739+rVq/jnn3+039+UqFWrFqpVq6a9X6RIEbRu3Rr79+9HTEwMhBDYunUrWrVqBSGEzmfWpEkTvHr1ChcvXtQp09vbW+f/nhoxMTH466+/0KZNGxQrVky73snJCV27dsWJEycS7IMPHjyAh4cHPn78iGPHjsHFxUX7WFofd1Piw4cP6NChA3bt2oU9e/agcePGOo+7u7vj0aNH2iZbx48fR7169eDu7o7jx48DAE6cOAEhhHY/1LC2ttb5/5uZmaFGjRrJxlmyZElUrlwZGzdu1K6LiYnBli1b0KpVK+3/0d7eHpGRkThw4ECK33fcfeHFixd49eoV3N3dE+w3+jpw4ABevnyJLl266PwPjY2NUbNmzQT/QwA6xwtA7gd2dnZo1KiRThnVqlWDtbW1toyDBw/iw4cPGDRokE7zoqFDh+oVqz6fW0qPSWkluWO6psnfgAEDdLbT91hLymKvmizo33//xY8//ojDhw8n+GF79epVss+/efMmrl27pm03GZ+mU7RGkSJFEmyTO3du7Un1kydP8Pr162THM7e3t0erVq2wfv16TJ48GQCwbt06FCpUSPvjmh7u3buHEiVKwMhIN48uU6aM9vG4SpQokaCMkiVLYtOmTQDkifvMmTPx7bffIn/+/Pj888/RsmVLeHl5Jdr+ODnxX8/NzQ1GRkba/g03b96EECLRuACZJMVVqFAhmJmZpTiOpNy7dw9GRkYoXry4zvoCBQrA3t4+wed39OhR7N69G6NGjdLpVwHI9wLIE8CkvHr1SuekNv7+p3nsxYsXsLW1TbKc+/fvY9y4cfjjjz8SJIDxvycWFhYJvg9x93FAfg5OTk6wtrbW2a5UqVJJxhDXzZs38c8//xj8vYv7vgHg1q1bEEJg7NixGDt2bJJlxk2SXV1ddR7X/O/i/29NTEx0+mQBgJGREbp164YlS5YgKioKVlZWWLduHSwsLLRt0lMiqe9ZVFQUnjx5AiMjI7x8+RLLly9Pcijp+J9Z/PeXGk+ePEFUVFSi/98yZcpArVYjNDQU5cqV067v0aMHTExMcO3atQTHgrQ+7qbE9OnTERERgb179yY6x48mWTh+/DicnZ1x6dIlTJkyBfny5dPOgXH8+HHY2tqiUqVKOs91dnbWOfHVxPnPP/8kG1enTp3w/fffIywsDIUKFUJAQAAeP36MTp06abcZMGAANm3ahGbNmqFQoUJo3LgxOnbsiKZNmyZb/q5duzBlyhQEBgbq9GOJH6++NMevpH6v4h+PTExMdPoyacp49eoVHB0dEy1Dsx9ovpvxvyf58uVLkPQnRp/PLaXHpLSS3DFd85sT//sc/zhFmRMTiyzm5cuX8PDwgK2tLSZNmgQ3NzdYWFjg4sWLGDVqlF6joKjValSoUAFz585N9PHChQvr3I97hTMuEadTn768vLywefNmnDp1ChUqVMAff/yBAQMGJDjpz+yGDh2KVq1aYceOHdi/fz/Gjh2L6dOn4/Dhw6hSpUqqyo7/o6dWq6FSqbB3795E/xfxT3TT6optcnElpVy5cnj58iXWrFmDb775RufHQbN/zp49G5UrV070+fHfjyH7X0xMDBo1aoTnz59j1KhRKF26NHLlyoWwsDD4+Pgk+J4k9RppSa1Wo1GjRhg5cmSij5csWVKvmDTvW/MeRowYgSZNmiS6bfwf4tTuG15eXpg9ezZ27NiBLl26YP369WjZsiXs7OxSVW5iNO+ve/fuSSaiFStW1LmfXvu+vtq1a4fVq1fj559/TtCZXcnjbpMmTbBv3z7MmjUL9evXh4WFhc7jBQsWhKurK44dO4aiRYtCCIFatWohX758GDJkCO7du4fjx4+jdu3aCY7VqYmzU6dOGDNmDDZv3oyhQ4di06ZNsLOz0zn5dXR0RGBgIPbv34+9e/di79698PPzg5eXV4IBOOI6fvw4vvzyS9SrVw+LFy+Gk5MTTE1N4efnh/Xr1ycbW2I0++SaNWsSvYgUfwQkc3PzBJ+XWq2Go6OjTs1fXEmd5KeUPp9bSo9JaSUt923KfJhYZDEBAQF49uwZtm3bhnr16mnXh4SEJNg2qRNBNzc3XL58GQ0aNDD4yk1c+fLlg62tbYKRkxLTtGlT5MuXD+vWrUPNmjURFRWFHj16pDqGT3FxccE///wDtVqtc5DXNBuL21wBiL0qFdeNGzcSXMF1c3PDt99+i2+//RY3b95E5cqV8dNPP2Ht2rUpiu/mzZs6J9+3bt2CWq3Wvp6bmxuEEHB1dU23Az2Q9P7i4uICtVqNmzdvamt5AODRo0d4+fJlgs8vb9682LJlC+rWrYsGDRrgxIkTKFiwoPa9APLKXsOGDdPpnQBXrlzBjRs3sGrVKnh5eWnXG9KcQsPFxQWHDh1CRESETvKjaT6SHDc3N0RERKTZ+9Y0zzE1NTW4TM3/7tatWzoj9ERHR+Pu3bsJTtzLly+PKlWqYN26dXB2dsb9+/exYMECg147qe+ZlZWV9uTKxsYGMTEx6bqvAInv+/ny5YOVlVWi/9/r16/DyMgoQTIwaNAgFC9eHOPGjYOdnR1Gjx6tfSytj7sp8fnnn6Nfv35o2bIlOnTogO3btyc4CXZ3d8exY8fg6uqKypUrw8bGBpUqVYKdnR327duHixcvJjlfgaFcXV1Ro0YNbNy4EQMHDsS2bdvQpk0bmJub62xnZmaGVq1aoVWrVlCr1RgwYACWLVuGsWPHJnkVe+vWrbCwsMD+/ft1yvPz80s2rk/9dgLypN3QfdLNzQ0HDx5EnTp1PpkIa76bN2/e1GmK9+TJE71rrZL73PQ9Jn1qf02PfVnzmxMSEqJTY3Pr1q00fy1Ke1nrMjFpM/24mf2HDx+wePHiBNvmypUr0aZRHTt2RFhYGFasWJHgsbdv36Z4rG0jIyO0adMGf/75J86fP5/g8bixmpiYoEuXLti0aRP8/f1RoUIFnZMXfYebTYnmzZvj4cOHOm15o6OjsWDBAlhbW8PDw0Nn+x07dui0TT979iz+/vtvNGvWTBtj/OFg3dzcYGNjo9fwq/FphuvT0JyoaV6vXbt2MDY2xsSJExNc0RFC4NmzZyl+zcTkypULABIMn9q8eXMASDDZoubKa4sWLRKU5ezsjIMHD+Lt27do1KiRNsZq1arBzc0Nc+bMQURERILnPXnyJLVvA0Di3xMhhF5DVCalefPmiI6OxpIlS7TrYmJi9D6x7tixI06fPo39+/cneOzly5eIjo5OUTyOjo6oX78+li1bhvDw8ASP6/NZVq9eHXny5MGKFSt0Xn/dunVJnrz06NEDf/31F+bPn488efJo99OUOn36tE5b99DQUOzcuRONGzeGsbExjI2N8dVXX2Hr1q2JXrRIq30FkPt+/P3e2NgYjRs3xs6dO3WGkX706BHWr1+PunXrJtoUb+zYsRgxYgTGjBmjs6+k9XE3pRo2bIgNGzZg37596NGjR4JaO3d3d9y9excbN27UNo0yMjJC7dq1MXfuXHz8+DFB/4q00KlTJ5w5cwa//fYbnj59qtMMCkCC45uRkZH2N+NTx1tjY2OoVCqdIaPv3r2r10SISR0LmzRpAltbW0ybNg0fP35M8Dx99smOHTsiJiZG2xw4rujoaO1rNmzYEKampliwYIHOcUzfSW/1+dz0PSZZWVlp18WX1GeVGpoa2PjnNYZexKCMxRqLLKZ27drInTs3vL29MXjwYKhUKqxZsybRKsRq1aph48aNGD58OD777DNYW1ujVatW6NGjBzZt2oR+/frhyJEjqFOnDmJiYnD9+nVs2rQJ+/fvT7QT9qdMmzYNf/31Fzw8PPD111+jTJkyCA8Px+bNm3HixAmdSey8vLzwyy+/4MiRI5g5c6ZOOWfPnoWnpyfGjx+fZh24v/76ayxbtgw+Pj64cOECihYtii1btuDkyZOYP38+bGxsdLYvXrw46tati/79++P9+/faEyhNdfGNGzfQoEEDdOzYEWXLloWJiQm2b9+OR48eoXPnzimOLyQkBF9++SWaNm2K06dPY+3atejatau2LbObmxumTJmCMWPG4O7du2jTpg1sbGwQEhKC7du34+uvv8aIESNS/TlpOtL+8MMP6Ny5M0xNTdGqVStUqlQJ3t7eWL58ubYp3tmzZ7Fq1Sq0adMm0bHoAfk5/vXXX6hfvz6aNGmCw4cPw9bWFitXrkSzZs1Qrlw59OzZE4UKFUJYWBiOHDkCW1tb/Pnnn6l+L6VLl4abmxtGjBiBsLAw2NraYuvWranqbN+qVSvUqVMHo0ePxt27d1G2bFls27ZNr35NAPDdd9/hjz/+QMuWLeHj44Nq1aohMjISV65cwZYtW3D37l3kzZs3RTEtWrQIdevWRYUKFdC3b18UK1YMjx49wunTp/HgwQNcvnz5k883MzPDhAkTMGjQIHzxxRfo2LEj7t69C39/f7i5uSV6NbJr164YOXIktm/fjv79+yfo46Ov8uXLo0mTJhg8eDDMzc21JxFxr4rPmDEDR44cQc2aNdG3b1+ULVsWz58/x8WLF3Hw4EE8f/7coNeOr1q1ajh48CDmzp2rbRZUs2ZNTJkyBQcOHEDdunUxYMAAmJiYYNmyZXj//v0n52qYPXs2Xr16BV9fX9jY2KB79+7pctxNqTZt2mibw9ja2mLZsmXaxzRJQ3BwMKZNm6ZdX69ePezdu1c7l0pa69ixI0aMGIERI0bAwcEhwdXzPn364Pnz5/jiiy/g7OyMe/fuYcGCBahcubJODWp8LVq0wNy5c9G0aVN07doVjx8/xqJFi1C8ePFk+39UrlwZxsbGmDlzJl69egVzc3N88cUXcHR0xJIlS9CjRw9UrVoVnTt3Rr58+XD//n3s3r0bderUwcKFCz9ZtoeHB7755htMnz4dgYGBaNy4MUxNTXHz5k1s3rwZP//8M9q3b6+dS2f69Olo2bIlmjdvjkuXLmHv3r16HSf0+dz0PSZZWlqibNmy2LhxI0qWLAkHBweUL18e5cuX1/5uDB48GE2aNIGxsbFBv4NxVatWDV999RXmz5+PZ8+e4fPPP8fRo0dx48YNAOlTS0JpKANHoCIDJDbc7MmTJ8Xnn38uLC0tRcGCBcXIkSO1Q0HGHR4vIiJCdO3aVdjb2wsAOkPPfvjwQcycOVOUK1dOmJubi9y5c4tq1aqJiRMnilevXmm3AyB8fX0TxBV/eD4h5HCRXl5eIl++fMLc3FwUK1ZM+Pr6ivfv3yd4frly5YSRkZHOsK5CpM9ws0II8ejRI9GzZ0+RN29eYWZmJipUqJBgeNC4QzP+9NNPonDhwtrx7TVDvwohxNOnT4Wvr68oXbq0yJUrl7CzsxM1a9YUmzZtSjbmxOIPCgoS7du3FzY2NiJ37txi4MCB4u3btwm237p1q6hbt67IlSuXyJUrlyhdurTw9fUVwcHBOu+9XLlyKYojrsmTJ4tChQppx7DX7HcfP34UEydOFK6ursLU1FQULlxYjBkzRmeYUyESzmMhhByuVzM8p2b4x0uXLol27dqJPHnyCHNzc+Hi4iI6duwoDh06lODzif//Tew7kZigoCDRsGFDYW1tLfLmzSv69u2rHbIz7v/e29tb5MqVK8HzNa8f17Nnz0SPHj2Era2tsLOzEz169BCXLl3Sa7hZIeRwlWPGjBHFixcXZmZmIm/evKJ27dpizpw52vHr4889EFdi343bt28LLy8vUaBAAWFqaioKFSokWrZsKbZs2aLdJv48C/H98ssvwsXFRZibm4saNWqIkydPimrVqommTZsmun3z5s0FAO18DymlOa6sXbtWlChRQpibm4sqVaokGN5TCPnd9fX1FYULFxampqaiQIECokGDBmL58uXabTTHDc3cByl1/fp1Ua9ePWFpaZlgKM+LFy+KJk2aCGtra2FlZSU8PT0TvO/EPt+YmBjRpUsXYWJiop1LJj2Ou5+S1L6kmbsk7txHQgjh6OgoAIhHjx5p1504cULg//OcxJfU8cbb2zvRoc6TUqdOnUSHtBZCiC1btojGjRsLR0dHYWZmJooUKSK++eabBPNfJObXX3/V7l+lS5cWfn5+iX6vE/tcV6xYIYoVKyaMjY0T/LYeOXJENGnSRNjZ2QkLCwvh5uYmfHx8dIZPTuq4orF8+XJRrVo1YWlpKWxsbESFChXEyJEjxX///afdJiYmRkycOFE4OTkJS0tLUb9+fXH16lW99gN9Pzd9jklCCHHq1ClRrVo1YWZmpnMcio6OFoMGDRL58uUTKpVK57ONf7xKyTE9MjJS+Pr6CgcHB2FtbS3atGmjHaJYMwcPZU4qIdhbhjJelSpV4ODggEOHDikditbdu3fh6uqK2bNnp0kNQHImTJiAiRMn4smTJym+Uk2UntRqNfLly4d27dol2nSnbdu2uHLlisFtnlUqFXx9fZO9uktEpBEYGIgqVapg7dq12lnMKfNhHwvKcOfPn0dgYKBOp1oiUsa7d+8SNKVcvXo1nj9/nujQpOHh4di9e3e6D7pARDnX27dvE6ybP38+jIyMdAauocyHfSwow1y9ehUXLlzATz/9BCcnpwSd9LKLiIiIRDsmx5VWQwrqQ994MmLIVcp8zpw5g2HDhqFDhw7IkycPLl68iF9//RXly5fXmZ8iJCQEJ0+exMqVK2FqaopvvvkmQVkPHz785GtZWlqmy9C0Scls8aSVmJiYZDsKW1tbJxi6mSirmDVrFi5cuABPT0+YmJhoh8z9+uuvE4zGRpkLEwvKMFu2bMGkSZNQqlQp/P777wnGUs8u5syZk+ywjIkND5xe9I0n/nC6lDMULVoUhQsXxi+//ILnz5/DwcEBXl5emDFjhs5Ei0ePHkXPnj1RpEgRrFq1KtFx/J2cnD75Wt7e3vD390/rt5CkzBZPWgkNDU12MsC0HACDKKPVrl0bBw4cwOTJkxEREYEiRYpgwoQJ+OGHH5QOjZLBPhZEaezOnTu4c+fOJ7epW7duhiVWmS0eyr4OHjz4yccLFiyIsmXLZlA0mS+etPLu3TucOHHik9sUK1ZMZ/4DIqKMwMSCiIiIiIhSjZ23iYiIiIgo1ZhYEBERERFRqjGxICIiIiKiVGNikYxjx46hVatWKFiwIFQqFXbs2JHiMjZt2oTKlSvDysoKLi4umD17dtoHSkRERJRNpcX5WEqFhYWhe/fuyJMnDywtLVGhQgWcP38+3V83K2NikYzIyEhUqlQJixYtMuj5e/fuRbdu3dCvXz9cvXoVixcvxrx58zjjLBEREZGeUns+llIvXrxAnTp1YGpqir179yIoKAg//fQTcufOnSGvn1VxVKgUUKlU2L59O9q0aaNd9/79e/zwww/4/fff8fLlS5QvXx4zZ87UzljbtWtXfPz4EZs3b9Y+Z8GCBZg1axbu378PlUqVwe+CiIiIKOsy5HwspUaPHo2TJ0/i+PHjaRN0DsEai1QaOHAgTp8+jQ0bNuCff/5Bhw4d0LRpU9y8eROA3NHjzw9gaWmJBw8e4N69e0qETERERJStJHc+llJ//PEHqlevjg4dOsDR0RFVqlTBihUr0jjq7IeJRSrcv38ffn5+2Lx5M9zd3eHm5oYRI0agbt268PPzAwA0adIE27Ztw6FDh6BWq3Hjxg389NNPAIDw8HAlwyciIiLK8vQ5H0upO3fuYMmSJShRogT279+P/v37Y/DgwVi1alUaR5+9mCgdQFZ25coVxMTEoGTJkjrr379/jzx58gAA+vbti9u3b6Nly5b4+PEjbG1tMWTIEEyYMAFGRszriIiIiFJDn/Ox69evo0yZMp8sZ9SoUZgxYwYAQK1Wo3r16pg2bRoAoEqVKrh69SqWLl0Kb2/vdHgX2QMTi1SIiIiAsbExLly4AGNjY53HrK2tAch2gDNnzsS0adPw8OFD5MuXD4cOHQIAFCtWLMNjJiIiIspO9DkfK1asGK5du/bJcjRJCAA4OTmhbNmyOo+XKVMGW7duTaOosycmFqlQpUoVxMTE4PHjx3B3d//ktsbGxihUqBAA4Pfff0etWrWQL1++jAiTiIiIKNvS53zMzMwMpUuX1rvMOnXqIDg4WGfdjRs34OLikqpYszsmFsmIiIjArVu3tPdDQkIQGBgIBwcHlCxZEt26dYOXlxd++uknVKlSBU+ePMGhQ4dQsWJFtGjRAk+fPsWWLVtQv359vHv3TtsG8OjRowq+KyIiIqKsI7XnYyk1bNgw1K5dG9OmTUPHjh1x9uxZLF++HMuXL0/Lt5X9CPqkI0eOCAAJbt7e3kIIIT58+CDGjRsnihYtKkxNTYWTk5No27at+Oeff4QQQjx58kR8/vnnIleuXMLKyko0aNBAnDlzRsF3RERERJS1pPZ8zBB//vmnKF++vDA3NxelS5cWy5cvT6N3k31xHgsiIiIiIko1DktERERERESpxsSCiIiIiIhSjZ23ExEdHY1Lly4hf/78nGuCiIiIiLTUajUePXqEKlWqwMSEp9Jx8dNIxKVLl1CjRg2lwyAiIiKiTOrs2bP47LPPlA4jU2FikYj8+fMDkDuMk5OTwtEQERERUWYRHh6OGjVqaM8XKRYTi0Romj85OTnB2dlZ4WiIiIiIKLNhc/mE+IkQEREREVGqMbEgIiIiIqJUY1MoIiKibComJgYfP35UOgyiLMXU1BTGxsZKh5ElMbEgIiLKZoQQePjwIV6+fKl0KERZkr29PQoUKACVSqV0KFkKEwsiIqJsRpNUODo6wsrKiidHRHoSQiAqKgqPHz8GAI4OmkJMLIiIiLKRmJgYbVKRJ08epcMhynIsLS0BAI8fP4ajoyObRaUAO28TERFlI5o+FVZWVgpHQpR1ab4/7KOUMkwsiIiIsiE2fyIyHL8/hmFiQUREREREqcY+FkRERJS+7t8Hnj5N+vG8eYEiRTIuHiJKF6yxICIiokTFxAABAcDvv8u/MTEGFHL/PlCqFFCtWtK3UqWA+/chhMDXX38NBwcHqFQq2NvbY+jQoWn7pnKIgIAAqFQqDjlMGYqJBRERESWwbRtQtCjg6Ql07Sr/Fi0q16fI06fAu3ef3ubdO+DpU+zbtw/+/v7YtWsXwsPDUb58eQOjzz6YIFBWwsSCiIiIdGzbBrRvDzx4oLs+LEyuT3Fyoafbt2/DyckJtWvXRoECBWBikv1bbHPUIcpOmFgQERFlc0IAkZH63V6/BgYPls9JrBwAGDJEbqdPeYmVk5jx48dj0KBBuH//PlQqFYoWLZpgmxcvXsDLywu5c+eGlZUVmjVrhps3b2of9/f3h729PXbs2IESJUrAwsICTZo0QWhoqHaby5cvw9PTEzY2NrC1tUW1atVw/vz5ZOPTp2wA2LlzJ6pWrQoLCwsUK1YMEydORHR0tPZxlUqFJUuW4Msvv0SuXLkwderUJF/z7t278PT0BADkzp0bKpUKPj4+AID3799j8ODBcHR0hIWFBerWrYtz584lWVZUVBSaNWuGOnXqaGs/Vq5ciTJlysDCwgKlS5fG4sWLdV5bpVJh27Zt8PT0hJWVFSpVqoTTp08n+1lRzsXEgoiIKJuLigKsrfW72dnJmomkCCFrMuzs9CsvuVZQGiNGjMCkSZPg7OyM8PDwRE+SfXx8cP78efzxxx84ffo0hBBo3ry5zlX/qKgoTJ06FatXr8bJkyfx8uVLdO7cWft4t27d4OzsjHPnzuHChQsYPXo0TE1N9fwcP1328ePH4eXlhSFDhiAoKAjLli2Dv79/guRhwoQJaNu2La5cuYJevXol+XqFCxfG1q1bAQDBwcEIDw/Hzz//DAAYOXIktm7dilWrVuHixYsoXrw4mjRpgufPnyco5+XLl2jUqBHUajUOHDgAe3t7rFu3DuPGjcPUqVNx7do1TJs2DWPHjsWqVat0nvvDDz9gxIgRCAwMRMmSJdGlSxedRIlIh6AEQkNDBQARGhqqdChEREQp8vbtWxEUFCTevn2rXRcRIYRMCTL+FnXign4bXrgg5s2bJ1xcXLRxe3h4iCFDhgghhLhx44YAIE6ePKl9/OnTp8LS0lJs2rRJCCGEn5+fACDOnDmj3ebatWsCgPj777+FEELY2NgIf3//FH+u+pTdoEEDMW3aNJ3nrVmzRjg5OWnvAxBDhw7V+3WPHDkiAIgXL15o10VERAhTU1Oxbt067boPHz6IggULilmzZuk879q1a6JixYriq6++Eu/fv9du7+bmJtavX6/zWpMnTxa1atUSQggREhIiAIiVK1dqH//333+1ZWZ3iX2PNHiemDTWWBAREWVzVlZARIR+tz179Ctzzx79yrOwSJv3cO3aNZiYmKBmzZradXny5EGpUqVw7do17ToTExN89tln2vulS5eGvb29dpvhw4ejT58+aNiwIWbMmIHbt2/rHUNyZV++fBmTJk2CtbW19ta3b1+Eh4cjKipK+7zq1aun/AOI4/bt2/j48SPq1KmjXWdqaooaNWrofBYA0KhRIxQvXhwbN26EmZkZACAyMhK3b99G7969dWKdMmVKgs+jYsWK2mUnJycAwOPHj1MVP2Vf2b9XFBERUQ6nUgG5cum3bePGgLOzbA6VWP8IlUo+3rgxYGysR4HnzqYo1vQ2YcIEdO3aFbt378bevXsxfvx4bNiwAW3btk112REREZg4cSLatWuX4DGLOBlWLn3/GWmgRYsW2Lp1K4KCglChQgVtnACwYsUKnUQNAIzj/VPjNhPTzEatVqvTM2TKwlhjQURERFrGxsD/m/Hj/+eRWpr78+frmVTcvw98/33y21lYyEnyPqFMmTKIjo7G33//rV337NkzBAcHo2zZstp10dHROp2xg4OD8fLlS5QpU0a7rmTJkhg2bBj++usvtGvXDn5+fnq8meTLrlq1KoKDg1G8ePEENyMjw065NLUMMXEmEXFzc4OZmRlOnjypXffx40ecO3dO57MAgBkzZsDb2xsNGjRAUFAQACB//vwoWLAg7ty5kyBOV1dXg+IkAphYEBERUTzt2gFbtgCFCumud3aW6xO5IJ/Qu3fAV18BL14A5csDJ08CFy7I28qVchtzc+DIESA4ONmZt0uUKIHWrVujb9++OHHiBC5fvozu3bujUKFCaN26tXY7U1NTDBo0CH///TcuXLgAHx8ffP7556hRowbevn2LgQMHIiAgAPfu3cPJkydx7tw5naTjUz5VNgCMGzcOq1evxsSJE/Hvv//i2rVr2LBhA3788Ue9yk+Mi4sLVCoVdu3ahSdPniAiIgK5cuVC//798d1332Hfvn0ICgpC3759ERUVhd69eycoY86cOejWrRu++OILXL9+HQAwceJETJ8+Hb/88gtu3LiBK1euwM/PD3PnzjU4VkrcsWPH0KpVKxQsWBAqlQo7duz45PaauUvi3x4+fKjdZsKECQkeL126dDq/k+SxKRQREREl0K4d0Lo1cPw4EB4OODkB7u561lQAwMCBwPnzgIMD8OefcnY9jSpVgF9+Af75B7h4EahfX68i/fz8MGTIELRs2RIfPnxAvXr1sGfPHp3mOlZWVhg1ahS6du2KsLAwuLu749dffwUgm/k8e/YMXl5eePToEfLmzYt27dph4sSJer3+p8oGgCZNmmDXrl2YNGkSZs6cCVNTU5QuXRp9+vTRq/zEFCpUCBMnTsTo0aPRs2dPeHl5wd/fHzNmzIBarUaPHj3w5s0bVK9eHfv370fu3LkTLWfevHmIiYnBF198gYCAAPTp0wdWVlaYPXs2vvvuO+TKlQsVKlTgTOfpIDIyEpUqVUKvXr0SbSaXlODgYNja2mrvOzo66jxerlw5HDx4UHs/M8z7ohJC3xGmc44HDx6gcOHCCA0NhbOzs9LhEBER6e3du3cICQmBq6urTrv+DLViBfD114CREbBvH9CoUcJtli8HvvkGKF5c1lgY2FQoLn9/fwwdOjRdZqlOz7Ip8/nU90hznhgUFIRCcar1zM3NYW5u/slyVSoVtm/fjjZt2iS5TUBAADw9PfHixQvY29snus2ECROwY8cOBAYG6vuWMgSbQhEREVHaOXtW1lYAwJQpiScVANCtm5wM49Yt4MCBjIuPKI2ULVsWdnZ22tv06dPTtPzKlSvDyckJjRo10ulPo3Hz5k0ULFgQxYoVQ7du3XD//v00fX1DMLEgIiKitPH4sexX8eED0LYtMHp00tvmygX8fxZpLFqUIeF9SrNmzXSGXo17mzZtWrq9br9+/ZJ83X79+qXb61LqBQUF4dWrV9rbmDFj0qRcJycnLF26FFu3bsXWrVtRuHBh1K9fHxcvXtRuU7NmTfj7+2Pfvn1YsmQJQkJC4O7ujjdv3qRJDIZiU6hEsCkUERFlVYo1hYqOlrUTAQFAqVKy5iJO+/BEBQcDpUvL4abu3NHth5HBwsLC8Pbt20Qfc3BwgIODQ7q87uPHj/H69etEH7O1tU3Qrp4yhj5NoQw5T9SnKVRiPDw8UKRIEaxZsybRx1++fAkXFxfMnTs30Q78GUX5Xh5ERESU9Y0ZI5MKa2tg27bkkwpAJiANGwIHDwJLlwIzZqR7mEkpFH8IrAzi6OjI5IGSVaNGDZw4cSLJx+3t7VGyZEncunUrA6NKiE2hiIiIKHU2bQLmzJHLfn5AvLkUPsnXV/799Vc5RC0RJRAYGKid+TwxERERuH379ie3yQissSAiIiLD/fsv0KuXXB45EmjfPmXPb9kSKFwYCA0FNm8GevRI+xiJFBQREaFTkxASEoLAwEA4ODigSJEiGDNmDMLCwrB69WoAwPz58+Hq6opy5crh3bt3WLlyJQ4fPoy//vpLW8aIESPQqlUruLi44L///sP48eNhbGyMLl26ZPj7i4s1FkRERGSYV69kJ+3ISOCLL4CpU1NehokJoOmknAk6cROltfPnz6NKlSqoUqUKAGD48OGoUqUKxo0bBwAIDw/XGdHpw4cP+Pbbb1GhQgV4eHjg8uXLOHjwIBo0aKDd5sGDB+jSpQtKlSqFjh07Ik+ePDhz5gzy5cuXsW8uHnbeTgQ7bxMRUVaVYZ231Wo5i97OnbLG4cIFwNCTmkePZBkfP8pJ9apVS9tYiVIovTpvZ3essSAiIqKUmz5dJhVmZsDWrYYnFQCQPz/QoYNcZq0FUZbFxIKIiIh03b8PXLyY9G3NGmDsWLnt4sXAZ5+l/jU1nbh//x14/jz15ZHBAgICoFKpFJtl3N/fP8kZpw1RtGhRzJ8/P83Ko6QpmlgcO3YMrVq1QsGCBaFSqbBjx45knxMQEICqVavC3NwcxYsXh7+/v87jMTExGDt2LFxdXWFpaQk3NzdMnjwZbPFFRESkh/v35TCw1aolffPyAoQA+vYF0mrM/Fq1gMqV5chQfn5pU2YOp3SCQDmPoolFZGQkKlWqhEV6VnuGhISgRYsW8PT0RGBgIIYOHYo+ffpg//792m1mzpyJJUuWYOHChbh27RpmzpyJWbNmYcGCBen1NoiIiLKPp0/1G/a1XDkgLX9bVarYWoslS2Qfjgzw8ePHDHmd9JCVY6fsSdHEolmzZpgyZQratm2r1/ZLly6Fq6srfvrpJ5QpUwYDBw5E+/btMW/ePO02p06dQuvWrdGiRQsULVoU7du3R+PGjXH27Nn0ehtERESZmxBy5CZ9bknMPp3ApElytu3kyktBiwF1p054Z2EB3L6N1hYWqFSpErZs2QIg9ur7oUOHUL16dVhZWaF27doIDg7WKWPnzp2oWrUqLCwsUKxYMUycOBHR0dHax1UqFZYsWYIvv/wSuXLlwtT/j2Q1ZcoUODo6wsbGBn369MHo0aNRuXJlALKFhampKR4+fKjzWkOHDoW7u3uy70vTtGfHjh0oUaIELCws0KRJE4SGhqZJ7Im5e/cuPD09AQC5c+eGSqWCj48PAOD9+/cYPHgwHB0dYWFhgbp16+LcuXNJlhUVFYVmzZqhTp062tqPlStXokyZMrCwsEDp0qWxePFinddWqVTYtm0bPD09YWVlhUqVKuH06dPJflaJefLkCapXr462bdvi/fv3qF69OuZo5k0B0KZNG5iamiIiIgKA7FytUql0hniNiopCr169YGNjgyJFimD58uUGxULJEJkEALF9+/ZPbuPu7i6GDBmis+63334Ttra22vtTp04VLi4uIjg4WAghRGBgoHB0dBRr165Nstx3796JV69eaW9BQUECgAgNDTX4/RARESnh7du3IigoSLx9+zZ2ZUSEEPIUP+NvERF6xz5lyhThnzu3EICI8PQUfn5+wtzcXAQEBIgjR44IAKJmzZoiICBA/Pvvv8Ld3V3Url1b+/xjx44JW1tb4e/vL27fvi3++usvUbRoUTFhwgTtNgCEo6Oj+O2338Tt27fFvXv3xNq1a4WFhYX47bffRHBwsJg4caKwtbUVlSpV0j6vZMmSYtasWdr7Hz58EHnz5hW//fZbsu/Lz89PmJqaiurVq4tTp06J8+fPixo1aqRJ7EmJjo4WW7duFQBEcHCwCA8PFy9fvhRCCDF48GBRsGBBsWfPHvHvv/8Kb29vkTt3bvHs2TMhhNB+1i9evBAvXrwQtWvXFo0bNxaRkZFCCCHWrl0rnJycxNatW8WdO3fE1q1bhYODg/D39xdCCBESEiIAiNKlS4tdu3aJ4OBg0b59e+Hi4iI+fvyo1+dlZ2cnhBDi/v37olSpUsLb21tER0cLIYQYPny4aNGihRBCCLVaLRwcHETevHnF3r17tfEVKlRIW56Li4twcHAQixYtEjdv3hTTp08XRkZG4vr160nGkOj36P9CQ0N5npiELJVYlChRQkybNk1n3e7duwUAERUVJYQQIiYmRowaNUqoVCphYmIiVCpVgufEN378eAEgwY07DBERZTVZNbF49+6dsLKyEhc3bpTPU6mEuHNH9O7dW3Tp0kV7snvw4EHtczTnAJr32qBBgwS/+WvWrBFOTk7a+wDE0KFDdbapWbOm8PX11VlXp04dncRi5syZokyZMtr7W7duFdbW1iJCj/fn5+cnAIgzZ85o1127dk0AEH///XeqYv+UuAmCRkREhDA1NRXr1q3Trvvw4YMoWLCgNnHSPO/atWuiYsWK4quvvhLv37/Xbu/m5ibWr1+v81qTJ08WtWrVEkLEJhYrV67UPv7vv/9qy0yOJrG4fv26KFy4sBg8eLBQq9Xax//44w9hZ2cnoqOjRWBgoChQoIAYMmSIGDVqlBBCiD59+oiuXbtqt3dxcRHdu3fX3ler1cLR0VEsWbIkyRiYWBgm240KtWnTJqxbtw7r16/HxYsXsWrVKsyZMwerVq1K8jljxozBq1evtLegoKAMjJiIiCidWVkBERH63U6c0K/MEyf0K8/KSq/ibt26haioKLj36oWDxsaAEJhbqhRWr16N27dva7erWLGidtnJyQkA8PjxYwDA5cuXMWnSJFhbW2tvffv2RXh4OKKiorTPq169us5rBwcHo0aNGjrr4t/38fHBrVu3cObMGQCyeVPHjh2RK1cuvd6fiYkJPoszelbp0qVhb2+Pa9eupSr2lLp9+zY+fvyIOnXqaNeZmpqiRo0a2lg0GjVqhOLFi2Pjxo0wMzMDIPvH3r59G71799aJdcqUKTr/J+DT/6vkvH37Fu7u7mjXrh1+/vlnqFQq7WPu7u548+YNLl26hKNHj8LDwwP169dHQEAAAODo0aOoX79+krGoVCoUKFBA71hIfyZKB5ASBQoUwKNHj3TWPXr0CLa2trC0tAQAfPfddxg9ejQ6d+4MAKhQoQLu3buH6dOnw9vbO9Fyzc3NYW5urr3/+vXrdHoHREREClCpAD1PgPH/31O9ttO3TD1o2sfv3r0bJa5fB/r1wxBra7Q+fhxmtrbak1ZTU1PtczQnm+r/d/SOiIjAxIkT0a5duwTlx53kTN9kIC5HR0e0atUKfn5+cHV1xd69e7UnsmkhPWM3VIsWLbB161YEBQWhQoUK2jgBYMWKFahZs6bO9sbGxjr3P/W/So65uTkaNmyIXbt24bvvvkOhQoW0j9nb26NSpUoICAjA6dOn0ahRI9SrVw+dOnXCjRs3cPPmTXh4eCQZiyYefWMh/WWpGotatWrh0KFDOusOHDiAWrVqae9HRUXByEj3bRkbG3PnISIiysTKli0Lc3Nz3L9/HwX79AGKFIHxixdwO38ehQsX1quMqlWrIjg4GMWLF09wi39uEFepUqUSdF5OrDNznz59sHHjRixfvhxubm46V/2TEx0djfPnz2vvBwcH4+XLlyhTpkyqYv8UTS1DTEyMdp2bmxvMzMxw8uRJ7bqPHz/i3LlzKFu2rM7zZ8yYAW9vbzRo0EDbmiN//vwoWLAg7ty5kyBOV1dXg+JMjJGREdasWYNq1arB09MT//33n87jHh4eOHLkCI4dO4b69evDwcEBZcqUwdSpU+Hk5ISSJUumWSykP0VrLCIiInR67IeEhCAwMBAODg4oUqQIxowZg7CwMKxevRoA0K9fPyxcuBAjR45Er169cPjwYWzatAm7d+/WltGqVStMnToVRYoUQbly5XDp0iXMnTsXvXr1yvD3R0RElOXkzQtYWHx6yFkLC7ldGrKxscGIESMwbNgwqNVqtOzQAXl++gmPxo3DPgAuLi7JljFu3Di0bNkSRYoUQfv27WFkZITLly/j6tWrmDJlSpLPGzRoEPr27Yvq1aujdu3a2LhxI/755x8UK1ZMZ7smTZrA1tYWU6ZMwaRJk1L0/kxNTTFo0CD88ssvMDExwcCBA/H5559rm1wZGvunuLi4QKVSYdeuXWjevDksLS1hbW2N/v3747vvvtOeb82aNQtRUVHoncicJHPmzEFMTAy++OILBAQEoHTp0pg4cSIGDx4MOzs7NG3aFO/fv8f58+fx4sULDB8+3KBYE2NsbIx169ahS5cu2tcvUKAAAKB+/fpYsGAB8uXLh9KlS2vXLVy4EB00s7hTxlOyg4emc1D8m7e3txBCCG9vb+Hh4ZHgOZUrVxZmZmaiWLFiws/PT+fx169fiyFDhogiRYoICwsLUaxYMfHDDz/odDpKDjvlEBFRVvWpTqd627dPCHNz2Ym6d28hLlzQvX1iNKLUUKvVYv78+aJUqVLCycREvPt/B/ALS5cm2hH50qVLAoAICQmJE/o+Ubt2bWFpaSlsbW1FjRo1xPLly7WPI4nBYiZNmiTy5s0rrK2tRa9evcTgwYPF559/nmC7sWPHCmNjY/Hff//p/b40nZG3bt0qihUrJszNzUXDhg0TjOpkaOyfMmnSJFGgQAGhUqm051dv374VgwYNEnnz5hXm5uaiTp064uzZs9rnJPZZDxo0SDg5OWlH3Vy3bp32fCx37tyiXr16Ytu2bUKI2M7bly5d0j7/xYsXAoA4cuSI3p+XxsePH0W7du1EmTJlxKNHj4QQQjx79kyoVCrRqVMn7Xbbt28XAMTSpUt1ynNxcRHz5s3TWVepUiUxfvz4JGNg523DqITglNTxPXjwAIULF0ZoaCicnZ2VDoeIiEhv7969Q0hICFxdXXXa5uvtxQvgs8+A27eBJk2A3buBeG3nM0yPHsDatYCPT4bPxt2oUSMUKFAAa9as0Vnfu3dvPHnyBH/88YfeZfn7+2Po0KGcATsL+dT3iOeJSctSfSyIiIgoHanVQPfuMqkoWhRYt065pAKInYl7wwbg2bN0e5moqCjMnTsX//77L65fv47x48fj4MGDOoO+vHr1CidOnMD69esxaNCgdIuFKCtjYkFERETS5MnAnj2yD8W2bUCePMrGU7MmUKWK7O/x22/p9jIqlQp79uxBvXr1UK1aNfz555/YunUrGjZsqN2mdevWaNy4Mfr164dGjRrpPL9Zs2Y6Q6/GvU2bNi3d4u7Xr1+Sr9uvX790e93UUurzovTHplCJYBUXERFlVQY3hdq9G2jZUi77+wNJDNGe4X79FejTB3B1BW7eVLYGJQlhYWF4+/Ztoo85ODjAwcEhXV738ePHSQ6Rb2trC0dHx3R53dRS6vNKCTaFMkyWmseCiIiI0sGtW7IJFAAMGJB5kgoA6NIF+O47ICQE2LcPaNFC6YgSiDvHQkZydHTMtMnDpyj1eVH6Y1MoIiKibEjvBgmRkUC7dsDLl0CtWsC8eekaV4pZWQE9e8rlxYuVjYVyDDboMQwTCyIiomxEM8NwVFRU8hsLAXz9NXDlCpA/P7BlC/D/SdUylf795d+9e4E7d5SNhXIEzfcn/ozd9GlsCkVERJSNGBsbw97eHo8fPwYAWFlZQaVSJb7twoUwXb8ewsQEH9auhXBw+PTEeEpxdoZpo0YwPnAA0QsWIHr6dKUjomxKCIGoqCg8fvwY9vb2MM6EfXoyMyYWRERE2YxmdmJNcpEYy/Pn4TJmDADg0Xff4UWhQrIfQyZl3aYNCh84APj54a6XF4Qhc3QQ6cne3l77PSL9MbEgIiLKZlQqFZycnODo6IiPHz8m3OC//2D+3XdQRUcjplMn2I8dC/skajUyjSJFIGbOhMn9+3A7dw4xXl5KR0TZlKmpKWsqDMTEgoiIKJsyNjZOeIL04YMcAerRI6BCBRj/+iuMLS2VCTClBgwARo+G6YoVMP36a6WjIaJ42HmbiIgoJxk2DDh9GrCzk5Pg5cqldET6690bMDcHzp8Hzp5VOhoiioeJBRERUU6xalXskK3r1gHFiysbT0rlzQt07CiXFy1SNhYiSoCJBRERUU5w6RLQr59cHj8+U040pxdfX/l340bg6VNlYyEiHUwsiIiIsrtnz+QkeO/eAc2bA+PGKR2R4WrUAKpVA96/B379VeloiCgOJhZERETZWUwM0LUrcPcuUKwYsHYtYJSFf/5Vqthai6VL5fsjokwhCx9ZiIiIKFnjxwN//QVYWgLbtwO5cysdUep17izfx927cjZuIsoUmFgQERFlVzt3AlOnyuWVK4GKFZWNJ61YWgK9esllduImyjSYWBAREWVHwcFAjx5yecgQ2RwqO+nfXzaL2rcPuHVL6WiICEwsiIiIsp+ICNlZ+80bwN0dmD1b6YjSnpsb0LSpXF6yRNlYiAgAEwsiIqLsRQjZTCgoCHByAjZtAkxNlY4qfWg6cfv5AVFRysZCREwsiIiIspWffgI2b5bJxJYtQIECSkeUfpo2BVxdgRcvgA0blI6GKMdjYkFERJRdHD4MjBoll+fPB2rXVjScdGdsHDvp36JFsraGiBTDxIKIiCg7CA0FOnUC1GrAy0t2bs4JevUCzM2BixeBv/9WOhqiHI2JBRERUVb37h3w1VfA06dA5cpy4jiVSumoMkbevHJeC4BDzxIpjIkFERFRVjd4MHDunJw0bts2Oc9DTqLpxL1pE/DkibKxEOVgTCyIiIiyspUrgRUrZA3F77/Lzsw5zWefyduHD8CvvyodDVGOxcSCiIgoqzp3LvZq/eTJQJMmysajpAED5N+lS4GYGGVjIcqhmFgQERFlRU+eyH4VHz4ArVsDY8YoHZGyOnUCHByAe/eA3buVjoYoR2JiQURElNVER8sOy6GhQMmSwKpVgFEO/0m3tAR695bL7MRNpIgcfhQiIiLKgn74Qc5ZkSuX7KxtZ6d0RJlD//6yr8lffwE3byodDVGOw8SCiIgoK9m6FZg1Sy77+QHlyikbT2bi6go0by6XlyxRNhaiHIiJBRERUVZx7Rrg4yOXR4wAOnRQNJxMSdOJ288PiIpSNhaiHIaJBRERUVbw+jXQti0QEQF4egLTpysdUebUtClQrBjw8iWwfr3S0RDlKEwsiIiIMjshZE1FcDDg7Axs2ACYmCgdVeZkZCT7WgCyE7cQysZDlIMwsSAiIsrsZs4Etm8HzMxkHwtHR6Ujytx69QIsLIDAQODMGaWjIcoxmFgQERFlZgcOyFGgAGDhQqBGDWXjyQocHIAuXeQyh54lyjBMLIiIiDKru3flCbJaLedo6NtX6YiyDk0n7s2bgcePlY2FKIdgYkFERJQZvX0rZ9Z+9gyoXl3WVpD+qleXtTsfPgArVyodDVGOwMSCiIgosxFCXnG/eBHIm1f2q7CwUDqqrMfXV/5dulTOVk5E6YqJBRERUWazbBng7y9HONqwAShSROmIsqaOHWViFhoK7N6tdDRE2R4TCyIioszkzBlg8GC5PH060KCBsvFkZRYWsm8KwE7cRBmAiQUREVFm8eiR7Ffx8aP8+913SkeU9X3zDaBSydG1btxQOhqibI2JBRERUWbw8SPQqRPw339AmTKAn588IabUcXUFWrSQy4sXKxsLUTbHxIKIiCgzGDUKOHoUsLEBtm2TfyltaDpx+/sDkZGKhkKUnTGxICIiUtqGDcC8eXJ51SqgdGll48luGjcGihcHXr0C1q9XOhqibIuJBRERkZKuXIntYDx6NNC2rbLxZEdGRkD//nJ50SI5nC8RpTkmFkREREp5+RJo1w6IigIaNgSmTFE6ouyrZ0/A0hK4fBk4dUrpaIiyJSYWRERESlCrgR49gFu35DwVv/8OGBsrHVX2lTs30KWLXObQs0TpgokFERGREqZOBXbtAszNZWftvHmVjij703Ti3rJFDu1LRGmKiQUREVFG27sXGD9eLi9ZAlSrpmw8OUXVqsDnn8uhfVesUDoaomyHiQUREVFGun0b6NpVdiDu10+2/aeMo6m1WLYMiI5WNhaibIaJBRERUUaJipIzar98CdSsCcyfr3REOU+HDrLZ2YMHwJ9/Kh0NUbbCxIKIiCgjCAF8/bUclcjRUbbzNzdXOqqcx9wc6NNHLrMTN1GaYmJBRESUERYuBNatkyM/bdoEODsrHVHO1a+fnNvi0CHg+nWloyHKNphYEBERpbcTJ4Dhw+Xy7NmAh4ey8eR0Li5Ay5ZyefFiZWMhykaYWBAREaWn8HDZrj86GujUCRg6VOmICIjtxL1qFRARoWwsRNkEEwsiIqL08uGDTCoePgTKlwd+/RVQqZSOigA503mJEsDr17KJGhGlGhMLIiKi9PLtt8DJk4CtrZwEL1cupSMiDSMjoH9/ubxokexcT0SpomhicezYMbRq1QoFCxaESqXCjh07kn1OQEAAqlatCnNzcxQvXhz+/v4JtgkLC0P37t2RJ08eWFpaokKFCjh//nzavwEiIqKkrFkjO2wDwNq18uo4ZS4+PoClJXDliuwHQ5QOUnq+GxAQAJVKleD28OFDne0WLVqEokWLwsLCAjVr1sTZs2fT8V3oR9HEIjIyEpUqVcIiPYd7CwkJQYsWLeDp6YnAwEAMHToUffr0wf79+7XbvHjxAnXq1IGpqSn27t2LoKAg/PTTT8idO3d6vQ0iIiJdgYFyaFkAGDsWaNVK0XAoCblzA926yWUOPUvpJKXnuxrBwcEIDw/X3hwdHbWPbdy4EcOHD8f48eNx8eJFVKpUCU2aNMHjx4/TOvwUUQmROer+VCoVtm/fjjZt2iS5zahRo7B7925cvXpVu65z5854+fIl9u3bBwAYPXo0Tp48iePHj+v92u/fv8f79++198PCwlC2bFmEhobCmcMBEhFRSjx/DlSvDoSEAM2ayUnYjI2VjoqSEhgIVKkCmJgAoaFAgQJKR0SZ3IMHD1C4cGEEBQWhUKFC2vXm5uYwT2ZuGn3OdwMCAuDp6YkXL17A3t4+0W1q1qyJzz77DAv/XyuqVqtRuHBhDBo0CKNHj07xe0orWaqPxenTp9GwYUOddU2aNMHp06e19//44w9Ur14dHTp0gKOjI6pUqYIVK1Z8stzp06fDzs5Oeytbtmy6xE9ERNlcTIy8Ah4SAri6yiZQTCoyt8qVgdq15ahdyZwvEMVVtmxZnfPH6dOnp2n5lStXhpOTExo1aoSTJ09q13/48AEXLlzQOSc2MjJCw4YNdc6JlZClEouHDx8if/78Ouvy58+P169f4+3btwCAO3fuYMmSJShRogT279+P/v37Y/DgwVi1alWS5Y4ZMwavXr3S3oKCgtL1fRARUTY1cSKwb59st799O+DgoHREpI8BA+TfZctkgkGkh6CgIJ3zxzFjxqRJuU5OTli6dCm2bt2KrVu3onDhwqhfvz4uXrwIAHj69CliYmISPSeO3w8jo5ko+urpQK1Wo3r16pg2bRoAoEqVKrh69SqWLl0Kb2/vRJ8Tv+rq9evXGRIrERFlI3/8AUyeLJeXLwcqVVI2HtJf+/bAsGFAWBiwcyfw1VdKR0RZgI2NDWxtbdO83FKlSqFUqVLa+7Vr18bt27cxb948rFmzJs1fLy1lqRqLAgUK4NGjRzrrHj16BFtbW1haWgKQWV78pkxlypTB/fv3MyxOIiLKYW7eBHr0kMuDBgHduysbD6WMuTnQt69cZiduyoRq1KiBW7duAQDy5s0LY2PjRM+JCyjcRyhLJRa1atXCoUOHdNYdOHAAtWrV0t6vU6cOgoODdba5ceMGXFxcMiRGIiLKYSIigHbt5ERrdeoAc+YoHREZ4ptv5NwWR44A164pHQ2RjsDAQDg5OQEAzMzMUK1aNZ1zYrVajUOHDumcEytB0cQiIiICgYGBCAwMBCCHkw0MDNTWLowZMwZeXl7a7fv164c7d+5g5MiRuH79OhYvXoxNmzZh2LBh2m2GDRuGM2fOYNq0abh16xbWr1+P5cuXw9fXN0PfGxER5QBCAH36AFevytGENm8GzMyUjooMUaQI8OWXcnnxYmVjoWwlpee78+fPx86dO3Hr1i1cvXoVQ4cOxeHDh3XOZYcPH44VK1Zg1apVuHbtGvr374/IyEj07NkzQ99bAkJBR44cEQAS3Ly9vYUQQnh7ewsPD48Ez6lcubIwMzMTxYoVE35+fgnK/fPPP0X58uWFubm5KF26tFi+fHmK4goNDRUARGhoqIHvjIiIcoS5c4UAhDAxEeLECaWjodT66y/5/7SxEeL1a6WjoUwqpeeJKT3fnTlzpnBzcxMWFhbCwcFB1K9fXxw+fDhBuQsWLBBFihQRZmZmokaNGuLMmTNp8fZSJdPMY5GZaMYn5jwWRESUpIAAoGFDOcTsggXAwIFKR0SppVYDZcoAN27IWov+/ZWOiDIhnicmLUv1sSAiIsoUHjwAOnWSSUX37gCb22YPRkaxQ88uWiSbuhGR3phYEBERpcT793J40seP5ZCyy5YBKpXSUVFa8fYGrKyAf/8Fjh9XOhqiLIWJBRERUUoMHQr8/TeQOzewbZs8CaXsw94+drhgDj1LlCLZboI8IiKidOPnByxdKmso1q0DihVTOiJKDwMGyEkOt20DwsOB/w/zSZTt3Lwph1h+/Fj2MYpr3LgUF8fEgoiISB8XLsR25p04EWjWTNl4KP1UqiTnJDl5UiYY48crHRFR2luxQh7T8uaVw2XHbdKpUhmUWLApFBERUXKePpWT4L1/D7RqBfzwg9IRUXrTdMhftgz4+FHZWIjSw5QpwNSpwMOHQGAgcOlS7O3iRYOKZGJBRET0KTExQJcuwP37QPHiwOrVcvQgyt6++grIn182hdq5U+loiNLeixdAhw5pWiSPjERERJ/y44/AwYOyk/b27bJzL2V/ZmZA375ymZ24KTvq0AH46680LZJ9LIiIiJKybRswY4Zc/vVXoHx5ZeOhjPX118C0aXIyxH//BcqVUzoiotT55ZfY5eLFgbFjgTNngAoVAFNT3W0HD05x8UwsiIiIEnP9upzTAACGDQM6d1Y2Hsp4hQsDrVvLmqrFi1lzQVnfvHm6962tgaNH5S0ulYqJBRERUZp48wZo2xaIiAA8PICZM5WOiJTi6ysTi9WrgenTAVtbpSMiMlxISLoWzz4WREREcQkB9OwpaywKFQI2bkzYRIByji++AEqXlknm2rVKR0OUdu7cSfMimVgQERHFNXs2sHWrTCa2bJEjA1HOpVLJCfMA2RRKCGXjIUorxYsDRYoAPXrIPmS3bqW6SCYWREREGocOAWPGyOVffgE+/1zZeChz8PICcuUCgoIStkUnyqpCQ2XzPktLYNYsoGRJwNkZ6NYNWLnSoCKZWBAREQHAvXtAp06AWi2bQn3zjdIRUWZhZwd07y6X2YGbsotChWQSsXw5EBwsbw0bAps2GXz8Y2JBRET07p2cEO3ZM6BqVXnyqFIpHRVlJpqZuLdvB8LClI2FKC1ERcl5LL7/HqhdG6hYEbh8GRg4UA61bQAmFkRElLMJIU8aL1wA8uSRP6iWlkpHRZlNhQqAu7uciX3FCqWjIUo9e3vZv+LdO2D0aOC//4BLl+SQtK1bG1QkEwsiIsrZVqwAfvsNMDICfv8dcHFROiLKrDS1FsuXAx8/KhsLUWo1by4T5Q0b5G3zZuDGjVQVycSCiIhyrr//BgYNkstTpwKNGikbD2VubdvKUcLCw2WTKKKsbMcO4OlTYN8+oFYt2SzK3T2274UBmFgQEVHO9Pix7Ffx4YM8YRw1SumIKLMzMwO+/lousxM3ZRcVKgB16sjk4rPP5LFx40aDimJiQUREOU90tBwBKiwMKFUK8PdnZ23SzzffAMbGwLFjwJUrSkdDZLi5c4Evv5R9y2rWlE1BS5aU8/g8eWJQkUwsiIgo5xk9GggIAKytZZMWW1ulI6KsolAhoE0bubxkiaKhEKWKJpFYvVo2iTp/PjbZyJ3boCKZWBARUc6yaRPw009y2d8fKFNG0XAoC9J04l6zBnj9WtlYiAx18iQwZw7QsqWcqyWup08NKpKJBRER5Rz//gv06iWXR46UfSyIUqp+fZmQRkTIq71EWVGXLnK47fgePZL7uAGYWBARUc7w6pXspB0ZCTRoIEeBIjKESgUMGCCXFy9O/OSMKLO7fx/o00d33cOHMqkoXdqgIplYEBFR9qdWA15ewM2bQOHCsm2xiYnSUVFW5uUl++hcuwYcOaJ0NEQpt2cPcOoUMHy4vP/ff4CHhxwlatMmg4pkYkFERNnf9OnAH38A5uZyZu18+ZSOiLI6W1s5azEgay2Ispp8+eTcFVu3yuSifn2gShV54cXIsBSBiQUREWVv+/YBY8fK5UWLgOrVlY2Hsg9Nc6gdO4AHDxQNhcgghQsDBw4A69YBNWrIpMLY2ODiDK4HVquBW7fkHBpqte5j9eoZHA8REVHaCQkBunaVbeC//hro3VvpiCg7KV9envQcOwYsXw5MmqR0RESfljt34nP2REUBf/4p57TQeP48xcUblFicOSOP0/fuJeyvpFIBMTGGlEpERJSGoqKAdu2AFy/klbhfflE6IsqOfH1jE4sff5SzcxNlVvPnp2vxBiUW/frJmuTduwEnJ05WSkREmYwQ8scqMFC2I96yRfavIEprbdvKk6HwcNl/p3NnpSMiSpq3d8qfM2OGPJ7a2ye7qUF9LG7eBKZNk0M429vLOTXi3oiIiBS1eLGcvMzICNi4UbYjJkoPpqaymR3ATtyUPU2bpnezKIMSi5o1Zf8KIiKiTOfUKWDoULk8axbg6aloOJQDfP217PB6/Dhw5YrS0RClrRTM02JQU6hBg4Bvv5VzaFSoIJP1uCpWNKRUIiKiVHr4EGjfHoiOBjp2jB2fnSg9FSwom0Rt2SJHHlu6VOmIiBRhUGLx1Vfyb69esetUKpnQsPM2EREp4uNHmUyEhwNlywK//spOgJRxfH1lYrF2LTBzJtuGU45kUGIREpLWYRAREaXSd9/Jpii2tsD27XJWZKKM4uEBlCsH/PsvsGoVMHiw0hERZTiDEgsXl7QOg4iIKBXWrwd+/lkur14NlCypbDyU86hUcsI8X1/ZiXvQINaYUY5j8Mzba9YAderIZoX37sl18+cDO3emUWRERET6+OcfoE8fufzDD0Dr1srGQzlXjx6ypiw4GDh8WOloiNKGuztgaanXpgYlFkuWyP5wzZsDL1/G9qmwt0/3eTeIiIhivXghO82+fQs0aQJMnKh0RJST2dgAXl5yedEiZWMh0odaDdy4AZw4ISd6jHvT2LNHztWiB4MSiwULgBUr5IUhY+PY9dWrc5Q1IiLKIGo10L07cOcOULSobA4V90eJSAkDBsi/O3cCoaHKxkL0KWfOAMWLy4np6tUD6tePvRk4TLdBiUVICFClSsL15uZAZKRBcRAREaXMpEnySpqFhZzx2MFB6YiIZAfu+vVl4rtsmdLRECWtXz9ZK3D1qpwA78WL2JueE+LFZ1Bi4eoKBAYmXL9vn0x6iIiI0tWuXbHNnpYuTfxqF5FSfH3l3xUrgPfvlY2FKCk3b8pZtcuUkf0Z7Ox0bwYwaFSo4cPld+bdOzl3xdmzwO+/A9OnAytXGhQHERGRfm7dkk2gANnsxNtb2XiI4mvdWo5u899/sjatSxelIyJKqGZNeTwtXjzNijQosejTR3YO//FHICoK6NpVfn9+/hno3DnNYiMiItIVGQm0awe8egXUqgXMm6d0REQJmZoC33wDjB8vO3EzsaDMaNAg4NtvgYcPgQoV5H4bV8WKKS5SJYQQKX3S69dy/iFAJhYREYCjo7yfxomPIh48eIDChQsjNDQUzs7OSodDRESArCLv1k1WkefPD1y8KK9qEWVG4eFAkSJAdLRsP16pktIRURrJNueJRon0iFCp5LFWpYod9jUlRRoSR4sWsU0Graxik4rgYNlfiYiIKM398otMKkxMgM2bmVRQ5ubkJGvXAA49S5lTSEjC2507sX8NYFBiYW0thw2Pjo5dd+2aTCq++sqgOIiIiJJ27JissgeAOXPkhE1EmZ2mE/e6dXLiL6LMxMXl0zcDGJRYbNsmm7d26yZrS65elUlFly6ynwUREVGaCQsDOnaU1fJduwKDBysdEZF+3N2B8uVlu/FVq5SOhiihNWuAOnVkDfC9e3Ld/PlyHhYDGJRYWFoCu3fLpk8dOwINGsiJJufONSgGIiKixH34ALRvDzx6JDsXLl8u2/4SZQUqVWytxeLFcm4LosxiyRI51Gvz5rJGTdOnwt5eJhcG0Lvz9uvXCdeFhwONGgEtWwIzZsSu13TszqqyTaccylnu3weePk368bx5ZUdCoqzE11eekNnbA+fPA25uSkdElDJv3gCFCsm/f/0lT5woS8s254lly8p5LNq0AWxsgMuXgWLFYpsifeqcIgl6Dzdrb5/4RSIh5NxEy5alqhM5EaXG/ftAqVJycpmkWFjIakYmF5RVrFolkwoAWLuWSQVlTTY2cq6VhQtlJ24mFpRZhIQkPrmoubkc2tsAeicWR44YVD4RZYSnTz+dVADy8adPmVhQ1nDxItCvn1yeMEEOR0iUVQ0YIBOLP/+UF4J4HKbMwNVVDoUcv6P2vn1yNm4D6J1YeHgYVD4REVHKPHsmh+l8904mFGPHKh0RUeqUKQN88QVw+LBs4jF1qtIREcn+Fb6+8lgrBHD2rBzSe/p0YOVKg4o0aOZtQPbx+PVXOcwsAJQrB/TqBdjZGVoiEaW7c+fkD5ylpdKRECVOM/LTvXuy6dOaNYlP4kSU1fj6ysRixQpg3DjZ3IRISX36yPOBH3+UI5d17SpHh/r5Z6BzZ4OKNOhorek/N28e8Py5vM2dK9ddvGhQHESUEfr1kx2m3N2BH36QHQkjIpSOiijWuHFyv7S0lGOb586tdEREaePLL2Un7idPgC1blI6GSI7M1K0bcPOmPBd4+BB48ADo3Ru4dcugIg1KLIYNk9+Pu3flcX/bNtn/o2VLYOhQg+IgooyQN68cvvPECTkSRJMmMtGoWRMYOVKOI/3qldJRUk61Y4fcLwFZDV+xoqLhEKUpExPgm2/kMmfipsygRQvg/Xu5bGUFODrK5eBgOSqUAQyusRg1Sn5HNExM5HnJ+fMGxUFEqXHunH7b7dsnr0ysXAn06CE7bMXEyHaVs2fLqwMODkDVqvIKwo4dsr07UXoLDpYTIgHAkCGySp4ou+nbFzA1BU6fBi5dUjoayumsrYG2bYHo6Nh1167JpOKrrwwq0qDEwtZWDmoQX2ioHFVNX8eOHUOrVq1QsGBBqFQq7NixI9nnBAQEoGrVqjA3N0fx4sXh7++f5LYzZsyASqXCUFajUHb255/AoEH6batSAcWLy2rO1atltePdu3JYz9695WNqtfzBmz9fHnDy5pUTkw0cCGzeLCcqI0pLb97Iztpv3shmerNnKx0RUfooUCD2hE0zlDKRUrZtk60UunWTnbc181d06SL7WRjAoMSiUyd5DrJxo0wmQkOBDRtkH5AuXfQvJzIyEpUqVcIiPasEQ0JC0KJFC3h6eiIwMBBDhw5Fnz59sH///gTbnjt3DsuWLUNFVqVTdrZ+vTz5//gx+Q6uFhYySYjPxUVeKV65UtZmPHggy+3XL3a4uatXZdV9x47yh7F0aVmlv3693J7IUELIkT+CgmSnwU2b5BVdouxKMxP3unXAixfKxkI5m6WlbAIdHCx/3xs0kOcDc+caXKTeM2/H9eED8N13cmI8Te2JqSnQv7+cgduQgQ5UKhW2b9+ONm3aJLnNqFGjsHv3bly9elW7rnPnznj58iX27dunXRcREYGqVati8eLFmDJlCipXroz5n5ia/P3793ivaWMGICwsDGXLls36MypS9rZkifyBEkJebZg48dP9IwydefvxY+DYMXk7ehT455+E2xQrJsek9vAA6tUDihZNfEZNovjmzJE/KKamcv+qVUvpiIjSlxBApUrAlSvyBG7YMKUjohTK0jNvv36dcF14uJy4sWVLeSKvYWub4uINSiw0oqKA27flspub7PdhKH0Si3r16qFq1ao6SYKfnx+GDh2KV3FOqLy9veHg4IB58+ahfv36ySYWEyZMwMSJExOsz5I7DOUMM2YAY8bI5QEDgAULMm5IzufPZefvo0fl7dIl2XwqrsKFY5MMDw+gRAkmGpTQ4cPyx0ytljViAwYoHRFRxli2TNYKFy8urxZzSOUsJUsnFkZGif8ea9IBlUouq1SyD2YKGTSPRa9esumVjY1seq0RGSmbev/2myGlJu/hw4fInz+/zrr8+fPj9evXePv2LSwtLbFhwwZcvHgR5/TtzApgzJgxGD58uPa+psaCKNMRQiYUM2fK+99/D0yZkrEn7Q4Ocli4L7+U91+9Ak6dik00zp+X7SPXrpU3QDafiptolC3LRCOnCw2V7WrVasDbW1Z5E+UU3brJEW9u3QIOHJAj9BFlhCNH0rV4gxKLVavkBdP4HbXfvpX9QdMrsUhOaGgohgwZggMHDsDCwkLv55mbm8M8Tvut14lVExEpTa2WTZ+WLpX3Z86UP0xKs7MDmjWTN0BeYTh9OjbR+PtvOTb2xo3yBshmWe7usc2nKlbkFbuc5N072YH16VOgShXZrI+JJuUk1taAjw/wyy+yEzcTC8ooHh7pWnyKEovXr+UFUyHk4B1xz91jYoA9e2KHwE0PBQoUwKN4I9I8evQItra2sLS0xIULF/D48WNUrVo1TlwxOHbsGBYuXIj379/D2Ng4/QIkSi8fP8ofofXr5QnY0qXA118rHVXicuUCGjaUN0CeRP79t0wyjh2TtRtPnwLbt8sbEDtpn6ZGo0oV3fGsKXsZPFgOkezgAGzdypngKWcaMEAmFrt2yZnmXVyUjohyopcvgV9/lcPMAkC5crJpkp2dQcWl6Jfb3l6e06hUQMmSCR9XqWT/0fRSq1Yt7NmzR2fdgQMHUOv/nf0aNGiAK1eu6Dzes2dPlC5dGqNGjWJSQVnT27dytIZdu+TJ9po1QOfOSkelPwuL2JoJQI7+cP58bKJx4oQ8sP35p7wB8mpenTqxz6teHTAzU+wtUBpauRJYsUL+YPz+O+DqqnRERMooVUqOwnPokLxYNH260hFRTnP+vKwts7QEatSQ6+bOBaZOBf76S85plUIp6rx99KisrfjiC3mRycEh9jEzM5lsFyyo/4tHRETg1v+nDK9SpQrmzp0LT09PODg4oEiRIhgzZgzCwsKwevVqAHK42fLly8PX1xe9evXC4cOHMXjwYOzevRtNkqhG1KfzdnxZulMOZS9v3si+DAEB8gR9yxY5U2Z2Eh0tO4BrEo3jx2WiEZelpRwtSJNo1KypW2VKWcPZs7Jm6sMH+cP1/fdKR0SkrO3b5RwuefPKfkc8rmUJ2eY80d1dDiCwYkVsK4HoaDl/xJ078jc5hQwaFerePTlqZXJNYgcMACZNSnzofEBOdufp6Zlgvbe3N/z9/eHj44O7d+8iICBA5znDhg1DUFAQnJ2dMXbsWPj4+CQZAxMLyrKePZP9Fs6dkx2a/vwz3dtGZgoxMXIYRk2iceyYbDoVl5mZTC40iUatWrIJFmVeT54A1arJk6fWreXETOxXQzlddLQcrjs0VHZS7dFD6YhID9nmPNHSUl7YK11ad31QkGwpEBWV4iJTNdxscmxtgcBA+Z3JSrLNDkNZ13//yWE4g4KAPHmAffvklzwnUqtl20/NPBpHj8rO4HGZmMjPR5No1Klj0PjblE6io2V1++HDsh3t2bMGt98lynamTgV+/BH4/HM58AVletnmPDF/ftm8unFj3fX798uJ8uL1a9ZHul4uSr+UhSgbu3MHqFs3dibiY8dyblIByKva5crJ4Ug3bJBJV3CwrLrt3l3OmREdDZw5I0fKat4cyJ1bfmbffgvs3Cnn3iDlfP+9TCpy5ZJNP5hUEMXq00dOEHnmDHDxotLRUE7SqRPQu7ccsTE0VN42bJD7ZJcuBhXJYVeIMpN//5U1FeHhsqrv4EF2bo1PM3pEyZLy4CeEbJ+pqc04elQmZxcuyNvcufI5FSrEzqVRr176DmFHsbZsAWbPlst+fnIOEyKKlT8/0L69HMxg0SI5Qg9RRpgzR/4+ennJC3SATHL799edgTsF2MCVKLM4d06e8IaHyyv0J04wqdCHSgUULSonWfvtN+D2bXnVZd06OSRv6dIy+fjnHzlDeYcO8oe8bFk58+3vv8taEEp7QUFAz55yecQI+dkTUUK+vvLv+vWsYc2Gjh07hlatWqFgwYJQqVTYsWOH3s89efIkTExMULlyZZ31EyZMgEql0rmVjt9XIjlmZnLG6xcvZN+FwEC5/82bB8SZ3y0lmFgQZQYBAXK4tefP5ZBvR48CTk5KR5V1OTsDXbsCy5bJ/hkPHwKbNskf7/Ll5TbXrsnHu3YFChUCSpSQVcKrV8saEEqd16+Btm2BiAjA05NDaRJ9Su3aQKVKct4fPz+lo6E0FhkZiUqVKmHRokUpet7Lly/h5eWFBg0aJPp4uXLlEB4err2dOHEiZYH16iVHn7SykrX6FSrI5chI+ZgB0rXzto0NcPkyO28TfdKuXbIa/P17eQK2c2fCae0pbT17Joe11Yw8FRgoO4nHVaRIbGdwDw/AzY2zQ+tLrZYza+/YIZO8CxfY9IwoOStWyFpWNzfgxg2OmpaJpeY8UaVSYfv27WjTpk2y23bu3BklSpSAsbExduzYgcDAQO1jEyZMSLAuxYyNZSuJ+Mfnp0+BAgVim0elQIr32uhoOYTsgwfJb9u9OwdmIfqk33+XV3XfvwdatZLT1zOpSH958gBt2sjq3gsXZE3Rrl3Ad9/JYWyNjYH79+VoGX36yNoMZ2fZmW3pUlnbwdEpkjZzpkwqzMzkpEdMKoiS17WrHNjg9m05ORllem/evMHr16+1t/fv36dZ2X5+frhz5w7Gjx+f5DY3b95EwYIFUaxYMXTr1g3379/Xr/DXr4FXr+Tv2Js38r7m9uKFPBcx8Lid4s7bJiayH56XV/LbLlliSEg5U0yMvIAaHi5bwLi7y3MbysaWLpWTvQgBdOsmq79NTVNdLPclA9jZyYkHNZMPRkQAp07FDnF79qzsh7Fhg7wBQL58sk+MpkajfPlseYUxxfvTX3/JoTMBYOHC2NlcicDj0yflygX4+Mg274sWAU2bKh1RppYZ9qWy8QajGD9+PCZMmJDqcm/evInRo0fj+PHjMDFJ/FS9Zs2a8Pf3R6lSpRAeHo6JEyfC3d0dV69ehU1yFyjt7WUNvGYwlPhUKmDiRMOCFwb48ksh/P0NeWbWEBoaKgCI0NDQDHm9rVuFcHYWQp5hypuzs1xP2dSMGbH/7P79hYiJSZNiuS+lk6goIQ4fFmLCBCE8PYWwsND9kAEhcueWB8effhLi3DkhPn5UOupUS/H+FBIihIOD3LB374wMlbIAHp/0EBwsPxiVSog7d5SOJtNSel/SnCcGBQWJV69eaW/v3r1L9rkAxPbt25N8PDo6WlSvXl0sWbJEu278+PGiUqVKnyz3xYsXwtbWVqxcuTL5NxAQIMSRI3I/27ZN3tfcTp0SIiws+TKSYFBisWSJEAUKCPHtt0KsXy/Ezp26t6wuIxOLrVvl/zX+OYpKJW884GYzarUQo0fH/qPHjJHr0gD3pQz07p0QJ04IMXWqEI0bC5ErV8IP3sZGiGbNZBJ56pQQHz4oHXWKpHh/iooSompVuVH16kK8fatI3JQ58fiUAo0ayQ9n5EilI8mUMsO+lJrzxOQSixcvXggAwtjYWHtTqVTadYcOHUryudWrVxejR4/WP5i7d/U7B+nfX4gnT/Qq0qDO25+q7VepZPVUVpZRnbdjYuQomUn1V1Gp5GA1//7LquJsQa2G2TBfmP66FADwYdIMfBw+Kk2KjomRo6eGhSX+OPeldPbxI4wuX4LxiaMwOnEUxqeOQ/X6tc4mwsoK6pq1EVPXAzF16kFdvQZgYaFQwJ+W4v1JCJj17wXTtf4QefLi7YkLEIWLZGjMlHnx+JQyxrt2wqJzGwiHPIi68SDTHieUoM++5OwMhISk776Unp231Wo1goKCdNYtXrwYhw8fxpYtW+Dq6opcuXIleF5ERASKFCmCCRMmYPDgwSmKKVm2tnKQEz1GYzJogrz4g6eQYY4f/3QneCHk45ykNuszwUf4wwfdsB5qqNAfS7B83DfAuIx5fe5L6c0UQI3/376DEWJQEf/AA0fhgaOoh2PIE/UcxkcOwvjIQQDAO5jjDD7HUXjgGOrhNGrhLayUfBN6i78/fYNlWAp/xMAIjZ9twOEyTCpIfzw+6TJCS9xBEbg8v4/+eTdhDfTo1EoA5L4UGirPr+rXVzqaWBEREbh165b2fkhICAIDA+Hg4IAiRYpgzJgxCAsLw+rVq2FkZITymmHR/8/R0REWFhY660eMGIFWrVrBxcUF//33H8aPHw9jY2N0MXDG7E9KQR1EqmfefveOybShwsOVjoAygjneYRM64kv8iY8wgRdWYwPS4YtPmYYaxghEFQSiCn7GUKigRlkE6SQaBfAI9XEU9XEUAPABpjiHz3AM9XAUHjiJOohA5h8h7HOcxi+QV8fGYDoOI/Hx1olIP2oYYxm+wTT8AF8sYmJhgMx2fnX+/Hl4enpq7w8fPhwA4O3tDX9/f4SHh+s/otP/PXjwAF26dMGzZ8+QL18+1K1bF2fOnEG+fPnSNPaUMqgpVEwMMG2aHNTm0SM53HKxYsDYsbJpT+/e6RBpBsqoplABAXLaguTs2SMHn6Es6M0bWHRqDeNjRyAsLPB+zWbENGuZ5i9z7BjQvHny23FfyiSEgOrmDRifOArjk8dgdOIojMJ0qy+FsTHUlatCXaeebD5Vqy6QO3eGhKfv/nRw3SN4jqgKo/D/EN36K7xfu5lzfVACPD4Z4PFjWJUuDNWHD3h77BzUVasrHVGmoO++dORI+tZY5Lj5zlIwMZ1BicWkScCqVfJv377A1avytTZuBObPB06fNiTqzCOj+1iEhSVey5RRbQUpnTx7BjRrBpw7B1hbA3/+mW5HOu5LWZwQ8p+jmbDv6FF5Py6VCqhYMXZ423r1gLx50yUcffanooU+4rZrQ6iOHwPKlAH+/ptzsFCieHwyUPfuwLp1cghazsYNIPPsS0wskmbQoOurVwPLl8uh9+P+4ypVAq5fN6TEnMnYWA5XDSS8yKe5P38+D7RZ0n//yZO/c+cABwfg8OF0vXzCfSmLU6nkAbtnT3kCceeOnKBv7Vp59aZkSfkrevky8MsvclbrfPmAcuXkXCgbN6Zp3b8++9P+yqNkUmFjA2zbxqSCksTjk4F8feXfDRvkhSrivpQFGJRYhIUBxYsnXK9WAx8/pjaknKVdO2DLFjkiRlzOznJ9u3bKxEWpEBIiZ+r59185a8+xY8Bnn6X7y3JfymYKF5ZXb5YvB4KDZbK6caNMJMqVk9sEBcmZSDt3BgoWlAlI374yIUlhe934PrU/nRnyO0rsmidXrFoFlC6dqtei7I/HJwN8/jlQpYrszMoaCy3uS2kkOlo2PfrUKEIa3bvLkaH0YFBTqGrVgGHD5OvErR2ZNAk4cED2xs/KlKjiygwzSFIaCAoCGjWSJ4HFiskvhB5Vh2mJ+1IO8eQJcOKEbDZ19Kg8EMc/nBctqtt0qlixFPeBSLA/2V+BcZ3PgagoYMwY2eGOSE88PqXQypXyYkGxYsDNm58e7z+HUXJfyjZNoWxsgCtX5G9FGjEosdi5E/D2lr8pkybJWb+Dg2UTqV275HlVVpZtdhjKWOfPA02byirrcuWAv/6SV5GJMsKLF8DJk7GJxsWLCScVKlQoNsnw8ABKlUo60bh/H3j6VHfdmzfyitKDB0DdunIECp4VEqWfqCj5vX35Eti9W7+ey5Tuss15YuvWsorH2zvNijQosQBkljhpkrxIFhEBVK0KjBsHNG6cZrEpJtvsMJRxjh4FWrWSJ16ffQbs3QvkyaN0VJSTvXkDnDoVm2icO5ewrWr+/DLJ0CQa5crJK6L378uk4927pMs3N5dDAhbhnBVE6Wr4cGDePJlU7N6tdDSEbHSeuHSprB3o1k02R4o/8d6XX6a4SIMTi+ws2+wwlDF27wbat5cnYfXrA3/8wY6slPlERQFnzsSOPHX6NPD+ve42Dg6xTabmzk2+zAsX5FUlIko/N2/K/lMqFXDrVoY3r6WEss154qea1qlUCWu99ZCqCfLOnweuXZPLZcvKZIcoR/n9d8DLS3aCatVKdq61tFQ6KqKErKyAL76QN0AmFWfPxiYaJ08Cz58DO3YoGiYRxVOiBNCkCbB/v7zCPGuW0hFRdqFWp3mRBiUWDx4AXbrI3yF7e7nu5Uugdm05KlpWTt6I9LZsGdC/v+ww27Ur4O8PmJoqHRWRfszNZW9Hd3d5/+NHWQNx7JisdTt5Utn4iCjWgAEysfj1V9l0hRewKK29ewdYWKS6GIOGF+jTR/4GXbsmL3A9fy6X1Wr5GFG2N2sW0K+fTCr69QPWrGFSQVmbqakc3nLkSDlXBhFlHi1aAC4u8oRr40alo6HsIiYGmDxZDhBgbS3nUAKAsWNlEmsAgxKLo0fl0OmlSsWuK1UKWLBAXuwiyraEAL7/Hhg1St4fPRpYvJhDABIRUfoxNpYXsQBg0SJlY6HsY+pU2dpi1izAzCx2ffnycqhjAxh0NlS4cOIT4cXEcHRNysbUajkT6vTp8v706fKWwnkBiIiIUqx3b3nyd/687B9FlFqrV8tJWLt10x06vFIl4Pp1g4o0KLGYPRsYNEju2xrnzwNDhgBz5hgUB1Hm9vGj7KS9ZIlMJJYskbUVREREGSFfPqBTJ7m8eLGysVD2EBYGFC+ecL1anXgNgh4MSix8fIDAQKBmTdn/z9xcLl+8CPTqJUcs1NyIsrx37+RwsuvWyYx+7drYKmmi7Chv3uQ78VlYyO2IKOMMGCD/btiQcAJLopQqW1ZOTBffli1AlSoGFWnQqFDz5xv0WkRZz5s3cmbKI0dkBr15sxxWlig7K1IECA7+9IlL3rycHI8oo9WsKeeOuXgR+O03OdgCkaHGjZOzboeFyVqKbdvksX/1amDXLoOKTNcJ8mbMkBd2NUPSZhXZZuITSp3nz4FmzWRbVmtr4M8/5QR4RERESvntN9nfomhROWFe3LbxlCGy1Xni8ePApEnA5ctARIRMXMeNAxo3Nqi4dE0sbG1lk6msNklkttphyDDh4fJLdfWqbNO3bx/w2WdKR0VERDldVJScMOzFC3nBq2VLpSPKcXiemLR0HSMz/VIWonQUEgLUrSuTCicnOYYykwoiIsoMrKxkh1aAnbgpbZw/L+fjWrNGTpSaChx8nyiuoCCZVNy5A7i6AidOAOXKKR0VERFRLM0AIvv2AbdvKxsLZV0PHgDu7kCNGnJo1yFD5IXUunXlYwZgYkGkcf48UK8e8N9/cqSEEyeyXjs+IiLK/ooXB5o2lU1DlixROhrKqvr0kcPKXrsm+5U+fy6X1Wr5mAGYWBABcjr5L74Anj0DqleXzZ842yMREWVWvr7y72+/yX4XRCl19KhMTEuVil1XqhSwYIE8DzIAEwui3bvllZ83bwAPD+DQISBPHqWjIiIiSlqzZnJkqBcv5LwWRClVuHDiE+HFxBh8cTVdEwt3d8DSMj1fgSiVNmwA2rSRk+C1bAns3SuHMyMiIsrMjI2B/v3l8qJFHDGHUm72bGDQINkUXOP8ednXYs4cg4o0aLjZixcBU1OgQgV5f+dOwM9PNkufMAEwMzMolkyDw4jlEMuXyw5wQgBduwL+/nLHJiIiygqePpVDz75/D5w5IyfQo3SXbc4Tc+eWzeiiowGT/8+ZrVnOlUt32+fP9SrSoJm3v/kGGD1aJhZ37gCdOwNt28pJiaOiODM3ZQGzZ8fOWNqvn7zaY8SWgURElIXkzQt06iRnSl60iIkFpUw6nLAblFjcuAFUriyXN2+WA+msXw+cPCmTDCYWlGkJAfz4IzBtmrw/erRcVqmUjYuIiMgQvr4ysdi4EfjpJyBfPqUjoqzC21u/7WbMAF6+BOztk93UoEu0QsiRqADg4EGgeXO5XLiwrJUjypTUamDgwNikYvp0eWNSQUREWVWNGnI0ww8fgF9/VToayo6mTdO7KZRBiUX16sCUKXKCvqNHgRYt5PqQECB/fkNKJEpnHz/KzHzxYplILFkiayuIiIiyOs3Qs0uXyhF9iNJSCrpjG5RYzJ8vO3APHAj88IOcpwUAtmwBatc2pESidPTuHdC+PbB2rRxFY+3a2FlLiYiIsrpOnQAHB+DePWDPHqWjoRzMoD4WFSsCV64kXD97tjxvI8o03ryRw8kePgyYm8tOQa1aKR0VERFR2rG0BHr1kkOELlrE3zlSTKqGwTl/XjaHWrNGLltYcLROykSePwcaNZJJhbU1sG8fD7ZERJQ99e8vm/ru3w/cvKl0NJRDGZRYPHggJ7+rUUPOoTFkiFyuW1c+RqS48HA5i/bff8vq4cOHgfr1lY6KiIgofRQrJmfjBmQ/QiIFGJRY9Okj+8JeuyYvCj9/LpfVavkYkaLu3pWZ79WrgJMTcOwY8NlnSkdFRESUvjSduP385MRiRGnB3V02t9ODQYnF0aMyGS5VKnZdqVLAggXyHI5IMdeuyaqz27cBV1fgxAmgXDmloyIiIkp/TZvK376XL4Hff1c6GsrsPDzkHChv3356uz175IVaPRiUWBQuLGss4ouJAQoWNKREojRw4YLMqsPCgLJlZVJRrJjSUREREWUMIyPZ1wKQnbhTMEwo5UBVqgAjRgAFCgB9+wJnzqS6SIMSi9mzgUGDZIdtjfPnZV+LOXNSHRNRyh07Bnh6As+eyYlWjh1jlktERDlPr15yNJ1Ll9LkRJGysfnzgf/+k03nHj8G6tWTF2bnzAEePTKoSIMSCx8fIDAQqFlTjuBpbi6XL16U+7ODQ+yNKN3t2QM0aSKHlvXwAA4dAvLkUToqIiKijJcnD9C5s1xetEjZWCjzMzEB2rUDdu6UIzB17QqMHSubJ2mG609JcYbEMH++Ic8iSgcbNwLduwPR0UDLlsCmTXp3MCIiIsqWfH0Bf385d9PcuYCjo9IRUWZ39qysudiwQe4vPj6yaXnLlsCAAXo3STIosfD2NuRZRGlsxQrgm29kG9IuXYBVqziRChERUfXqch6As2eBX38FxoxROiLKjB4/lpPR+fnJuU9atZKd/ps0kXOiADLBaNo0fRMLQHbU3rFDDsIDyIF3vvySM29TBpkzB/juO7ncrx+wcCF3PiIiIo0BA2RisXQpMHIkfyMpIWdnwM1N9mPw8QHy5Uu4TcWKKRqy36A+FrduAWXKAF5ewLZt8ta9u0wubt82pEQiPQkB/PhjbFIxahSweDEPmERERHF16iT7W9y/D+zapXQ0lBkdOiRrCL77LvGkAgBsbYEjR/Qu0qDEYvBgmeCEhsoO2xcvyv3W1VU+RpQu1Go5HNnUqfL+9OnAjBmx1XVEREQkWVgAvXvLZXbipsS4u6d5kQY1hTp6VI5gFnfUpzx55DlenTppFRpRHNHRQM+ewNq1MpFYtCh2rG4iIiJKqF8/OUfAgQPAjRtAyZJKR0SZSZUqiV+cValkYlq8uGwi5empd5EG1ViYm8uRPeOLiADMzAwpkegT3r0D2reXSYWxsexoxKSCiIjo01xdgRYt5PKSJcrGQplP06bAnTtArlwyefD0BKytZb+Gzz4DwsOBhg3lULR6MiixaNkS+Ppr4O+/ZZN3IWQNRr9+sgO3vo4dO4ZWrVqhYMGCUKlU2LFjR7LPCQgIQNWqVWFubo7ixYvD399f5/Hp06fjs88+g42NDRwdHdGmTRsEBwen7A1S5hERIQ+KO3fKjHb7dqBbN6WjIiIiyhoGDJB//fyAyEhlY6HM5elT4NtvgePHgZ9+krdjx+Rs3JGRwF9/yX6tkyfrXaRBicUvv8g+FrVqyZoSCwvZBKp4ceDnn/UvJzIyEpUqVcIiPdv+hYSEoEWLFvD09ERgYCCGDh2KPn36YP/+/dptjh49Cl9fX5w5cwYHDhzAx48f0bhxY0Tyy5T1PH8uM+XDh2UGvXevHAqNiIiI9NOkiTxpe/UKWL9e6WgoM9m0SQ7XH1/nzvIxQD6eggv0BvWxsLeXF5Bv3gSuX5frypSRiUVKNGvWDM2aNdN7+6VLl8LV1RU//fTT/1+zDE6cOIF58+ahSZMmAIB9+/bpPMff3x+Ojo64cOEC6tWrl7IASTkPHwKNGwNXrsjOPHv3yjG5iYiISH9GRrL58IgRsn9inz4c9IQkCwvg1KmEJ/CnTsnHADlwjmZZDwbPYwEAJUrIW0Y5ffo0GjZsqLOuSZMmGDp0aJLPefXqFQDAIW5P83jev3+P9+/fa++/SawDCWWcu3dlTcXt24CTk6yKK19e6aiIiIiypp49ZZOWy5eB06eB2rWVjogyg0GDZD+GCxdi56o4dw5YuRL4/nt5f/9+oHJlvYvUO7EYPlz/OOfO1X/blHj48CHy58+vsy5//vx4/fo13r59C0tLS53H1Go1hg4dijp16qD8J05Mp0+fjokTJ6ZLzJRC164BjRrJaeRdXeVIFm5uSkdFRESUdTk4AF27Ar/9JmstmFgQIJNNV1c5yfCaNXJdqVLAihVyfwFk4pGCAXP0Tiz8/ORFYxMTWYMmROLbZabaNV9fX1y9ehUnTpz45HZjxozB8DiZU1hYGMqWLZve4VF8Fy/KtqBPnwJly8qaikKFlI6KiIgo6xswQCYWmzfLK8DxLtRSDhMdDUybJmfd/tSgOPEu2idH78Ti1Stg61bA0REoVkzWlOTJk6LXSrUCBQrg0aNHOusePXoEW1vbBLUVAwcOxK5du3Ds2DE4Ozt/slxzc3OYm5tr779+/Trtgib9HD8uhxt7/RqoXl32qcibV+moiIiIsodq1YCaNeWQnitXAj/8oHREpCQTE2DWLMDLK02L1XtUqNy5gZAQuXz3ruzLkdFq1aqFQ4cO6aw7cOAAatWqpb0vhMDAgQOxfft2HD58GK6urhkdJqXU3r2yo/br14CHh5xinkkFERFR2vL1lX+XLpVXrClna9BAznqdhvSusfjqK6BePaBgQdncqXp1OVdZYu7c0a/MiIgI3Lp1S3s/JCQEgYGBcHBwQJEiRTBmzBiEhYVh9erVAIB+/fph4cKFGDlyJHr16oXDhw9j06ZN2L17t7YMX19frF+/Hjt37oSNjQ0ePnwIALCzs0tQq0GZwKZNsgouOlrOV7F5c4qr3YiIiEgPHTrITrMPHgC7dgFt2igdESmpWTNg9Gg5Ame1anKivLhSMjnd/6mESKq3REL79gG3bgGDBwOTJgE2NolvN2SIfuUFBATAM5Fpwr29veHv7w8fHx/cvXsXAQEBOs8ZNmwYgoKC4OzsjLFjx8LHxyf2DSXRycPPz09nu0958OABChcujNDQ0GSbUVEqrFwpZ1oUQo6ZvHo1YGqqdFRERETZ15gxwIwZcvTFAweUjiZLyjbniUafaLikUgExMSkuMkWJhUbPnnKSvKQSi6wu2+wwmdlPP8kxtQHgm2/kKBVJVYERERFR2rh7V3aWFUJORlaqlNIRZTk8T0yaQTNv+/ll36SC0pkQwNixsUnFyJHAkiVMKoiIiDJC0aJysBQAWLxY0VAoE3n3Lk2KMSixIDKIWi3b0U2ZIu9Pnw7MnJm5xigmIiLK7jSduP39gYgIRUMhBcXEAJMny6H9ra1jO0mPHQv8+qtBRTKxoIwRHQ34+MhJWADZ9Gn0aEVDIiIiypEaNQKKF5ejMa5fr3Q0pJSpU2VyOWsWYGYWu758edkP1gBMLCj9vXsnR6JYs0Y2eVqzRk7UQ0RERBnPyCj2d3jRoqRnPabsbfVqYPlyOTpn3CbplSrJ/jcGYGJB6SsiQrbl3LEDMDcHtm0DundXOioiIqKczcdHDu/+zz/AyZNKR0NKCAuTNVfxqdXAx48GFcnEgtLP8+eyuvXQITk28p49Bo2JTERERGksd26ga1e5vGiRsrGQMsqWBY4fT7h+yxagShWDitR7gjyiFHn4UM6mfeWKPHjt3QvUrKl0VERERKTh6ys76W7dKn+3CxRQOiLKSOPGAd7esuZCrZatSoKDZROpXbsMKpI1FpT27t0D3N1lUlGgAHDsGJMKIiKizKZKFaBWLdnsxcDOupSFtW4N/PkncPCgbFkybhxw7Zpc16iRQUUysaC0df06ULeunKK9aFHgxAk5ugARERFlPpqhZ5ctkyM4Us7i7i5nYH/8GIiKkudtjRsbXBwTC0o7Fy/KHfTBA6BMGblzurkpHRURERElpX17IF8++dv9xx9KR0NK+PBB/v/v39e9GYCJBaWN48cBT0/g6VOgWjXZ/KlQIaWjIiIiok8xNwf69JHL7MSds9y8KS8IW1oCLi6Aq6u8FS0q/xqAnbcp9fbtA9q1A96+BerVk23zbG2VjoqIiIj00a8fMHMmcPiwbGNfpozSEVFG8PEBTExkR20nJ0ClSnWRTCwodTZvlhOrfPwING8uhyiztFQ6KiIiItJXkSJAq1bAzp3A4sXAggVKR0QZITAQuHABKF06zYpkUygy3K+/Ap07y6SiUydg+3YmFURERFmRphP3qlVyclvK/sqWlU3Y0xATCzLM3LmyTaZaDXz9NbBuHWBmpnRUREREZIgGDYASJYA3b4C1a5WOhjLCzJnAyJFAQADw7Bnw+rXuzQBMLChlhJDjHH/7rbz/3XfA0qWAsbGycREREZHhjIyAAQPk8qJF8veesreGDYEzZ4AvvgAcHeWExrlzA/b28q8BmFiQ/tRqYMgQYPJkeX/aNJntpkFnHyIiIlKYjw9gZQVcvSpHe6Q0cezYMbRq1QoFCxaESqXCjh079H7uyZMnYWJigsqVKyd4bNGiRShatCgsLCxQs2ZNnD17NmWBHTkSezt8OPamuW8AJhakn+hooGfP2A5dixYBY8YwqSAiIsou7O3lgCwAh55NQ5GRkahUqRIWpfAzffnyJby8vNCgQYMEj23cuBHDhw/H+PHjcfHiRVSqVAlNmjTB48eP9X8BDw9ZU7ViBTB6NFC8uFx3/77BLVGYWFDy3r8HOnQAVq+WO9qaNbHVpURERJR9aH7ft20DwsOVjSWbaNasGaZMmYK2bdum6Hn9+vVD165dUatWrQSPzZ07F3379kXPnj1RtmxZLF26FFZWVvjtt9/0f4GtW4EmTeTAO5cuyfM9AHj1SrZKMQATC/q0iAigZUtgxw7ZOXvrVqB7d6WjIiIiovRQuTJQu7ZsqbBihdLRZGpv3rzB69evtbf3mhPzNODn54c7d+5g/PjxCR778OEDLly4gIYNG2rXGRkZoWHDhjh9+rT+LzJliuwnu2IFYGoau75OHeDiRYPiZmJBSXvxAmjUCDh4EMiVC9izB2jdWumoiIiIKD1php5dtkwOKU+JKlu2LOzs7LS36dOnp0m5N2/exOjRo7F27VqYmCSccu7p06eIiYlB/vz5ddbnz58fDx8+1P+FgoPlxMbx2dkBL1+mMGqJiQUl7uFDoH59OVpA7tzAoUNyKDoiIiLK3r76So4S9N9/ctI8SlRQUBBevXqlvY0ZMybVZcbExKBr166YOHEiSpYsmQZRfkKBAsCtWwnXnzgBFCtmUJFMLCihe/cAd3fgn3/kTnf0KFCzptJRERERUUYwNwf69pXL7MSdJBsbG9ja2mpv5ubmqS7zzZs3OH/+PAYOHAgTExOYmJhg0qRJuHz5MkxMTHD48GHkzZsXxsbGePTokc5zHz16hAIFCuj/Yn37ytE+//5bDsbz339yXrIRI4D+/Q2Kn4kF6bp+HahbV2awLi5yuLkKFZSOioiIiDLSN9/IEYMCAoCgIKWjyTFsbW1x5coVBAYGam/9+vVDqVKlEBgYiJo1a8LMzAzVqlXDoUOHtM9Tq9U4dOhQoh29kzR6NNC1q2yREhEhm0X16SP/94MGGRR/woZblHNduiRHB3jyBChdGjhwAHB2VjoqIiIiymiFCwNffikHb1m8GFi4UOmIsqyIiAjcitPkKCQkBIGBgXBwcECRIkUwZswYhIWFYfXq1TAyMkL58uV1nu/o6AgLCwud9cOHD4e3tzeqV6+OGjVqYP78+YiMjETPnj31D0ylAn74QU52fOuWTC7KlgWsrQ1+r0wsSDpxAmjRQk7hXrUqsG8fkC+f0lERERGRUnx9ZWKxejUwfTpgY6N0RFnS+fPn4enpqb0/fPhwAIC3tzf8/f0RHh6O+/fvp6jMTp064cmTJxg3bhwePnyIypUrY9++fQk6dOvFzEwmFGlAJQTnbI/vwYMHKFy4MEJDQ+GcE67Y79sHtGsHvH0r+1b8+accEYCIiIhyLiGAMmXk6EGLFnEOq//LceeJKcA+Fjnd5s2yqvPtW6BZM5lkMKkgIiIilSo2mVi0SCYaRJ/AxCIn++03oHNnOUZ1p06yutPKSumoiIiIKLPw9pbnBkFBwLFjSkdDmRwTi5xq3jygd29ArZbDja1bJ9vYEREREWnY2QHdu8tlDj1LyWBikdMIAYwfD/y/4xBGjJAzaxobKxsXERERZU6ambi3b5dzHRAlgYlFTqJWA0OHApMmyftTpwKzZsk2lERERESJqVhRznEVHQ0sX650NJSJMbHIKaKjgV69gF9+kfcXLgS+/55JBRERESVPU2uxfLnsm0mUCCYWOcH790DHjsCqVbLJ0+rVsQcIIiIiouS0awfkzw+Eh8vBXogSwcQiu4uMBFq1ku0izcyALVuAHj2UjoqIiIiyEjMzOdgLwE7clCQmFtnZixdAo0bAgQNArlzAnj1AmzZKR0VERPS/9u48ropy/wP45wCyKYsJgiggKoKYAm5cXFNJXDK1ui6X9LibWy5p4RUDNEMTMzOtNBMyFTWVa+Glq7ikgkvIURFERAw1BHdERQSe3x/nx9SRxYMsw/J5v17zYuaZZ2a+s3A4X2aeZ6gmmjJF/eTDkSNAfLzc0VA1xMSitsrIAF57DYiJAczNgQMHgL595Y6KiIiIaqpmzYAhQ9Tj69bJGwtVS0wsaqM//gB69ADOnVM/D3nkCPCPf8gdFREREdV0hW00N28GsrLkjYWqHSYWtU1SkjqpSE4G7O2BY8fU3cQRERERlVfv3kCbNkB2tjq5IPobJha1SVycOqm4dg1wdlYnFa1ayR0VERER1RYKBTBtmnp87Vr1i3eJ/h8Ti9ri+HH1fxFu3QI6dAB++039LCQRERFRRRo9Wt0pTGIicPiw3NFQNcLEojb49Vd1708PHqjvWBw8CFhayh0VERER1UZmZn91Xc+uZ+lvmFjUdD/9pH5PxZMnwIABQGSk+heeiIiIqLIUNuIODweuX5c1FKo+mFjUZN9/D4wYATx7pn6zdng4YGwsd1RERERU2736KtCzJ5CfD2zYIHc0VE0wsaipvvgCmDABKCgAJk4Etm5VvxWTiIiIqCoU3rVYvx7IzZU3FqoWmFjUNEIAAQHAnDnq6Q8+UP9C6+rKGhYRERHVMUOHAtbWwM2bwJ49ckdD1QATi5qkoECdUAQGqqc/+QRYsULd9RsRERFRVdLXByZPVo+zETeBiUXNkZenfvRp9Wr19Jo1wMKFTCqIiIhIPpMnq5+aOHoUOH9e7mhIZkwsaoKnT9WNtENC1L+8oaHAjBlyR0VERER1XdOmwLBh6vF16+SNhWTHxKK6e/RI3Z3s7t3qW44//QSMGSN3VERERERqhY24N29Wv1OL6iwmFtXZ/ftAv37A/v3qN1xGRKgbShERERFVF716AS4u6n+G/vCD3NGQjPTkDqDOS0sDbt8uWn7njvo/AMnJgLk5sG8f4OlZ5eERERERlUqhAKZNUz+mvW6d+ifbgNZJTCzklJYGODkBOTml1wsLY1JBRERE1dfo0YCvL3DxInDwINC3r9wRkQz4KJScbt9+cVIBAJaWlR8LERER0csyNf2rDSgbcddZTCyIiIiIqPymTVP//M9/gOvX5Y2FZMHEgoiIiIjKr21bdUPu/Hzg22/ljoZkwMSCiIiIiCpGYdezGzYAubnyxkJVjokFEREREVWMoUMBGxsgIwPYtUvuaKiKyZpY/Pbbbxg8eDBsbGygUCgQHh7+wmUOHz6MDh06wMDAAK1atUJISEiROmvXrkXz5s1haGgIDw8PnDp1quKDJyIiIiJN9eoBkyerx9mIu86RNbF49OgRXF1dsXbtWq3qp6amYtCgQejduzdUKhVmz56NiRMn4tdff5XqbN++HXPnzoW/vz/OnDkDV1dXeHt7IzMzs7J2g4iIiIgKTZoE6OkBx44B587JHQ1VIYUQQsgdBAAoFArs2bMHQ0t5s/RHH32EiIgIxMfHS2UjR47E/fv3ERkZCQDw8PBA586d8dVXXwEACgoKYGtri5kzZ8LX17fY9T59+hRPnz6Vpm/cuAEXFxdcu3YNzZo1q4C9K4E277EwNASSkgA7u8qLg4iIiKgiDR8O7NypvntRyxpyX79+Hba2tpX/PbEGqlFtLGJiYuDl5aVR5u3tjZiYGABAbm4uYmNjNero6OjAy8tLqlOcoKAgmJmZSYOLi0vl7MDz7OzUSUNsbMkDkwoiIiKqaQobcf/4I3D/vqyhUNWpUW/evnnzJqysrDTKrKyskJWVhSdPnuDevXvIz88vts7FixdLXO+CBQswd+5cabrwjkWVsLNj4kBERES1S8+e6u5nL1wAQkOBWbPkjoiqQI26Y1FZDAwMYGpqKg0mJiZyh0RERERUcykUf921WLcOKCiQNx6qEjUqsbC2tkZGRoZGWUZGBkxNTWFkZAQLCwvo6uoWW8fa2roqQyUiIiKq2959FzAxAS5dAg4elDsaqgI1KrHw9PREVFSURtn+/fvh6ekJANDX10fHjh016hQUFCAqKkqqQ0RERERVwMQEGDNGPa5lD6BUs8maWGRnZ0OlUkGlUgFQdyerUqmQlpYGQN32YUzhBQngvffew5UrV/Dhhx/i4sWLWLduHXbs2IE5c+ZIdebOnYsNGzYgNDQUiYmJmDp1Kh49eoRx48ZV6b4RERER1XnTpql/7t2r7g2TajVZE4vff/8d7u7ucHd3B6BOCtzd3fHxxx8DANLT06UkAwAcHBwQERGB/fv3w9XVFStXrsR3330Hb29vqc6IESMQHByMjz/+GG5ublCpVIiMjCzSoJuIiIiIKpmLC9C7t7qNRS3rdpaKqjbvsahO2D8xERERUQXZtQt45x3A0hK4dg0wMJA7onLh98SS1ag2FkRERERUwwwZAtjYALduqZMMqrWYWBARERFR5dHTA6ZMUY+zEXetxsSCiIiIiCrXpEnqBCM6Gvj/Tnuo9mFiQURERESVq0kT4O231eO8a1FrMbEgIiIiospX+CbuLVuAe/fkjYUqBRMLIiIiIqp83bsD7doBT54AoaFyR0OVgIkFEREREVU+heKvF+atW6d+twXVKkwsiIiIiKhqvPsuYGoKJCcDBw7IHQ1VMCYWRERERFQ1GjQAlEr1OBtx1zpMLIiIiIio6hQ+DvXLL8Aff8gbC1UoJhZEREREVHWcnYG+fdVtLL79Vu5oqAIxsSAiIiKiqlV41+K774CnT+WNhSoMEwsiIiIiqlpvvgk0awbcugXs3Cl3NFRBmFgQERERUdXS0wOmTFGPsxF3rcHEgoiIiIiq3qRJQL16wIkTwJkzckdDFYCJBRERERFVPSsr4J131OPr1skbC1UIJhZEREREJI/CRtxbtwL37skbC5UbEwsiIiIikke3bkD79sCTJ8CmTXJHQ+XExIKIiIiI5KFQANOnq8fXrVO/24JqLCYWRERERCQfHx/AzAxISQH+9z+5o6FyYGJBRERERPKpXx8YO1Y9zkbcNRoTCyIiIiKS19Sp6p+//AJcvSprKPTymFgQERERkbycnAAvL0AI4Jtv5I6GXhITCyIiIiKSX2Ej7u++A3Jy5I2FXgoTCyIiIiKS3xtvALa2wJ07wI4dckdDL4GJBRERERHJT08PeO899TgbcddITCyIiIiIqHqYMAGoVw84eRKIjZU7GiojJhZEREREVD1YWQH//Kd6fO1aeWOhMmNiQURERETVR2Ej7m3b1O0tqMZgYkFERERE1YenJ+Dmpu4ZatMmuaMpt99++w2DBw+GjY0NFAoFwsPDS61/7NgxdOvWDY0aNYKRkRGcnZ2xatUqjToBAQFQKBQag7OzcyXuhXaYWBARERFR9aFQ/HXX4uuvgYICeeMpp0ePHsHV1RVrtXy0q379+pgxYwZ+++03JCYmws/PD35+fli/fr1GvbZt2yI9PV0ajh07Vhnhl4me3AEQEREREWkYNQqYNw+4cgX49VdgwAC5Iyri4cOHyMrKkqYNDAxgYGBQpN6AAQMwoAzxu7u7w93dXZpu3rw5du/ejaNHj2Ly5MlSuZ6eHqytrV8y+srBOxZEREREVL3Urw+MG6cer6aNuF1cXGBmZiYNQUFBlbKduLg4REdHo1evXhrlycnJsLGxQYsWLeDj44O0tLRK2X5Z8I4FEREREVU/06YBX3wB7NsHpKYCDg5yR6QhISEBTZs2laaLu1tRHs2aNcOtW7eQl5eHgIAATJw4UZrn4eGBkJAQODk5IT09HYGBgejRowfi4+NhYmJSoXGUBRMLIiIiIqp+HB2Bfv2A//1P3dbis8/kjkiDiYkJTE1NK239R48eRXZ2Nk6cOAFfX1+0atUKo0aNAgCNR6vat28PDw8P2NvbY8eOHZgwYUKlxfQifBSKiIiIiKqnwkbcGzcCT57IG0sVc3BwQLt27TBp0iTMmTMHAQEBJdY1NzdH69atcfny5aoLsBhMLIiIiIioeho0CLCzA+7eBXbskDsa2RQUFODp06clzs/OzkZKSgqaNGlShVEVxcSCiIiIiKonXV3gvffU49W0EfeLZGdnQ6VSQaVSAQBSU1OhUqmkxtYLFizAmDFjpPpr167Fzz//jOTkZCQnJ2Pjxo0IDg7Gu+++K9WZN28ejhw5gqtXryI6OhrDhg2Drq6u9KiUXNjGgoiIiIiqr4kTgYAA4PRp9dC5s9wRlcnvv/+O3r17S9Nz584FACiVSoSEhCA9PV2jR6eCggIsWLAAqamp0NPTQ8uWLbF8+XJMmTJFqnP9+nWMGjUKd+7cgaWlJbp3744TJ07A0tKy6nasGAohhJA1gmro+vXrsLW1xbVr19CsWTO5wyEiIiKq20aPBn78EVAqgZAQWUPh98SS8VEoIiIiIqreChtxh4UBd+7IGwuViIkFEREREVVvHh5Ahw7A06fA99/LHQ2VgIkFEREREVVvCoX6hXmA+p0W+fnyxkPFYmJBRERERNXfqFFAw4bqt3BHRsodDRWDiQURERERVX/GxsC4cerxGtr1bG3HxIKIiIiIaoapU9U/IyOBlBR5Y6Ei+B4LIiIiIqoZ9PUBT08gJgYIDARmz9acb2GhflM3yYKJBRERERFVf2lpgJMTkJOjnt68WT38naEhkJTE5EImfBSKiIiIiKq/27f/SipKkpOjrkeyYGJBRERERETlxsSCiIiIiIjKjYkFERERERGVGxMLIiIiIiIqNyYWRERERERUbkwsiIiIiIio3JhYEBEREVH1Z2Ghfk9FaQwN1fVIFnxBHhERERFVf3Z26pfflfaeCr55W1bV4o7F2rVr0bx5cxgaGsLDwwOnTp0qse6zZ8+wePFitGzZEoaGhnB1dUVkZKRGnfz8fCxatAgODg4wMjJCy5YtsWTJEgghKntXiIiIiKiy2NkBHTqUPDCpkJXsicX27dsxd+5c+Pv748yZM3B1dYW3tzcyMzOLre/n54dvv/0Wa9asQUJCAt577z0MGzYMcXFxUp3ly5fj66+/xldffYXExEQsX74cn332GdasWVNVu0VEREREVKcohMz/xvfw8EDnzp3x1VdfAQAKCgpga2uLmTNnwtfXt0h9GxsbLFy4ENOnT5fK3n77bRgZGeHHH38EALzxxhuwsrLCxo0bS6xTmuvXr8PW1hbXrl1Ds2bNyruLRERERFRL8HtiyWS9Y5Gbm4vY2Fh4eXlJZTo6OvDy8kJMTEyxyzx9+hSGzzXcMTIywrFjx6Tprl27IioqCpcuXQIAnD17FseOHcOAAQNKXGdWVpY0PHz4sLy7RkRERERUp8jaePv27dvIz8+HlZWVRrmVlRUuXrxY7DLe3t74/PPP0bNnT7Rs2RJRUVHYvXs38vPzpTq+vr7IysqCs7MzdHV1kZ+fj6VLl8LHx6fYdQYFBSEwMLDidoyIiIiIqI6RvY1FWa1evRqOjo5wdnaGvr4+ZsyYgXHjxkFH569d2bFjB7Zs2YKtW7fizJkzCA0NRXBwMEJDQ4td54IFC/DgwQNpSEhIqKrdISIiIiKqFWS9Y2FhYQFdXV1kZGRolGdkZMDa2rrYZSwtLREeHo6cnBzcuXMHNjY28PX1RYsWLaQ68+fPh6+vL0aOHAkAaNeuHf744w8EBQVBqVQWWaeBgQEMDAyk6aysrIrYPSIiIiKiOkPWOxb6+vro2LEjoqKipLKCggJERUXB09Oz1GUNDQ3RtGlT5OXlYdeuXRgyZIg07/Hjxxp3MABAV1cXBQUFFbsDREREREQEoBq8IG/u3LlQKpXo1KkTunTpgi+++AKPHj3CuHHjAABjxoxB06ZNERQUBAA4efIkbty4ATc3N9y4cQMBAQEoKCjAhx9+KK1z8ODBWLp0Kezs7NC2bVvExcXh888/x/jx42XZRyIiIiKi2k72xGLEiBG4desWPv74Y9y8eRNubm6IjIyUGnSnpaVp3H3IycmBn58frly5ggYNGmDgwIHYvHkzzM3NpTpr1qzBokWLMG3aNGRmZsLGxgZTpkzBxx9/XNW7R0RERERUJ8j+HovqiP0TExEREVFx+D2xZLLfsaiOCttipKenyxwJEREREVUnhd8P2Xa3KCYWxSjspapLly4yR0JERERE1VFGRgbs7OzkDqNa4aNQxcjLy0NcXBysrKyK9C5VmR4+fAgXFxckJCTAxMSkyrZLtQ+vJapIvJ6oIvF6oooi17VUUFCAjIwMuLu7Q0+P/6P/OyYW1UhWVhbMzMzw4MEDmJqayh0O1WC8lqgi8XqiisTriSoKr6Xqp8a9eZuIiIiIiKofJhZERERERFRuTCyqEQMDA/j7+8PAwEDuUKiG47VEFYnXE1UkXk9UUXgtVT9sY0FEREREROXGOxZERERERFRuTCyIiIiIiKjcmFgQEREREVG5MbEgIiIiItkFBATAzc1N7jCoHJhYlGLt2rVo3rw5DA0N4eHhgVOnTr1wmZ07d8LZ2RmGhoZo164d9u3bpzF/7NixUCgUGkP//v3LHNu5c+fQo0cPGBoawtbWFp999lmp9c+ePYtRo0bB1tYWRkZGaNOmDVavXl3m7dZmPN+lW7ZsGRQKBWbPnv3Cui86Ltpo3rx5kWO3bNmyl4i8bijr9bthwwb06NEDDRs2RMOGDeHl5aXVNf+8u3fvwsfHB6ampjA3N8eECROQnZ39wuViYmLQp08f1K9fH6ampujZsyeePHlS5u3XRXXtXF+9erXIZ4FCocCJEydKXS4tLQ2DBg2CsbExGjdujPnz5yMvL0/r7QJAfn4+Fi1aBAcHBxgZGaFly5ZYsmQJ6nK/N4V/157/PA4PD4dCoajyeBQKBcLDw6t8u1QCQcUKCwsT+vr64vvvvxcXLlwQkyZNEubm5iIjI6PEZY4fPy50dXXFZ599JhISEoSfn5+oV6+eOH/+vFRHqVSK/v37i/T0dGm4e/dumWJ78OCBsLKyEj4+PiI+Pl5s27ZNGBkZiW+//bbEZTZu3Cjef/99cfjwYZGSkiI2b94sjIyMxJo1a8q07dqK57t0p06dEs2bNxft27cXs2bNKrWuNsdFG/b29mLx4sUaxy47O/ul4q/tXub6/de//iXWrl0r4uLiRGJiohg7dqwwMzMT169fL9O2+/fvL1xdXcWJEyfE0aNHRatWrcSoUaNKXSY6OlqYmpqKoKAgER8fLy5evCi2b98ucnJyyrTtuqgunuvU1FQBQBw4cEDj8yA3N7fEZfLy8sSrr74qvLy8RFxcnNi3b5+wsLAQCxYs0Hq7QgixdOlS0ahRI/HLL7+I1NRUsXPnTtGgQQOxevXqMq2nNlEqlcLQ0FCYm5tr/D3bs2ePKO/XSn9/f+Hq6lqmZQCIPXv2lGu7VHGYWJSgS5cuYvr06dJ0fn6+sLGxEUFBQSUuM3z4cDFo0CCNMg8PDzFlyhRpWqlUiiFDhpQrtnXr1omGDRuKp0+fSmUfffSRcHJyKtN6pk2bJnr37l2uWGoLnu+SPXz4UDg6Oor9+/eLXr16vTCx0Oa4aMPe3l6sWrWqjNHWTS9z/T4vLy9PmJiYiNDQUK2XSUhIEADE6dOnpbL//ve/QqFQiBs3bpS4nIeHh/Dz89N6O/SXuniuCxOLuLg4rZfZt2+f0NHRETdv3pTKvv76a2FqaqrxWfoigwYNEuPHj9coe+utt4SPj4/W66htlEqleOONN4Szs7OYP3++VF5cYvHTTz8JFxcXoa+vL+zt7UVwcHCp634+sTh16pTw8vISjRo1EqampqJnz54iNjZWmm9vby8ASIO9vb00Lzw8XLi7uwsDAwPh4OAgAgICxLNnz6T5AMSGDRvE0KFDhZGRkWjVqpX4z3/+oxFPfHy8GDRokDAxMRENGjQQ3bt3F5cvXxZHjhwRenp6Ij09XaP+rFmzRPfu3V94DGszPgpVjNzcXMTGxsLLy0sq09HRgZeXF2JiYkpcLiYmRmMZAPD29i6yzOHDh9G4cWM4OTlh6tSpuHPnTpnii4mJQc+ePaGvr6+xnaSkJNy7d0/r9Tx48ACvvPJKmbZdG/F8l2769OkYNGhQkX0tLV5tjos2li1bhkaNGsHd3R0rVqwo82MMdcHLXr/Pe/z4MZ49e1amayQmJgbm5ubo1KmTVObl5QUdHR2cPHmy2GUyMzNx8uRJNG7cGF27doWVlRV69eqFY8eOab3duqqun+s333wTjRs3Rvfu3bF3794XxtuuXTtYWVlJZd7e3sjKysKFCxe03mbXrl0RFRWFS5cuAVA/Znrs2DEMGDDgpfahttDV1cWnn36KNWvW4Pr168XWiY2NxfDhwzFy5EicP38eAQEBWLRoEUJCQrTezsOHD6FUKnHs2DGcOHECjo6OGDhwIB4+fAgAOH36NABg06ZNSE9Pl6aPHj2KMWPGYNasWUhISMC3336LkJAQLF26VGP9gYGBGD58OM6dO4eBAwfCx8cHd+/eBQDcuHEDPXv2hIGBAQ4ePIjY2FiMHz8eeXl56NmzJ1q0aIHNmzdL63r27Bm2bNmC8ePHa71/tZGe3AFUR7dv30Z+fr7GBxIAWFlZ4eLFiyUud/PmzWKXuXnzpjTdv39/vPXWW3BwcEBKSgr+/e9/Y8CAAYiJiYGurq5W8d28eRMODg5FtlM4r2HDhi9cR3R0NLZv346IiAittlmb8XyXLCwsDGfOnJE+rLWN90XHRRvvv/8+OnTogFdeeQXR0dFYsGAB0tPT8fnnn5dpPbXdy16/z/voo49gY2OjdQIJqM9148aNNcr09PTwyiuvlHi+r1y5AkDdSDM4OBhubm744Ycf0LdvX8THx8PR0VHr7dc1dfVcN2jQACtXrkS3bt2go6ODXbt2YejQoQgPD8ebb75ZYrzFHafCedry9fVFVlYWnJ2doauri/z8fCxduhQ+Pj5ar6O2GjZsGNzc3ODv74+NGzcWmf/555+jb9++WLRoEQCgdevWSEhIwIoVKzB27FitttGnTx+N6fXr18Pc3BxHjhzBG2+8AUtLSwCAubk5rK2tpXqBgYHw9fWFUqkEALRo0QJLlizBhx9+CH9/f6ne2LFjMWrUKADAp59+ii+//BKnTp1C//79sXbtWpiZmSEsLAz16tWT9qHQhAkTsGnTJsyfPx8A8PPPPyMnJwfDhw/Xat9qKyYWVWzkyJHSeLt27dC+fXu0bNkShw8fRt++faskhvj4eAwZMgT+/v7o169flWyzrqrJ5/vatWuYNWsW9u/fD0NDw0qMsHhz586Vxtu3bw99fX1MmTIFQUFBMDAwqPJ4arNly5YhLCwMhw8frvRzXVBQAACYMmUKxo0bBwBwd3dHVFQUvv/+ewQFBVXq9uu6mniuLSwsND4POnfujD///BMrVqwoMbGoKDt27MCWLVuwdetWtG3bFiqVCrNnz4aNjY30pbUuW758Ofr06YN58+YVmZeYmIghQ4ZolHXr1g1ffPEF8vPztfrnWkZGBvz8/HD48GFkZmYiPz8fjx8/RlpaWqnLnT17FsePH9e4Q5Gfn4+cnBw8fvwYxsbGANR/WwoVdi6QmZkJAFCpVOjRo4eUVDxv7Nix8PPzw4kTJ/CPf/wDISEhGD58OOrXr//C/arN+ChUMSwsLKCrq4uMjAyN8oyMDI2M+HnW1tZlXqZFixawsLDA5cuXtY6vpO0UzitNQkIC+vbti8mTJ8PPz0/rbdZmPN/Fi42NRWZmJjp06AA9PT3o6enhyJEj+PLLL6Gnp4f8/PwyxfuiWF/Ew8MDeXl5uHr1arnWU9u87PVbKDg4GMuWLcP//vc/jT+y2rC2tpb+CBfKy8vD3bt3S9x2kyZNAAAuLi4a5W3atHnhl4W6juf6Lx4eHqV+jpbnc/Pv5s+fD19fX4wcORLt2rXD6NGjMWfOHCbA/69nz57w9vbGggULKmX9SqUSKpUKq1evRnR0NFQqFRo1aoTc3NxSl8vOzkZgYCBUKpU0nD9/HsnJyRoJ9fNJg0KhkBJiIyOjUrfRuHFjDB48GJs2bUJGRgb++9//1vnHoAAmFsXS19dHx44dERUVJZUVFBQgKioKnp6eJS7n6empsQwA7N+/v9Rlrl+/jjt37kgfwNrw9PTEb7/9hmfPnmlsx8nJqdTHYi5cuIDevXtDqVQWec6wLuP5Ll7fvn1x/vx5jQ/mTp06wcfHByqVqsT/Nr3McdGGSqWCjo5Okccx6rqXvX4B4LPPPsOSJUsQGRmp8ey8tjw9PXH//n3ExsZKZQcPHkRBQQE8PDyKXaZ58+awsbFBUlKSRvmlS5dgb29f5hjqEp7rv6hUqlI/Rz09PXH+/HmNZGj//v0wNTUtkuiU5vHjx9DR0fyqpKurK335JPVdsJ9//rlIO582bdrg+PHjGmXHjx9H69attX4U+Pjx43j//fcxcOBAtG3bFgYGBrh9+7ZGnXr16hX5R1eHDh2QlJSEVq1aFRmeP58lad++PY4eParxt/d5EydOxPbt27F+/Xq0bNkS3bp102rdtZrcrcerq7CwMGFgYCBCQkJEQkKCmDx5sjA3N9foYWL06NHC19dXmj5+/LjQ09MTwcHBIjExUfj7+2t0s/nw4UMxb948ERMTI1JTU8WBAwdEhw4dhKOjY5m63rt//76wsrISo0ePFvHx8SIsLEwYGxtrdD+6e/dujV6Dzp8/LywtLcW7776r0V1fZmZmeQ5TrcHzrZ3ieoUq63HRRnR0tFi1apVQqVQiJSVF/Pjjj8LS0lKMGTOmXPHXVi9z/S5btkzo6+uLn376SeMaefjwYZm23b9/f+Hu7i5Onjwpjh07JhwdHTW6IL1+/bpwcnISJ0+elMpWrVolTE1Nxc6dO0VycrLw8/MThoaG4vLly+U4CnVDXTzXISEhYuvWrSIxMVEkJiaKpUuXCh0dHfH9999LdZ7/DCzsbrZfv35CpVKJyMhIYWlpWebuZpVKpWjatKnU3ezu3buFhYWF+PDDD8u0ntqkuN4OR48eLQwNDTV6hYqNjRU6Ojpi8eLFIikpSYSEhAgjIyOxadOmEtf9fK9Q7u7u4vXXXxcJCQnixIkTokePHsLIyEijx0BHR0cxdepUje7cIyMjhZ6enggICBDx8fEiISFBbNu2TSxcuFBaDsV0U2tmZibFd/v2bdGoUSPx1ltvidOnT4tLly6JH374QVy8eFGqn5+fL2xtbYW+vr5YtmyZdgewlmNiUYo1a9YIOzs7oa+vL7p06SJOnDihMb9Xr15CqVRqlO3YsUO0bt1a6Ovri7Zt24qIiAhp3uPHj0W/fv2EpaWlqFevnrC3txeTJk3S+INQ0nqfd/bsWdG9e3dhYGAgmjZtWuSC3rRpk8YvuL+/v0aXbCima7a6rq6d78IuHA8dOvTig/O3WJ9PLMp6XArjK+3ai42NFR4eHsLMzEwYGhqKNm3aiE8//ZTvOShFWa/f57tpLBz8/f2lOi86T0IIcefOHTFq1CjRoEEDYWpqKsaNG6fxhbWk6ywoKEg0a9ZMGBsbC09PT3H06NGX3fU6p7ad6xd9BoaEhIg2bdoIY2NjYWpqKrp06SJ27typUef5z0AhhLh69aoYMGCAMDIyEhYWFuKDDz7Q6G5Um8/ArKwsMWvWLGFnZycMDQ1FixYtxMKFC8vUZW1tU1xikZqaKvT19UvsbrZevXrCzs5OrFixotR1P59YnDlzRnTq1EkYGhoKR0dHsXPnziJdke/du1e0atVK6OnpaVzDkZGRomvXrsLIyEi6btavXy/Nf1FiIYT6b2+/fv2EsbGxMDExET169BApKSkayyxatEjo6uqKP//8s9R9qysUQtTh10dWU/b29ggMDNS61wSq2eQ634cOHcJbb72FK1euaNWzVEVSKpVQKBRl6naQqh7PU90h57mui5+BVHtMmDABt27demEXyHUFe4WqZi5cuAAzMzOMGTNG7lCoCsh5vvft24d///vfVf4HVQiBw4cP870F1RzPU90h57mui5+BVDs8ePAA58+fx9atW5lU/A3vWBARERERlcFrr72GU6dOYcqUKVi1apXc4VQbTCyIiIiIiKjc2N0sERERERGVGxMLIiIiIiIqNyYWRERERERUbkwsiIiIiIio3JhYEBERERFRuTGxIKI677XXXsPs2bPlDqNGCw8PR6tWraCrq4vZs2cjJCQE5ubmcof1QgqFAuHh4XKHQURUKzCxICIqo8OHD0OhUOD+/ftyh1JtTJkyBe+88w6uXbuGJUuWYMSIEbh06ZLcYUkCAgLg5uZWpDw9PR0DBgyo+oCIiGohvnmbiIjKJTs7G5mZmfD29oaNjY1UbmRkVOnbzs3Nhb6+/ksvb21tXYHREBHVbbxjQUT0nM2bN6NTp04wMTGBtbU1/vWvfyEzMxMAcPXqVfTu3RsA0LBhQygUCowdOxYAUFBQgKCgIDg4OMDIyAiurq746aefpPUW3umIiopCp06dYGxsjK5duyIpKUlj+z///DM6d+4MQ0NDWFhYYNiwYQCAxYsX49VXXy0Sr5ubGxYtWlTi/ly4cAFvvPEGTE1NYWJigh49eiAlJUWKefHixWjWrBkMDAzg5uaGyMhIadmrV69CoVBg9+7d6N27N4yNjeHq6oqYmBhpn0xMTAAAffr0gUKhwOHDh4t9FOqTTz5B48aNYWJigokTJ8LX11fjLkJxj6QNHTpUOr4A0Lx5cyxZsgRjxoyBqakpJk+eDAD46KOP0Lp1axgbG6NFixZYtGgRnj17BgAICQlBYGAgzp49C4VCAYVCgZCQEABFH4U6f/48+vTpAyMjIzRq1AiTJ09Gdna2NH/s2LEYOnQogoOD0aRJEzRq1AjTp0+XtkVEVJcxsSAies6zZ8+wZMkSnD17FuHh4bh69ar05dbW1ha7du0CACQlJSE9PR2rV68GAAQFBeGHH37AN998gwsXLmDOnDl49913ceTIEY31L1y4ECtXrsTvv/8OPT09jB8/XpoXERGBYcOGYeDAgYiLi0NUVBS6dOkCABg/fjwSExNx+vRpqX5cXBzOnTuHcePGFbsvN27cQM+ePWFgYICDBw8iNjYW48ePR15eHgBg9erVWLlyJYKDg3Hu3Dl4e3vjzTffRHJycpGY582bB5VKhdatW2PUqFHIy8vTSIx27dqF9PR0dO3atUgcW7ZswdKlS7F8+XLExsbCzs4OX3/9tdbn5O+Cg4Ph6uqKuLg4KaEyMTFBSEgIEhISsHr1amzYsAGrVq0CAIwYMQIffPAB2rZti/T0dKSnp2PEiBFF1vvo0SN4e3ujYcOGOH36NHbu3IkDBw5gxowZGvUOHTqElJQUHDp0CKGhoQgJCZESFSKiOk0QEdVxvXr1ErNmzSpx/unTpwUA8fDhQyGEEIcOHRIAxL1796Q6OTk5wtjYWERHR2ssO2HCBDFq1CiN5Q4cOCDNj4iIEADEkydPhBBCeHp6Ch8fnxJjGTBggJg6dao0PXPmTPHaa6+VWH/BggXCwcFB5ObmFjvfxsZGLF26VKOsc+fOYtq0aUIIIVJTUwUA8d1330nzL1y4IACIxMREIYQQ9+7dEwDEoUOHpDqbNm0SZmZm0rSHh4eYPn26xna6desmXF1dpenizsOQIUOEUqmUpu3t7cXQoUNL3N9CK1asEB07dpSm/f39NbZVCIDYs2ePEEKI9evXi4YNG4rs7GxpfkREhNDR0RE3b94UQgihVCqFvb29yMvLk+r885//FCNGjHhhTEREtR3vWBARPSc2NhaDBw+GnZ0dTExM0KtXLwBAWlpaictcvnwZjx8/xuuvv44GDRpIww8//CA9dlSoffv20niTJk0AQHrUSqVSoW/fviVuZ9KkSdi2bRtycnKQm5uLrVu3atzxeJ5KpUKPHj1Qr169IvOysrLw559/olu3bhrl3bp1Q2JiotYxayMpKUm681Lo+WltderUqUjZ9u3b0a1bN1hbW6NBgwbw8/Mr9XwVJzExEa6urqhfv75U1q1bNxQUFGg8rta2bVvo6upK002aNCnTsSAiqq3YeJuI6G8KH4fx9vbGli1bYGlpibS0NHh7eyM3N7fE5Qqfw4+IiEDTpk015hkYGGhM//1LvkKhAKBu6wC8uMHz4MGDYWBggD179kBfXx/Pnj3DO++8U2L9impAXVrMFUVHRwdCCI2y4tou/P2LPwDExMTAx8cHgYGB8Pb2hpmZGcLCwrBy5coKja/Q80maQqGo8GNBRFQT8Y4FEdHfXLx4EXfu3MGyZcvQo0cPODs7F/lvdGEvRPn5+VKZi4sLDAwMkJaWhlatWmkMtra2Wm+/ffv2iIqKKnG+np4elEolNm3ahE2bNmHkyJGlJg/t27fH0aNHi/2CbmpqChsbGxw/flyj/Pjx43BxcdE6Zm04OTlptA0BUGTa0tIS6enp0nR+fj7i4+NfuO7o6GjY29tj4cKF6NSpExwdHfHHH39o1NHX19c4X8Vp06YNzp49i0ePHkllx48fh46ODpycnF4YBxFRXcfEgojob+zs7KCvr481a9bgypUr2Lt3L5YsWaJRx97eHgqFAr/88gtu3bqF7OxsmJiYYN68eZgzZw5CQ0ORkpKCM2fOYM2aNQgNDdV6+/7+/ti2bRv8/f2RmJiI8+fPY/ny5Rp1Jk6ciIMHDyIyMrLUx6AAYMaMGcjKysLIkSPx+++/Izk5GZs3b5Ye7Zk/fz6WL1+O7du3IykpCb6+vlCpVJg1a5bWMWtj5syZ2LhxI0JDQ5GcnIxPPvkE586dk+5+AOpepSIiIhAREYGLFy9i6tSpWr0rxNHREWlpaQgLC0NKSgq+/PJL7NmzR6NO8+bNkZqaCpVKhdu3b+Pp06dF1uPj4wNDQ0MolUrEx8fj0KFDmDlzJkaPHg0rK6tyHwMiotqOiQUR0d9YWloiJCQEO3fuhIuLC5YtW4bg4GCNOk2bNkVgYCB8fX1hZWUl9Rq0ZMkSLFq0CEFBQWjTpg369++PiIgIODg4aL391157DTt37sTevXvh5uaGPn364NSpUxp1HB0d0bVrVzg7O8PDw6PU9TVq1AgHDx5EdnY2evXqhY4dO2LDhg3S4zzvv/8+5s6diw8++ADt2rVDZGQk9u7dC0dHR61j1oaPjw8WLFiAefPmoUOHDkhNTcXYsWNhaGgo1Rk/fjyUSiXGjBmDXr16oUWLFlLXvqV58803MWfOHMyYMQNubm6Ijo4u0v3u22+/jf79+6N3796wtLTEtm3biqzH2NgYv/76K+7evYvOnTvjnXfeQd++ffHVV1+V/wAQEdUBCvH8A61ERFStCSHg6OiIadOmYe7cuXKH89Jef/11WFtbY/PmzXKHQkREFYCNt4mIapBbt24hLCwMN2/eLPHdFdXR48eP8c0338Db2xu6urrYtm0bDhw4gP3798sdGhERVRAmFkRENUjjxo1hYWGB9evXo2HDhnKHozWFQoF9+/Zh6dKlyMnJgZOTE3bt2gUvLy+5QyMiogrCR6GIiIiIiKjc2HibiIiIiIjKjYkFERERERGVGxMLIiIiIiIqNyYWRERERERUbkwsiIiIiIio3JhYEBERERFRuTGxICIiIiKicmNiQURERERE5fZ/GVoNWmeRb7MAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cut this\n",
    "\n",
    "def extract_altered_value(config_name, family):\n",
    "    \"\"\"\n",
    "    Given a config name and a family, extract the altered value.\n",
    "    For each family, a different rule is applied:\n",
    "    \n",
    "    - num_processes: extract the integer after \"num_processes_\"\n",
    "    - batching: extract the integer after \"batching_\"\n",
    "    - precis: extract the precision setting; if quant4 is True, return \"load_in_4bit=True\",\n",
    "              otherwise return the float precision (e.g., \"float32\" or \"float16\")\n",
    "    - decoding: extract the decoder_temperature (as a float) from the config name.\n",
    "    - latency: if the config is exactly \"latency_False\", return \"No latency\"; otherwise, \n",
    "               extract and join all numeric values in the config string.\n",
    "    \"\"\"\n",
    "    if family == \"num_processes\":\n",
    "        m = re.search(r'num_processes_(\\d+)', config_name)\n",
    "        return int(m.group(1)) if m else config_name\n",
    "    \n",
    "    elif family == \"batching\":\n",
    "        m = re.search(r'batching_(\\d+)', config_name)\n",
    "        return int(m.group(1)) if m else config_name\n",
    "    \n",
    "    elif family == \"precis\":\n",
    "        m = re.search(r'precis_(float\\d+)', config_name)\n",
    "        precision = m.group(1) if m else None\n",
    "        # If quant4 is True, we assume load_in_4bit is the relevant setting. COME BACK TO THIS!!!\n",
    "        if \"quant4_True\" in config_name:\n",
    "            return \"load_in_4bit=True\"\n",
    "        else:\n",
    "            return precision\n",
    "        \n",
    "    elif family == \"decoding\":\n",
    "        # This family might have several variants. We extract the decoder_temperature. COME BACK TO\n",
    "        m = re.search(r'decoder_temperature_([\\d\\.]+)', config_name)\n",
    "        return float(m.group(1)) if m else config_name\n",
    "    \n",
    "    elif family == \"latency\":\n",
    "        # If it's simply \"latency_False\", nothing was altered.\n",
    "        if config_name == \"latency_False\":\n",
    "            return \"No latency\"\n",
    "        else:\n",
    "            # Find all numbers (either integer or float) in the string.\n",
    "            numbers = re.findall(r'\\d+\\.\\d+|\\d+', config_name)\n",
    "            return \", \".join(numbers)\n",
    "    else:\n",
    "        return config_name\n",
    "\n",
    "def plot_family(df, family, metric1, metric2):\n",
    "    \"\"\"\n",
    "    For a given family, subset the DataFrame (rows whose config_name starts with family).\n",
    "    Create a new column that holds the altered value for that family, sort the data by that value,\n",
    "    and plot two metrics against this altered value.\n",
    "    \n",
    "    Parameters:\n",
    "      - df: a DataFrame with a \"config_name\" column.\n",
    "      - family: the family string (e.g. \"num_processes\", \"batching\", etc).\n",
    "      - metric1: name of the first metric column to plot on the left Y axis (e.g., \"flops_per_token\").\n",
    "      - metric2: name of the second metric column to plot on the right Y axis (e.g., \"total_energy_kwh\").\n",
    "    \"\"\"\n",
    "    # Subset rows where config_name starts with the family string.\n",
    "    df_family = df[df['config_name'].str.startswith(family)].copy()\n",
    "    \n",
    "    # Apply the parser to create an \"altered_value\" column.\n",
    "    df_family['altered_value'] = df_family['config_name'].apply(lambda x: extract_altered_value(x, family))\n",
    "    \n",
    "    # Attempt to sort by altered_value.\n",
    "    # If the values are numeric, convert them.\n",
    "    try:\n",
    "        df_family['altered_value'] = pd.to_numeric(df_family['altered_value'])\n",
    "    except:\n",
    "        pass  # leave as string if conversion fails\n",
    "    \n",
    "    df_family.sort_values('altered_value', inplace=True)\n",
    "    \n",
    "    # Create a plot with twin y-axes.\n",
    "    fig, ax1 = plt.subplots(figsize=(8,5))\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # Plot metric1 on ax1 and metric2 on ax2.\n",
    "    ax1.plot(df_family['altered_value'], df_family[metric1], marker='o', label=metric1, color='blue')\n",
    "    ax2.plot(df_family['altered_value'], df_family[metric2], marker='s', label=metric2, color='red')\n",
    "    \n",
    "    ax1.set_xlabel(f'{family} configuration')\n",
    "    ax1.set_ylabel(metric1, color='blue')\n",
    "    ax2.set_ylabel(metric2, color='red')\n",
    "    plt.title(f'{family}: {metric1} and {metric2} vs altered setting')\n",
    "    \n",
    "    # Combine the legends.\n",
    "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='best')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "families = [\"num_processes\", \"batching\", \"precis\", \"decoding\", \"latency\"]\n",
    "\n",
    "for fam in families:\n",
    "    plot_family(df_controlled_dropped, fam, metric1=\"flops_per_token\", metric2=\"energy_per_token_kwh\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# RESTART FROM HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR CONTROLLED EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'controlled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;241m==\u001b[39m possible_files[\u001b[43mcontrolled\u001b[49m]:\n\u001b[1;32m      3\u001b[0m     df \u001b[38;5;241m=\u001b[39m df_controlled_dropped\n\u001b[1;32m      5\u001b[0m     configs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_processes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatency\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatching\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecis\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'controlled' is not defined"
     ]
    }
   ],
   "source": [
    "if file == possible_files[controlled]:\n",
    "    \n",
    "    df = df_controlled_dropped\n",
    "    \n",
    "    configs = ['num_processes', 'decoder', 'latency', 'batching', 'precis']\n",
    "    dfs = {config: df[df['config_name'].str.startswith(config)] for config in configs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == possible_files[controlled]:\n",
    "    \n",
    "for name, df in dfs:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # ----- First subplot: Divergence Energy vs Batch Size -----\n",
    "    axes[0].plot(\n",
    "        df['num_processes'],\n",
    "        df['divergence_energy_flops_per_token'],\n",
    "        marker='o', \n",
    "        linestyle='-',\n",
    "        color='orange'\n",
    "    )\n",
    "    axes[0].set_xlabel('Batch Size (Fixed Batching)')\n",
    "    axes[0].set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "    axes[0].set_title(f'Divergence Energy vs Batch Size ({name})')\n",
    "    axes[0].set_xticks(df['num_processes'])\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # ----- Second subplot: Two Y-axes with Energy per Token and FLOPs per Token -----\n",
    "    ax1 = axes[1]\n",
    "    line1, = ax1.plot(\n",
    "        df['num_processes'], \n",
    "        df['energy_per_token_kwh'], \n",
    "        marker='o', \n",
    "        linestyle='-', \n",
    "        color='blue', \n",
    "        label='Energy per Token (kWh)'\n",
    "    )\n",
    "    ax1.set_xlabel('Batch Size (Fixed Batching)')\n",
    "    ax1.set_ylabel('Energy per Token (kWh)', color='blue')\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax1.set_xticks(df['num_processes'])\n",
    "    ax1.set_title(f'Metrics vs Batch Size ({name})')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    line2, = ax2.plot(\n",
    "        df['num_processes'], \n",
    "        df['flops_per_token'], \n",
    "        marker='s', \n",
    "        linestyle='--', \n",
    "        color='red', \n",
    "        label='FLOPs per Token'\n",
    "    )\n",
    "    ax2.set_ylabel('FLOPs per Token', color='red')\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    # Combine legends\n",
    "    lines = [line1, line2]\n",
    "    labels = [line.get_label() for line in lines]\n",
    "    ax1.legend(lines, labels, loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Step 1: Create a new 'precision' column for plotting\n",
    "    def determine_precision(row):\n",
    "        if row.get('load_in_4bit', False):\n",
    "            return 'INT4'\n",
    "        elif row.get('load_in_8bit', False):\n",
    "            return 'INT8'\n",
    "        elif row.get('fp_precision') == 'torch.float16':\n",
    "            return 'FP16'\n",
    "        else:\n",
    "            return 'FP32'\n",
    "\n",
    "    precics_df['precision'] = precics_df.apply(determine_precision, axis=1)\n",
    "\n",
    "    # Step 2: Define custom precision order\n",
    "    precision_order = ['FP32', 'FP16', 'INT8', 'INT4']\n",
    "\n",
    "    # Step 3: Sort the dataframe according to precision order\n",
    "    precics_df['precision'] = pd.Categorical(precics_df['precision'], categories=precision_order, ordered=True)\n",
    "    precics_df = precics_df.sort_values('precision')\n",
    "\n",
    "    # Step 4: Plotting\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # ----- First subplot: Divergence Energy vs Precision -----\n",
    "    axes[0].plot(\n",
    "        precics_df['precision'],\n",
    "        precics_df['divergence_energy_flops_per_token'],\n",
    "        marker='o', \n",
    "        linestyle='-',\n",
    "        color='orange'\n",
    "    )\n",
    "    axes[0].set_xlabel('Precision')\n",
    "    axes[0].set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "    axes[0].set_title('Divergence Energy vs Precision')\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # ----- Second subplot: Two Y-axes with Energy per Token and FLOPs per Token -----\n",
    "    ax1 = axes[1]\n",
    "    line1, = ax1.plot(\n",
    "        precics_df['precision'], \n",
    "        precics_df['energy_per_token_kwh'], \n",
    "        marker='o', \n",
    "        linestyle='-', \n",
    "        color='blue', \n",
    "        label='Energy per Token (kWh)'\n",
    "    )\n",
    "    ax1.set_xlabel('Precision')\n",
    "    ax1.set_ylabel('Energy per Token (kWh)', color='blue')\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax1.set_title('Metrics vs Precision')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    line2, = ax2.plot(\n",
    "        precics_df['precision'], \n",
    "        precics_df['flops_per_token'], \n",
    "        marker='s', \n",
    "        linestyle='--', \n",
    "        color='red', \n",
    "        label='FLOPs per Token'\n",
    "    )\n",
    "    ax2.set_ylabel('FLOPs per Token', color='red')\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    # Combine legends\n",
    "    lines = [line1, line2]\n",
    "    labels = [line.get_label() for line in lines]\n",
    "    ax1.legend(lines, labels, loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == possible_files[controlled]:\n",
    "\n",
    "    # --- Step 1: Filter the dataframe based on the config names ---\n",
    "    config_names = [\n",
    "        'decoding_greedy_decoder_temperature_0',\n",
    "        'decoding_greedy_decoder_temperature_0.7',\n",
    "        'decoding_greedy_decoder_temperature_1.0',\n",
    "        'decoding_greedy_decoder_temperature_1.3',\n",
    "        'decoding_top_k_decoder_top_k_50_decoder_temperature_0',\n",
    "        'decoding_top_k_decoder_top_k_50_decoder_temperature_0.7',\n",
    "        'decoding_top_k_decoder_top_k_50_decoder_temperature_1.0',\n",
    "        'decoding_top_k_decoder_top_k_50_decoder_temperature_1.3',\n",
    "        'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0',\n",
    "        'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.7',\n",
    "        'decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.0',\n",
    "        'decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.3'\n",
    "    ]\n",
    "    filtered_decoding = decoding_df[decoding_df['config_name'].isin(config_names)].copy()\n",
    "\n",
    "    # --- Step 2: Extract method and temperature from the config_name ---\n",
    "    def extract_method_and_temp(config):\n",
    "        if config.startswith(\"decoding_greedy_decoder_temperature_\"):\n",
    "            temp = float(config.split(\"decoding_greedy_decoder_temperature_\")[-1])\n",
    "            return \"greedy\", temp\n",
    "        elif config.startswith(\"decoding_top_k_decoder_top_k_50_decoder_temperature_\"):\n",
    "            temp = float(config.split(\"decoding_top_k_decoder_top_k_50_decoder_temperature_\")[-1])\n",
    "            return \"top_k\", temp\n",
    "        elif config.startswith(\"decoding_top_p_decoder_top_p_0.9_decoder_temperature_\"):\n",
    "            temp = float(config.split(\"decoding_top_p_decoder_top_p_0.9_decoder_temperature_\")[-1])\n",
    "            return \"top_p\", temp\n",
    "        else:\n",
    "            return \"unknown\", None\n",
    "\n",
    "    # Apply the extraction function and assign to new columns\n",
    "    filtered_decoding[['method', 'temperature']] = filtered_decoding['config_name'].apply(\n",
    "        lambda x: pd.Series(extract_method_and_temp(x))\n",
    "    )\n",
    "\n",
    "    # Optionally sort the dataframe by method and temperature for clarity.\n",
    "    filtered_decoding = filtered_decoding.sort_values(['method', 'temperature'])\n",
    "\n",
    "    # --- Step 3: Plotting ---\n",
    "\n",
    "    # Define colors for each method\n",
    "    colors = {\n",
    "        'greedy': 'blue',\n",
    "        'top_k': 'green',\n",
    "        'top_p': 'red'\n",
    "    }\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # --- Left subplot: Divergence Energy vs Temperature ---\n",
    "    ax_left = axes[0]\n",
    "    methods = filtered_decoding['method'].unique()\n",
    "    for m in methods:\n",
    "        subdf = filtered_decoding[filtered_decoding['method'] == m]\n",
    "        ax_left.plot(subdf['temperature'], subdf['divergence_energy_flops_per_token'],\n",
    "                    marker='o', linestyle='-', label=m, color=colors.get(m))\n",
    "    ax_left.set_xlabel('Decoder Temperature')\n",
    "    ax_left.set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "    ax_left.set_title('Divergence Energy vs Decoder Temperature')\n",
    "    ax_left.grid(True)\n",
    "    ax_left.legend(title=\"Method\")\n",
    "\n",
    "    # --- Right subplot: Two Y-axes with Energy per Token and FLOPs per Token ---\n",
    "    ax1 = axes[1]\n",
    "    # Primary axis for Energy per Token\n",
    "    for m in methods:\n",
    "        subdf = filtered_decoding[filtered_decoding['method'] == m]\n",
    "        ax1.plot(subdf['temperature'], subdf['energy_per_token_kwh'],\n",
    "                marker='o', linestyle='-', label=f'{m} Energy', color=colors.get(m))\n",
    "    ax1.set_xlabel('Decoder Temperature')\n",
    "    ax1.set_ylabel('Energy per Token (kWh)', color='black')\n",
    "    ax1.set_title('Metrics vs Decoder Temperature')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Secondary axis for FLOPs per Token\n",
    "    ax2 = ax1.twinx()\n",
    "    for m in methods:\n",
    "        subdf = filtered_decoding[filtered_decoding['method'] == m]\n",
    "        ax2.plot(subdf['temperature'], subdf['flops_per_token'],\n",
    "                marker='s', linestyle='--', label=f'{m} FLOPs', color=colors.get(m))\n",
    "    ax2.set_ylabel('FLOPs per Token', color='black')\n",
    "\n",
    "    # --- Combine legends from both axes ---\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == possible_files[controlled]:\n",
    "\n",
    "    # --- 1. Filter the latency_df to only keep the specified configurations ---\n",
    "    latency_configs = [\n",
    "        'latency_False',\n",
    "        'latency_True_latency_0.05_latency_0.2_latency_False',\n",
    "        'latency_True_latency_0.2_latency_0.6_latency_False',\n",
    "        'latency_True_latency_0.05_latency_0.2_latency_True_latency_4.0_latency_5',\n",
    "        'latency_True_latency_0.2_latency_0.6_latency_True_latency_5.0_latency_8'\n",
    "    ]\n",
    "    latency_filtered = latency_df[latency_df['config_name'].isin(latency_configs)].copy()\n",
    "\n",
    "    # --- 2. Define a function to parse the config string ---\n",
    "    def parse_latency_config(config):\n",
    "        \"\"\"\n",
    "        Parses a latency configuration string and returns a dict with:\n",
    "        - simulate (boolean)\n",
    "        - delay_min (float or None)\n",
    "        - delay_max (float or None)\n",
    "        - simulate_burst (boolean or None)\n",
    "        - burst_size (float or None)\n",
    "        - burst_interval (float or None)\n",
    "        \"\"\"\n",
    "        tokens = config.split('_')\n",
    "        \n",
    "        # There will be extra \"latency\" tokens in the string.\n",
    "        # Look at the total number of tokens:\n",
    "        # For baseline: e.g., \"latency_False\" -> tokens: [\"latency\", \"False\"]\n",
    "        # Without burst: 8 tokens, e.g.:\n",
    "        #   [\"latency\", \"True\", \"latency\", \"0.05\", \"latency\", \"0.2\", \"latency\", \"False\"]\n",
    "        # With burst: 12 tokens, e.g.:\n",
    "        #   [\"latency\", \"True\", \"latency\", \"0.05\", \"latency\", \"0.2\", \"latency\", \"True\", \"latency\", \"4.0\", \"latency\", \"5\"]\n",
    "        res = {}\n",
    "        if len(tokens) == 2:\n",
    "            # Baseline: no simulation\n",
    "            res['simulate'] = (tokens[1] == \"True\")\n",
    "            res['delay_min'] = None\n",
    "            res['delay_max'] = None\n",
    "            res['simulate_burst'] = None\n",
    "            res['burst_size'] = None\n",
    "            res['burst_interval'] = None\n",
    "        elif len(tokens) == 8:\n",
    "            # Without burst: tokens at positions 1, 3, 5, and 7 are our values.\n",
    "            res['simulate'] = (tokens[1] == \"True\")\n",
    "            res['delay_min'] = float(tokens[3])\n",
    "            res['delay_max'] = float(tokens[5])\n",
    "            res['simulate_burst'] = (tokens[7] == \"True\")\n",
    "            res['burst_size'] = None\n",
    "            res['burst_interval'] = None\n",
    "        elif len(tokens) == 12:\n",
    "            # With burst: tokens at positions 1, 3, 5, 7, 9, and 11.\n",
    "            res['simulate'] = (tokens[1] == \"True\")\n",
    "            res['delay_min'] = float(tokens[3])\n",
    "            res['delay_max'] = float(tokens[5])\n",
    "            res['simulate_burst'] = (tokens[7] == \"True\")\n",
    "            res['burst_size'] = float(tokens[9])\n",
    "            res['burst_interval'] = float(tokens[11])\n",
    "        else:\n",
    "            res['simulate'] = None\n",
    "            res['delay_min'] = None\n",
    "            res['delay_max'] = None\n",
    "            res['simulate_burst'] = None\n",
    "            res['burst_size'] = None\n",
    "            res['burst_interval'] = None\n",
    "        return res\n",
    "\n",
    "    # Apply the parser so that we have new columns for the latency parameters\n",
    "    latency_params = latency_filtered['config_name'].apply(lambda x: pd.Series(parse_latency_config(x)))\n",
    "    latency_filtered = pd.concat([latency_filtered, latency_params], axis=1)\n",
    "\n",
    "    # --- 3. Create a user-friendly label for each configuration ---\n",
    "    def make_latency_label(row):\n",
    "        if row['simulate'] is False:\n",
    "            return \"No simulation\"\n",
    "        elif row['simulate'] is True and row['simulate_burst'] is False:\n",
    "            return f\"Sim ({row['delay_min']}-{row['delay_max']})\"\n",
    "        elif row['simulate'] is True and row['simulate_burst'] is True:\n",
    "            return f\"Sim ({row['delay_min']}-{row['delay_max']}) Burst ({row['burst_size']},{row['burst_interval']})\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "\n",
    "    latency_filtered['latency_label'] = latency_filtered.apply(make_latency_label, axis=1)\n",
    "\n",
    "    # --- 4. Order the configurations as desired ---\n",
    "    order_labels = [\n",
    "        \"No simulation\",\n",
    "        \"Sim (0.05-0.2)\",\n",
    "        \"Sim (0.2-0.6)\",\n",
    "        \"Sim (0.05-0.2) Burst (4.0,5)\",\n",
    "        \"Sim (0.2-0.6) Burst (5.0,8)\"\n",
    "    ]\n",
    "    latency_filtered['latency_label'] = pd.Categorical(latency_filtered['latency_label'], \n",
    "                                                        categories=order_labels, ordered=True)\n",
    "    latency_filtered = latency_filtered.sort_values('latency_label')\n",
    "\n",
    "    # --- 5. Create the two subplots ---\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Left Subplot: Divergence Energy vs Latency Configuration (categorical x-axis)\n",
    "    axes[0].plot(\n",
    "        latency_filtered['latency_label'],\n",
    "        latency_filtered['divergence_energy_flops_per_token'],\n",
    "        marker='o',\n",
    "        linestyle='-',\n",
    "        color='orange'\n",
    "    )\n",
    "    axes[0].set_xlabel('Latency Configuration')\n",
    "    axes[0].set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "    axes[0].set_title('Divergence Energy vs Latency Config')\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Right Subplot: Two y-axes for Energy per Token and FLOPs per Token\n",
    "    ax1 = axes[1]\n",
    "    line1, = ax1.plot(\n",
    "        latency_filtered['latency_label'],\n",
    "        latency_filtered['energy_per_token_kwh'],\n",
    "        marker='o',\n",
    "        linestyle='-',\n",
    "        color='blue',\n",
    "        label='Energy per Token (kWh)'\n",
    "    )\n",
    "    ax1.set_xlabel('Latency Configuration')\n",
    "    ax1.set_ylabel('Energy per Token (kWh)', color='blue')\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax1.set_title('Metrics vs Latency Config')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Create secondary y-axis for FLOPs per Token\n",
    "    ax2 = ax1.twinx()\n",
    "    line2, = ax2.plot(\n",
    "        latency_filtered['latency_label'],\n",
    "        latency_filtered['flops_per_token'],\n",
    "        marker='s',\n",
    "        linestyle='--',\n",
    "        color='red',\n",
    "        label='FLOPs per Token'\n",
    "    )\n",
    "    ax2.set_ylabel('FLOPs per Token', color='red')\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    # Combine legends from both axes\n",
    "    lines = [line1, line2]\n",
    "    labels = [line.get_label() for line in lines]\n",
    "    ax1.legend(lines, labels, loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == possible_files[controlled]:\n",
    "    print(f\"var energy: {df_controlled_dropped.total_energy_kwh.max()} / {df_controlled_dropped.total_energy_kwh.min()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORK OUT STANDARD DEVIATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Histogram of raw total_energy_kwh\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_scenarios_dropped['total_energy_kwh'], bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Total Energy (kWh)')\n",
    "plt.xlabel('Total Energy (kWh)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot to spot outliers\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.boxplot(df_scenarios_dropped['total_energy_kwh'], vert=False)\n",
    "plt.title('Boxplot of Total Energy (kWh)')\n",
    "plt.xlabel('Total Energy (kWh)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# If distribution is very skewed: log-transform\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(np.log(df_scenarios_dropped['total_energy_kwh']), bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Log-Transformed Total Energy (kWh)')\n",
    "plt.xlabel('Log(Total Energy (kWh))')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for Scenario Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == possible_files[\"scenario\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scenarios_dropped.total_energy_kwh.max() / df_scenarios_dropped.total_energy_kwh.min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

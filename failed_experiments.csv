experiment_id,timestamp,suite,config,error_message
unknown,2025-04-25T20:44:12.735205,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0g6zmxnr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-26T17:38:32.628831,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpw2r6f6e4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:46:21.241358,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7qo0vulg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:46:51.195572,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0qhpsale.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:47:40.297979,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2dqjtzj3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:48:10.242932,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpz1sshiqu.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:48:42.376258,grid,"{""config_name"": ""num_processes_2_batching_4_precision_int4_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptxhmh5ik.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:49:12.247685,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfaeufef7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:49:42.169023,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2desno56.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:50:15.641769,grid,"{""config_name"": ""num_processes_3_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp1v2ap1t3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:50:45.815046,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0loulmxy.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:51:15.760381,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpjkf3g5rx.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:51:45.681410,grid,"{""config_name"": ""num_processes_1_batching_16_precision_int4_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_ejy8cwi.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:52:15.708244,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9scazlcm.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:52:45.651281,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpi5rbjcwk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:53:15.527321,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_gqju0m4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:53:45.467485,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpn6oljqcs.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:54:15.403364,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpg1v1otod.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:54:45.275128,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmplu28axts.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:55:15.110360,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpksojpoq5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:55:45.002424,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpsiyc0cju.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:56:14.919763,grid,"{""config_name"": ""num_processes_3_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptqvisory.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:56:44.862345,grid,"{""config_name"": ""num_processes_1_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpql0i0hov.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:57:27.469634,grid,"{""config_name"": ""num_processes_3_batching_2_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp6p86hv8p.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:57:57.360854,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0hs0wqh5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:58:27.250295,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpaebejj6j.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:58:57.240893,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptawxch6x.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:59:27.252839,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp32_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppd8qthqg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:59:57.152929,grid,"{""config_name"": ""num_processes_2_batching_2_precision_int8_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpsap54jp5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:00:27.745739,grid,"{""config_name"": ""num_processes_3_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpk6zuke2x.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:00:57.869254,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2w75q8dh.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:01:33.495096,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpduniqlme.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:02:03.543816,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp56i6iqqv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:02:33.644888,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp6krfkm3t.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:03:18.661808,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpit_a92wv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:04:11.665332,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5oqkv41n.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:04:41.984846,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpr0a53snt.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:05:21.764163,grid,"{""config_name"": ""num_processes_3_batching_4_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvvbyefhf.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:05:51.884432,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8otbzjbm.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:06:22.039644,grid,"{""config_name"": ""num_processes_3_batching_16_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpbok15h5c.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:06:52.181092,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmps2d22fx9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:07:22.240231,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpod7veifl.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:07:52.370326,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpamxrf7n5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:08:22.525336,grid,"{""config_name"": ""num_processes_4_batching_2_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfysa93v5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:08:52.703234,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvv9ubeh3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:09:47.610704,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp06vqp9gu.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:10:17.707839,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpalz7n49k.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:10:47.967412,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int8_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdxon102i.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:11:18.103993,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfh2kpj8k.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:11:53.807687,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpd5w1hao1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:12:23.655070,grid,"{""config_name"": ""num_processes_3_batching_4_precision_fp32_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpv36jyvsg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:12:53.543015,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpy6r1inyj.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:13:26.514595,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwcr4o_3a.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:13:56.330800,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4hx4qb9s.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:14:26.114697,grid,"{""config_name"": ""num_processes_2_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_91yjlal.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:15:02.913465,grid,"{""config_name"": ""num_processes_1_batching_2_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpkevnmqz_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:15:35.268646,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpm4bjt_7d.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:16:06.403296,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_iguftg3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:16:36.283517,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpeijbuk77.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:17:06.205693,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppjzaoscq.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:17:36.085585,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgldgfm55.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:18:05.951421,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpbpi185li.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:18:35.841386,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpnp0_fr9w.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:19:05.682211,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int4_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmput3kd0ly.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:19:35.548995,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfkgptvy3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:20:05.432795,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpl4ttaiou.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:20:35.432559,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int4_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0rpdwvvz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:21:05.489974,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_e0dr0yf.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:21:50.883740,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvbxyvt75.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:22:20.822494,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptyleogfr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:23:01.252685,grid,"{""config_name"": ""num_processes_3_batching_32_precision_int4_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp94uwfqfp.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:23:31.205551,grid,"{""config_name"": ""num_processes_1_batching_8_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpatjz4hpv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:24:02.211134,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9r9b04o0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:24:32.037920,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpndk26_tq.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:25:01.889768,grid,"{""config_name"": ""num_processes_4_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpb98hjqcf.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:25:33.800749,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppftt4ro0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:26:07.034280,grid,"{""config_name"": ""num_processes_4_batching_2_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpuaiqcxt6.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:26:39.892738,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpl7d6ege7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:27:25.540790,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp6jnap6_j.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:27:58.900677,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpswg6yun1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:28:31.772664,grid,"{""config_name"": ""num_processes_2_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpejnqi4fo.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:29:04.544760,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0scda27l.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:29:38.170081,grid,"{""config_name"": ""num_processes_3_batching_32_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8g81elh3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:30:10.828490,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpq6lhg8ho.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:30:43.492307,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpv_1dt5_w.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:31:15.900783,grid,"{""config_name"": ""num_processes_4_batching_16_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpoaomf2e1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:31:49.228722,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpm75js10x.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:32:22.323693,grid,"{""config_name"": ""num_processes_2_batching_64_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpc69843an.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:33:18.280447,grid,"{""config_name"": ""num_processes_4_batching_2_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvu2h4c07.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:33:51.190416,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_0_f55kg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:34:23.825269,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzdj5wjey.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:34:56.748763,grid,"{""config_name"": ""num_processes_3_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpyljoi316.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:54:40.452593,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfcmdlihr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:55:10.072710,grid,"{""config_name"": ""num_processes_1_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4rfs7cmr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:55:39.743351,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpn0nxplbd.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:56:09.316336,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpmszb79yg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:56:38.918063,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptxsjfmpg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:57:08.619518,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpv3978qnj.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:57:38.388844,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdq8ey6c9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:58:07.901393,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpn7dvocso.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:58:52.760603,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgbnc0wjb.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-29T12:48:11.539901,grid,"{""config_name"": ""num_processes_2_batching_2_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3s47o_j0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:10:13.435706,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppz2j45uv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:10:43.094645,grid,"{""config_name"": ""num_processes_1_batching_2_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmplr2s513j.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:11:12.656835,grid,"{""config_name"": ""num_processes_1_batching_32_precision_int4_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpu8syg_al.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:11:42.208198,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp32_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5idp1pqt.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:12:11.788974,grid,"{""config_name"": ""num_processes_3_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp6r95gsd2.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:12:41.348871,grid,"{""config_name"": ""num_processes_1_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpv0yekkns.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:13:11.064895,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpf1g0afa8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:14:03.881315,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpcaqx57dw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:14:33.396183,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfudj6gyl.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:15:02.951668,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_mix6v86.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:15:42.825850,grid,"{""config_name"": ""num_processes_3_batching_2_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4mj18luh.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:16:12.384398,grid,"{""config_name"": ""num_processes_3_batching_16_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpjuldjzal.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:16:42.013309,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpu714jcom.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:17:11.587159,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpyptwuhnk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:17:41.244860,grid,"{""config_name"": ""num_processes_2_batching_4_precision_int4_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3tayyn6h.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:18:10.721511,grid,"{""config_name"": ""num_processes_3_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmplfx2z74i.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:18:41.668382,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpootr19g5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:19:11.276575,grid,"{""config_name"": ""num_processes_1_batching_4_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpw5x0lakv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:19:40.832983,grid,"{""config_name"": ""num_processes_3_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpuyu5v41k.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:20:10.423126,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdfzxkv9w.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:20:39.979705,grid,"{""config_name"": ""num_processes_1_batching_32_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmplst5cv_6.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:21:19.557207,grid,"{""config_name"": ""num_processes_1_batching_2_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpmt2dl06p.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:21:49.090552,grid,"{""config_name"": ""num_processes_1_batching_2_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp52ec_qhs.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:22:18.656676,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0iwyslku.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:22:48.415885,grid,"{""config_name"": ""num_processes_4_batching_64_precision_int4_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4d4uzs9z.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:23:17.975845,grid,"{""config_name"": ""num_processes_1_batching_8_precision_int8_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0_2ktsda.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:23:50.524839,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdyr69hj6.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:24:26.085243,grid,"{""config_name"": ""num_processes_2_batching_4_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp45il2b3c.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:24:55.604988,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp72gqk0oz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:25:48.491296,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpmrhqjbou.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:26:41.219119,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2y91gdrj.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:27:25.103995,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwxmwucn7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:27:54.593262,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9_p7stm8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:28:24.136180,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpuyj88hjz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:51:45.878665,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpe04i2ca7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:37:08.265091,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpk_bt68a4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:37:37.981918,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7vyv24pc.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:38:07.725712,grid,"{""config_name"": ""num_processes_1_batching_32_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3emk8vlx.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:38:37.423568,grid,"{""config_name"": ""num_processes_1_batching_2_precision_int8_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2m4erh7l.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:39:07.122625,grid,"{""config_name"": ""num_processes_3_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpiij2nau9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:39:36.805105,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvlqzjryl.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:40:06.520316,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpj4p4hgyd.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:40:36.237335,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp16_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpo5ggmbe3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:41:05.956075,grid,"{""config_name"": ""num_processes_3_batching_2_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpx0i9qfn6.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:41:50.535212,grid,"{""config_name"": ""num_processes_2_batching_2_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdrj4l68q.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:42:20.196831,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpuzgsie2q.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:43:12.083980,grid,"{""config_name"": ""num_processes_3_batching_4_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpyckiu7dg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:43:41.804836,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzc7ffh3x.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:44:11.537499,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int8_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_28uoa_g.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:44:41.280100,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpsvuq5g1p.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:45:11.044446,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpntq2v55m.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:45:40.810913,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp26nkkksq.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:46:10.508752,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7tdtlheg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:46:40.263860,grid,"{""config_name"": ""num_processes_4_batching_64_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmph4sshrms.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:47:09.988125,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2cbmh141.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:47:39.661158,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp33gsfexu.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:48:09.429245,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int4_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp37n335eo.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:48:39.150445,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpp0k6nmsl.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:00:35.402705,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpv266p7oi.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:01:10.772643,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int4_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppfdys0kx.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:01:40.345314,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpy0eqagum.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:02:10.081655,grid,"{""config_name"": ""num_processes_3_batching_2_precision_int8_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpy_sfs59a.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:02:39.730490,grid,"{""config_name"": ""num_processes_2_batching_16_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvi4fsp4o.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:03:09.364802,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp785vdy78.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:03:39.037384,grid,"{""config_name"": ""num_processes_3_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp31zq0hcv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:04:08.723443,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgcudovls.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:04:40.909298,grid,"{""config_name"": ""num_processes_4_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp88fhbrx5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:05:10.678387,grid,"{""config_name"": ""num_processes_3_batching_4_precision_int8_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpg2hgmwr8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:05:40.324120,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpessb3nix.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:06:09.986934,grid,"{""config_name"": ""num_processes_2_batching_64_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmprzx7pow8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:06:51.815256,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmplpygf3ib.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:23:06.612107,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpbmrfqg7w.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:23:40.870276,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpyazlrfo2.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:24:31.061433,grid,"{""config_name"": ""num_processes_1_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8klix6e_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:25:11.875746,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpuri7ivk0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:25:54.183355,grid,"{""config_name"": ""num_processes_4_batching_8_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9xnl_imc.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:26:23.797999,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptkinznyf.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:26:53.419511,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvcb63dy8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-15T01:18:51.517982,scenarios,"{""config_name"": ""R4_Standard_DualGPU_TopP_4bit"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R4_Standard_DualGPU_TopP_4bit"", ""realistic"": true}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.05, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 3.0, ""burst_size"": 6}, ""decoder_config"": {""decoding_mode"": ""top_p"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.9}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": null, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdc5b5x7d.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:29:23.514940,grid,"{""config_name"": ""num_processes_2_batching_4_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_8_blpgo.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:29:53.063286,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwz7wun11.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:30:22.700513,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzezs2vv4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:30:52.206953,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmphxuzaxyk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:31:21.768419,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int8_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpnhytdctg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:31:51.278293,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpcxj_si2m.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:32:20.846082,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_5bcsg0g.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:32:50.388287,grid,"{""config_name"": ""num_processes_3_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5piufm1_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:33:19.932564,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppco_5yf0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:33:49.409207,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpk4lehe6f.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:34:19.163688,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpmfmqiy8n.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:34:48.703101,grid,"{""config_name"": ""num_processes_2_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpy9ti28ch.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:35:18.347633,grid,"{""config_name"": ""num_processes_1_batching_2_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_ngn8mcb.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:35:47.896789,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp32_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpxkhcysfw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:36:17.457014,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9sc62xsk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:36:46.976190,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppg99775t.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:37:16.550961,grid,"{""config_name"": ""num_processes_1_batching_2_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpm8wntpoa.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:37:46.149560,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpji2irop5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:38:15.724845,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpxvacjpmt.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:39:00.210465,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp1u8kkaee.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:39:29.770951,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpeu_2g1p5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:39:59.417467,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp32_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpd1i86h0z.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:40:29.256595,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpkowsg0l4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:41:04.525000,grid,"{""config_name"": ""num_processes_2_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzln9zp3r.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:41:34.215773,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7fathkvc.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:42:04.171452,grid,"{""config_name"": ""num_processes_1_batching_32_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmplbwvwacu.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:42:33.715641,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int4_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpq0osyh2p.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:43:03.239547,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int8_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpx02_d5du.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:43:32.739641,grid,"{""config_name"": ""num_processes_3_batching_16_precision_int8_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpaxy58urk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:44:02.288942,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpggitqoa7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:44:31.872565,grid,"{""config_name"": ""num_processes_3_batching_2_precision_int4_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpozlqelyi.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:45:01.455041,grid,"{""config_name"": ""num_processes_4_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwee1ym1f.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:45:31.131121,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpb87hkst5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:46:00.773818,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp25b95i5h.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:46:30.357526,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int4_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfx55bmed.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:46:59.938506,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpay8dp9is.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:47:29.518327,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2q0k6itb.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:47:59.101070,grid,"{""config_name"": ""num_processes_1_batching_8_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpsv5s1h8x.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:48:32.205303,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp80hdq0fa.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:49:02.007787,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptv36r3d8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:49:53.219943,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpljb59jzq.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:50:22.811474,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpj7jwkoce.json', '--launched']' returned non-zero exit status 1."

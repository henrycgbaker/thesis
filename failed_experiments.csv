experiment_id,timestamp,suite,config,error_message
unknown,2025-04-17T01:11:48.235628,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvxfwgijk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T01:51:31.929905,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4iyrim4r.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T02:29:31.106382,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp20en59nm.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T03:14:47.256936,controlled,"{""config_name"": ""batching_256"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 256}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp220pfoc3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T06:54:40.208598,controlled,"{""config_name"": ""batching_128"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 128}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 128, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpxhw7tu_2.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T07:44:03.028737,controlled,"{""config_name"": ""batching_256"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 256}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp53nyu18h.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T08:37:55.147177,controlled,"{""config_name"": ""batching_128"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 128}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 128, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmphvapauqw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T13:38:06.239367,controlled,"{""config_name"": ""batching_256"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 256}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpve1gmedz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T14:35:41.307481,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdfz8hqbi.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T14:42:29.489398,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpcb5m9fyv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T14:49:05.362357,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3hbgv9wl.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T15:27:22.927227,controlled,"{""config_name"": ""batching_128"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 128}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 128, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpkapr7uq1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T16:20:37.463594,controlled,"{""config_name"": ""batching_256"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 256}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqs_xdjyi.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T16:31:12.287247,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmply4dco_d.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T16:33:13.587374,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpujnhmf10.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T16:38:20.323566,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3z_x15t2.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:29:37.114416,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpnzil3hzh.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:31:32.578960,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpy5ekuofu.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:32:41.327298,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5ln55xh9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:33:49.313324,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpsqswpl1j.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T14:00:30.291420,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpjlyes0ox.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T14:02:05.033421,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4f2emkij.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T14:03:39.353575,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpiirmz0hy.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T14:31:33.450076,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp1pl40gyi.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T15:12:37.015788,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5hp8m9al.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T16:11:22.104163,scenarios,"{""config_name"": ""R7_anti_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R7_anti_platonic_ideal"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 1, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 20}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.2, ""decoder_top_k"": null, ""decoder_top_p"": null, ""top_k"": 200}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2_izfejw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T16:15:59.539862,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpnc_b0kvt.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T16:41:46.298402,scenarios,"{""config_name"": ""R7_anti_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R7_anti_platonic_ideal"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 1, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 20}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.2, ""decoder_top_k"": null, ""decoder_top_p"": null, ""top_k"": 200}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9qabtsc1.json', '--launched']' died with <Signals.SIGKILL: 9>."
unknown,2025-04-18T17:28:25.479980,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', 'MAIN_a_single_experiment.py', '--config', '/tmp/tmpev4uyo0p.json', '--launched']' returned non-zero exit status 1."

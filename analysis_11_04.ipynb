{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will later move this into function script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_files = [\"controlled\", \"scenarios\", \"grid\", \"text_generation\"]\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "def process_possible_files(func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Loops over the global list 'possible_files', calls the provided function on each file,\n",
    "    and creates a global variable with the naming convention 'df_<file>_cleaned'\n",
    "    to store the resulting DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        func (callable): A function that takes at least a file name (first argument).\n",
    "        *args: Additional positional arguments that 'func' needs.\n",
    "        **kwargs: Additional keyword arguments that 'func' needs.\n",
    "    \n",
    "    The function will also attempt to display each transposed DataFrame.\n",
    "    \"\"\"\n",
    "    for file in possible_files:\n",
    "        try:\n",
    "            var_name = f\"df_{file}_cleaned\"\n",
    "            # Run the provided function on the file, passing along any additional arguments.\n",
    "            result_df = func(file, *args, **kwargs)\n",
    "            # Dynamically create a global variable with the result.\n",
    "            globals()[var_name] = result_df\n",
    "            print(f\"Found & inspecting: {var_name}\")\n",
    "            display(result_df.T)\n",
    "        except Exception as e:\n",
    "            print(f\"{file} did not process correctly: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference_metrics_raw_inference_metrics_number_input_prompts\n",
      "variables_quantisation_cached_flops_for_quantised_models\n",
      "setup_is_encoder_decoder\n",
      "variables_config_name\n",
      "variables_batching_options_max_batch_size___adaptive_batching\n",
      "variables_query_rate\n",
      "compute_metrics_flops\n",
      "variables_batching_options_batch_size___fixed_batching\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_3\n",
      "compute_metrics_compute_utilisation_cpu_usage_percent\n",
      "variables_batching_options_adaptive_batching\n",
      "global_energy_metrics_local_process_results_ram_power_process_2\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_2\n",
      "global_energy_metrics_global_experiment_results_ram_energy_total\n",
      "global_energy_metrics_local_process_results_ram_energy_process_2\n",
      "global_energy_metrics_local_process_results_gpu_power_process_3\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_3\n",
      "variables_quantisation_load_in_8bit\n",
      "global_energy_metrics_global_derived_quantities_flops_per_joule\n",
      "variables_decoder_config_decoding_mode\n",
      "global_energy_metrics_per-process_emissions_2\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_2\n",
      "global_energy_metrics_local_process_results_ram_power_process_1\n",
      "global_energy_metrics_global_experiment_results_total_energy_kwh\n",
      "setup_gpu_model\n",
      "variables_inference_type\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_1\n",
      "global_energy_metrics_global_experiment_results_cpu_energy_total\n",
      "inference_metrics_raw_inference_metrics_total_input_tokens\n",
      "global_energy_metrics_global_experiment_results_total_energy_joules\n",
      "model_architecture_total_params\n",
      "global_energy_metrics_per-process_emissions_3\n",
      "setup_os\n",
      "variables_max_input_tokens\n",
      "compute_metrics_memory_gpu_max_memory_reserved_bytes\n",
      "global_energy_metrics_global_derived_quantities_joules_per_token\n",
      "variables_quantisation_load_in_4bit\n",
      "setup_task_type\n",
      "global_energy_metrics_global_derived_quantities_tokens_per_joule\n",
      "inference_metrics_inference_performance_average_latency_ms_per_batch\n",
      "variables_accelerate_config_num_processes\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_0\n",
      "setup_model\n",
      "global_energy_metrics_local_process_results_gpu_power_process_1\n",
      "global_energy_metrics_global_experiment_results_gpu_power_avg\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_0\n",
      "variables_accelerate_config_distributed_type\n",
      "global_energy_metrics_global_derived_quantities_joules_per_flop\n",
      "variables_decoder_config_decoder_top_k\n",
      "global_energy_metrics_local_process_results_ram_power_process_3\n",
      "global_energy_metrics_local_process_results_cpu_power_process_2\n",
      "variables_latency_simulation_simulate\n",
      "global_energy_metrics_local_process_results_gpu_power_process_0\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_2\n",
      "global_energy_metrics_local_process_results_ram_energy_process_0\n",
      "setup_experiment_id\n",
      "variables_latency_simulation_delay_max\n",
      "setup_available_gpu_count\n",
      "variables_decoder_config_decoder_temperature\n",
      "global_energy_metrics_per-process_emissions_0\n",
      "global_energy_metrics_experiment_id\n",
      "variables_sharding_config_sharding_strategy\n",
      "compute_metrics_compute_utilisation_cpu_memory_usage_bytes\n",
      "variables_latency_simulation_burst_size\n",
      "variables_fp_precision\n",
      "global_energy_metrics_local_process_results_cpu_power_process_3\n",
      "global_energy_metrics_local_process_results_ram_power_process_0\n",
      "setup_date_time\n",
      "global_energy_metrics_global_experiment_results_gpu_energy_total\n",
      "inference_metrics_inference_performance_throughput_queries_per_sec\n",
      "compute_metrics_memory_gpu_current_memory_reserved_bytes\n",
      "variables_sharding_config_fsdp_config_use_orig_params\n",
      "variables_decode_token_to_text\n",
      "setup_region\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_3\n",
      "inference_metrics_raw_inference_metrics_total_generated_tokens\n",
      "variables_sharding_config_fsdp_config_cpu_offload\n",
      "global_energy_metrics_local_process_results_cpu_power_process_0\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_3\n",
      "setup_python_version\n",
      "global_energy_metrics_global_experiment_results_ram_power_avg\n",
      "compute_metrics_memory_gpu_max_memory_allocated_bytes\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_1\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_0\n",
      "setup_cpu_model\n",
      "variables_decoder_config_decoder_top_p\n",
      "variables_latency_simulation_simulate_burst\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_3\n",
      "inference_metrics_inference_performance_total_inference_time_sec\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_1\n",
      "variables_batching_options_adaptive_max_tokens\n",
      "compute_metrics_memory_gpu_current_memory_allocated_bytes\n",
      "variables_latency_simulation_burst_interval\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_1\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_1\n",
      "variables_number_input_prompts\n",
      "global_energy_metrics_global_experiment_results_cpu_power_avg\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_2\n",
      "global_energy_metrics_local_process_results_cpu_power_process_1\n",
      "inference_metrics_inference_performance_throughput_tokens_per_sec\n",
      "global_energy_metrics_per-process_emissions_1\n",
      "global_energy_metrics_local_process_results_ram_energy_process_1\n",
      "setup_country\n",
      "variables_latency_simulation_delay_min\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_2\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_0\n",
      "variables_max_output_tokens\n",
      "global_energy_metrics_local_process_results_ram_energy_process_3\n",
      "setup_available_cpu_count\n",
      "model_architecture_architecture\n",
      "variables_backend\n",
      "global_energy_metrics_local_process_results_gpu_power_process_2\n",
      "variables_quantisation_quantization\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_0\n"
     ]
    }
   ],
   "source": [
    "notebook_dir = os.getcwd()\n",
    "df = process_possible_files\n",
    "df = pd.read_csv(\"analysis_results/controlled_results.csv\")\n",
    "\n",
    "columns = list(df.columns)\n",
    "for col in columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "controlled did not exist: [Errno 2] No such file or directory: 'controlled_results.csv'\n",
      "scenarios did not exist: [Errno 2] No such file or directory: 'scenarios_results.csv'\n",
      "grid did not exist: [Errno 2] No such file or directory: 'grid_results.csv'\n",
      "text_generation did not exist: [Errno 2] No such file or directory: 'text_generation_results.csv'\n"
     ]
    }
   ],
   "source": [
    "def clean_column(col: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean a single column name by:\n",
    "      - Stripping whitespace and replacing any non-standard quotes.\n",
    "      - Checking for per-process metric patterns.\n",
    "      - Applying special renames.\n",
    "      - Removing the 'variables_' prefix if present.\n",
    "      - Otherwise, attempting to strip off any messy prefixes using a known list of tokens.\n",
    "    \n",
    "    If no known token is found, the original (normalized) column name is returned.\n",
    "    \"\"\"\n",
    "    # Normalize the column string: remove extra whitespace and fix common issues with quotes.\n",
    "    col = col.strip()\n",
    "    col = col.replace(\"“\", \"\\\"\").replace(\"”\", \"\\\"\")\n",
    "    \n",
    "    # 1. Special exact mappings.\n",
    "    special_mappings = {\n",
    "        \"setup_cpu_model\": \"cpu_model\",\n",
    "        \"setup_gpu_model\": \"gpu_model\",\n",
    "        \"model_architecture_total_params\": \"total_params\",  # now maps to total_params\n",
    "        \"model_architecture_architecture\": \"model_arch\"\n",
    "    }\n",
    "    if col in special_mappings:\n",
    "        return special_mappings[col]\n",
    "    \n",
    "    # 2. Remove the 'variables_' prefix if it exists.\n",
    "    if col.startswith(\"variables_\"):\n",
    "        col = col[len(\"variables_\"):]\n",
    "    \n",
    "    # 3. First, check if it is a per-process metric column.\n",
    "    per_process_patterns = [\n",
    "        r'(cpu_power_process_\\d+)',\n",
    "        r'(gpu_power_process_\\d+)',\n",
    "        r'(ram_power_process_\\d+)',\n",
    "        r'(cpu_energy_process_\\d+)',\n",
    "        r'(gpu_energy_process_\\d+)',\n",
    "        r'(ram_energy_process_\\d+)',\n",
    "        r'(total_energy_kwh_process_\\d+)',\n",
    "        r'(total_energy_joules_process_\\d+)'\n",
    "    ]\n",
    "    for pattern in per_process_patterns:\n",
    "        match = re.search(pattern, col)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    \n",
    "    # 4. For non-per-process columns, search for a known token in the cleaned column.\n",
    "    tokens = [\n",
    "        \"config_name\", \"experiment_id\", \"date_time\", \"model\", \"is_encoder_decoder\",\n",
    "        \"task_type\", \"available_gpu_count\", \"gpu_model\", \"available_cpu_count\", \"cpu_model\",\n",
    "        \"os\", \"python_version\", \"country\", \"region\", \"fsdp_use_orig_params\", \"fsdp_cpu_offload\",\n",
    "        \"sharding_strategy\", \"distributed_type\", \"num_processes\", \"max_input_tokens\", \"max_output_tokens\",\n",
    "        \"number_input_prompts\", \"decode_token_to_text\", \"decoder_temperature\", \"decoder_top_k\", \"decoder_top_p\",\n",
    "        \"query_rate\", \"latency_simulate\", \"latency_delay_min\", \"latency_delay_max\", \"latency_simulate_burst\",\n",
    "        \"latency_burst_interval\", \"latency_burst_size\", \"fp_precision\", \"quantization\", \"load_in_8bit\",\n",
    "        \"load_in_4bit\", \"cached_flops_for_quantised_models\", \"batch_size___fixed_batching\", \"adaptive_batching\",\n",
    "        \"adaptive_max_tokens\", \"max_batch_size___adaptive_batching\", \"inference_type\", \"backend\", \"total_params\",\n",
    "        \"architecture\", \"total_input_tokens\", \"total_generated_tokens\", \"total_inference_time_sec\", \n",
    "        \"average_latency_ms_per_batch\", \"throughput_queries_per_sec\", \"throughput_tokens_per_sec\", \"flops\",\n",
    "        \"gpu_current_memory_allocated_bytes\", \"gpu_max_memory_allocated_bytes\", \"gpu_current_memory_reserved_bytes\",\n",
    "        \"gpu_max_memory_reserved_bytes\", \"gpu_utilization_percent\", \"cpu_usage_percent\", \"cpu_memory_usage_bytes\",\n",
    "        # Per-process metrics:\n",
    "        \"cpu_power_process_0\", \"gpu_power_process_0\", \"ram_power_process_0\",\n",
    "        \"cpu_energy_process_0\", \"gpu_energy_process_0\", \"ram_energy_process_0\",\n",
    "        \"total_energy_kwh_process_0\", \"total_energy_joules_process_0\",\n",
    "        # Global averages and totals:\n",
    "        \"cpu_power_avg\", \"gpu_power_avg\", \"ram_power_avg\", \"cpu_energy_total\", \"gpu_energy_total\", \"ram_energy_total\",\n",
    "        \"total_energy_kwh\", \"total_energy_joules\", \"tokens_per_joule\", \"joules_per_token\", \"flops_per_joule\", \"joules_per_flop\",\n",
    "        \"per-process_emissions\"\n",
    "    ]\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in col:\n",
    "            idx = col.find(token)\n",
    "            return col[idx:]\n",
    "    \n",
    "    return col\n",
    "\n",
    "def resolve_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Resolve duplicate columns in the DataFrame.\n",
    "    \n",
    "    For any column that appears more than once:\n",
    "      - For 'adaptive_batching', if duplicates exist, prefer the one with a boolean dtype;\n",
    "        otherwise, pick the first occurrence.\n",
    "      - For all other columns (including 'experiment_id' and 'number_input_prompts'),\n",
    "        keep only the first occurrence.\n",
    "    \"\"\"\n",
    "    # Build a mapping of column name to list of indices where it occurs.\n",
    "    seen = {}\n",
    "    for idx, col in enumerate(df.columns):\n",
    "        seen.setdefault(col, []).append(idx)\n",
    "    \n",
    "    # Choose one index per duplicate group.\n",
    "    chosen_indices = []\n",
    "    for col, indices in seen.items():\n",
    "        if len(indices) == 1:\n",
    "            chosen_indices.append(indices[0])\n",
    "        else:\n",
    "            if col == \"adaptive_batching\":\n",
    "                # Look for a column with boolean type.\n",
    "                bool_idx = None\n",
    "                for i in indices:\n",
    "                    if pd.api.types.is_bool_dtype(df.iloc[:, i]):\n",
    "                        bool_idx = i\n",
    "                        break\n",
    "                chosen_indices.append(bool_idx if bool_idx is not None else indices[0])\n",
    "            else:\n",
    "                # For experiment_id, number_input_prompts, or any duplicate, keep the first occurrence.\n",
    "                chosen_indices.append(indices[0])\n",
    "    \n",
    "    # Sort indices to preserve the original order.\n",
    "    chosen_indices.sort()\n",
    "    return df.iloc[:, chosen_indices]\n",
    "\n",
    "def clean_and_reorder_columns(df: pd.DataFrame, desired_order: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean DataFrame columns by:\n",
    "      1. Renaming each column to remove extraneous prefixes and apply special mappings.\n",
    "      2. Removing duplicates (applying special resolution for some columns).\n",
    "      3. Reordering columns into the order specified by 'desired_order'. Any columns not explicitly mentioned\n",
    "         will be appended at the end.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with messy, flattened column names.\n",
    "        desired_order (list): List of column names (after cleaning) indicating the preferred ordering.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with cleaned and reordered columns.\n",
    "    \"\"\"\n",
    "    # Build mapping from original column names to cleaned names.\n",
    "    mapping = {col: clean_column(col) for col in df.columns}\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    df = df.rename(columns=mapping)\n",
    "    \n",
    "    # Resolve duplicates as required.\n",
    "    df = resolve_duplicates(df)\n",
    "    \n",
    "    # Reorder columns: first, the ones matching the desired order.\n",
    "    ordered_cols = [col for col in desired_order if col in df.columns]\n",
    "    # Then, append any remaining columns.\n",
    "    remaining_cols = [col for col in df.columns if col not in desired_order]\n",
    "    final_order = ordered_cols + remaining_cols\n",
    "    \n",
    "    return df[final_order]\n",
    "\n",
    "# Example desired order list\n",
    "desired_order = [\n",
    "    \"config_name\",\n",
    "    \"experiment_id\",\n",
    "    \"date_time\",\n",
    "    \"model\",\n",
    "    # num_process\n",
    "    \"num_processes\",\n",
    "    # batching\n",
    "    \"batch_size___fixed_batching\",\n",
    "    # decodeer\n",
    "    \"decoder_temperature\",\n",
    "    \"decoder_top_k\",\n",
    "    \"decoder_top_p\",\n",
    "    # latency\n",
    "    \"latency_simulation_simulate\"\n",
    "    \"latency_simulation_delay_max\",\n",
    "    \"latency_simulation_delay_min\",\n",
    "    \"latency_simulation_simulate_burst\",\n",
    "    \"latency_simulation_burst_size\",\n",
    "    \"latency_simulation_burst_interval\",\n",
    "    # precision / quantisation\n",
    "    \"fp_precision\",\n",
    "    \"quantization\",\n",
    "    \"load_in_8bit\",\n",
    "    \"load_in_4bit\",\n",
    "    \"cached_flops_for_quantised_models\",\n",
    "    \n",
    "    # UNUSED PARAMS\n",
    "    \"sharding_strategy\",\n",
    "    \"sharding_config_fsdp_config_use_orig_params\",\n",
    "    \"sharding_config_fsdp_config_cpu_offload\",\n",
    "    \"adaptive_batching\",\n",
    "    \"adaptive_max_tokens\",\n",
    "    \"query_rate\",\n",
    "    \"total_input_tokens\",\n",
    "    \"total_generated_tokens\"\n",
    "    \n",
    "    # CONSTANT SETUP ====\n",
    "    \"date_time\",\n",
    "    \"is_encoder_decoder\",\n",
    "    \"task_type\",\n",
    "    \"available_gpu_count\",\n",
    "    \"gpu_model\",\n",
    "    \"available_cpu_count\",\n",
    "    \"cpu_model\",\n",
    "    \"os\",\n",
    "    \"python_version\",\n",
    "    \"country\",\n",
    "    \"region\",\n",
    "    \"distributed_type\",\n",
    "    \"decode_token_to_text\",\n",
    "    \"inference_type\",\n",
    "    \"backend\",\n",
    "    \"total_params\",\n",
    "    \"model_arch\",\n",
    "\n",
    "    # Validation (should be same):\n",
    "    \"max_input_tokens\",\n",
    "    \"max_output_tokens\",\n",
    "    \"number_input_prompts\",\n",
    "    \n",
    "    # RESULTS =====\n",
    "    # energy\n",
    "    \"total_energy_kwh\",\n",
    "    \"total_energy_joules\",\n",
    "    # FLOPS\n",
    "    \"flops\",\n",
    "    \"tokens_per_joule\",\n",
    "    \"joules_per_token\",\n",
    "    \"flops_per_joule\",\n",
    "    \"joules_per_flop\",\n",
    "    \"total_inference_time_sec\", \n",
    "    # inference performance\n",
    "    \"average_latency_ms_per_batch\",\n",
    "    \"throughput_queries_per_sec\",\n",
    "    \"throughput_tokens_per_sec\",\n",
    "    # CPU utilization\n",
    "    \"cpu_usage_percent\",\n",
    "    \"cpu_memory_usage_bytes\",\n",
    "    # GPU utilization\n",
    "    \"gpu_utilization_percent_0\", \"gpu_utilization_percent_1\", \"gpu_utilization_percent_2\", \"gpu_utilization_percent_3\",\n",
    "    # Compute mem\n",
    "    \"gpu_current_memory_allocated_bytes\",\n",
    "    \"gpu_max_memory_allocated_bytes\",\n",
    "    \"gpu_current_memory_reserved_bytes\",\n",
    "    \"gpu_max_memory_reserved_bytes\",\n",
    "    # Per-process metrics:\n",
    "    \"cpu_power_process_0\", \"cpu_power_process_1\", \"cpu_power_process_2\", \"cpu_power_process_3\",\n",
    "    \"gpu_power_process_0\", \"gpu_power_process_1\", \"gpu_power_process_2\", \"gpu_power_process_3\",\n",
    "    \"ram_power_process_0\", \"ram_power_process_1\", \"ram_power_process_2\", \"ram_power_process_3\",\n",
    "    \"cpu_energy_process_0\", \"cpu_energy_process_1\", \"cpu_energy_process_2\", \"cpu_energy_process_3\",\n",
    "    \"gpu_energy_process_0\", \"gpu_energy_process_1\", \"gpu_energy_process_2\", \"gpu_energy_process_3\",\n",
    "    \"ram_energy_process_0\", \"ram_energy_process_1\", \"ram_energy_process_2\", \"ram_energy_process_3\",\n",
    "    \"total_energy_kwh_process_0\", \"total_energy_kwh_process_1\", \"total_energy_kwh_process_2\", \"total_energy_kwh_process_3\",\n",
    "    \"total_energy_joules_process_0\", \"total_energy_joules_process_1\", \"total_energy_joules_process_2\", \"total_energy_joules_process_3\",\n",
    "    # Global averages and totals:\n",
    "    \"cpu_power_avg\",\n",
    "    \"gpu_power_avg\",\n",
    "    \"ram_power_avg\",\n",
    "    \"cpu_energy_total\",\n",
    "    \"gpu_energy_total\",\n",
    "    \"ram_energy_total\",\n",
    "    # per-process_emsisisons\n",
    "    \"per-process_emissions_0\", \"per-process_emissions_1\", \"per-process_emissions_2\",\"per-process_emissions_3\"\n",
    "]\n",
    "\n",
    "def inspect_results(name, desired_order):\n",
    "    input_file = f\"analysis_results/{name}_results.csv\"\n",
    "    \n",
    "    df = pd.read_csv(input_file)\n",
    "    df_cleaned = clean_and_reorder_columns(df, desired_order)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "# ========================\n",
    "\n",
    "possible_files = [\"controlled\", \"scenarios\", \"grid\", \"text_generation\"]\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "for file in possible_files:\n",
    "    try:\n",
    "        var_name = f\"df_{file}_cleaned\"\n",
    "        globals()[var_name] = inspect_results(file, desired_order)  # dynamically create variable\n",
    "        print(f\"Found & inspecting: {var_name}\")\n",
    "        display(globals()[var_name].T)\n",
    "    except Exception as e:\n",
    "        print(f\"{file} did not exist: {e}\")\n",
    "\n",
    "# COME BACK TO THIS\n",
    "#process_possible_files(func=clean_and_reorder_columns, \n",
    "#                       desired_order=desired_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found & inspecting dropped version: df_controlled_dropped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>config_name</th>\n",
       "      <td>num_processes_1</td>\n",
       "      <td>num_processes_2</td>\n",
       "      <td>num_processes_3</td>\n",
       "      <td>num_processes_4</td>\n",
       "      <td>batching_1</td>\n",
       "      <td>batching_2</td>\n",
       "      <td>batching_4</td>\n",
       "      <td>batching_8</td>\n",
       "      <td>batching_16</td>\n",
       "      <td>batching_32</td>\n",
       "      <td>batching_64</td>\n",
       "      <td>precis_float32_quant_False_quant8_False_quant4...</td>\n",
       "      <td>precis_float16_quant_False_quant8_False_quant4...</td>\n",
       "      <td>precis_float16_quant_True_quant8_True_quant4_F...</td>\n",
       "      <td>precis_float16_quant_True_quant8_False_quant4_...</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.2</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.4</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.6</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.8</td>\n",
       "      <td>decoding_greedy_decoder_temperature_1.0</td>\n",
       "      <td>decoding_greedy_decoder_temperature_1.2</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>latency_False</td>\n",
       "      <td>latency_True_latency_0.05_latency_0.2_latency_...</td>\n",
       "      <td>latency_True_latency_0.2_latency_0.6_latency_F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <td>233</td>\n",
       "      <td>234</td>\n",
       "      <td>235</td>\n",
       "      <td>236</td>\n",
       "      <td>237</td>\n",
       "      <td>238</td>\n",
       "      <td>239</td>\n",
       "      <td>240</td>\n",
       "      <td>241</td>\n",
       "      <td>242</td>\n",
       "      <td>243</td>\n",
       "      <td>244</td>\n",
       "      <td>245</td>\n",
       "      <td>246</td>\n",
       "      <td>247</td>\n",
       "      <td>248</td>\n",
       "      <td>249</td>\n",
       "      <td>250</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>256</td>\n",
       "      <td>257</td>\n",
       "      <td>258</td>\n",
       "      <td>259</td>\n",
       "      <td>260</td>\n",
       "      <td>261</td>\n",
       "      <td>262</td>\n",
       "      <td>263</td>\n",
       "      <td>264</td>\n",
       "      <td>265</td>\n",
       "      <td>266</td>\n",
       "      <td>267</td>\n",
       "      <td>268</td>\n",
       "      <td>269</td>\n",
       "      <td>270</td>\n",
       "      <td>271</td>\n",
       "      <td>272</td>\n",
       "      <td>273</td>\n",
       "      <td>274</td>\n",
       "      <td>275</td>\n",
       "      <td>276</td>\n",
       "      <td>277</td>\n",
       "      <td>278</td>\n",
       "      <td>279</td>\n",
       "      <td>280</td>\n",
       "      <td>281</td>\n",
       "      <td>282</td>\n",
       "      <td>283</td>\n",
       "      <td>284</td>\n",
       "      <td>285</td>\n",
       "      <td>286</td>\n",
       "      <td>287</td>\n",
       "      <td>288</td>\n",
       "      <td>289</td>\n",
       "      <td>290</td>\n",
       "      <td>296</td>\n",
       "      <td>297</td>\n",
       "      <td>298</td>\n",
       "      <td>299</td>\n",
       "      <td>300</td>\n",
       "      <td>301</td>\n",
       "      <td>302</td>\n",
       "      <td>303</td>\n",
       "      <td>304</td>\n",
       "      <td>305</td>\n",
       "      <td>306</td>\n",
       "      <td>307</td>\n",
       "      <td>308</td>\n",
       "      <td>309</td>\n",
       "      <td>310</td>\n",
       "      <td>311</td>\n",
       "      <td>312</td>\n",
       "      <td>313</td>\n",
       "      <td>314</td>\n",
       "      <td>315</td>\n",
       "      <td>316</td>\n",
       "      <td>317</td>\n",
       "      <td>318</td>\n",
       "      <td>319</td>\n",
       "      <td>320</td>\n",
       "      <td>321</td>\n",
       "      <td>322</td>\n",
       "      <td>323</td>\n",
       "      <td>328</td>\n",
       "      <td>329</td>\n",
       "      <td>330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <td>April 11, 2025 at 05:02:12 PM</td>\n",
       "      <td>April 11, 2025 at 05:03:25 PM</td>\n",
       "      <td>April 11, 2025 at 05:04:40 PM</td>\n",
       "      <td>April 11, 2025 at 05:05:55 PM</td>\n",
       "      <td>April 11, 2025 at 05:13:02 PM</td>\n",
       "      <td>April 11, 2025 at 05:18:36 PM</td>\n",
       "      <td>April 11, 2025 at 05:21:39 PM</td>\n",
       "      <td>April 11, 2025 at 05:23:23 PM</td>\n",
       "      <td>April 11, 2025 at 05:24:30 PM</td>\n",
       "      <td>April 11, 2025 at 05:25:17 PM</td>\n",
       "      <td>April 11, 2025 at 05:25:56 PM</td>\n",
       "      <td>April 11, 2025 at 05:26:49 PM</td>\n",
       "      <td>April 11, 2025 at 05:27:40 PM</td>\n",
       "      <td>April 11, 2025 at 05:29:22 PM</td>\n",
       "      <td>April 11, 2025 at 05:30:29 PM</td>\n",
       "      <td>April 11, 2025 at 05:31:35 PM</td>\n",
       "      <td>April 11, 2025 at 05:32:41 PM</td>\n",
       "      <td>April 11, 2025 at 05:33:46 PM</td>\n",
       "      <td>April 11, 2025 at 05:34:52 PM</td>\n",
       "      <td>April 11, 2025 at 05:35:58 PM</td>\n",
       "      <td>April 11, 2025 at 05:37:04 PM</td>\n",
       "      <td>April 11, 2025 at 05:38:09 PM</td>\n",
       "      <td>April 11, 2025 at 05:39:42 PM</td>\n",
       "      <td>April 11, 2025 at 05:40:48 PM</td>\n",
       "      <td>April 11, 2025 at 05:41:54 PM</td>\n",
       "      <td>April 11, 2025 at 05:43:00 PM</td>\n",
       "      <td>April 11, 2025 at 05:44:05 PM</td>\n",
       "      <td>April 11, 2025 at 05:45:11 PM</td>\n",
       "      <td>April 11, 2025 at 05:46:17 PM</td>\n",
       "      <td>April 11, 2025 at 05:47:23 PM</td>\n",
       "      <td>April 11, 2025 at 05:48:29 PM</td>\n",
       "      <td>April 11, 2025 at 05:49:38 PM</td>\n",
       "      <td>April 11, 2025 at 05:50:44 PM</td>\n",
       "      <td>April 11, 2025 at 05:51:50 PM</td>\n",
       "      <td>April 11, 2025 at 05:52:55 PM</td>\n",
       "      <td>April 11, 2025 at 05:54:01 PM</td>\n",
       "      <td>April 11, 2025 at 05:55:07 PM</td>\n",
       "      <td>April 11, 2025 at 05:56:12 PM</td>\n",
       "      <td>April 11, 2025 at 05:57:18 PM</td>\n",
       "      <td>April 11, 2025 at 05:58:24 PM</td>\n",
       "      <td>April 11, 2025 at 05:59:29 PM</td>\n",
       "      <td>April 11, 2025 at 06:00:36 PM</td>\n",
       "      <td>April 11, 2025 at 06:01:44 PM</td>\n",
       "      <td>April 11, 2025 at 06:02:51 PM</td>\n",
       "      <td>April 11, 2025 at 06:03:57 PM</td>\n",
       "      <td>April 11, 2025 at 06:05:03 PM</td>\n",
       "      <td>April 11, 2025 at 06:06:10 PM</td>\n",
       "      <td>April 11, 2025 at 06:07:16 PM</td>\n",
       "      <td>April 11, 2025 at 06:08:21 PM</td>\n",
       "      <td>April 11, 2025 at 06:09:27 PM</td>\n",
       "      <td>April 11, 2025 at 06:10:32 PM</td>\n",
       "      <td>April 11, 2025 at 06:11:38 PM</td>\n",
       "      <td>April 11, 2025 at 06:12:45 PM</td>\n",
       "      <td>April 11, 2025 at 06:13:51 PM</td>\n",
       "      <td>April 11, 2025 at 06:14:58 PM</td>\n",
       "      <td>April 11, 2025 at 06:16:04 PM</td>\n",
       "      <td>April 11, 2025 at 06:17:15 PM</td>\n",
       "      <td>April 11, 2025 at 06:20:42 PM</td>\n",
       "      <td>April 11, 2025 at 06:21:47 PM</td>\n",
       "      <td>April 11, 2025 at 06:22:52 PM</td>\n",
       "      <td>April 11, 2025 at 06:23:58 PM</td>\n",
       "      <td>April 11, 2025 at 06:25:04 PM</td>\n",
       "      <td>April 11, 2025 at 06:26:10 PM</td>\n",
       "      <td>April 11, 2025 at 06:27:16 PM</td>\n",
       "      <td>April 11, 2025 at 06:28:21 PM</td>\n",
       "      <td>April 11, 2025 at 06:29:27 PM</td>\n",
       "      <td>April 11, 2025 at 06:30:33 PM</td>\n",
       "      <td>April 11, 2025 at 06:31:40 PM</td>\n",
       "      <td>April 11, 2025 at 06:32:49 PM</td>\n",
       "      <td>April 11, 2025 at 06:33:55 PM</td>\n",
       "      <td>April 11, 2025 at 06:35:01 PM</td>\n",
       "      <td>April 11, 2025 at 06:36:06 PM</td>\n",
       "      <td>April 11, 2025 at 06:37:12 PM</td>\n",
       "      <td>April 11, 2025 at 06:38:18 PM</td>\n",
       "      <td>April 11, 2025 at 06:39:24 PM</td>\n",
       "      <td>April 11, 2025 at 06:40:30 PM</td>\n",
       "      <td>April 11, 2025 at 06:41:37 PM</td>\n",
       "      <td>April 11, 2025 at 06:42:44 PM</td>\n",
       "      <td>April 11, 2025 at 06:43:50 PM</td>\n",
       "      <td>April 11, 2025 at 06:44:56 PM</td>\n",
       "      <td>April 11, 2025 at 06:46:02 PM</td>\n",
       "      <td>April 11, 2025 at 06:47:09 PM</td>\n",
       "      <td>April 11, 2025 at 06:48:16 PM</td>\n",
       "      <td>April 11, 2025 at 06:49:22 PM</td>\n",
       "      <td>April 11, 2025 at 06:50:29 PM</td>\n",
       "      <td>April 11, 2025 at 06:53:27 PM</td>\n",
       "      <td>April 11, 2025 at 06:54:34 PM</td>\n",
       "      <td>April 11, 2025 at 06:55:45 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_processes</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size___fixed_batching</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_temperature</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_k</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_p</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate_burst</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_size</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_interval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp_precision</th>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantization</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_8bit</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_4bit</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_input_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_params</th>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_input_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_output_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_input_prompts</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh</th>\n",
       "      <td>0.003973</td>\n",
       "      <td>0.009084</td>\n",
       "      <td>0.014652</td>\n",
       "      <td>0.022451</td>\n",
       "      <td>0.173708</td>\n",
       "      <td>0.121135</td>\n",
       "      <td>0.064102</td>\n",
       "      <td>0.035372</td>\n",
       "      <td>0.021079</td>\n",
       "      <td>0.012114</td>\n",
       "      <td>0.007437</td>\n",
       "      <td>0.021202</td>\n",
       "      <td>0.012864</td>\n",
       "      <td>0.025157</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020611</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>0.021079</td>\n",
       "      <td>0.021087</td>\n",
       "      <td>0.021035</td>\n",
       "      <td>0.021028</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.020493</td>\n",
       "      <td>0.020526</td>\n",
       "      <td>0.020592</td>\n",
       "      <td>0.020612</td>\n",
       "      <td>0.020695</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.021167</td>\n",
       "      <td>0.021317</td>\n",
       "      <td>0.021256</td>\n",
       "      <td>0.021237</td>\n",
       "      <td>0.021173</td>\n",
       "      <td>0.021219</td>\n",
       "      <td>0.021218</td>\n",
       "      <td>0.021238</td>\n",
       "      <td>0.021238</td>\n",
       "      <td>0.021201</td>\n",
       "      <td>0.021264</td>\n",
       "      <td>0.021225</td>\n",
       "      <td>0.021234</td>\n",
       "      <td>0.021319</td>\n",
       "      <td>0.021258</td>\n",
       "      <td>0.021287</td>\n",
       "      <td>0.021207</td>\n",
       "      <td>0.021255</td>\n",
       "      <td>0.021197</td>\n",
       "      <td>0.021211</td>\n",
       "      <td>0.021179</td>\n",
       "      <td>0.02115</td>\n",
       "      <td>0.021163</td>\n",
       "      <td>0.021133</td>\n",
       "      <td>0.021166</td>\n",
       "      <td>0.021162</td>\n",
       "      <td>0.021253</td>\n",
       "      <td>0.021272</td>\n",
       "      <td>0.021315</td>\n",
       "      <td>0.020483</td>\n",
       "      <td>0.020574</td>\n",
       "      <td>0.020635</td>\n",
       "      <td>0.02061</td>\n",
       "      <td>0.021128</td>\n",
       "      <td>0.021085</td>\n",
       "      <td>0.021104</td>\n",
       "      <td>0.021038</td>\n",
       "      <td>0.021123</td>\n",
       "      <td>0.021142</td>\n",
       "      <td>0.021125</td>\n",
       "      <td>0.021159</td>\n",
       "      <td>0.021188</td>\n",
       "      <td>0.021216</td>\n",
       "      <td>0.021275</td>\n",
       "      <td>0.021175</td>\n",
       "      <td>0.021218</td>\n",
       "      <td>0.021133</td>\n",
       "      <td>0.021153</td>\n",
       "      <td>0.021139</td>\n",
       "      <td>0.021052</td>\n",
       "      <td>0.021089</td>\n",
       "      <td>0.021076</td>\n",
       "      <td>0.021173</td>\n",
       "      <td>0.021169</td>\n",
       "      <td>0.021177</td>\n",
       "      <td>0.021209</td>\n",
       "      <td>0.021157</td>\n",
       "      <td>0.020897</td>\n",
       "      <td>0.021343</td>\n",
       "      <td>0.022104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules</th>\n",
       "      <td>14303.761229</td>\n",
       "      <td>32700.724679</td>\n",
       "      <td>52747.350103</td>\n",
       "      <td>80824.506502</td>\n",
       "      <td>625349.848478</td>\n",
       "      <td>436084.529304</td>\n",
       "      <td>230767.542556</td>\n",
       "      <td>127338.055234</td>\n",
       "      <td>75884.699531</td>\n",
       "      <td>43611.764042</td>\n",
       "      <td>26773.911916</td>\n",
       "      <td>76325.798731</td>\n",
       "      <td>46310.921387</td>\n",
       "      <td>90564.656156</td>\n",
       "      <td>75601.377686</td>\n",
       "      <td>74199.651611</td>\n",
       "      <td>76054.746039</td>\n",
       "      <td>75884.577747</td>\n",
       "      <td>75912.204543</td>\n",
       "      <td>75727.619266</td>\n",
       "      <td>75701.472545</td>\n",
       "      <td>75790.175016</td>\n",
       "      <td>73773.389464</td>\n",
       "      <td>73892.703968</td>\n",
       "      <td>74129.708593</td>\n",
       "      <td>74203.606308</td>\n",
       "      <td>74501.001648</td>\n",
       "      <td>75946.539604</td>\n",
       "      <td>76201.793024</td>\n",
       "      <td>76742.959091</td>\n",
       "      <td>76520.796084</td>\n",
       "      <td>76452.8938</td>\n",
       "      <td>76223.569931</td>\n",
       "      <td>76386.637887</td>\n",
       "      <td>76383.180866</td>\n",
       "      <td>76458.267707</td>\n",
       "      <td>76456.077645</td>\n",
       "      <td>76322.508765</td>\n",
       "      <td>76552.127557</td>\n",
       "      <td>76410.590357</td>\n",
       "      <td>76443.543844</td>\n",
       "      <td>76748.976626</td>\n",
       "      <td>76530.379229</td>\n",
       "      <td>76631.935788</td>\n",
       "      <td>76346.735078</td>\n",
       "      <td>76517.116778</td>\n",
       "      <td>76308.943626</td>\n",
       "      <td>76361.089511</td>\n",
       "      <td>76245.168806</td>\n",
       "      <td>76141.04486</td>\n",
       "      <td>76187.233345</td>\n",
       "      <td>76079.755405</td>\n",
       "      <td>76195.841449</td>\n",
       "      <td>76181.591128</td>\n",
       "      <td>76512.58586</td>\n",
       "      <td>76578.514995</td>\n",
       "      <td>76733.750114</td>\n",
       "      <td>73737.29051</td>\n",
       "      <td>74065.599056</td>\n",
       "      <td>74286.409458</td>\n",
       "      <td>74197.531957</td>\n",
       "      <td>76059.345286</td>\n",
       "      <td>75905.904876</td>\n",
       "      <td>75972.984254</td>\n",
       "      <td>75736.281912</td>\n",
       "      <td>76043.391166</td>\n",
       "      <td>76110.532775</td>\n",
       "      <td>76051.292784</td>\n",
       "      <td>76172.032345</td>\n",
       "      <td>76276.785887</td>\n",
       "      <td>76377.761846</td>\n",
       "      <td>76590.669268</td>\n",
       "      <td>76229.985716</td>\n",
       "      <td>76384.326872</td>\n",
       "      <td>76078.501706</td>\n",
       "      <td>76152.181146</td>\n",
       "      <td>76101.321315</td>\n",
       "      <td>75787.25771</td>\n",
       "      <td>75921.972142</td>\n",
       "      <td>75872.506432</td>\n",
       "      <td>76223.661305</td>\n",
       "      <td>76208.729832</td>\n",
       "      <td>76236.684702</td>\n",
       "      <td>76352.285347</td>\n",
       "      <td>76166.395123</td>\n",
       "      <td>75230.05363</td>\n",
       "      <td>76834.458713</td>\n",
       "      <td>79575.575957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops</th>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens_per_joule</th>\n",
       "      <td>1.145433</td>\n",
       "      <td>0.501029</td>\n",
       "      <td>0.310613</td>\n",
       "      <td>0.202711</td>\n",
       "      <td>0.023441</td>\n",
       "      <td>0.037341</td>\n",
       "      <td>0.070998</td>\n",
       "      <td>0.128665</td>\n",
       "      <td>0.215907</td>\n",
       "      <td>0.375678</td>\n",
       "      <td>0.611939</td>\n",
       "      <td>0.214659</td>\n",
       "      <td>0.353783</td>\n",
       "      <td>0.180909</td>\n",
       "      <td>0.216716</td>\n",
       "      <td>0.22081</td>\n",
       "      <td>0.215424</td>\n",
       "      <td>0.215907</td>\n",
       "      <td>0.215828</td>\n",
       "      <td>0.216354</td>\n",
       "      <td>0.216429</td>\n",
       "      <td>0.216176</td>\n",
       "      <td>0.222085</td>\n",
       "      <td>0.221727</td>\n",
       "      <td>0.221018</td>\n",
       "      <td>0.220798</td>\n",
       "      <td>0.219917</td>\n",
       "      <td>0.215731</td>\n",
       "      <td>0.215008</td>\n",
       "      <td>0.213492</td>\n",
       "      <td>0.214112</td>\n",
       "      <td>0.214302</td>\n",
       "      <td>0.214947</td>\n",
       "      <td>0.214488</td>\n",
       "      <td>0.214497</td>\n",
       "      <td>0.214287</td>\n",
       "      <td>0.214293</td>\n",
       "      <td>0.214668</td>\n",
       "      <td>0.214024</td>\n",
       "      <td>0.214421</td>\n",
       "      <td>0.214328</td>\n",
       "      <td>0.213475</td>\n",
       "      <td>0.214085</td>\n",
       "      <td>0.213801</td>\n",
       "      <td>0.2146</td>\n",
       "      <td>0.214122</td>\n",
       "      <td>0.214706</td>\n",
       "      <td>0.21456</td>\n",
       "      <td>0.214886</td>\n",
       "      <td>0.21518</td>\n",
       "      <td>0.215049</td>\n",
       "      <td>0.215353</td>\n",
       "      <td>0.215025</td>\n",
       "      <td>0.215065</td>\n",
       "      <td>0.214135</td>\n",
       "      <td>0.21395</td>\n",
       "      <td>0.213518</td>\n",
       "      <td>0.222194</td>\n",
       "      <td>0.221209</td>\n",
       "      <td>0.220552</td>\n",
       "      <td>0.220816</td>\n",
       "      <td>0.215411</td>\n",
       "      <td>0.215846</td>\n",
       "      <td>0.215656</td>\n",
       "      <td>0.21633</td>\n",
       "      <td>0.215456</td>\n",
       "      <td>0.215266</td>\n",
       "      <td>0.215434</td>\n",
       "      <td>0.215092</td>\n",
       "      <td>0.214797</td>\n",
       "      <td>0.214513</td>\n",
       "      <td>0.213916</td>\n",
       "      <td>0.214929</td>\n",
       "      <td>0.214494</td>\n",
       "      <td>0.215357</td>\n",
       "      <td>0.215148</td>\n",
       "      <td>0.215292</td>\n",
       "      <td>0.216184</td>\n",
       "      <td>0.215801</td>\n",
       "      <td>0.215941</td>\n",
       "      <td>0.214946</td>\n",
       "      <td>0.214988</td>\n",
       "      <td>0.21491</td>\n",
       "      <td>0.214584</td>\n",
       "      <td>0.215108</td>\n",
       "      <td>0.217785</td>\n",
       "      <td>0.213238</td>\n",
       "      <td>0.205892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_token</th>\n",
       "      <td>0.873032</td>\n",
       "      <td>1.995894</td>\n",
       "      <td>3.219443</td>\n",
       "      <td>4.933136</td>\n",
       "      <td>42.659789</td>\n",
       "      <td>26.779939</td>\n",
       "      <td>14.084933</td>\n",
       "      <td>7.772098</td>\n",
       "      <td>4.631634</td>\n",
       "      <td>2.661851</td>\n",
       "      <td>1.63415</td>\n",
       "      <td>4.658557</td>\n",
       "      <td>2.826594</td>\n",
       "      <td>5.527628</td>\n",
       "      <td>4.614342</td>\n",
       "      <td>4.528787</td>\n",
       "      <td>4.642013</td>\n",
       "      <td>4.631627</td>\n",
       "      <td>4.633313</td>\n",
       "      <td>4.622047</td>\n",
       "      <td>4.620451</td>\n",
       "      <td>4.625865</td>\n",
       "      <td>4.50277</td>\n",
       "      <td>4.510053</td>\n",
       "      <td>4.524518</td>\n",
       "      <td>4.529029</td>\n",
       "      <td>4.54718</td>\n",
       "      <td>4.635409</td>\n",
       "      <td>4.650988</td>\n",
       "      <td>4.684018</td>\n",
       "      <td>4.670459</td>\n",
       "      <td>4.666314</td>\n",
       "      <td>4.652318</td>\n",
       "      <td>4.66227</td>\n",
       "      <td>4.662059</td>\n",
       "      <td>4.666642</td>\n",
       "      <td>4.666509</td>\n",
       "      <td>4.658356</td>\n",
       "      <td>4.672371</td>\n",
       "      <td>4.663732</td>\n",
       "      <td>4.665744</td>\n",
       "      <td>4.684386</td>\n",
       "      <td>4.671044</td>\n",
       "      <td>4.677242</td>\n",
       "      <td>4.659835</td>\n",
       "      <td>4.670234</td>\n",
       "      <td>4.657528</td>\n",
       "      <td>4.660711</td>\n",
       "      <td>4.653636</td>\n",
       "      <td>4.647281</td>\n",
       "      <td>4.6501</td>\n",
       "      <td>4.64354</td>\n",
       "      <td>4.650625</td>\n",
       "      <td>4.649755</td>\n",
       "      <td>4.669958</td>\n",
       "      <td>4.673982</td>\n",
       "      <td>4.683456</td>\n",
       "      <td>4.500567</td>\n",
       "      <td>4.520605</td>\n",
       "      <td>4.534083</td>\n",
       "      <td>4.528658</td>\n",
       "      <td>4.642294</td>\n",
       "      <td>4.632929</td>\n",
       "      <td>4.637023</td>\n",
       "      <td>4.622576</td>\n",
       "      <td>4.64132</td>\n",
       "      <td>4.645418</td>\n",
       "      <td>4.641803</td>\n",
       "      <td>4.649172</td>\n",
       "      <td>4.655566</td>\n",
       "      <td>4.661729</td>\n",
       "      <td>4.674723</td>\n",
       "      <td>4.652709</td>\n",
       "      <td>4.662129</td>\n",
       "      <td>4.643463</td>\n",
       "      <td>4.64796</td>\n",
       "      <td>4.644856</td>\n",
       "      <td>4.625687</td>\n",
       "      <td>4.633909</td>\n",
       "      <td>4.63089</td>\n",
       "      <td>4.652323</td>\n",
       "      <td>4.651412</td>\n",
       "      <td>4.653118</td>\n",
       "      <td>4.660174</td>\n",
       "      <td>4.648828</td>\n",
       "      <td>4.591678</td>\n",
       "      <td>4.689603</td>\n",
       "      <td>4.856908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops_per_joule</th>\n",
       "      <td>1185000974.364989</td>\n",
       "      <td>518336249.72279</td>\n",
       "      <td>321342606.972544</td>\n",
       "      <td>209713263.05247</td>\n",
       "      <td>27104781.482585</td>\n",
       "      <td>38868544.637947</td>\n",
       "      <td>73450411.636865</td>\n",
       "      <td>133110019.326187</td>\n",
       "      <td>223364803.416953</td>\n",
       "      <td>388655936.426967</td>\n",
       "      <td>633077864.986458</td>\n",
       "      <td>222073941.90463</td>\n",
       "      <td>366003752.151563</td>\n",
       "      <td>187158784.81295</td>\n",
       "      <td>224201879.805033</td>\n",
       "      <td>228437339.327415</td>\n",
       "      <td>222865394.679583</td>\n",
       "      <td>223365161.886555</td>\n",
       "      <td>223283872.404349</td>\n",
       "      <td>223828124.501124</td>\n",
       "      <td>223905433.056266</td>\n",
       "      <td>223643381.078152</td>\n",
       "      <td>229757248.73563</td>\n",
       "      <td>229386259.846373</td>\n",
       "      <td>228652875.007557</td>\n",
       "      <td>228425164.711328</td>\n",
       "      <td>227513330.26575</td>\n",
       "      <td>223182926.853609</td>\n",
       "      <td>222435330.199059</td>\n",
       "      <td>220866789.524664</td>\n",
       "      <td>221508032.594712</td>\n",
       "      <td>221704766.827728</td>\n",
       "      <td>222371780.91456</td>\n",
       "      <td>221897068.152067</td>\n",
       "      <td>221907110.976747</td>\n",
       "      <td>221689184.198326</td>\n",
       "      <td>221695534.41967</td>\n",
       "      <td>222083514.646961</td>\n",
       "      <td>221417373.154566</td>\n",
       "      <td>221827509.955699</td>\n",
       "      <td>221731883.961792</td>\n",
       "      <td>220849472.375148</td>\n",
       "      <td>221480295.326627</td>\n",
       "      <td>221186778.315872</td>\n",
       "      <td>222013043.200503</td>\n",
       "      <td>221518683.752156</td>\n",
       "      <td>222122993.553691</td>\n",
       "      <td>221971308.970354</td>\n",
       "      <td>222308787.015928</td>\n",
       "      <td>222612797.398213</td>\n",
       "      <td>222477838.462899</td>\n",
       "      <td>222792133.111257</td>\n",
       "      <td>222452704.383082</td>\n",
       "      <td>222494315.782651</td>\n",
       "      <td>221531801.63285</td>\n",
       "      <td>221341077.118197</td>\n",
       "      <td>220893296.207842</td>\n",
       "      <td>229869729.08804</td>\n",
       "      <td>228850791.85564</td>\n",
       "      <td>228170551.204544</td>\n",
       "      <td>228443865.261377</td>\n",
       "      <td>222851918.188743</td>\n",
       "      <td>223302403.426195</td>\n",
       "      <td>223105241.417056</td>\n",
       "      <td>223802523.245601</td>\n",
       "      <td>222898673.155884</td>\n",
       "      <td>222702041.034166</td>\n",
       "      <td>222875514.308708</td>\n",
       "      <td>222522236.459516</td>\n",
       "      <td>222216638.996013</td>\n",
       "      <td>221922855.337331</td>\n",
       "      <td>221305952.215789</td>\n",
       "      <td>222353065.317298</td>\n",
       "      <td>221903781.669947</td>\n",
       "      <td>222795804.50584</td>\n",
       "      <td>222580243.115083</td>\n",
       "      <td>222728997.344947</td>\n",
       "      <td>223651989.862195</td>\n",
       "      <td>223255146.236354</td>\n",
       "      <td>223400699.280619</td>\n",
       "      <td>222371514.343019</td>\n",
       "      <td>222415083.292085</td>\n",
       "      <td>222333526.955779</td>\n",
       "      <td>221996904.429798</td>\n",
       "      <td>222538705.760019</td>\n",
       "      <td>225308506.046856</td>\n",
       "      <td>220603766.552551</td>\n",
       "      <td>213004691.317366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_flop</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_inference_time_sec</th>\n",
       "      <td>37.07336</td>\n",
       "      <td>37.114287</td>\n",
       "      <td>37.785984</td>\n",
       "      <td>37.507834</td>\n",
       "      <td>384.649219</td>\n",
       "      <td>292.383712</td>\n",
       "      <td>147.516985</td>\n",
       "      <td>74.266558</td>\n",
       "      <td>37.168908</td>\n",
       "      <td>18.70642</td>\n",
       "      <td>9.628563</td>\n",
       "      <td>22.945557</td>\n",
       "      <td>23.267255</td>\n",
       "      <td>72.234728</td>\n",
       "      <td>37.354927</td>\n",
       "      <td>36.263684</td>\n",
       "      <td>37.233629</td>\n",
       "      <td>36.712846</td>\n",
       "      <td>37.177409</td>\n",
       "      <td>37.286998</td>\n",
       "      <td>36.730154</td>\n",
       "      <td>36.862467</td>\n",
       "      <td>36.388011</td>\n",
       "      <td>36.456038</td>\n",
       "      <td>36.447105</td>\n",
       "      <td>36.306288</td>\n",
       "      <td>36.211281</td>\n",
       "      <td>37.147624</td>\n",
       "      <td>37.538299</td>\n",
       "      <td>37.345801</td>\n",
       "      <td>37.266966</td>\n",
       "      <td>37.24014</td>\n",
       "      <td>37.286302</td>\n",
       "      <td>37.472509</td>\n",
       "      <td>37.066333</td>\n",
       "      <td>37.176715</td>\n",
       "      <td>37.421394</td>\n",
       "      <td>36.979404</td>\n",
       "      <td>37.373825</td>\n",
       "      <td>37.459553</td>\n",
       "      <td>36.784267</td>\n",
       "      <td>37.335853</td>\n",
       "      <td>36.763149</td>\n",
       "      <td>37.198482</td>\n",
       "      <td>36.812719</td>\n",
       "      <td>37.283309</td>\n",
       "      <td>37.419533</td>\n",
       "      <td>37.420523</td>\n",
       "      <td>37.239923</td>\n",
       "      <td>37.278837</td>\n",
       "      <td>37.05608</td>\n",
       "      <td>36.896263</td>\n",
       "      <td>37.303935</td>\n",
       "      <td>37.005236</td>\n",
       "      <td>37.377651</td>\n",
       "      <td>37.014072</td>\n",
       "      <td>37.463349</td>\n",
       "      <td>36.610644</td>\n",
       "      <td>36.43053</td>\n",
       "      <td>36.471863</td>\n",
       "      <td>36.407234</td>\n",
       "      <td>37.230651</td>\n",
       "      <td>37.061346</td>\n",
       "      <td>36.947661</td>\n",
       "      <td>36.866788</td>\n",
       "      <td>36.912187</td>\n",
       "      <td>37.250632</td>\n",
       "      <td>36.874463</td>\n",
       "      <td>37.227124</td>\n",
       "      <td>36.74442</td>\n",
       "      <td>37.353906</td>\n",
       "      <td>36.856164</td>\n",
       "      <td>36.478415</td>\n",
       "      <td>36.804445</td>\n",
       "      <td>36.749301</td>\n",
       "      <td>37.267507</td>\n",
       "      <td>37.349722</td>\n",
       "      <td>36.404344</td>\n",
       "      <td>36.764964</td>\n",
       "      <td>36.751617</td>\n",
       "      <td>36.289531</td>\n",
       "      <td>36.688996</td>\n",
       "      <td>36.790459</td>\n",
       "      <td>36.692678</td>\n",
       "      <td>36.887141</td>\n",
       "      <td>36.504055</td>\n",
       "      <td>37.91957</td>\n",
       "      <td>40.774318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_latency_ms_per_batch</th>\n",
       "      <td>4634.170037</td>\n",
       "      <td>4639.28586</td>\n",
       "      <td>4723.248003</td>\n",
       "      <td>4688.479238</td>\n",
       "      <td>3005.072024</td>\n",
       "      <td>4568.495493</td>\n",
       "      <td>4609.905773</td>\n",
       "      <td>4641.65987</td>\n",
       "      <td>4646.113508</td>\n",
       "      <td>4676.605061</td>\n",
       "      <td>4814.281646</td>\n",
       "      <td>2868.194596</td>\n",
       "      <td>2908.406936</td>\n",
       "      <td>9029.341061</td>\n",
       "      <td>4669.365846</td>\n",
       "      <td>4532.960497</td>\n",
       "      <td>4654.203603</td>\n",
       "      <td>4589.105755</td>\n",
       "      <td>4647.176079</td>\n",
       "      <td>4660.874719</td>\n",
       "      <td>4591.269241</td>\n",
       "      <td>4607.80839</td>\n",
       "      <td>4548.501365</td>\n",
       "      <td>4557.004705</td>\n",
       "      <td>4555.888145</td>\n",
       "      <td>4538.285978</td>\n",
       "      <td>4526.410158</td>\n",
       "      <td>4643.452946</td>\n",
       "      <td>4692.287417</td>\n",
       "      <td>4668.225076</td>\n",
       "      <td>4658.370769</td>\n",
       "      <td>4655.01752</td>\n",
       "      <td>4660.787711</td>\n",
       "      <td>4684.063664</td>\n",
       "      <td>4633.29158</td>\n",
       "      <td>4647.089355</td>\n",
       "      <td>4677.674297</td>\n",
       "      <td>4622.425475</td>\n",
       "      <td>4671.72815</td>\n",
       "      <td>4682.444169</td>\n",
       "      <td>4598.03337</td>\n",
       "      <td>4666.981563</td>\n",
       "      <td>4595.393663</td>\n",
       "      <td>4649.810295</td>\n",
       "      <td>4601.58986</td>\n",
       "      <td>4660.413619</td>\n",
       "      <td>4677.441662</td>\n",
       "      <td>4677.565389</td>\n",
       "      <td>4654.990417</td>\n",
       "      <td>4659.854676</td>\n",
       "      <td>4632.01002</td>\n",
       "      <td>4612.032873</td>\n",
       "      <td>4662.991815</td>\n",
       "      <td>4625.654561</td>\n",
       "      <td>4672.206413</td>\n",
       "      <td>4626.75899</td>\n",
       "      <td>4682.918639</td>\n",
       "      <td>4576.330444</td>\n",
       "      <td>4553.816217</td>\n",
       "      <td>4558.982923</td>\n",
       "      <td>4550.904239</td>\n",
       "      <td>4653.831399</td>\n",
       "      <td>4632.668298</td>\n",
       "      <td>4618.457622</td>\n",
       "      <td>4608.348549</td>\n",
       "      <td>4614.023335</td>\n",
       "      <td>4656.328988</td>\n",
       "      <td>4609.307881</td>\n",
       "      <td>4653.39056</td>\n",
       "      <td>4593.052498</td>\n",
       "      <td>4669.238309</td>\n",
       "      <td>4607.020464</td>\n",
       "      <td>4559.80192</td>\n",
       "      <td>4600.555674</td>\n",
       "      <td>4593.6626</td>\n",
       "      <td>4658.438392</td>\n",
       "      <td>4668.715262</td>\n",
       "      <td>4550.543062</td>\n",
       "      <td>4595.620491</td>\n",
       "      <td>4593.952187</td>\n",
       "      <td>4536.191409</td>\n",
       "      <td>4586.124506</td>\n",
       "      <td>4598.807349</td>\n",
       "      <td>4586.584774</td>\n",
       "      <td>4610.892601</td>\n",
       "      <td>4563.006856</td>\n",
       "      <td>4739.946273</td>\n",
       "      <td>5096.789718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_queries_per_sec</th>\n",
       "      <td>3.452614</td>\n",
       "      <td>3.448807</td>\n",
       "      <td>3.387499</td>\n",
       "      <td>3.41262</td>\n",
       "      <td>0.332771</td>\n",
       "      <td>0.437781</td>\n",
       "      <td>0.867697</td>\n",
       "      <td>1.723521</td>\n",
       "      <td>3.443739</td>\n",
       "      <td>6.842571</td>\n",
       "      <td>13.29378</td>\n",
       "      <td>5.578422</td>\n",
       "      <td>5.501293</td>\n",
       "      <td>1.772001</td>\n",
       "      <td>3.42659</td>\n",
       "      <td>3.529702</td>\n",
       "      <td>3.437752</td>\n",
       "      <td>3.486518</td>\n",
       "      <td>3.442951</td>\n",
       "      <td>3.432832</td>\n",
       "      <td>3.484875</td>\n",
       "      <td>3.472367</td>\n",
       "      <td>3.517642</td>\n",
       "      <td>3.511078</td>\n",
       "      <td>3.511939</td>\n",
       "      <td>3.52556</td>\n",
       "      <td>3.53481</td>\n",
       "      <td>3.445712</td>\n",
       "      <td>3.409851</td>\n",
       "      <td>3.427427</td>\n",
       "      <td>3.434677</td>\n",
       "      <td>3.437151</td>\n",
       "      <td>3.432896</td>\n",
       "      <td>3.415837</td>\n",
       "      <td>3.453269</td>\n",
       "      <td>3.443015</td>\n",
       "      <td>3.420503</td>\n",
       "      <td>3.461386</td>\n",
       "      <td>3.424857</td>\n",
       "      <td>3.417019</td>\n",
       "      <td>3.479749</td>\n",
       "      <td>3.42834</td>\n",
       "      <td>3.481747</td>\n",
       "      <td>3.441001</td>\n",
       "      <td>3.477059</td>\n",
       "      <td>3.433172</td>\n",
       "      <td>3.420673</td>\n",
       "      <td>3.420583</td>\n",
       "      <td>3.437171</td>\n",
       "      <td>3.433583</td>\n",
       "      <td>3.454224</td>\n",
       "      <td>3.469186</td>\n",
       "      <td>3.431273</td>\n",
       "      <td>3.45897</td>\n",
       "      <td>3.424506</td>\n",
       "      <td>3.458144</td>\n",
       "      <td>3.416673</td>\n",
       "      <td>3.496251</td>\n",
       "      <td>3.513537</td>\n",
       "      <td>3.509555</td>\n",
       "      <td>3.515785</td>\n",
       "      <td>3.438027</td>\n",
       "      <td>3.453733</td>\n",
       "      <td>3.46436</td>\n",
       "      <td>3.47196</td>\n",
       "      <td>3.467689</td>\n",
       "      <td>3.436183</td>\n",
       "      <td>3.471237</td>\n",
       "      <td>3.438353</td>\n",
       "      <td>3.483522</td>\n",
       "      <td>3.426683</td>\n",
       "      <td>3.47296</td>\n",
       "      <td>3.508924</td>\n",
       "      <td>3.477841</td>\n",
       "      <td>3.483059</td>\n",
       "      <td>3.434627</td>\n",
       "      <td>3.427067</td>\n",
       "      <td>3.516064</td>\n",
       "      <td>3.481576</td>\n",
       "      <td>3.48284</td>\n",
       "      <td>3.527188</td>\n",
       "      <td>3.488784</td>\n",
       "      <td>3.479163</td>\n",
       "      <td>3.488434</td>\n",
       "      <td>3.470044</td>\n",
       "      <td>3.50646</td>\n",
       "      <td>3.375566</td>\n",
       "      <td>3.139231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_tokens_per_sec</th>\n",
       "      <td>441.934582</td>\n",
       "      <td>441.447253</td>\n",
       "      <td>433.599929</td>\n",
       "      <td>436.815414</td>\n",
       "      <td>38.110047</td>\n",
       "      <td>55.693937</td>\n",
       "      <td>111.065177</td>\n",
       "      <td>220.610736</td>\n",
       "      <td>440.798529</td>\n",
       "      <td>875.849029</td>\n",
       "      <td>1701.603812</td>\n",
       "      <td>714.038023</td>\n",
       "      <td>704.16556</td>\n",
       "      <td>226.816108</td>\n",
       "      <td>438.603457</td>\n",
       "      <td>451.801864</td>\n",
       "      <td>440.032318</td>\n",
       "      <td>446.274309</td>\n",
       "      <td>440.697741</td>\n",
       "      <td>439.402499</td>\n",
       "      <td>446.064017</td>\n",
       "      <td>444.462926</td>\n",
       "      <td>450.258192</td>\n",
       "      <td>449.418013</td>\n",
       "      <td>449.528157</td>\n",
       "      <td>451.271694</td>\n",
       "      <td>452.455683</td>\n",
       "      <td>441.051094</td>\n",
       "      <td>436.460902</td>\n",
       "      <td>438.710638</td>\n",
       "      <td>439.638685</td>\n",
       "      <td>439.95538</td>\n",
       "      <td>439.410702</td>\n",
       "      <td>437.227191</td>\n",
       "      <td>442.018372</td>\n",
       "      <td>440.705965</td>\n",
       "      <td>437.824412</td>\n",
       "      <td>443.057441</td>\n",
       "      <td>438.381673</td>\n",
       "      <td>437.378413</td>\n",
       "      <td>445.407816</td>\n",
       "      <td>438.827532</td>\n",
       "      <td>445.663669</td>\n",
       "      <td>440.448076</td>\n",
       "      <td>445.063568</td>\n",
       "      <td>439.445974</td>\n",
       "      <td>437.846188</td>\n",
       "      <td>437.834606</td>\n",
       "      <td>439.957941</td>\n",
       "      <td>439.498684</td>\n",
       "      <td>442.140667</td>\n",
       "      <td>444.055811</td>\n",
       "      <td>439.203001</td>\n",
       "      <td>442.74815</td>\n",
       "      <td>438.336798</td>\n",
       "      <td>442.642464</td>\n",
       "      <td>437.334098</td>\n",
       "      <td>447.520131</td>\n",
       "      <td>449.732686</td>\n",
       "      <td>449.223003</td>\n",
       "      <td>450.020456</td>\n",
       "      <td>440.067511</td>\n",
       "      <td>442.077841</td>\n",
       "      <td>443.438084</td>\n",
       "      <td>444.410829</td>\n",
       "      <td>443.864249</td>\n",
       "      <td>439.831465</td>\n",
       "      <td>444.318334</td>\n",
       "      <td>440.109201</td>\n",
       "      <td>445.890832</td>\n",
       "      <td>438.615437</td>\n",
       "      <td>444.538941</td>\n",
       "      <td>449.142317</td>\n",
       "      <td>445.163616</td>\n",
       "      <td>445.831612</td>\n",
       "      <td>439.632303</td>\n",
       "      <td>438.664576</td>\n",
       "      <td>450.056174</td>\n",
       "      <td>445.641672</td>\n",
       "      <td>445.803508</td>\n",
       "      <td>451.480067</td>\n",
       "      <td>446.564413</td>\n",
       "      <td>445.332854</td>\n",
       "      <td>446.5196</td>\n",
       "      <td>444.165626</td>\n",
       "      <td>448.826851</td>\n",
       "      <td>432.072408</td>\n",
       "      <td>401.821561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_0</th>\n",
       "      <td>0.003973</td>\n",
       "      <td>0.004542</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.005594</td>\n",
       "      <td>0.04328</td>\n",
       "      <td>0.030147</td>\n",
       "      <td>0.01602</td>\n",
       "      <td>0.008813</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>0.003248</td>\n",
       "      <td>0.006229</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.005151</td>\n",
       "      <td>0.00528</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.00517</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.00517</td>\n",
       "      <td>0.005295</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>0.00534</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.00533</td>\n",
       "      <td>0.005341</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.005335</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>0.005282</td>\n",
       "      <td>0.005281</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.005317</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.005281</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.00536</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005171</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.00532</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.00529</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.005287</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.005328</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.005171</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.005583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004542</td>\n",
       "      <td>0.004858</td>\n",
       "      <td>0.00558</td>\n",
       "      <td>0.04346</td>\n",
       "      <td>0.030251</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.005167</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.005257</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.00512</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>0.00525</td>\n",
       "      <td>0.00533</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.00528</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>0.005295</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.00526</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.005335</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>0.005148</td>\n",
       "      <td>0.00522</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.005295</td>\n",
       "      <td>0.005266</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.005257</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.00532</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.005281</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>0.005328</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.00537</td>\n",
       "      <td>0.005435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004846</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>0.043619</td>\n",
       "      <td>0.030646</td>\n",
       "      <td>0.016074</td>\n",
       "      <td>0.008825</td>\n",
       "      <td>0.005238</td>\n",
       "      <td>0.00299</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.005138</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>0.005116</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>0.005203</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.005355</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.005276</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.00534</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>0.005281</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>0.005235</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>0.00531</td>\n",
       "      <td>0.005334</td>\n",
       "      <td>0.005125</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.00525</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.00526</td>\n",
       "      <td>0.005287</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.005264</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.00533</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.005558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>0.043349</td>\n",
       "      <td>0.030091</td>\n",
       "      <td>0.016138</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.00186</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.006265</td>\n",
       "      <td>0.005278</td>\n",
       "      <td>0.005138</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.00523</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.005244</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.005119</td>\n",
       "      <td>0.005112</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.005151</td>\n",
       "      <td>0.005193</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.00529</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>0.00531</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>0.005317</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.005336</td>\n",
       "      <td>0.00532</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.00533</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.00516</td>\n",
       "      <td>0.005077</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.005328</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.005237</td>\n",
       "      <td>0.00531</td>\n",
       "      <td>0.00529</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.005335</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>0.005305</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.00525</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.00521</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.00532</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.005354</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.005528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_avg</th>\n",
       "      <td>46.225986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.802324</td>\n",
       "      <td>453.303389</td>\n",
       "      <td>691.338204</td>\n",
       "      <td>268.587557</td>\n",
       "      <td>358.312906</td>\n",
       "      <td>320.232011</td>\n",
       "      <td>1118.538726</td>\n",
       "      <td>492.01174</td>\n",
       "      <td>677.800449</td>\n",
       "      <td>437.204647</td>\n",
       "      <td>391.714159</td>\n",
       "      <td>204.366104</td>\n",
       "      <td>382.524126</td>\n",
       "      <td>266.289626</td>\n",
       "      <td>234.621729</td>\n",
       "      <td>285.611934</td>\n",
       "      <td>391.571721</td>\n",
       "      <td>409.822402</td>\n",
       "      <td>429.799515</td>\n",
       "      <td>432.050167</td>\n",
       "      <td>421.301499</td>\n",
       "      <td>393.303811</td>\n",
       "      <td>292.735859</td>\n",
       "      <td>495.914887</td>\n",
       "      <td>412.077225</td>\n",
       "      <td>383.197083</td>\n",
       "      <td>390.294755</td>\n",
       "      <td>571.329062</td>\n",
       "      <td>392.706854</td>\n",
       "      <td>367.056529</td>\n",
       "      <td>474.542887</td>\n",
       "      <td>334.40488</td>\n",
       "      <td>367.160655</td>\n",
       "      <td>503.445063</td>\n",
       "      <td>410.155781</td>\n",
       "      <td>195.802022</td>\n",
       "      <td>291.842585</td>\n",
       "      <td>337.884587</td>\n",
       "      <td>439.834917</td>\n",
       "      <td>432.162595</td>\n",
       "      <td>367.760453</td>\n",
       "      <td>397.983108</td>\n",
       "      <td>584.680567</td>\n",
       "      <td>404.882464</td>\n",
       "      <td>373.916889</td>\n",
       "      <td>373.171862</td>\n",
       "      <td>581.747394</td>\n",
       "      <td>396.201549</td>\n",
       "      <td>525.567555</td>\n",
       "      <td>399.772335</td>\n",
       "      <td>389.105744</td>\n",
       "      <td>277.971773</td>\n",
       "      <td>384.025206</td>\n",
       "      <td>1477.347167</td>\n",
       "      <td>451.401374</td>\n",
       "      <td>555.380175</td>\n",
       "      <td>406.571211</td>\n",
       "      <td>375.751597</td>\n",
       "      <td>371.866695</td>\n",
       "      <td>311.990543</td>\n",
       "      <td>297.637035</td>\n",
       "      <td>319.099187</td>\n",
       "      <td>422.491341</td>\n",
       "      <td>385.364127</td>\n",
       "      <td>529.887179</td>\n",
       "      <td>384.95846</td>\n",
       "      <td>323.807523</td>\n",
       "      <td>416.411664</td>\n",
       "      <td>375.259303</td>\n",
       "      <td>555.406601</td>\n",
       "      <td>412.056644</td>\n",
       "      <td>333.941971</td>\n",
       "      <td>441.068223</td>\n",
       "      <td>367.534498</td>\n",
       "      <td>296.116516</td>\n",
       "      <td>426.171555</td>\n",
       "      <td>464.683503</td>\n",
       "      <td>373.273991</td>\n",
       "      <td>102.99226</td>\n",
       "      <td>415.753303</td>\n",
       "      <td>441.421415</td>\n",
       "      <td>281.424198</td>\n",
       "      <td>422.539237</td>\n",
       "      <td>354.061436</td>\n",
       "      <td>221.602844</td>\n",
       "      <td>373.637229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_avg</th>\n",
       "      <td>0.923219</td>\n",
       "      <td>0.94983</td>\n",
       "      <td>0.954332</td>\n",
       "      <td>0.958816</td>\n",
       "      <td>0.951091</td>\n",
       "      <td>0.957124</td>\n",
       "      <td>0.958018</td>\n",
       "      <td>0.954639</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.959702</td>\n",
       "      <td>0.955094</td>\n",
       "      <td>0.664005</td>\n",
       "      <td>0.928296</td>\n",
       "      <td>0.9769</td>\n",
       "      <td>0.947205</td>\n",
       "      <td>0.952953</td>\n",
       "      <td>0.962324</td>\n",
       "      <td>0.963021</td>\n",
       "      <td>0.963892</td>\n",
       "      <td>0.955985</td>\n",
       "      <td>0.959559</td>\n",
       "      <td>0.956723</td>\n",
       "      <td>0.95529</td>\n",
       "      <td>0.954029</td>\n",
       "      <td>0.955858</td>\n",
       "      <td>0.951728</td>\n",
       "      <td>0.948094</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>0.963921</td>\n",
       "      <td>0.95377</td>\n",
       "      <td>0.96025</td>\n",
       "      <td>0.961562</td>\n",
       "      <td>0.958358</td>\n",
       "      <td>0.952374</td>\n",
       "      <td>0.95813</td>\n",
       "      <td>0.95802</td>\n",
       "      <td>0.962087</td>\n",
       "      <td>0.958308</td>\n",
       "      <td>0.95993</td>\n",
       "      <td>0.964699</td>\n",
       "      <td>0.955347</td>\n",
       "      <td>0.959208</td>\n",
       "      <td>0.960846</td>\n",
       "      <td>0.962158</td>\n",
       "      <td>0.962879</td>\n",
       "      <td>0.962166</td>\n",
       "      <td>0.965268</td>\n",
       "      <td>0.959845</td>\n",
       "      <td>0.963443</td>\n",
       "      <td>0.963372</td>\n",
       "      <td>0.966059</td>\n",
       "      <td>0.954208</td>\n",
       "      <td>0.963354</td>\n",
       "      <td>0.962415</td>\n",
       "      <td>0.957899</td>\n",
       "      <td>0.96216</td>\n",
       "      <td>0.960668</td>\n",
       "      <td>0.953066</td>\n",
       "      <td>0.949621</td>\n",
       "      <td>0.955473</td>\n",
       "      <td>0.956434</td>\n",
       "      <td>0.945956</td>\n",
       "      <td>0.955248</td>\n",
       "      <td>0.959702</td>\n",
       "      <td>0.958246</td>\n",
       "      <td>0.95934</td>\n",
       "      <td>0.964747</td>\n",
       "      <td>0.956913</td>\n",
       "      <td>0.954762</td>\n",
       "      <td>0.957826</td>\n",
       "      <td>0.956864</td>\n",
       "      <td>0.958314</td>\n",
       "      <td>0.947865</td>\n",
       "      <td>0.95182</td>\n",
       "      <td>0.964067</td>\n",
       "      <td>0.958583</td>\n",
       "      <td>0.964557</td>\n",
       "      <td>0.960877</td>\n",
       "      <td>0.962227</td>\n",
       "      <td>0.963644</td>\n",
       "      <td>0.962694</td>\n",
       "      <td>0.962244</td>\n",
       "      <td>0.958251</td>\n",
       "      <td>0.954216</td>\n",
       "      <td>0.962374</td>\n",
       "      <td>0.962766</td>\n",
       "      <td>0.960215</td>\n",
       "      <td>0.956742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_total</th>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.004173</td>\n",
       "      <td>0.042788</td>\n",
       "      <td>0.03621</td>\n",
       "      <td>0.018196</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>0.004569</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.00899</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.004507</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>0.004612</td>\n",
       "      <td>0.004569</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.00454</td>\n",
       "      <td>0.004495</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.00447</td>\n",
       "      <td>0.004483</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>0.004592</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.004563</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.004617</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.004581</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.004604</td>\n",
       "      <td>0.004579</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>0.00456</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.004564</td>\n",
       "      <td>0.004612</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.004497</td>\n",
       "      <td>0.004512</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>0.004586</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>0.00456</td>\n",
       "      <td>0.004529</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>0.004589</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>0.004589</td>\n",
       "      <td>0.004586</td>\n",
       "      <td>0.00454</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>0.004586</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>0.004984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_total</th>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>0.011857</td>\n",
       "      <td>0.018244</td>\n",
       "      <td>0.130587</td>\n",
       "      <td>0.084684</td>\n",
       "      <td>0.045785</td>\n",
       "      <td>0.026333</td>\n",
       "      <td>0.01648</td>\n",
       "      <td>0.009785</td>\n",
       "      <td>0.006235</td>\n",
       "      <td>0.018275</td>\n",
       "      <td>0.009992</td>\n",
       "      <td>0.016105</td>\n",
       "      <td>0.016397</td>\n",
       "      <td>0.016074</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>0.016436</td>\n",
       "      <td>0.016487</td>\n",
       "      <td>0.016428</td>\n",
       "      <td>0.01645</td>\n",
       "      <td>0.016483</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.016032</td>\n",
       "      <td>0.016062</td>\n",
       "      <td>0.016112</td>\n",
       "      <td>0.016181</td>\n",
       "      <td>0.016497</td>\n",
       "      <td>0.016523</td>\n",
       "      <td>0.016694</td>\n",
       "      <td>0.016637</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.016579</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.016596</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>0.01659</td>\n",
       "      <td>0.016545</td>\n",
       "      <td>0.016591</td>\n",
       "      <td>0.016613</td>\n",
       "      <td>0.016648</td>\n",
       "      <td>0.016684</td>\n",
       "      <td>0.016649</td>\n",
       "      <td>0.016622</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>0.016612</td>\n",
       "      <td>0.016566</td>\n",
       "      <td>0.016577</td>\n",
       "      <td>0.016571</td>\n",
       "      <td>0.016538</td>\n",
       "      <td>0.016558</td>\n",
       "      <td>0.016539</td>\n",
       "      <td>0.016522</td>\n",
       "      <td>0.016496</td>\n",
       "      <td>0.016597</td>\n",
       "      <td>0.016642</td>\n",
       "      <td>0.01669</td>\n",
       "      <td>0.015956</td>\n",
       "      <td>0.016032</td>\n",
       "      <td>0.016109</td>\n",
       "      <td>0.016096</td>\n",
       "      <td>0.016511</td>\n",
       "      <td>0.016489</td>\n",
       "      <td>0.016512</td>\n",
       "      <td>0.016479</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.016522</td>\n",
       "      <td>0.016523</td>\n",
       "      <td>0.016553</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.016596</td>\n",
       "      <td>0.016658</td>\n",
       "      <td>0.016605</td>\n",
       "      <td>0.016603</td>\n",
       "      <td>0.016546</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>0.016534</td>\n",
       "      <td>0.016466</td>\n",
       "      <td>0.016465</td>\n",
       "      <td>0.016487</td>\n",
       "      <td>0.016491</td>\n",
       "      <td>0.016573</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.016591</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.016585</td>\n",
       "      <td>0.017087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_generated_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>14659</td>\n",
       "      <td>16284</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_config_decoding_mode</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   0   \\\n",
       "config_name                                           num_processes_1   \n",
       "experiment_id                                                     233   \n",
       "date_time                               April 11, 2025 at 05:02:12 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       1   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.003973   \n",
       "total_energy_joules                                      14303.761229   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             1.145433   \n",
       "joules_per_token                                             0.873032   \n",
       "flops_per_joule                                     1185000974.364989   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     37.07336   \n",
       "average_latency_ms_per_batch                              4634.170037   \n",
       "throughput_queries_per_sec                                   3.452614   \n",
       "throughput_tokens_per_sec                                  441.934582   \n",
       "total_energy_kwh_process_0                                   0.003973   \n",
       "total_energy_kwh_process_1                                        NaN   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                               46.225986   \n",
       "ram_power_avg                                                0.923219   \n",
       "cpu_energy_total                                             0.001241   \n",
       "gpu_energy_total                                             0.002724   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   1   \\\n",
       "config_name                                           num_processes_2   \n",
       "experiment_id                                                     234   \n",
       "date_time                               April 11, 2025 at 05:03:25 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       2   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.009084   \n",
       "total_energy_joules                                      32700.724679   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.501029   \n",
       "joules_per_token                                             1.995894   \n",
       "flops_per_joule                                       518336249.72279   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    37.114287   \n",
       "average_latency_ms_per_batch                               4639.28586   \n",
       "throughput_queries_per_sec                                   3.448807   \n",
       "throughput_tokens_per_sec                                  441.447253   \n",
       "total_energy_kwh_process_0                                   0.004542   \n",
       "total_energy_kwh_process_1                                   0.004542   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                                     0.0   \n",
       "ram_power_avg                                                 0.94983   \n",
       "cpu_energy_total                                             0.002359   \n",
       "gpu_energy_total                                             0.006706   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   2   \\\n",
       "config_name                                           num_processes_3   \n",
       "experiment_id                                                     235   \n",
       "date_time                               April 11, 2025 at 05:04:40 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       3   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.014652   \n",
       "total_energy_joules                                      52747.350103   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.310613   \n",
       "joules_per_token                                             3.219443   \n",
       "flops_per_joule                                      321342606.972544   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    37.785984   \n",
       "average_latency_ms_per_batch                              4723.248003   \n",
       "throughput_queries_per_sec                                   3.387499   \n",
       "throughput_tokens_per_sec                                  433.599929   \n",
       "total_energy_kwh_process_0                                   0.004947   \n",
       "total_energy_kwh_process_1                                   0.004858   \n",
       "total_energy_kwh_process_2                                   0.004846   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                              284.802324   \n",
       "ram_power_avg                                                0.954332   \n",
       "cpu_energy_total                                             0.002769   \n",
       "gpu_energy_total                                             0.011857   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   3   \\\n",
       "config_name                                           num_processes_4   \n",
       "experiment_id                                                     236   \n",
       "date_time                               April 11, 2025 at 05:05:55 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.022451   \n",
       "total_energy_joules                                      80824.506502   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.202711   \n",
       "joules_per_token                                             4.933136   \n",
       "flops_per_joule                                       209713263.05247   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    37.507834   \n",
       "average_latency_ms_per_batch                              4688.479238   \n",
       "throughput_queries_per_sec                                    3.41262   \n",
       "throughput_tokens_per_sec                                  436.815414   \n",
       "total_energy_kwh_process_0                                   0.005594   \n",
       "total_energy_kwh_process_1                                    0.00558   \n",
       "total_energy_kwh_process_2                                   0.005645   \n",
       "total_energy_kwh_process_3                                   0.005633   \n",
       "gpu_power_avg                                              453.303389   \n",
       "ram_power_avg                                                0.958816   \n",
       "cpu_energy_total                                             0.004173   \n",
       "gpu_energy_total                                             0.018244   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   4   \\\n",
       "config_name                                                batching_1   \n",
       "experiment_id                                                     237   \n",
       "date_time                               April 11, 2025 at 05:13:02 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                         1   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.173708   \n",
       "total_energy_joules                                     625349.848478   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.023441   \n",
       "joules_per_token                                            42.659789   \n",
       "flops_per_joule                                       27104781.482585   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                   384.649219   \n",
       "average_latency_ms_per_batch                              3005.072024   \n",
       "throughput_queries_per_sec                                   0.332771   \n",
       "throughput_tokens_per_sec                                   38.110047   \n",
       "total_energy_kwh_process_0                                    0.04328   \n",
       "total_energy_kwh_process_1                                    0.04346   \n",
       "total_energy_kwh_process_2                                   0.043619   \n",
       "total_energy_kwh_process_3                                   0.043349   \n",
       "gpu_power_avg                                              691.338204   \n",
       "ram_power_avg                                                0.951091   \n",
       "cpu_energy_total                                             0.042788   \n",
       "gpu_energy_total                                             0.130587   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          14659   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   5   \\\n",
       "config_name                                                batching_2   \n",
       "experiment_id                                                     238   \n",
       "date_time                               April 11, 2025 at 05:18:36 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                         2   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.121135   \n",
       "total_energy_joules                                     436084.529304   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.037341   \n",
       "joules_per_token                                            26.779939   \n",
       "flops_per_joule                                       38868544.637947   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                   292.383712   \n",
       "average_latency_ms_per_batch                              4568.495493   \n",
       "throughput_queries_per_sec                                   0.437781   \n",
       "throughput_tokens_per_sec                                   55.693937   \n",
       "total_energy_kwh_process_0                                   0.030147   \n",
       "total_energy_kwh_process_1                                   0.030251   \n",
       "total_energy_kwh_process_2                                   0.030646   \n",
       "total_energy_kwh_process_3                                   0.030091   \n",
       "gpu_power_avg                                              268.587557   \n",
       "ram_power_avg                                                0.957124   \n",
       "cpu_energy_total                                              0.03621   \n",
       "gpu_energy_total                                             0.084684   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16284   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   6   \\\n",
       "config_name                                                batching_4   \n",
       "experiment_id                                                     239   \n",
       "date_time                               April 11, 2025 at 05:21:39 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                         4   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.064102   \n",
       "total_energy_joules                                     230767.542556   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.070998   \n",
       "joules_per_token                                            14.084933   \n",
       "flops_per_joule                                       73450411.636865   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                   147.516985   \n",
       "average_latency_ms_per_batch                              4609.905773   \n",
       "throughput_queries_per_sec                                   0.867697   \n",
       "throughput_tokens_per_sec                                  111.065177   \n",
       "total_energy_kwh_process_0                                    0.01602   \n",
       "total_energy_kwh_process_1                                    0.01587   \n",
       "total_energy_kwh_process_2                                   0.016074   \n",
       "total_energy_kwh_process_3                                   0.016138   \n",
       "gpu_power_avg                                              358.312906   \n",
       "ram_power_avg                                                0.958018   \n",
       "cpu_energy_total                                             0.018196   \n",
       "gpu_energy_total                                             0.045785   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   7   \\\n",
       "config_name                                                batching_8   \n",
       "experiment_id                                                     240   \n",
       "date_time                               April 11, 2025 at 05:23:23 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                         8   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.035372   \n",
       "total_energy_joules                                     127338.055234   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.128665   \n",
       "joules_per_token                                             7.772098   \n",
       "flops_per_joule                                      133110019.326187   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    74.266558   \n",
       "average_latency_ms_per_batch                               4641.65987   \n",
       "throughput_queries_per_sec                                   1.723521   \n",
       "throughput_tokens_per_sec                                  220.610736   \n",
       "total_energy_kwh_process_0                                   0.008813   \n",
       "total_energy_kwh_process_1                                   0.008805   \n",
       "total_energy_kwh_process_2                                   0.008825   \n",
       "total_energy_kwh_process_3                                   0.008929   \n",
       "gpu_power_avg                                              320.232011   \n",
       "ram_power_avg                                                0.954639   \n",
       "cpu_energy_total                                             0.008976   \n",
       "gpu_energy_total                                             0.026333   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   8   \\\n",
       "config_name                                               batching_16   \n",
       "experiment_id                                                     241   \n",
       "date_time                               April 11, 2025 at 05:24:30 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.021079   \n",
       "total_energy_joules                                      75884.699531   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.215907   \n",
       "joules_per_token                                             4.631634   \n",
       "flops_per_joule                                      223364803.416953   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    37.168908   \n",
       "average_latency_ms_per_batch                              4646.113508   \n",
       "throughput_queries_per_sec                                   3.443739   \n",
       "throughput_tokens_per_sec                                  440.798529   \n",
       "total_energy_kwh_process_0                                   0.005296   \n",
       "total_energy_kwh_process_1                                   0.005256   \n",
       "total_energy_kwh_process_2                                   0.005238   \n",
       "total_energy_kwh_process_3                                   0.005289   \n",
       "gpu_power_avg                                             1118.538726   \n",
       "ram_power_avg                                                0.954839   \n",
       "cpu_energy_total                                             0.004569   \n",
       "gpu_energy_total                                              0.01648   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   9   \\\n",
       "config_name                                               batching_32   \n",
       "experiment_id                                                     242   \n",
       "date_time                               April 11, 2025 at 05:25:17 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        32   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.012114   \n",
       "total_energy_joules                                      43611.764042   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.375678   \n",
       "joules_per_token                                             2.661851   \n",
       "flops_per_joule                                      388655936.426967   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     18.70642   \n",
       "average_latency_ms_per_batch                              4676.605061   \n",
       "throughput_queries_per_sec                                   6.842571   \n",
       "throughput_tokens_per_sec                                  875.849029   \n",
       "total_energy_kwh_process_0                                   0.003041   \n",
       "total_energy_kwh_process_1                                   0.003042   \n",
       "total_energy_kwh_process_2                                    0.00299   \n",
       "total_energy_kwh_process_3                                   0.003042   \n",
       "gpu_power_avg                                               492.01174   \n",
       "ram_power_avg                                                0.959702   \n",
       "cpu_energy_total                                             0.002314   \n",
       "gpu_energy_total                                             0.009785   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                   10  \\\n",
       "config_name                                               batching_64   \n",
       "experiment_id                                                     243   \n",
       "date_time                               April 11, 2025 at 05:25:56 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        64   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.007437   \n",
       "total_energy_joules                                      26773.911916   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.611939   \n",
       "joules_per_token                                              1.63415   \n",
       "flops_per_joule                                      633077864.986458   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     9.628563   \n",
       "average_latency_ms_per_batch                              4814.281646   \n",
       "throughput_queries_per_sec                                   13.29378   \n",
       "throughput_tokens_per_sec                                 1701.603812   \n",
       "total_energy_kwh_process_0                                   0.001865   \n",
       "total_energy_kwh_process_1                                   0.001859   \n",
       "total_energy_kwh_process_2                                   0.001853   \n",
       "total_energy_kwh_process_3                                    0.00186   \n",
       "gpu_power_avg                                              677.800449   \n",
       "ram_power_avg                                                0.955094   \n",
       "cpu_energy_total                                             0.001194   \n",
       "gpu_energy_total                                             0.006235   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                                  11  \\\n",
       "config_name                        precis_float32_quant_False_quant8_False_quant4...   \n",
       "experiment_id                                                                    244   \n",
       "date_time                                              April 11, 2025 at 05:26:49 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021202   \n",
       "total_energy_joules                                                     76325.798731   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214659   \n",
       "joules_per_token                                                            4.658557   \n",
       "flops_per_joule                                                      222073941.90463   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   22.945557   \n",
       "average_latency_ms_per_batch                                             2868.194596   \n",
       "throughput_queries_per_sec                                                  5.578422   \n",
       "throughput_tokens_per_sec                                                 714.038023   \n",
       "total_energy_kwh_process_0                                                  0.005286   \n",
       "total_energy_kwh_process_1                                                  0.005333   \n",
       "total_energy_kwh_process_2                                                  0.005283   \n",
       "total_energy_kwh_process_3                                                  0.005299   \n",
       "gpu_power_avg                                                             437.204647   \n",
       "ram_power_avg                                                               0.664005   \n",
       "cpu_energy_total                                                            0.002912   \n",
       "gpu_energy_total                                                            0.018275   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "\n",
       "                                                                                  12  \\\n",
       "config_name                        precis_float16_quant_False_quant8_False_quant4...   \n",
       "experiment_id                                                                    245   \n",
       "date_time                                              April 11, 2025 at 05:27:40 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.012864   \n",
       "total_energy_joules                                                     46310.921387   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.353783   \n",
       "joules_per_token                                                            2.826594   \n",
       "flops_per_joule                                                     366003752.151563   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.267255   \n",
       "average_latency_ms_per_batch                                             2908.406936   \n",
       "throughput_queries_per_sec                                                  5.501293   \n",
       "throughput_tokens_per_sec                                                  704.16556   \n",
       "total_energy_kwh_process_0                                                  0.003248   \n",
       "total_energy_kwh_process_1                                                  0.003201   \n",
       "total_energy_kwh_process_2                                                  0.003249   \n",
       "total_energy_kwh_process_3                                                  0.003166   \n",
       "gpu_power_avg                                                             391.714159   \n",
       "ram_power_avg                                                               0.928296   \n",
       "cpu_energy_total                                                            0.002852   \n",
       "gpu_energy_total                                                            0.009992   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "\n",
       "                                                                                  13  \\\n",
       "config_name                        precis_float16_quant_True_quant8_True_quant4_F...   \n",
       "experiment_id                                                                    246   \n",
       "date_time                                              April 11, 2025 at 05:29:22 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                    True   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.025157   \n",
       "total_energy_joules                                                     90564.656156   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.180909   \n",
       "joules_per_token                                                            5.527628   \n",
       "flops_per_joule                                                      187158784.81295   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   72.234728   \n",
       "average_latency_ms_per_batch                                             9029.341061   \n",
       "throughput_queries_per_sec                                                  1.772001   \n",
       "throughput_tokens_per_sec                                                 226.816108   \n",
       "total_energy_kwh_process_0                                                  0.006229   \n",
       "total_energy_kwh_process_1                                                  0.006351   \n",
       "total_energy_kwh_process_2                                                  0.006312   \n",
       "total_energy_kwh_process_3                                                  0.006265   \n",
       "gpu_power_avg                                                             204.366104   \n",
       "ram_power_avg                                                                 0.9769   \n",
       "cpu_energy_total                                                             0.00899   \n",
       "gpu_energy_total                                                            0.016105   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "\n",
       "                                                                                  14  \\\n",
       "config_name                        precis_float16_quant_True_quant8_False_quant4_...   \n",
       "experiment_id                                                                    247   \n",
       "date_time                                              April 11, 2025 at 05:30:29 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                               0.021   \n",
       "total_energy_joules                                                     75601.377686   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.216716   \n",
       "joules_per_token                                                            4.614342   \n",
       "flops_per_joule                                                     224201879.805033   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.354927   \n",
       "average_latency_ms_per_batch                                             4669.365846   \n",
       "throughput_queries_per_sec                                                   3.42659   \n",
       "throughput_tokens_per_sec                                                 438.603457   \n",
       "total_energy_kwh_process_0                                                  0.005292   \n",
       "total_energy_kwh_process_1                                                  0.005213   \n",
       "total_energy_kwh_process_2                                                  0.005217   \n",
       "total_energy_kwh_process_3                                                  0.005278   \n",
       "gpu_power_avg                                                             382.524126   \n",
       "ram_power_avg                                                               0.947205   \n",
       "cpu_energy_total                                                            0.004573   \n",
       "gpu_energy_total                                                            0.016397   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "\n",
       "                                                                      15  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_0   \n",
       "experiment_id                                                        248   \n",
       "date_time                                  April 11, 2025 at 05:31:35 PM   \n",
       "model                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                          4   \n",
       "batch_size___fixed_batching                                           16   \n",
       "decoder_temperature                                                  0.0   \n",
       "decoder_top_k                                                          0   \n",
       "decoder_top_p                                                        0.0   \n",
       "latency_simulation_delay_min                                         0.0   \n",
       "latency_simulation_simulate_burst                                  False   \n",
       "latency_simulation_burst_size                                          0   \n",
       "latency_simulation_burst_interval                                    0.0   \n",
       "fp_precision                                               torch.float16   \n",
       "quantization                                                        True   \n",
       "load_in_8bit                                                       False   \n",
       "load_in_4bit                                                        True   \n",
       "total_input_tokens                                                 16384   \n",
       "total_params                                                   615606272   \n",
       "max_input_tokens                                                     128   \n",
       "max_output_tokens                                                    128   \n",
       "number_input_prompts                                                 128   \n",
       "total_energy_kwh                                                0.020611   \n",
       "total_energy_joules                                         74199.651611   \n",
       "flops                                                     16949970993152   \n",
       "tokens_per_joule                                                 0.22081   \n",
       "joules_per_token                                                4.528787   \n",
       "flops_per_joule                                         228437339.327415   \n",
       "joules_per_flop                                                      0.0   \n",
       "total_inference_time_sec                                       36.263684   \n",
       "average_latency_ms_per_batch                                 4532.960497   \n",
       "throughput_queries_per_sec                                      3.529702   \n",
       "throughput_tokens_per_sec                                     451.801864   \n",
       "total_energy_kwh_process_0                                      0.005151   \n",
       "total_energy_kwh_process_1                                      0.005167   \n",
       "total_energy_kwh_process_2                                      0.005155   \n",
       "total_energy_kwh_process_3                                      0.005138   \n",
       "gpu_power_avg                                                 266.289626   \n",
       "ram_power_avg                                                   0.952953   \n",
       "cpu_energy_total                                                0.004507   \n",
       "gpu_energy_total                                                0.016074   \n",
       "latency_simulation_simulate                                        False   \n",
       "latency_simulation_delay_max                                         0.0   \n",
       "total_generated_tokens                                             16384   \n",
       "decoder_config_decoding_mode                                      greedy   \n",
       "\n",
       "                                                                        16  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_0.2   \n",
       "experiment_id                                                          249   \n",
       "date_time                                    April 11, 2025 at 05:32:41 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    0.2   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float16   \n",
       "quantization                                                          True   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                          True   \n",
       "total_input_tokens                                                   16384   \n",
       "total_params                                                     615606272   \n",
       "max_input_tokens                                                       128   \n",
       "max_output_tokens                                                      128   \n",
       "number_input_prompts                                                   128   \n",
       "total_energy_kwh                                                  0.021126   \n",
       "total_energy_joules                                           76054.746039   \n",
       "flops                                                       16949970993152   \n",
       "tokens_per_joule                                                  0.215424   \n",
       "joules_per_token                                                  4.642013   \n",
       "flops_per_joule                                           222865394.679583   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                         37.233629   \n",
       "average_latency_ms_per_batch                                   4654.203603   \n",
       "throughput_queries_per_sec                                        3.437752   \n",
       "throughput_tokens_per_sec                                       440.032318   \n",
       "total_energy_kwh_process_0                                         0.00528   \n",
       "total_energy_kwh_process_1                                        0.005296   \n",
       "total_energy_kwh_process_2                                        0.005279   \n",
       "total_energy_kwh_process_3                                         0.00527   \n",
       "gpu_power_avg                                                   234.621729   \n",
       "ram_power_avg                                                     0.962324   \n",
       "cpu_energy_total                                                  0.004626   \n",
       "gpu_energy_total                                                  0.016469   \n",
       "latency_simulation_simulate                                          False   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "total_generated_tokens                                               16384   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "\n",
       "                                                                        17  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_0.4   \n",
       "experiment_id                                                          250   \n",
       "date_time                                    April 11, 2025 at 05:33:46 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    0.4   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float16   \n",
       "quantization                                                          True   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                          True   \n",
       "total_input_tokens                                                   16384   \n",
       "total_params                                                     615606272   \n",
       "max_input_tokens                                                       128   \n",
       "max_output_tokens                                                      128   \n",
       "number_input_prompts                                                   128   \n",
       "total_energy_kwh                                                  0.021079   \n",
       "total_energy_joules                                           75884.577747   \n",
       "flops                                                       16949970993152   \n",
       "tokens_per_joule                                                  0.215907   \n",
       "joules_per_token                                                  4.631627   \n",
       "flops_per_joule                                           223365161.886555   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                         36.712846   \n",
       "average_latency_ms_per_batch                                   4589.105755   \n",
       "throughput_queries_per_sec                                        3.486518   \n",
       "throughput_tokens_per_sec                                       446.274309   \n",
       "total_energy_kwh_process_0                                        0.005228   \n",
       "total_energy_kwh_process_1                                        0.005299   \n",
       "total_energy_kwh_process_2                                        0.005323   \n",
       "total_energy_kwh_process_3                                         0.00523   \n",
       "gpu_power_avg                                                   285.611934   \n",
       "ram_power_avg                                                     0.963021   \n",
       "cpu_energy_total                                                  0.004612   \n",
       "gpu_energy_total                                                  0.016436   \n",
       "latency_simulation_simulate                                          False   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "total_generated_tokens                                               16384   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "\n",
       "                                                                        18  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_0.6   \n",
       "experiment_id                                                          251   \n",
       "date_time                                    April 11, 2025 at 05:34:52 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    0.6   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float16   \n",
       "quantization                                                          True   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                          True   \n",
       "total_input_tokens                                                   16384   \n",
       "total_params                                                     615606272   \n",
       "max_input_tokens                                                       128   \n",
       "max_output_tokens                                                      128   \n",
       "number_input_prompts                                                   128   \n",
       "total_energy_kwh                                                  0.021087   \n",
       "total_energy_joules                                           75912.204543   \n",
       "flops                                                       16949970993152   \n",
       "tokens_per_joule                                                  0.215828   \n",
       "joules_per_token                                                  4.633313   \n",
       "flops_per_joule                                           223283872.404349   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                         37.177409   \n",
       "average_latency_ms_per_batch                                   4647.176079   \n",
       "throughput_queries_per_sec                                        3.442951   \n",
       "throughput_tokens_per_sec                                       440.697741   \n",
       "total_energy_kwh_process_0                                        0.005296   \n",
       "total_energy_kwh_process_1                                        0.005267   \n",
       "total_energy_kwh_process_2                                        0.005263   \n",
       "total_energy_kwh_process_3                                        0.005261   \n",
       "gpu_power_avg                                                   391.571721   \n",
       "ram_power_avg                                                     0.963892   \n",
       "cpu_energy_total                                                  0.004569   \n",
       "gpu_energy_total                                                  0.016487   \n",
       "latency_simulation_simulate                                          False   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "total_generated_tokens                                               16384   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "\n",
       "                                                                        19  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_0.8   \n",
       "experiment_id                                                          252   \n",
       "date_time                                    April 11, 2025 at 05:35:58 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    0.8   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float16   \n",
       "quantization                                                          True   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                          True   \n",
       "total_input_tokens                                                   16384   \n",
       "total_params                                                     615606272   \n",
       "max_input_tokens                                                       128   \n",
       "max_output_tokens                                                      128   \n",
       "number_input_prompts                                                   128   \n",
       "total_energy_kwh                                                  0.021035   \n",
       "total_energy_joules                                           75727.619266   \n",
       "flops                                                       16949970993152   \n",
       "tokens_per_joule                                                  0.216354   \n",
       "joules_per_token                                                  4.622047   \n",
       "flops_per_joule                                           223828124.501124   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                         37.286998   \n",
       "average_latency_ms_per_batch                                   4660.874719   \n",
       "throughput_queries_per_sec                                        3.432832   \n",
       "throughput_tokens_per_sec                                       439.402499   \n",
       "total_energy_kwh_process_0                                        0.005289   \n",
       "total_energy_kwh_process_1                                          0.0052   \n",
       "total_energy_kwh_process_2                                        0.005255   \n",
       "total_energy_kwh_process_3                                        0.005291   \n",
       "gpu_power_avg                                                   409.822402   \n",
       "ram_power_avg                                                     0.955985   \n",
       "cpu_energy_total                                                  0.004577   \n",
       "gpu_energy_total                                                  0.016428   \n",
       "latency_simulation_simulate                                          False   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "total_generated_tokens                                               16384   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "\n",
       "                                                                        20  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_1.0   \n",
       "experiment_id                                                          253   \n",
       "date_time                                    April 11, 2025 at 05:37:04 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    1.0   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float16   \n",
       "quantization                                                          True   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                          True   \n",
       "total_input_tokens                                                   16384   \n",
       "total_params                                                     615606272   \n",
       "max_input_tokens                                                       128   \n",
       "max_output_tokens                                                      128   \n",
       "number_input_prompts                                                   128   \n",
       "total_energy_kwh                                                  0.021028   \n",
       "total_energy_joules                                           75701.472545   \n",
       "flops                                                       16949970993152   \n",
       "tokens_per_joule                                                  0.216429   \n",
       "joules_per_token                                                  4.620451   \n",
       "flops_per_joule                                           223905433.056266   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                         36.730154   \n",
       "average_latency_ms_per_batch                                   4591.269241   \n",
       "throughput_queries_per_sec                                        3.484875   \n",
       "throughput_tokens_per_sec                                       446.064017   \n",
       "total_energy_kwh_process_0                                        0.005251   \n",
       "total_energy_kwh_process_1                                        0.005257   \n",
       "total_energy_kwh_process_2                                        0.005277   \n",
       "total_energy_kwh_process_3                                        0.005244   \n",
       "gpu_power_avg                                                   429.799515   \n",
       "ram_power_avg                                                     0.959559   \n",
       "cpu_energy_total                                                  0.004548   \n",
       "gpu_energy_total                                                   0.01645   \n",
       "latency_simulation_simulate                                          False   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "total_generated_tokens                                               16384   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "\n",
       "                                                                        21  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_1.2   \n",
       "experiment_id                                                          254   \n",
       "date_time                                    April 11, 2025 at 05:38:09 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    1.2   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float16   \n",
       "quantization                                                          True   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                          True   \n",
       "total_input_tokens                                                   16384   \n",
       "total_params                                                     615606272   \n",
       "max_input_tokens                                                       128   \n",
       "max_output_tokens                                                      128   \n",
       "number_input_prompts                                                   128   \n",
       "total_energy_kwh                                                  0.021053   \n",
       "total_energy_joules                                           75790.175016   \n",
       "flops                                                       16949970993152   \n",
       "tokens_per_joule                                                  0.216176   \n",
       "joules_per_token                                                  4.625865   \n",
       "flops_per_joule                                           223643381.078152   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                         36.862467   \n",
       "average_latency_ms_per_batch                                    4607.80839   \n",
       "throughput_queries_per_sec                                        3.472367   \n",
       "throughput_tokens_per_sec                                       444.462926   \n",
       "total_energy_kwh_process_0                                        0.005273   \n",
       "total_energy_kwh_process_1                                        0.005256   \n",
       "total_energy_kwh_process_2                                        0.005268   \n",
       "total_energy_kwh_process_3                                        0.005255   \n",
       "gpu_power_avg                                                   432.050167   \n",
       "ram_power_avg                                                     0.956723   \n",
       "cpu_energy_total                                                   0.00454   \n",
       "gpu_energy_total                                                  0.016483   \n",
       "latency_simulation_simulate                                          False   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "total_generated_tokens                                               16384   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "\n",
       "                                                                                  22  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    256   \n",
       "date_time                                              April 11, 2025 at 05:39:42 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.020493   \n",
       "total_energy_joules                                                     73773.389464   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.222085   \n",
       "joules_per_token                                                             4.50277   \n",
       "flops_per_joule                                                      229757248.73563   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.388011   \n",
       "average_latency_ms_per_batch                                             4548.501365   \n",
       "throughput_queries_per_sec                                                  3.517642   \n",
       "throughput_tokens_per_sec                                                 450.258192   \n",
       "total_energy_kwh_process_0                                                  0.005115   \n",
       "total_energy_kwh_process_1                                                   0.00512   \n",
       "total_energy_kwh_process_2                                                  0.005138   \n",
       "total_energy_kwh_process_3                                                  0.005119   \n",
       "gpu_power_avg                                                             421.301499   \n",
       "ram_power_avg                                                                0.95529   \n",
       "cpu_energy_total                                                            0.004495   \n",
       "gpu_energy_total                                                            0.015968   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  23  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    257   \n",
       "date_time                                              April 11, 2025 at 05:40:48 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.020526   \n",
       "total_energy_joules                                                     73892.703968   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.221727   \n",
       "joules_per_token                                                            4.510053   \n",
       "flops_per_joule                                                     229386259.846373   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.456038   \n",
       "average_latency_ms_per_batch                                             4557.004705   \n",
       "throughput_queries_per_sec                                                  3.511078   \n",
       "throughput_tokens_per_sec                                                 449.418013   \n",
       "total_energy_kwh_process_0                                                   0.00517   \n",
       "total_energy_kwh_process_1                                                    0.0051   \n",
       "total_energy_kwh_process_2                                                  0.005143   \n",
       "total_energy_kwh_process_3                                                  0.005112   \n",
       "gpu_power_avg                                                             393.303811   \n",
       "ram_power_avg                                                               0.954029   \n",
       "cpu_energy_total                                                            0.004464   \n",
       "gpu_energy_total                                                            0.016032   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  24  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    258   \n",
       "date_time                                              April 11, 2025 at 05:41:54 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.020592   \n",
       "total_energy_joules                                                     74129.708593   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.221018   \n",
       "joules_per_token                                                            4.524518   \n",
       "flops_per_joule                                                     228652875.007557   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.447105   \n",
       "average_latency_ms_per_batch                                             4555.888145   \n",
       "throughput_queries_per_sec                                                  3.511939   \n",
       "throughput_tokens_per_sec                                                 449.528157   \n",
       "total_energy_kwh_process_0                                                  0.005177   \n",
       "total_energy_kwh_process_1                                                  0.005169   \n",
       "total_energy_kwh_process_2                                                  0.005158   \n",
       "total_energy_kwh_process_3                                                  0.005088   \n",
       "gpu_power_avg                                                             292.735859   \n",
       "ram_power_avg                                                               0.955858   \n",
       "cpu_energy_total                                                              0.0045   \n",
       "gpu_energy_total                                                            0.016062   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  25  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    259   \n",
       "date_time                                              April 11, 2025 at 05:43:00 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.020612   \n",
       "total_energy_joules                                                     74203.606308   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.220798   \n",
       "joules_per_token                                                            4.529029   \n",
       "flops_per_joule                                                     228425164.711328   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.306288   \n",
       "average_latency_ms_per_batch                                             4538.285978   \n",
       "throughput_queries_per_sec                                                   3.52556   \n",
       "throughput_tokens_per_sec                                                 451.271694   \n",
       "total_energy_kwh_process_0                                                  0.005172   \n",
       "total_energy_kwh_process_1                                                  0.005173   \n",
       "total_energy_kwh_process_2                                                  0.005116   \n",
       "total_energy_kwh_process_3                                                  0.005151   \n",
       "gpu_power_avg                                                             495.914887   \n",
       "ram_power_avg                                                               0.951728   \n",
       "cpu_energy_total                                                             0.00447   \n",
       "gpu_energy_total                                                            0.016112   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  26  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    260   \n",
       "date_time                                              April 11, 2025 at 05:44:05 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.020695   \n",
       "total_energy_joules                                                     74501.001648   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.219917   \n",
       "joules_per_token                                                             4.54718   \n",
       "flops_per_joule                                                      227513330.26575   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.211281   \n",
       "average_latency_ms_per_batch                                             4526.410158   \n",
       "throughput_queries_per_sec                                                   3.53481   \n",
       "throughput_tokens_per_sec                                                 452.455683   \n",
       "total_energy_kwh_process_0                                                   0.00517   \n",
       "total_energy_kwh_process_1                                                  0.005199   \n",
       "total_energy_kwh_process_2                                                  0.005132   \n",
       "total_energy_kwh_process_3                                                  0.005193   \n",
       "gpu_power_avg                                                             412.077225   \n",
       "ram_power_avg                                                               0.948094   \n",
       "cpu_energy_total                                                            0.004483   \n",
       "gpu_energy_total                                                            0.016181   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  27  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    261   \n",
       "date_time                                              April 11, 2025 at 05:45:11 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021096   \n",
       "total_energy_joules                                                     75946.539604   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215731   \n",
       "joules_per_token                                                            4.635409   \n",
       "flops_per_joule                                                     223182926.853609   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.147624   \n",
       "average_latency_ms_per_batch                                             4643.452946   \n",
       "throughput_queries_per_sec                                                  3.445712   \n",
       "throughput_tokens_per_sec                                                 441.051094   \n",
       "total_energy_kwh_process_0                                                  0.005295   \n",
       "total_energy_kwh_process_1                                                   0.00525   \n",
       "total_energy_kwh_process_2                                                  0.005203   \n",
       "total_energy_kwh_process_3                                                  0.005348   \n",
       "gpu_power_avg                                                             383.197083   \n",
       "ram_power_avg                                                               0.962667   \n",
       "cpu_energy_total                                                            0.004568   \n",
       "gpu_energy_total                                                            0.016497   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  28  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    262   \n",
       "date_time                                              April 11, 2025 at 05:46:17 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021167   \n",
       "total_energy_joules                                                     76201.793024   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215008   \n",
       "joules_per_token                                                            4.650988   \n",
       "flops_per_joule                                                     222435330.199059   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.538299   \n",
       "average_latency_ms_per_batch                                             4692.287417   \n",
       "throughput_queries_per_sec                                                  3.409851   \n",
       "throughput_tokens_per_sec                                                 436.460902   \n",
       "total_energy_kwh_process_0                                                  0.005316   \n",
       "total_energy_kwh_process_1                                                   0.00533   \n",
       "total_energy_kwh_process_2                                                  0.005233   \n",
       "total_energy_kwh_process_3                                                  0.005289   \n",
       "gpu_power_avg                                                             390.294755   \n",
       "ram_power_avg                                                               0.963921   \n",
       "cpu_energy_total                                                            0.004614   \n",
       "gpu_energy_total                                                            0.016523   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  29  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    263   \n",
       "date_time                                              April 11, 2025 at 05:47:23 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021317   \n",
       "total_energy_joules                                                     76742.959091   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.213492   \n",
       "joules_per_token                                                            4.684018   \n",
       "flops_per_joule                                                     220866789.524664   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.345801   \n",
       "average_latency_ms_per_batch                                             4668.225076   \n",
       "throughput_queries_per_sec                                                  3.427427   \n",
       "throughput_tokens_per_sec                                                 438.710638   \n",
       "total_energy_kwh_process_0                                                  0.005347   \n",
       "total_energy_kwh_process_1                                                  0.005325   \n",
       "total_energy_kwh_process_2                                                  0.005325   \n",
       "total_energy_kwh_process_3                                                  0.005321   \n",
       "gpu_power_avg                                                             571.329062   \n",
       "ram_power_avg                                                                0.95377   \n",
       "cpu_energy_total                                                            0.004592   \n",
       "gpu_energy_total                                                            0.016694   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  30  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    264   \n",
       "date_time                                              April 11, 2025 at 05:48:29 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021256   \n",
       "total_energy_joules                                                     76520.796084   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214112   \n",
       "joules_per_token                                                            4.670459   \n",
       "flops_per_joule                                                     221508032.594712   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.266966   \n",
       "average_latency_ms_per_batch                                             4658.370769   \n",
       "throughput_queries_per_sec                                                  3.434677   \n",
       "throughput_tokens_per_sec                                                 439.638685   \n",
       "total_energy_kwh_process_0                                                   0.00534   \n",
       "total_energy_kwh_process_1                                                  0.005234   \n",
       "total_energy_kwh_process_2                                                  0.005355   \n",
       "total_energy_kwh_process_3                                                  0.005327   \n",
       "gpu_power_avg                                                             392.706854   \n",
       "ram_power_avg                                                                0.96025   \n",
       "cpu_energy_total                                                            0.004588   \n",
       "gpu_energy_total                                                            0.016637   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  31  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    265   \n",
       "date_time                                              April 11, 2025 at 05:49:38 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021237   \n",
       "total_energy_joules                                                       76452.8938   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214302   \n",
       "joules_per_token                                                            4.666314   \n",
       "flops_per_joule                                                     221704766.827728   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    37.24014   \n",
       "average_latency_ms_per_batch                                              4655.01752   \n",
       "throughput_queries_per_sec                                                  3.437151   \n",
       "throughput_tokens_per_sec                                                  439.95538   \n",
       "total_energy_kwh_process_0                                                  0.005323   \n",
       "total_energy_kwh_process_1                                                  0.005277   \n",
       "total_energy_kwh_process_2                                                  0.005304   \n",
       "total_energy_kwh_process_3                                                  0.005333   \n",
       "gpu_power_avg                                                             367.056529   \n",
       "ram_power_avg                                                               0.961562   \n",
       "cpu_energy_total                                                            0.004594   \n",
       "gpu_energy_total                                                            0.016611   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  32  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    266   \n",
       "date_time                                              April 11, 2025 at 05:50:44 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021173   \n",
       "total_energy_joules                                                     76223.569931   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214947   \n",
       "joules_per_token                                                            4.652318   \n",
       "flops_per_joule                                                      222371780.91456   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.286302   \n",
       "average_latency_ms_per_batch                                             4660.787711   \n",
       "throughput_queries_per_sec                                                  3.432896   \n",
       "throughput_tokens_per_sec                                                 439.410702   \n",
       "total_energy_kwh_process_0                                                   0.00533   \n",
       "total_energy_kwh_process_1                                                  0.005243   \n",
       "total_energy_kwh_process_2                                                  0.005314   \n",
       "total_energy_kwh_process_3                                                  0.005286   \n",
       "gpu_power_avg                                                             474.542887   \n",
       "ram_power_avg                                                               0.958358   \n",
       "cpu_energy_total                                                            0.004563   \n",
       "gpu_energy_total                                                            0.016579   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  33  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    267   \n",
       "date_time                                              April 11, 2025 at 05:51:50 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021219   \n",
       "total_energy_joules                                                     76386.637887   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214488   \n",
       "joules_per_token                                                             4.66227   \n",
       "flops_per_joule                                                     221897068.152067   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.472509   \n",
       "average_latency_ms_per_batch                                             4684.063664   \n",
       "throughput_queries_per_sec                                                  3.415837   \n",
       "throughput_tokens_per_sec                                                 437.227191   \n",
       "total_energy_kwh_process_0                                                  0.005341   \n",
       "total_energy_kwh_process_1                                                  0.005303   \n",
       "total_energy_kwh_process_2                                                  0.005276   \n",
       "total_energy_kwh_process_3                                                  0.005299   \n",
       "gpu_power_avg                                                              334.40488   \n",
       "ram_power_avg                                                               0.952374   \n",
       "cpu_energy_total                                                            0.004593   \n",
       "gpu_energy_total                                                            0.016594   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  34  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    268   \n",
       "date_time                                              April 11, 2025 at 05:52:55 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021218   \n",
       "total_energy_joules                                                     76383.180866   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214497   \n",
       "joules_per_token                                                            4.662059   \n",
       "flops_per_joule                                                     221907110.976747   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.066333   \n",
       "average_latency_ms_per_batch                                              4633.29158   \n",
       "throughput_queries_per_sec                                                  3.453269   \n",
       "throughput_tokens_per_sec                                                 442.018372   \n",
       "total_energy_kwh_process_0                                                  0.005302   \n",
       "total_energy_kwh_process_1                                                   0.00528   \n",
       "total_energy_kwh_process_2                                                  0.005318   \n",
       "total_energy_kwh_process_3                                                  0.005318   \n",
       "gpu_power_avg                                                             367.160655   \n",
       "ram_power_avg                                                                0.95813   \n",
       "cpu_energy_total                                                            0.004591   \n",
       "gpu_energy_total                                                            0.016596   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  35  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    269   \n",
       "date_time                                              April 11, 2025 at 05:54:01 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021238   \n",
       "total_energy_joules                                                     76458.267707   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214287   \n",
       "joules_per_token                                                            4.666642   \n",
       "flops_per_joule                                                     221689184.198326   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.176715   \n",
       "average_latency_ms_per_batch                                             4647.089355   \n",
       "throughput_queries_per_sec                                                  3.443015   \n",
       "throughput_tokens_per_sec                                                 440.705965   \n",
       "total_energy_kwh_process_0                                                  0.005306   \n",
       "total_energy_kwh_process_1                                                  0.005318   \n",
       "total_energy_kwh_process_2                                                  0.005307   \n",
       "total_energy_kwh_process_3                                                  0.005307   \n",
       "gpu_power_avg                                                             503.445063   \n",
       "ram_power_avg                                                                0.95802   \n",
       "cpu_energy_total                                                            0.004591   \n",
       "gpu_energy_total                                                            0.016617   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  36  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    270   \n",
       "date_time                                              April 11, 2025 at 05:55:07 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021238   \n",
       "total_energy_joules                                                     76456.077645   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214293   \n",
       "joules_per_token                                                            4.666509   \n",
       "flops_per_joule                                                      221695534.41967   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.421394   \n",
       "average_latency_ms_per_batch                                             4677.674297   \n",
       "throughput_queries_per_sec                                                  3.420503   \n",
       "throughput_tokens_per_sec                                                 437.824412   \n",
       "total_energy_kwh_process_0                                                  0.005313   \n",
       "total_energy_kwh_process_1                                                  0.005295   \n",
       "total_energy_kwh_process_2                                                   0.00534   \n",
       "total_energy_kwh_process_3                                                   0.00529   \n",
       "gpu_power_avg                                                             410.155781   \n",
       "ram_power_avg                                                               0.962087   \n",
       "cpu_energy_total                                                            0.004617   \n",
       "gpu_energy_total                                                             0.01659   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  37  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    271   \n",
       "date_time                                              April 11, 2025 at 05:56:12 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021201   \n",
       "total_energy_joules                                                     76322.508765   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214668   \n",
       "joules_per_token                                                            4.658356   \n",
       "flops_per_joule                                                     222083514.646961   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.979404   \n",
       "average_latency_ms_per_batch                                             4622.425475   \n",
       "throughput_queries_per_sec                                                  3.461386   \n",
       "throughput_tokens_per_sec                                                 443.057441   \n",
       "total_energy_kwh_process_0                                                  0.005335   \n",
       "total_energy_kwh_process_1                                                  0.005315   \n",
       "total_energy_kwh_process_2                                                  0.005337   \n",
       "total_energy_kwh_process_3                                                  0.005215   \n",
       "gpu_power_avg                                                             195.802022   \n",
       "ram_power_avg                                                               0.958308   \n",
       "cpu_energy_total                                                            0.004625   \n",
       "gpu_energy_total                                                            0.016545   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  38  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    272   \n",
       "date_time                                              April 11, 2025 at 05:57:18 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021264   \n",
       "total_energy_joules                                                     76552.127557   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214024   \n",
       "joules_per_token                                                            4.672371   \n",
       "flops_per_joule                                                     221417373.154566   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.373825   \n",
       "average_latency_ms_per_batch                                              4671.72815   \n",
       "throughput_queries_per_sec                                                  3.424857   \n",
       "throughput_tokens_per_sec                                                 438.381673   \n",
       "total_energy_kwh_process_0                                                  0.005321   \n",
       "total_energy_kwh_process_1                                                  0.005325   \n",
       "total_energy_kwh_process_2                                                  0.005309   \n",
       "total_energy_kwh_process_3                                                   0.00531   \n",
       "gpu_power_avg                                                             291.842585   \n",
       "ram_power_avg                                                                0.95993   \n",
       "cpu_energy_total                                                            0.004642   \n",
       "gpu_energy_total                                                            0.016591   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  39  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    273   \n",
       "date_time                                              April 11, 2025 at 05:58:24 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021225   \n",
       "total_energy_joules                                                     76410.590357   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214421   \n",
       "joules_per_token                                                            4.663732   \n",
       "flops_per_joule                                                     221827509.955699   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.459553   \n",
       "average_latency_ms_per_batch                                             4682.444169   \n",
       "throughput_queries_per_sec                                                  3.417019   \n",
       "throughput_tokens_per_sec                                                 437.378413   \n",
       "total_energy_kwh_process_0                                                  0.005359   \n",
       "total_energy_kwh_process_1                                                   0.00526   \n",
       "total_energy_kwh_process_2                                                  0.005322   \n",
       "total_energy_kwh_process_3                                                  0.005285   \n",
       "gpu_power_avg                                                             337.884587   \n",
       "ram_power_avg                                                               0.964699   \n",
       "cpu_energy_total                                                            0.004581   \n",
       "gpu_energy_total                                                            0.016613   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  40  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    274   \n",
       "date_time                                              April 11, 2025 at 05:59:29 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021234   \n",
       "total_energy_joules                                                     76443.543844   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214328   \n",
       "joules_per_token                                                            4.665744   \n",
       "flops_per_joule                                                     221731883.961792   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.784267   \n",
       "average_latency_ms_per_batch                                              4598.03337   \n",
       "throughput_queries_per_sec                                                  3.479749   \n",
       "throughput_tokens_per_sec                                                 445.407816   \n",
       "total_energy_kwh_process_0                                                  0.005304   \n",
       "total_energy_kwh_process_1                                                  0.005307   \n",
       "total_energy_kwh_process_2                                                  0.005307   \n",
       "total_energy_kwh_process_3                                                  0.005317   \n",
       "gpu_power_avg                                                             439.834917   \n",
       "ram_power_avg                                                               0.955347   \n",
       "cpu_energy_total                                                            0.004556   \n",
       "gpu_energy_total                                                            0.016648   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  41  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    275   \n",
       "date_time                                              April 11, 2025 at 06:00:36 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021319   \n",
       "total_energy_joules                                                     76748.976626   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.213475   \n",
       "joules_per_token                                                            4.684386   \n",
       "flops_per_joule                                                     220849472.375148   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.335853   \n",
       "average_latency_ms_per_batch                                             4666.981563   \n",
       "throughput_queries_per_sec                                                   3.42834   \n",
       "throughput_tokens_per_sec                                                 438.827532   \n",
       "total_energy_kwh_process_0                                                  0.005338   \n",
       "total_energy_kwh_process_1                                                  0.005326   \n",
       "total_energy_kwh_process_2                                                  0.005322   \n",
       "total_energy_kwh_process_3                                                  0.005333   \n",
       "gpu_power_avg                                                             432.162595   \n",
       "ram_power_avg                                                               0.959208   \n",
       "cpu_energy_total                                                            0.004604   \n",
       "gpu_energy_total                                                            0.016684   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  42  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    276   \n",
       "date_time                                              April 11, 2025 at 06:01:44 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021258   \n",
       "total_energy_joules                                                     76530.379229   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214085   \n",
       "joules_per_token                                                            4.671044   \n",
       "flops_per_joule                                                     221480295.326627   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.763149   \n",
       "average_latency_ms_per_batch                                             4595.393663   \n",
       "throughput_queries_per_sec                                                  3.481747   \n",
       "throughput_tokens_per_sec                                                 445.663669   \n",
       "total_energy_kwh_process_0                                                  0.005282   \n",
       "total_energy_kwh_process_1                                                  0.005309   \n",
       "total_energy_kwh_process_2                                                  0.005331   \n",
       "total_energy_kwh_process_3                                                  0.005336   \n",
       "gpu_power_avg                                                             367.760453   \n",
       "ram_power_avg                                                               0.960846   \n",
       "cpu_energy_total                                                            0.004579   \n",
       "gpu_energy_total                                                            0.016649   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  43  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    277   \n",
       "date_time                                              April 11, 2025 at 06:02:51 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021287   \n",
       "total_energy_joules                                                     76631.935788   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.213801   \n",
       "joules_per_token                                                            4.677242   \n",
       "flops_per_joule                                                     221186778.315872   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.198482   \n",
       "average_latency_ms_per_batch                                             4649.810295   \n",
       "throughput_queries_per_sec                                                  3.441001   \n",
       "throughput_tokens_per_sec                                                 440.448076   \n",
       "total_energy_kwh_process_0                                                  0.005281   \n",
       "total_energy_kwh_process_1                                                  0.005321   \n",
       "total_energy_kwh_process_2                                                  0.005364   \n",
       "total_energy_kwh_process_3                                                   0.00532   \n",
       "gpu_power_avg                                                             397.983108   \n",
       "ram_power_avg                                                               0.962158   \n",
       "cpu_energy_total                                                            0.004634   \n",
       "gpu_energy_total                                                            0.016622   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  44  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    278   \n",
       "date_time                                              April 11, 2025 at 06:03:57 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021207   \n",
       "total_energy_joules                                                     76346.735078   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                              0.2146   \n",
       "joules_per_token                                                            4.659835   \n",
       "flops_per_joule                                                     222013043.200503   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.812719   \n",
       "average_latency_ms_per_batch                                              4601.58986   \n",
       "throughput_queries_per_sec                                                  3.477059   \n",
       "throughput_tokens_per_sec                                                 445.063568   \n",
       "total_energy_kwh_process_0                                                  0.005293   \n",
       "total_energy_kwh_process_1                                                  0.005297   \n",
       "total_energy_kwh_process_2                                                  0.005293   \n",
       "total_energy_kwh_process_3                                                  0.005324   \n",
       "gpu_power_avg                                                             584.680567   \n",
       "ram_power_avg                                                               0.962879   \n",
       "cpu_energy_total                                                             0.00456   \n",
       "gpu_energy_total                                                            0.016617   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  45  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    279   \n",
       "date_time                                              April 11, 2025 at 06:05:03 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021255   \n",
       "total_energy_joules                                                     76517.116778   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214122   \n",
       "joules_per_token                                                            4.670234   \n",
       "flops_per_joule                                                     221518683.752156   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.283309   \n",
       "average_latency_ms_per_batch                                             4660.413619   \n",
       "throughput_queries_per_sec                                                  3.433172   \n",
       "throughput_tokens_per_sec                                                 439.445974   \n",
       "total_energy_kwh_process_0                                                  0.005315   \n",
       "total_energy_kwh_process_1                                                  0.005325   \n",
       "total_energy_kwh_process_2                                                  0.005315   \n",
       "total_energy_kwh_process_3                                                  0.005301   \n",
       "gpu_power_avg                                                             404.882464   \n",
       "ram_power_avg                                                               0.962166   \n",
       "cpu_energy_total                                                            0.004611   \n",
       "gpu_energy_total                                                            0.016612   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  46  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    280   \n",
       "date_time                                              April 11, 2025 at 06:06:10 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021197   \n",
       "total_energy_joules                                                     76308.943626   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214706   \n",
       "joules_per_token                                                            4.657528   \n",
       "flops_per_joule                                                     222122993.553691   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.419533   \n",
       "average_latency_ms_per_batch                                             4677.441662   \n",
       "throughput_queries_per_sec                                                  3.420673   \n",
       "throughput_tokens_per_sec                                                 437.846188   \n",
       "total_energy_kwh_process_0                                                  0.005325   \n",
       "total_energy_kwh_process_1                                                  0.005335   \n",
       "total_energy_kwh_process_2                                                  0.005234   \n",
       "total_energy_kwh_process_3                                                  0.005302   \n",
       "gpu_power_avg                                                             373.916889   \n",
       "ram_power_avg                                                               0.965268   \n",
       "cpu_energy_total                                                              0.0046   \n",
       "gpu_energy_total                                                            0.016566   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  47  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    281   \n",
       "date_time                                              April 11, 2025 at 06:07:16 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021211   \n",
       "total_energy_joules                                                     76361.089511   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                             0.21456   \n",
       "joules_per_token                                                            4.660711   \n",
       "flops_per_joule                                                     221971308.970354   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.420523   \n",
       "average_latency_ms_per_batch                                             4677.565389   \n",
       "throughput_queries_per_sec                                                  3.420583   \n",
       "throughput_tokens_per_sec                                                 437.834606   \n",
       "total_energy_kwh_process_0                                                  0.005327   \n",
       "total_energy_kwh_process_1                                                  0.005263   \n",
       "total_energy_kwh_process_2                                                  0.005292   \n",
       "total_energy_kwh_process_3                                                   0.00533   \n",
       "gpu_power_avg                                                             373.171862   \n",
       "ram_power_avg                                                               0.959845   \n",
       "cpu_energy_total                                                            0.004603   \n",
       "gpu_energy_total                                                            0.016577   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  48  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    282   \n",
       "date_time                                              April 11, 2025 at 06:08:21 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021179   \n",
       "total_energy_joules                                                     76245.168806   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214886   \n",
       "joules_per_token                                                            4.653636   \n",
       "flops_per_joule                                                     222308787.015928   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.239923   \n",
       "average_latency_ms_per_batch                                             4654.990417   \n",
       "throughput_queries_per_sec                                                  3.437171   \n",
       "throughput_tokens_per_sec                                                 439.957941   \n",
       "total_energy_kwh_process_0                                                  0.005317   \n",
       "total_energy_kwh_process_1                                                  0.005307   \n",
       "total_energy_kwh_process_2                                                  0.005249   \n",
       "total_energy_kwh_process_3                                                  0.005306   \n",
       "gpu_power_avg                                                             581.747394   \n",
       "ram_power_avg                                                               0.963443   \n",
       "cpu_energy_total                                                            0.004577   \n",
       "gpu_energy_total                                                            0.016571   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  49  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    283   \n",
       "date_time                                              April 11, 2025 at 06:09:27 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                             0.02115   \n",
       "total_energy_joules                                                      76141.04486   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                             0.21518   \n",
       "joules_per_token                                                            4.647281   \n",
       "flops_per_joule                                                     222612797.398213   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.278837   \n",
       "average_latency_ms_per_batch                                             4659.854676   \n",
       "throughput_queries_per_sec                                                  3.433583   \n",
       "throughput_tokens_per_sec                                                 439.498684   \n",
       "total_energy_kwh_process_0                                                  0.005316   \n",
       "total_energy_kwh_process_1                                                  0.005318   \n",
       "total_energy_kwh_process_2                                                  0.005273   \n",
       "total_energy_kwh_process_3                                                  0.005243   \n",
       "gpu_power_avg                                                             396.201549   \n",
       "ram_power_avg                                                               0.963372   \n",
       "cpu_energy_total                                                            0.004582   \n",
       "gpu_energy_total                                                            0.016538   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  50  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    284   \n",
       "date_time                                              April 11, 2025 at 06:10:32 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021163   \n",
       "total_energy_joules                                                     76187.233345   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215049   \n",
       "joules_per_token                                                              4.6501   \n",
       "flops_per_joule                                                     222477838.462899   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    37.05608   \n",
       "average_latency_ms_per_batch                                              4632.01002   \n",
       "throughput_queries_per_sec                                                  3.454224   \n",
       "throughput_tokens_per_sec                                                 442.140667   \n",
       "total_energy_kwh_process_0                                                  0.005299   \n",
       "total_energy_kwh_process_1                                                  0.005315   \n",
       "total_energy_kwh_process_2                                                  0.005281   \n",
       "total_energy_kwh_process_3                                                  0.005268   \n",
       "gpu_power_avg                                                             525.567555   \n",
       "ram_power_avg                                                               0.966059   \n",
       "cpu_energy_total                                                            0.004574   \n",
       "gpu_energy_total                                                            0.016558   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  51  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    285   \n",
       "date_time                                              April 11, 2025 at 06:11:38 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021133   \n",
       "total_energy_joules                                                     76079.755405   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215353   \n",
       "joules_per_token                                                             4.64354   \n",
       "flops_per_joule                                                     222792133.111257   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.896263   \n",
       "average_latency_ms_per_batch                                             4612.032873   \n",
       "throughput_queries_per_sec                                                  3.469186   \n",
       "throughput_tokens_per_sec                                                 444.055811   \n",
       "total_energy_kwh_process_0                                                  0.005281   \n",
       "total_energy_kwh_process_1                                                  0.005289   \n",
       "total_energy_kwh_process_2                                                  0.005327   \n",
       "total_energy_kwh_process_3                                                  0.005236   \n",
       "gpu_power_avg                                                             399.772335   \n",
       "ram_power_avg                                                               0.954208   \n",
       "cpu_energy_total                                                            0.004564   \n",
       "gpu_energy_total                                                            0.016539   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  52  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    286   \n",
       "date_time                                              April 11, 2025 at 06:12:45 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021166   \n",
       "total_energy_joules                                                     76195.841449   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215025   \n",
       "joules_per_token                                                            4.650625   \n",
       "flops_per_joule                                                     222452704.383082   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.303935   \n",
       "average_latency_ms_per_batch                                             4662.991815   \n",
       "throughput_queries_per_sec                                                  3.431273   \n",
       "throughput_tokens_per_sec                                                 439.203001   \n",
       "total_energy_kwh_process_0                                                  0.005296   \n",
       "total_energy_kwh_process_1                                                  0.005289   \n",
       "total_energy_kwh_process_2                                                  0.005251   \n",
       "total_energy_kwh_process_3                                                  0.005329   \n",
       "gpu_power_avg                                                             389.105744   \n",
       "ram_power_avg                                                               0.963354   \n",
       "cpu_energy_total                                                            0.004612   \n",
       "gpu_energy_total                                                            0.016522   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  53  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    287   \n",
       "date_time                                              April 11, 2025 at 06:13:51 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021162   \n",
       "total_energy_joules                                                     76181.591128   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215065   \n",
       "joules_per_token                                                            4.649755   \n",
       "flops_per_joule                                                     222494315.782651   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.005236   \n",
       "average_latency_ms_per_batch                                             4625.654561   \n",
       "throughput_queries_per_sec                                                   3.45897   \n",
       "throughput_tokens_per_sec                                                  442.74815   \n",
       "total_energy_kwh_process_0                                                  0.005303   \n",
       "total_energy_kwh_process_1                                                  0.005316   \n",
       "total_energy_kwh_process_2                                                  0.005235   \n",
       "total_energy_kwh_process_3                                                  0.005308   \n",
       "gpu_power_avg                                                             277.971773   \n",
       "ram_power_avg                                                               0.962415   \n",
       "cpu_energy_total                                                            0.004634   \n",
       "gpu_energy_total                                                            0.016496   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  54  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    288   \n",
       "date_time                                              April 11, 2025 at 06:14:58 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021253   \n",
       "total_energy_joules                                                      76512.58586   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214135   \n",
       "joules_per_token                                                            4.669958   \n",
       "flops_per_joule                                                      221531801.63285   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.377651   \n",
       "average_latency_ms_per_batch                                             4672.206413   \n",
       "throughput_queries_per_sec                                                  3.424506   \n",
       "throughput_tokens_per_sec                                                 438.336798   \n",
       "total_energy_kwh_process_0                                                  0.005313   \n",
       "total_energy_kwh_process_1                                                  0.005352   \n",
       "total_energy_kwh_process_2                                                  0.005294   \n",
       "total_energy_kwh_process_3                                                  0.005294   \n",
       "gpu_power_avg                                                             384.025206   \n",
       "ram_power_avg                                                               0.957899   \n",
       "cpu_energy_total                                                            0.004625   \n",
       "gpu_energy_total                                                            0.016597   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  55  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    289   \n",
       "date_time                                              April 11, 2025 at 06:16:04 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021272   \n",
       "total_energy_joules                                                     76578.514995   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                             0.21395   \n",
       "joules_per_token                                                            4.673982   \n",
       "flops_per_joule                                                     221341077.118197   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.014072   \n",
       "average_latency_ms_per_batch                                              4626.75899   \n",
       "throughput_queries_per_sec                                                  3.458144   \n",
       "throughput_tokens_per_sec                                                 442.642464   \n",
       "total_energy_kwh_process_0                                                  0.005304   \n",
       "total_energy_kwh_process_1                                                  0.005329   \n",
       "total_energy_kwh_process_2                                                   0.00531   \n",
       "total_energy_kwh_process_3                                                  0.005329   \n",
       "gpu_power_avg                                                            1477.347167   \n",
       "ram_power_avg                                                                0.96216   \n",
       "cpu_energy_total                                                            0.004598   \n",
       "gpu_energy_total                                                            0.016642   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  56  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    290   \n",
       "date_time                                              April 11, 2025 at 06:17:15 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021315   \n",
       "total_energy_joules                                                     76733.750114   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.213518   \n",
       "joules_per_token                                                            4.683456   \n",
       "flops_per_joule                                                     220893296.207842   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.463349   \n",
       "average_latency_ms_per_batch                                             4682.918639   \n",
       "throughput_queries_per_sec                                                  3.416673   \n",
       "throughput_tokens_per_sec                                                 437.334098   \n",
       "total_energy_kwh_process_0                                                   0.00536   \n",
       "total_energy_kwh_process_1                                                  0.005324   \n",
       "total_energy_kwh_process_2                                                  0.005334   \n",
       "total_energy_kwh_process_3                                                  0.005297   \n",
       "gpu_power_avg                                                             451.401374   \n",
       "ram_power_avg                                                               0.960668   \n",
       "cpu_energy_total                                                            0.004594   \n",
       "gpu_energy_total                                                             0.01669   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "\n",
       "                                                                                  57  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    296   \n",
       "date_time                                              April 11, 2025 at 06:20:42 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.020483   \n",
       "total_energy_joules                                                      73737.29051   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.222194   \n",
       "joules_per_token                                                            4.500567   \n",
       "flops_per_joule                                                      229869729.08804   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.610644   \n",
       "average_latency_ms_per_batch                                             4576.330444   \n",
       "throughput_queries_per_sec                                                  3.496251   \n",
       "throughput_tokens_per_sec                                                 447.520131   \n",
       "total_energy_kwh_process_0                                                  0.005141   \n",
       "total_energy_kwh_process_1                                                  0.005133   \n",
       "total_energy_kwh_process_2                                                  0.005125   \n",
       "total_energy_kwh_process_3                                                  0.005083   \n",
       "gpu_power_avg                                                             555.380175   \n",
       "ram_power_avg                                                               0.953066   \n",
       "cpu_energy_total                                                            0.004497   \n",
       "gpu_energy_total                                                            0.015956   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  58  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    297   \n",
       "date_time                                              April 11, 2025 at 06:21:47 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.020574   \n",
       "total_energy_joules                                                     74065.599056   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.221209   \n",
       "joules_per_token                                                            4.520605   \n",
       "flops_per_joule                                                      228850791.85564   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    36.43053   \n",
       "average_latency_ms_per_batch                                             4553.816217   \n",
       "throughput_queries_per_sec                                                  3.513537   \n",
       "throughput_tokens_per_sec                                                 449.732686   \n",
       "total_energy_kwh_process_0                                                  0.005139   \n",
       "total_energy_kwh_process_1                                                  0.005133   \n",
       "total_energy_kwh_process_2                                                   0.00513   \n",
       "total_energy_kwh_process_3                                                  0.005172   \n",
       "gpu_power_avg                                                             406.571211   \n",
       "ram_power_avg                                                               0.949621   \n",
       "cpu_energy_total                                                            0.004512   \n",
       "gpu_energy_total                                                            0.016032   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  59  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    298   \n",
       "date_time                                              April 11, 2025 at 06:22:52 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.020635   \n",
       "total_energy_joules                                                     74286.409458   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.220552   \n",
       "joules_per_token                                                            4.534083   \n",
       "flops_per_joule                                                     228170551.204544   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.471863   \n",
       "average_latency_ms_per_batch                                             4558.982923   \n",
       "throughput_queries_per_sec                                                  3.509555   \n",
       "throughput_tokens_per_sec                                                 449.223003   \n",
       "total_energy_kwh_process_0                                                  0.005171   \n",
       "total_energy_kwh_process_1                                                  0.005132   \n",
       "total_energy_kwh_process_2                                                  0.005172   \n",
       "total_energy_kwh_process_3                                                   0.00516   \n",
       "gpu_power_avg                                                             375.751597   \n",
       "ram_power_avg                                                               0.955473   \n",
       "cpu_energy_total                                                            0.004496   \n",
       "gpu_energy_total                                                            0.016109   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  60  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    299   \n",
       "date_time                                              April 11, 2025 at 06:23:58 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                             0.02061   \n",
       "total_energy_joules                                                     74197.531957   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.220816   \n",
       "joules_per_token                                                            4.528658   \n",
       "flops_per_joule                                                     228443865.261377   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.407234   \n",
       "average_latency_ms_per_batch                                             4550.904239   \n",
       "throughput_queries_per_sec                                                  3.515785   \n",
       "throughput_tokens_per_sec                                                 450.020456   \n",
       "total_energy_kwh_process_0                                                  0.005172   \n",
       "total_energy_kwh_process_1                                                  0.005148   \n",
       "total_energy_kwh_process_2                                                  0.005214   \n",
       "total_energy_kwh_process_3                                                  0.005077   \n",
       "gpu_power_avg                                                             371.866695   \n",
       "ram_power_avg                                                               0.956434   \n",
       "cpu_energy_total                                                            0.004484   \n",
       "gpu_energy_total                                                            0.016096   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  61  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    300   \n",
       "date_time                                              April 11, 2025 at 06:25:04 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021128   \n",
       "total_energy_joules                                                     76059.345286   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215411   \n",
       "joules_per_token                                                            4.642294   \n",
       "flops_per_joule                                                     222851918.188743   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.230651   \n",
       "average_latency_ms_per_batch                                             4653.831399   \n",
       "throughput_queries_per_sec                                                  3.438027   \n",
       "throughput_tokens_per_sec                                                 440.067511   \n",
       "total_energy_kwh_process_0                                                   0.00532   \n",
       "total_energy_kwh_process_1                                                   0.00522   \n",
       "total_energy_kwh_process_2                                                  0.005261   \n",
       "total_energy_kwh_process_3                                                  0.005326   \n",
       "gpu_power_avg                                                             311.990543   \n",
       "ram_power_avg                                                               0.945956   \n",
       "cpu_energy_total                                                            0.004586   \n",
       "gpu_energy_total                                                            0.016511   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  62  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    301   \n",
       "date_time                                              April 11, 2025 at 06:26:10 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021085   \n",
       "total_energy_joules                                                     75905.904876   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215846   \n",
       "joules_per_token                                                            4.632929   \n",
       "flops_per_joule                                                     223302403.426195   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.061346   \n",
       "average_latency_ms_per_batch                                             4632.668298   \n",
       "throughput_queries_per_sec                                                  3.453733   \n",
       "throughput_tokens_per_sec                                                 442.077841   \n",
       "total_energy_kwh_process_0                                                  0.005293   \n",
       "total_energy_kwh_process_1                                                  0.005214   \n",
       "total_energy_kwh_process_2                                                   0.00525   \n",
       "total_energy_kwh_process_3                                                  0.005328   \n",
       "gpu_power_avg                                                             297.637035   \n",
       "ram_power_avg                                                               0.955248   \n",
       "cpu_energy_total                                                            0.004565   \n",
       "gpu_energy_total                                                            0.016489   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  63  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    302   \n",
       "date_time                                              April 11, 2025 at 06:27:16 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021104   \n",
       "total_energy_joules                                                     75972.984254   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215656   \n",
       "joules_per_token                                                            4.637023   \n",
       "flops_per_joule                                                     223105241.417056   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.947661   \n",
       "average_latency_ms_per_batch                                             4618.457622   \n",
       "throughput_queries_per_sec                                                   3.46436   \n",
       "throughput_tokens_per_sec                                                 443.438084   \n",
       "total_energy_kwh_process_0                                                  0.005289   \n",
       "total_energy_kwh_process_1                                                  0.005256   \n",
       "total_energy_kwh_process_2                                                  0.005255   \n",
       "total_energy_kwh_process_3                                                  0.005304   \n",
       "gpu_power_avg                                                             319.099187   \n",
       "ram_power_avg                                                               0.959702   \n",
       "cpu_energy_total                                                             0.00456   \n",
       "gpu_energy_total                                                            0.016512   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  64  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    303   \n",
       "date_time                                              April 11, 2025 at 06:28:21 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021038   \n",
       "total_energy_joules                                                     75736.281912   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                             0.21633   \n",
       "joules_per_token                                                            4.622576   \n",
       "flops_per_joule                                                     223802523.245601   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.866788   \n",
       "average_latency_ms_per_batch                                             4608.348549   \n",
       "throughput_queries_per_sec                                                   3.47196   \n",
       "throughput_tokens_per_sec                                                 444.410829   \n",
       "total_energy_kwh_process_0                                                   0.00529   \n",
       "total_energy_kwh_process_1                                                  0.005249   \n",
       "total_energy_kwh_process_2                                                  0.005262   \n",
       "total_energy_kwh_process_3                                                  0.005237   \n",
       "gpu_power_avg                                                             422.491341   \n",
       "ram_power_avg                                                               0.958246   \n",
       "cpu_energy_total                                                            0.004529   \n",
       "gpu_energy_total                                                            0.016479   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  65  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    304   \n",
       "date_time                                              April 11, 2025 at 06:29:27 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021123   \n",
       "total_energy_joules                                                     76043.391166   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215456   \n",
       "joules_per_token                                                             4.64132   \n",
       "flops_per_joule                                                     222898673.155884   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.912187   \n",
       "average_latency_ms_per_batch                                             4614.023335   \n",
       "throughput_queries_per_sec                                                  3.467689   \n",
       "throughput_tokens_per_sec                                                 443.864249   \n",
       "total_energy_kwh_process_0                                                  0.005258   \n",
       "total_energy_kwh_process_1                                                  0.005295   \n",
       "total_energy_kwh_process_2                                                   0.00526   \n",
       "total_energy_kwh_process_3                                                   0.00531   \n",
       "gpu_power_avg                                                             385.364127   \n",
       "ram_power_avg                                                                0.95934   \n",
       "cpu_energy_total                                                            0.004583   \n",
       "gpu_energy_total                                                            0.016509   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  66  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    305   \n",
       "date_time                                              April 11, 2025 at 06:30:33 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021142   \n",
       "total_energy_joules                                                     76110.532775   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215266   \n",
       "joules_per_token                                                            4.645418   \n",
       "flops_per_joule                                                     222702041.034166   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.250632   \n",
       "average_latency_ms_per_batch                                             4656.328988   \n",
       "throughput_queries_per_sec                                                  3.436183   \n",
       "throughput_tokens_per_sec                                                 439.831465   \n",
       "total_energy_kwh_process_0                                                  0.005299   \n",
       "total_energy_kwh_process_1                                                  0.005266   \n",
       "total_energy_kwh_process_2                                                  0.005287   \n",
       "total_energy_kwh_process_3                                                   0.00529   \n",
       "gpu_power_avg                                                             529.887179   \n",
       "ram_power_avg                                                               0.964747   \n",
       "cpu_energy_total                                                            0.004589   \n",
       "gpu_energy_total                                                            0.016522   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  67  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    306   \n",
       "date_time                                              April 11, 2025 at 06:31:40 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021125   \n",
       "total_energy_joules                                                     76051.292784   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215434   \n",
       "joules_per_token                                                            4.641803   \n",
       "flops_per_joule                                                     222875514.308708   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.874463   \n",
       "average_latency_ms_per_batch                                             4609.307881   \n",
       "throughput_queries_per_sec                                                  3.471237   \n",
       "throughput_tokens_per_sec                                                 444.318334   \n",
       "total_energy_kwh_process_0                                                  0.005263   \n",
       "total_energy_kwh_process_1                                                  0.005225   \n",
       "total_energy_kwh_process_2                                                  0.005324   \n",
       "total_energy_kwh_process_3                                                  0.005313   \n",
       "gpu_power_avg                                                              384.95846   \n",
       "ram_power_avg                                                               0.956913   \n",
       "cpu_energy_total                                                            0.004571   \n",
       "gpu_energy_total                                                            0.016523   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  68  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    307   \n",
       "date_time                                              April 11, 2025 at 06:32:49 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021159   \n",
       "total_energy_joules                                                     76172.032345   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215092   \n",
       "joules_per_token                                                            4.649172   \n",
       "flops_per_joule                                                     222522236.459516   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.227124   \n",
       "average_latency_ms_per_batch                                              4653.39056   \n",
       "throughput_queries_per_sec                                                  3.438353   \n",
       "throughput_tokens_per_sec                                                 440.109201   \n",
       "total_energy_kwh_process_0                                                  0.005315   \n",
       "total_energy_kwh_process_1                                                  0.005277   \n",
       "total_energy_kwh_process_2                                                  0.005268   \n",
       "total_energy_kwh_process_3                                                  0.005299   \n",
       "gpu_power_avg                                                             323.807523   \n",
       "ram_power_avg                                                               0.954762   \n",
       "cpu_energy_total                                                            0.004575   \n",
       "gpu_energy_total                                                            0.016553   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  69  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    308   \n",
       "date_time                                              April 11, 2025 at 06:33:55 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021188   \n",
       "total_energy_joules                                                     76276.785887   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214797   \n",
       "joules_per_token                                                            4.655566   \n",
       "flops_per_joule                                                     222216638.996013   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    36.74442   \n",
       "average_latency_ms_per_batch                                             4593.052498   \n",
       "throughput_queries_per_sec                                                  3.483522   \n",
       "throughput_tokens_per_sec                                                 445.890832   \n",
       "total_energy_kwh_process_0                                                  0.005287   \n",
       "total_energy_kwh_process_1                                                  0.005339   \n",
       "total_energy_kwh_process_2                                                  0.005292   \n",
       "total_energy_kwh_process_3                                                   0.00527   \n",
       "gpu_power_avg                                                             416.411664   \n",
       "ram_power_avg                                                               0.957826   \n",
       "cpu_energy_total                                                            0.004557   \n",
       "gpu_energy_total                                                              0.0166   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  70  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    309   \n",
       "date_time                                              April 11, 2025 at 06:35:01 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021216   \n",
       "total_energy_joules                                                     76377.761846   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214513   \n",
       "joules_per_token                                                            4.661729   \n",
       "flops_per_joule                                                     221922855.337331   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.353906   \n",
       "average_latency_ms_per_batch                                             4669.238309   \n",
       "throughput_queries_per_sec                                                  3.426683   \n",
       "throughput_tokens_per_sec                                                 438.615437   \n",
       "total_energy_kwh_process_0                                                  0.005331   \n",
       "total_energy_kwh_process_1                                                  0.005257   \n",
       "total_energy_kwh_process_2                                                  0.005321   \n",
       "total_energy_kwh_process_3                                                  0.005307   \n",
       "gpu_power_avg                                                             375.259303   \n",
       "ram_power_avg                                                               0.956864   \n",
       "cpu_energy_total                                                            0.004589   \n",
       "gpu_energy_total                                                            0.016596   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  71  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    310   \n",
       "date_time                                              April 11, 2025 at 06:36:06 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021275   \n",
       "total_energy_joules                                                     76590.669268   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.213916   \n",
       "joules_per_token                                                            4.674723   \n",
       "flops_per_joule                                                     221305952.215789   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.856164   \n",
       "average_latency_ms_per_batch                                             4607.020464   \n",
       "throughput_queries_per_sec                                                   3.47296   \n",
       "throughput_tokens_per_sec                                                 444.538941   \n",
       "total_energy_kwh_process_0                                                  0.005291   \n",
       "total_energy_kwh_process_1                                                  0.005326   \n",
       "total_energy_kwh_process_2                                                  0.005323   \n",
       "total_energy_kwh_process_3                                                  0.005335   \n",
       "gpu_power_avg                                                             555.406601   \n",
       "ram_power_avg                                                               0.958314   \n",
       "cpu_energy_total                                                            0.004586   \n",
       "gpu_energy_total                                                            0.016658   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  72  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    311   \n",
       "date_time                                              April 11, 2025 at 06:37:12 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021175   \n",
       "total_energy_joules                                                     76229.985716   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214929   \n",
       "joules_per_token                                                            4.652709   \n",
       "flops_per_joule                                                     222353065.317298   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.478415   \n",
       "average_latency_ms_per_batch                                              4559.80192   \n",
       "throughput_queries_per_sec                                                  3.508924   \n",
       "throughput_tokens_per_sec                                                 449.142317   \n",
       "total_energy_kwh_process_0                                                  0.005258   \n",
       "total_energy_kwh_process_1                                                   0.00532   \n",
       "total_energy_kwh_process_2                                                  0.005312   \n",
       "total_energy_kwh_process_3                                                  0.005285   \n",
       "gpu_power_avg                                                             412.056644   \n",
       "ram_power_avg                                                               0.947865   \n",
       "cpu_energy_total                                                             0.00454   \n",
       "gpu_energy_total                                                            0.016605   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  73  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    312   \n",
       "date_time                                              April 11, 2025 at 06:38:18 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021218   \n",
       "total_energy_joules                                                     76384.326872   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214494   \n",
       "joules_per_token                                                            4.662129   \n",
       "flops_per_joule                                                     221903781.669947   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.804445   \n",
       "average_latency_ms_per_batch                                             4600.555674   \n",
       "throughput_queries_per_sec                                                  3.477841   \n",
       "throughput_tokens_per_sec                                                 445.163616   \n",
       "total_energy_kwh_process_0                                                  0.005293   \n",
       "total_energy_kwh_process_1                                                  0.005353   \n",
       "total_energy_kwh_process_2                                                  0.005268   \n",
       "total_energy_kwh_process_3                                                  0.005305   \n",
       "gpu_power_avg                                                             333.941971   \n",
       "ram_power_avg                                                                0.95182   \n",
       "cpu_energy_total                                                            0.004584   \n",
       "gpu_energy_total                                                            0.016603   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  74  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    313   \n",
       "date_time                                              April 11, 2025 at 06:39:24 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021133   \n",
       "total_energy_joules                                                     76078.501706   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215357   \n",
       "joules_per_token                                                            4.643463   \n",
       "flops_per_joule                                                      222795804.50584   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.749301   \n",
       "average_latency_ms_per_batch                                               4593.6626   \n",
       "throughput_queries_per_sec                                                  3.483059   \n",
       "throughput_tokens_per_sec                                                 445.831612   \n",
       "total_energy_kwh_process_0                                                  0.005274   \n",
       "total_energy_kwh_process_1                                                  0.005269   \n",
       "total_energy_kwh_process_2                                                  0.005319   \n",
       "total_energy_kwh_process_3                                                   0.00527   \n",
       "gpu_power_avg                                                             441.068223   \n",
       "ram_power_avg                                                               0.964067   \n",
       "cpu_energy_total                                                            0.004556   \n",
       "gpu_energy_total                                                            0.016546   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  75  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    314   \n",
       "date_time                                              April 11, 2025 at 06:40:30 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021153   \n",
       "total_energy_joules                                                     76152.181146   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215148   \n",
       "joules_per_token                                                             4.64796   \n",
       "flops_per_joule                                                     222580243.115083   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.267507   \n",
       "average_latency_ms_per_batch                                             4658.438392   \n",
       "throughput_queries_per_sec                                                  3.434627   \n",
       "throughput_tokens_per_sec                                                 439.632303   \n",
       "total_energy_kwh_process_0                                                  0.005323   \n",
       "total_energy_kwh_process_1                                                  0.005249   \n",
       "total_energy_kwh_process_2                                                  0.005332   \n",
       "total_energy_kwh_process_3                                                   0.00525   \n",
       "gpu_power_avg                                                             367.534498   \n",
       "ram_power_avg                                                               0.958583   \n",
       "cpu_energy_total                                                            0.004571   \n",
       "gpu_energy_total                                                            0.016551   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  76  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    315   \n",
       "date_time                                              April 11, 2025 at 06:41:37 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021139   \n",
       "total_energy_joules                                                     76101.321315   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215292   \n",
       "joules_per_token                                                            4.644856   \n",
       "flops_per_joule                                                     222728997.344947   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.349722   \n",
       "average_latency_ms_per_batch                                             4668.715262   \n",
       "throughput_queries_per_sec                                                  3.427067   \n",
       "throughput_tokens_per_sec                                                 438.664576   \n",
       "total_energy_kwh_process_0                                                  0.005328   \n",
       "total_energy_kwh_process_1                                                  0.005228   \n",
       "total_energy_kwh_process_2                                                  0.005297   \n",
       "total_energy_kwh_process_3                                                  0.005286   \n",
       "gpu_power_avg                                                             296.116516   \n",
       "ram_power_avg                                                               0.964557   \n",
       "cpu_energy_total                                                            0.004574   \n",
       "gpu_energy_total                                                            0.016534   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  77  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    316   \n",
       "date_time                                              April 11, 2025 at 06:42:44 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021052   \n",
       "total_energy_joules                                                      75787.25771   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.216184   \n",
       "joules_per_token                                                            4.625687   \n",
       "flops_per_joule                                                     223651989.862195   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.404344   \n",
       "average_latency_ms_per_batch                                             4550.543062   \n",
       "throughput_queries_per_sec                                                  3.516064   \n",
       "throughput_tokens_per_sec                                                 450.056174   \n",
       "total_energy_kwh_process_0                                                  0.005208   \n",
       "total_energy_kwh_process_1                                                  0.005281   \n",
       "total_energy_kwh_process_2                                                  0.005268   \n",
       "total_energy_kwh_process_3                                                  0.005296   \n",
       "gpu_power_avg                                                             426.171555   \n",
       "ram_power_avg                                                               0.960877   \n",
       "cpu_energy_total                                                            0.004555   \n",
       "gpu_energy_total                                                            0.016466   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  78  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    317   \n",
       "date_time                                              April 11, 2025 at 06:43:50 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021089   \n",
       "total_energy_joules                                                     75921.972142   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215801   \n",
       "joules_per_token                                                            4.633909   \n",
       "flops_per_joule                                                     223255146.236354   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.764964   \n",
       "average_latency_ms_per_batch                                             4595.620491   \n",
       "throughput_queries_per_sec                                                  3.481576   \n",
       "throughput_tokens_per_sec                                                 445.641672   \n",
       "total_energy_kwh_process_0                                                  0.005225   \n",
       "total_energy_kwh_process_1                                                  0.005298   \n",
       "total_energy_kwh_process_2                                                  0.005264   \n",
       "total_energy_kwh_process_3                                                  0.005302   \n",
       "gpu_power_avg                                                             464.683503   \n",
       "ram_power_avg                                                               0.962227   \n",
       "cpu_energy_total                                                            0.004593   \n",
       "gpu_energy_total                                                            0.016465   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  79  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    318   \n",
       "date_time                                              April 11, 2025 at 06:44:56 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021076   \n",
       "total_energy_joules                                                     75872.506432   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215941   \n",
       "joules_per_token                                                             4.63089   \n",
       "flops_per_joule                                                     223400699.280619   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.751617   \n",
       "average_latency_ms_per_batch                                             4593.952187   \n",
       "throughput_queries_per_sec                                                   3.48284   \n",
       "throughput_tokens_per_sec                                                 445.803508   \n",
       "total_energy_kwh_process_0                                                  0.005262   \n",
       "total_energy_kwh_process_1                                                  0.005298   \n",
       "total_energy_kwh_process_2                                                  0.005306   \n",
       "total_energy_kwh_process_3                                                   0.00521   \n",
       "gpu_power_avg                                                             373.273991   \n",
       "ram_power_avg                                                               0.963644   \n",
       "cpu_energy_total                                                            0.004558   \n",
       "gpu_energy_total                                                            0.016487   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  80  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    319   \n",
       "date_time                                              April 11, 2025 at 06:46:02 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021173   \n",
       "total_energy_joules                                                     76223.661305   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214946   \n",
       "joules_per_token                                                            4.652323   \n",
       "flops_per_joule                                                     222371514.343019   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.289531   \n",
       "average_latency_ms_per_batch                                             4536.191409   \n",
       "throughput_queries_per_sec                                                  3.527188   \n",
       "throughput_tokens_per_sec                                                 451.480067   \n",
       "total_energy_kwh_process_0                                                  0.005188   \n",
       "total_energy_kwh_process_1                                                  0.005328   \n",
       "total_energy_kwh_process_2                                                   0.00533   \n",
       "total_energy_kwh_process_3                                                  0.005327   \n",
       "gpu_power_avg                                                              102.99226   \n",
       "ram_power_avg                                                               0.962694   \n",
       "cpu_energy_total                                                            0.004651   \n",
       "gpu_energy_total                                                            0.016491   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  81  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    320   \n",
       "date_time                                              April 11, 2025 at 06:47:09 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021169   \n",
       "total_energy_joules                                                     76208.729832   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214988   \n",
       "joules_per_token                                                            4.651412   \n",
       "flops_per_joule                                                     222415083.292085   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.688996   \n",
       "average_latency_ms_per_batch                                             4586.124506   \n",
       "throughput_queries_per_sec                                                  3.488784   \n",
       "throughput_tokens_per_sec                                                 446.564413   \n",
       "total_energy_kwh_process_0                                                  0.005262   \n",
       "total_energy_kwh_process_1                                                  0.005314   \n",
       "total_energy_kwh_process_2                                                  0.005274   \n",
       "total_energy_kwh_process_3                                                   0.00532   \n",
       "gpu_power_avg                                                             415.753303   \n",
       "ram_power_avg                                                               0.962244   \n",
       "cpu_energy_total                                                            0.004565   \n",
       "gpu_energy_total                                                            0.016573   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  82  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    321   \n",
       "date_time                                              April 11, 2025 at 06:48:16 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021177   \n",
       "total_energy_joules                                                     76236.684702   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                             0.21491   \n",
       "joules_per_token                                                            4.653118   \n",
       "flops_per_joule                                                     222333526.955779   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.790459   \n",
       "average_latency_ms_per_batch                                             4598.807349   \n",
       "throughput_queries_per_sec                                                  3.479163   \n",
       "throughput_tokens_per_sec                                                 445.332854   \n",
       "total_energy_kwh_process_0                                                  0.005286   \n",
       "total_energy_kwh_process_1                                                  0.005303   \n",
       "total_energy_kwh_process_2                                                  0.005284   \n",
       "total_energy_kwh_process_3                                                  0.005304   \n",
       "gpu_power_avg                                                             441.421415   \n",
       "ram_power_avg                                                               0.958251   \n",
       "cpu_energy_total                                                            0.004546   \n",
       "gpu_energy_total                                                              0.0166   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  83  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    322   \n",
       "date_time                                              April 11, 2025 at 06:49:22 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021209   \n",
       "total_energy_joules                                                     76352.285347   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214584   \n",
       "joules_per_token                                                            4.660174   \n",
       "flops_per_joule                                                     221996904.429798   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.692678   \n",
       "average_latency_ms_per_batch                                             4586.584774   \n",
       "throughput_queries_per_sec                                                  3.488434   \n",
       "throughput_tokens_per_sec                                                   446.5196   \n",
       "total_energy_kwh_process_0                                                  0.005245   \n",
       "total_energy_kwh_process_1                                                  0.005309   \n",
       "total_energy_kwh_process_2                                                  0.005301   \n",
       "total_energy_kwh_process_3                                                  0.005354   \n",
       "gpu_power_avg                                                             281.424198   \n",
       "ram_power_avg                                                               0.954216   \n",
       "cpu_energy_total                                                            0.004586   \n",
       "gpu_energy_total                                                            0.016591   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                                  84  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    323   \n",
       "date_time                                              April 11, 2025 at 06:50:29 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021157   \n",
       "total_energy_joules                                                     76166.395123   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215108   \n",
       "joules_per_token                                                            4.648828   \n",
       "flops_per_joule                                                     222538705.760019   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.887141   \n",
       "average_latency_ms_per_batch                                             4610.892601   \n",
       "throughput_queries_per_sec                                                  3.470044   \n",
       "throughput_tokens_per_sec                                                 444.165626   \n",
       "total_energy_kwh_process_0                                                  0.005301   \n",
       "total_energy_kwh_process_1                                                  0.005258   \n",
       "total_energy_kwh_process_2                                                  0.005298   \n",
       "total_energy_kwh_process_3                                                    0.0053   \n",
       "gpu_power_avg                                                             422.539237   \n",
       "ram_power_avg                                                               0.962374   \n",
       "cpu_energy_total                                                            0.004548   \n",
       "gpu_energy_total                                                            0.016578   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "\n",
       "                                                                   85  \\\n",
       "config_name                                             latency_False   \n",
       "experiment_id                                                     328   \n",
       "date_time                               April 11, 2025 at 06:53:27 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.020897   \n",
       "total_energy_joules                                       75230.05363   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.217785   \n",
       "joules_per_token                                             4.591678   \n",
       "flops_per_joule                                      225308506.046856   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    36.504055   \n",
       "average_latency_ms_per_batch                              4563.006856   \n",
       "throughput_queries_per_sec                                    3.50646   \n",
       "throughput_tokens_per_sec                                  448.826851   \n",
       "total_energy_kwh_process_0                                   0.005171   \n",
       "total_energy_kwh_process_1                                   0.005258   \n",
       "total_energy_kwh_process_2                                   0.005255   \n",
       "total_energy_kwh_process_3                                   0.005214   \n",
       "gpu_power_avg                                              354.061436   \n",
       "ram_power_avg                                                0.962766   \n",
       "cpu_energy_total                                             0.004566   \n",
       "gpu_energy_total                                               0.0163   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "\n",
       "                                                                                  86  \\\n",
       "config_name                        latency_True_latency_0.05_latency_0.2_latency_...   \n",
       "experiment_id                                                                    329   \n",
       "date_time                                              April 11, 2025 at 06:54:34 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                    0.05   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021343   \n",
       "total_energy_joules                                                     76834.458713   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.213238   \n",
       "joules_per_token                                                            4.689603   \n",
       "flops_per_joule                                                     220603766.552551   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    37.91957   \n",
       "average_latency_ms_per_batch                                             4739.946273   \n",
       "throughput_queries_per_sec                                                  3.375566   \n",
       "throughput_tokens_per_sec                                                 432.072408   \n",
       "total_energy_kwh_process_0                                                  0.005325   \n",
       "total_energy_kwh_process_1                                                   0.00537   \n",
       "total_energy_kwh_process_2                                                  0.005339   \n",
       "total_energy_kwh_process_3                                                  0.005309   \n",
       "gpu_power_avg                                                             221.602844   \n",
       "ram_power_avg                                                               0.960215   \n",
       "cpu_energy_total                                                            0.004726   \n",
       "gpu_energy_total                                                            0.016585   \n",
       "latency_simulation_simulate                                                     True   \n",
       "latency_simulation_delay_max                                                     0.2   \n",
       "total_generated_tokens                                                         16384   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "\n",
       "                                                                                  87  \n",
       "config_name                        latency_True_latency_0.2_latency_0.6_latency_F...  \n",
       "experiment_id                                                                    330  \n",
       "date_time                                              April 11, 2025 at 06:55:45 PM  \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0  \n",
       "num_processes                                                                      4  \n",
       "batch_size___fixed_batching                                                       16  \n",
       "decoder_temperature                                                              1.0  \n",
       "decoder_top_k                                                                      0  \n",
       "decoder_top_p                                                                    0.0  \n",
       "latency_simulation_delay_min                                                     0.2  \n",
       "latency_simulation_simulate_burst                                              False  \n",
       "latency_simulation_burst_size                                                      0  \n",
       "latency_simulation_burst_interval                                                0.0  \n",
       "fp_precision                                                           torch.float16  \n",
       "quantization                                                                    True  \n",
       "load_in_8bit                                                                   False  \n",
       "load_in_4bit                                                                    True  \n",
       "total_input_tokens                                                             16384  \n",
       "total_params                                                               615606272  \n",
       "max_input_tokens                                                                 128  \n",
       "max_output_tokens                                                                128  \n",
       "number_input_prompts                                                             128  \n",
       "total_energy_kwh                                                            0.022104  \n",
       "total_energy_joules                                                     79575.575957  \n",
       "flops                                                                 16949970993152  \n",
       "tokens_per_joule                                                            0.205892  \n",
       "joules_per_token                                                            4.856908  \n",
       "flops_per_joule                                                     213004691.317366  \n",
       "joules_per_flop                                                                  0.0  \n",
       "total_inference_time_sec                                                   40.774318  \n",
       "average_latency_ms_per_batch                                             5096.789718  \n",
       "throughput_queries_per_sec                                                  3.139231  \n",
       "throughput_tokens_per_sec                                                 401.821561  \n",
       "total_energy_kwh_process_0                                                  0.005583  \n",
       "total_energy_kwh_process_1                                                  0.005435  \n",
       "total_energy_kwh_process_2                                                  0.005558  \n",
       "total_energy_kwh_process_3                                                  0.005528  \n",
       "gpu_power_avg                                                             373.637229  \n",
       "ram_power_avg                                                               0.956742  \n",
       "cpu_energy_total                                                            0.004984  \n",
       "gpu_energy_total                                                            0.017087  \n",
       "latency_simulation_simulate                                                     True  \n",
       "latency_simulation_delay_max                                                     0.6  \n",
       "total_generated_tokens                                                         16384  \n",
       "decoder_config_decoding_mode                                                     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found & inspecting dropped version: df_scenarios_dropped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>config_name</th>\n",
       "      <td>A1_Max_Throughput_Exploit</td>\n",
       "      <td>A2_Precision_Minimalist</td>\n",
       "      <td>A3_Quantisation_Gaming</td>\n",
       "      <td>default</td>\n",
       "      <td>A5_Parallel_Overdrive</td>\n",
       "      <td>R2_Low_Latency_Chatbot_Deployment</td>\n",
       "      <td>R3_Balanced_Enterprise_Service</td>\n",
       "      <td>R4_High_Load_Cloud_API_Deployment</td>\n",
       "      <td>R5_Real_Time_Mobile_Inference</td>\n",
       "      <td>R6_Medium_Scale_Language_Model_Serving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <td>220</td>\n",
       "      <td>221</td>\n",
       "      <td>222</td>\n",
       "      <td>223</td>\n",
       "      <td>224</td>\n",
       "      <td>228</td>\n",
       "      <td>229</td>\n",
       "      <td>230</td>\n",
       "      <td>231</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <td>April 11, 2025 at 04:28:24 PM</td>\n",
       "      <td>April 11, 2025 at 04:29:05 PM</td>\n",
       "      <td>April 11, 2025 at 04:29:46 PM</td>\n",
       "      <td>April 11, 2025 at 04:31:30 PM</td>\n",
       "      <td>April 11, 2025 at 04:32:11 PM</td>\n",
       "      <td>April 11, 2025 at 04:35:15 PM</td>\n",
       "      <td>April 11, 2025 at 04:36:43 PM</td>\n",
       "      <td>April 11, 2025 at 04:38:09 PM</td>\n",
       "      <td>April 11, 2025 at 04:55:10 PM</td>\n",
       "      <td>April 11, 2025 at 04:55:58 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_processes</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size___fixed_batching</th>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_temperature</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_k</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_p</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate_burst</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_size</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_interval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp_precision</th>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantization</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_8bit</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_4bit</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_input_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_params</th>\n",
       "      <td>1100048384</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_input_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_output_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_input_prompts</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh</th>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.022337</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.045144</td>\n",
       "      <td>0.008436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules</th>\n",
       "      <td>26276.086899</td>\n",
       "      <td>5043.594678</td>\n",
       "      <td>2748.678723</td>\n",
       "      <td>11613.150827</td>\n",
       "      <td>19803.636424</td>\n",
       "      <td>20669.796894</td>\n",
       "      <td>80411.455879</td>\n",
       "      <td>10468.775683</td>\n",
       "      <td>162518.073262</td>\n",
       "      <td>30368.288695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops</th>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens_per_joule</th>\n",
       "      <td>0.623533</td>\n",
       "      <td>3.248477</td>\n",
       "      <td>5.960682</td>\n",
       "      <td>1.410814</td>\n",
       "      <td>0.827323</td>\n",
       "      <td>0.792654</td>\n",
       "      <td>0.203752</td>\n",
       "      <td>1.565035</td>\n",
       "      <td>0.086883</td>\n",
       "      <td>0.53951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_token</th>\n",
       "      <td>1.603765</td>\n",
       "      <td>0.307837</td>\n",
       "      <td>0.167766</td>\n",
       "      <td>0.70881</td>\n",
       "      <td>1.208718</td>\n",
       "      <td>1.261584</td>\n",
       "      <td>4.907926</td>\n",
       "      <td>0.638963</td>\n",
       "      <td>11.509779</td>\n",
       "      <td>1.853533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops_per_joule</th>\n",
       "      <td>645072116.656167</td>\n",
       "      <td>3360692536.878901</td>\n",
       "      <td>6166588640.753133</td>\n",
       "      <td>1459549716.198339</td>\n",
       "      <td>855901948.028895</td>\n",
       "      <td>820035682.010454</td>\n",
       "      <td>210790500.032728</td>\n",
       "      <td>1619097734.639612</td>\n",
       "      <td>104295914.004625</td>\n",
       "      <td>558147058.058945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_flop</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_inference_time_sec</th>\n",
       "      <td>12.157593</td>\n",
       "      <td>5.11736</td>\n",
       "      <td>9.56734</td>\n",
       "      <td>71.473257</td>\n",
       "      <td>6.201934</td>\n",
       "      <td>88.568613</td>\n",
       "      <td>46.186702</td>\n",
       "      <td>56.839973</td>\n",
       "      <td>984.640872</td>\n",
       "      <td>12.265104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_latency_ms_per_batch</th>\n",
       "      <td>12157.593134</td>\n",
       "      <td>5117.360245</td>\n",
       "      <td>4783.670129</td>\n",
       "      <td>8934.157172</td>\n",
       "      <td>3100.966923</td>\n",
       "      <td>2767.769153</td>\n",
       "      <td>11546.675429</td>\n",
       "      <td>3552.498301</td>\n",
       "      <td>7692.506816</td>\n",
       "      <td>3066.276043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_queries_per_sec</th>\n",
       "      <td>10.5284</td>\n",
       "      <td>25.012896</td>\n",
       "      <td>13.378849</td>\n",
       "      <td>1.79088</td>\n",
       "      <td>20.638724</td>\n",
       "      <td>1.445207</td>\n",
       "      <td>2.77136</td>\n",
       "      <td>2.251936</td>\n",
       "      <td>0.129997</td>\n",
       "      <td>10.436112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_tokens_per_sec</th>\n",
       "      <td>1347.635163</td>\n",
       "      <td>3201.650698</td>\n",
       "      <td>1712.492663</td>\n",
       "      <td>229.232591</td>\n",
       "      <td>2641.756654</td>\n",
       "      <td>184.986526</td>\n",
       "      <td>354.734142</td>\n",
       "      <td>288.247851</td>\n",
       "      <td>14.340254</td>\n",
       "      <td>1335.822327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_0</th>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.00139</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.005224</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.045144</td>\n",
       "      <td>0.002133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_1</th>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_2</th>\n",
       "      <td>0.001778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_3</th>\n",
       "      <td>0.001837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_avg</th>\n",
       "      <td>1936.748224</td>\n",
       "      <td>2709.616605</td>\n",
       "      <td>59.55226</td>\n",
       "      <td>69.072265</td>\n",
       "      <td>873.557158</td>\n",
       "      <td>50.244713</td>\n",
       "      <td>255.785297</td>\n",
       "      <td>81.048935</td>\n",
       "      <td>65.177186</td>\n",
       "      <td>535.599288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_avg</th>\n",
       "      <td>0.977014</td>\n",
       "      <td>0.942083</td>\n",
       "      <td>0.909635</td>\n",
       "      <td>0.947124</td>\n",
       "      <td>0.921537</td>\n",
       "      <td>0.699726</td>\n",
       "      <td>0.981844</td>\n",
       "      <td>1.081179</td>\n",
       "      <td>0.942028</td>\n",
       "      <td>0.921829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_total</th>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.00188</td>\n",
       "      <td>0.00091</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.005052</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.029285</td>\n",
       "      <td>0.001521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_total</th>\n",
       "      <td>0.005963</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.004585</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.017239</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.015628</td>\n",
       "      <td>0.006904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_config_decoding_mode</th>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_k</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_k</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_p</td>\n",
       "      <td>greedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_generated_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>14120</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    0  \\\n",
       "config_name                                 A1_Max_Throughput_Exploit   \n",
       "experiment_id                                                     220   \n",
       "date_time                               April 11, 2025 at 04:28:24 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                       256   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                     True   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.007299   \n",
       "total_energy_joules                                      26276.086899   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.623533   \n",
       "joules_per_token                                             1.603765   \n",
       "flops_per_joule                                      645072116.656167   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    12.157593   \n",
       "average_latency_ms_per_batch                             12157.593134   \n",
       "throughput_queries_per_sec                                    10.5284   \n",
       "throughput_tokens_per_sec                                 1347.635163   \n",
       "total_energy_kwh_process_0                                   0.001851   \n",
       "total_energy_kwh_process_1                                   0.001833   \n",
       "total_energy_kwh_process_2                                   0.001778   \n",
       "total_energy_kwh_process_3                                   0.001837   \n",
       "gpu_power_avg                                             1936.748224   \n",
       "ram_power_avg                                                0.977014   \n",
       "cpu_energy_total                                             0.001324   \n",
       "gpu_energy_total                                             0.005963   \n",
       "latency_simulation_simulate                                     False   \n",
       "decoder_config_decoding_mode                                   greedy   \n",
       "total_generated_tokens                                          16384   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "\n",
       "                                                                    1  \\\n",
       "config_name                                   A2_Precision_Minimalist   \n",
       "experiment_id                                                     221   \n",
       "date_time                               April 11, 2025 at 04:29:05 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       2   \n",
       "batch_size___fixed_batching                                       128   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.001401   \n",
       "total_energy_joules                                       5043.594678   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             3.248477   \n",
       "joules_per_token                                             0.307837   \n",
       "flops_per_joule                                     3360692536.878901   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                      5.11736   \n",
       "average_latency_ms_per_batch                              5117.360245   \n",
       "throughput_queries_per_sec                                  25.012896   \n",
       "throughput_tokens_per_sec                                 3201.650698   \n",
       "total_energy_kwh_process_0                                   0.000733   \n",
       "total_energy_kwh_process_1                                   0.000668   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                             2709.616605   \n",
       "ram_power_avg                                                0.942083   \n",
       "cpu_energy_total                                             0.000254   \n",
       "gpu_energy_total                                             0.001145   \n",
       "latency_simulation_simulate                                     False   \n",
       "decoder_config_decoding_mode                                   greedy   \n",
       "total_generated_tokens                                          16384   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "\n",
       "                                                                    2  \\\n",
       "config_name                                    A3_Quantisation_Gaming   \n",
       "experiment_id                                                     222   \n",
       "date_time                               April 11, 2025 at 04:29:46 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       1   \n",
       "batch_size___fixed_batching                                        64   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                      50   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.000764   \n",
       "total_energy_joules                                       2748.678723   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             5.960682   \n",
       "joules_per_token                                             0.167766   \n",
       "flops_per_joule                                     6166588640.753133   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                      9.56734   \n",
       "average_latency_ms_per_batch                              4783.670129   \n",
       "throughput_queries_per_sec                                  13.378849   \n",
       "throughput_tokens_per_sec                                 1712.492663   \n",
       "total_energy_kwh_process_0                                   0.000764   \n",
       "total_energy_kwh_process_1                                        NaN   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                                59.55226   \n",
       "ram_power_avg                                                0.909635   \n",
       "cpu_energy_total                                             0.000374   \n",
       "gpu_energy_total                                             0.000387   \n",
       "latency_simulation_simulate                                     False   \n",
       "decoder_config_decoding_mode                                    top_k   \n",
       "total_generated_tokens                                          16384   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "\n",
       "                                                                    3  \\\n",
       "config_name                                                   default   \n",
       "experiment_id                                                     223   \n",
       "date_time                               April 11, 2025 at 04:31:30 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       1   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                     True   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.003226   \n",
       "total_energy_joules                                      11613.150827   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             1.410814   \n",
       "joules_per_token                                              0.70881   \n",
       "flops_per_joule                                     1459549716.198339   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    71.473257   \n",
       "average_latency_ms_per_batch                              8934.157172   \n",
       "throughput_queries_per_sec                                    1.79088   \n",
       "throughput_tokens_per_sec                                  229.232591   \n",
       "total_energy_kwh_process_0                                   0.003226   \n",
       "total_energy_kwh_process_1                                        NaN   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                               69.072265   \n",
       "ram_power_avg                                                0.947124   \n",
       "cpu_energy_total                                              0.00188   \n",
       "gpu_energy_total                                              0.00133   \n",
       "latency_simulation_simulate                                     False   \n",
       "decoder_config_decoding_mode                                   greedy   \n",
       "total_generated_tokens                                          16384   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "\n",
       "                                                                    4  \\\n",
       "config_name                                     A5_Parallel_Overdrive   \n",
       "experiment_id                                                     224   \n",
       "date_time                               April 11, 2025 at 04:32:11 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        64   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.005501   \n",
       "total_energy_joules                                      19803.636424   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.827323   \n",
       "joules_per_token                                             1.208718   \n",
       "flops_per_joule                                      855901948.028895   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     6.201934   \n",
       "average_latency_ms_per_batch                              3100.966923   \n",
       "throughput_queries_per_sec                                  20.638724   \n",
       "throughput_tokens_per_sec                                 2641.756654   \n",
       "total_energy_kwh_process_0                                    0.00139   \n",
       "total_energy_kwh_process_1                                   0.001335   \n",
       "total_energy_kwh_process_2                                   0.001389   \n",
       "total_energy_kwh_process_3                                   0.001388   \n",
       "gpu_power_avg                                              873.557158   \n",
       "ram_power_avg                                                0.921537   \n",
       "cpu_energy_total                                              0.00091   \n",
       "gpu_energy_total                                             0.004585   \n",
       "latency_simulation_simulate                                     False   \n",
       "decoder_config_decoding_mode                                   greedy   \n",
       "total_generated_tokens                                          16384   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "\n",
       "                                                                    5  \\\n",
       "config_name                         R2_Low_Latency_Chatbot_Deployment   \n",
       "experiment_id                                                     228   \n",
       "date_time                               April 11, 2025 at 04:35:15 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       1   \n",
       "batch_size___fixed_batching                                         4   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.9   \n",
       "latency_simulation_delay_min                                     0.01   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.005742   \n",
       "total_energy_joules                                      20669.796894   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.792654   \n",
       "joules_per_token                                             1.261584   \n",
       "flops_per_joule                                      820035682.010454   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    88.568613   \n",
       "average_latency_ms_per_batch                              2767.769153   \n",
       "throughput_queries_per_sec                                   1.445207   \n",
       "throughput_tokens_per_sec                                  184.986526   \n",
       "total_energy_kwh_process_0                                   0.005742   \n",
       "total_energy_kwh_process_1                                        NaN   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                               50.244713   \n",
       "ram_power_avg                                                0.699726   \n",
       "cpu_energy_total                                             0.002531   \n",
       "gpu_energy_total                                             0.003197   \n",
       "latency_simulation_simulate                                      True   \n",
       "decoder_config_decoding_mode                                    top_p   \n",
       "total_generated_tokens                                          16384   \n",
       "latency_simulation_delay_max                                     0.05   \n",
       "\n",
       "                                                                    6  \\\n",
       "config_name                            R3_Balanced_Enterprise_Service   \n",
       "experiment_id                                                     229   \n",
       "date_time                               April 11, 2025 at 04:36:43 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        32   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                      50   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.5   \n",
       "latency_simulation_simulate_burst                                True   \n",
       "latency_simulation_burst_size                                       5   \n",
       "latency_simulation_burst_interval                                 4.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                     True   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.022337   \n",
       "total_energy_joules                                      80411.455879   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.203752   \n",
       "joules_per_token                                             4.907926   \n",
       "flops_per_joule                                      210790500.032728   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    46.186702   \n",
       "average_latency_ms_per_batch                             11546.675429   \n",
       "throughput_queries_per_sec                                    2.77136   \n",
       "throughput_tokens_per_sec                                  354.734142   \n",
       "total_energy_kwh_process_0                                   0.005224   \n",
       "total_energy_kwh_process_1                                    0.00583   \n",
       "total_energy_kwh_process_2                                   0.005714   \n",
       "total_energy_kwh_process_3                                   0.005568   \n",
       "gpu_power_avg                                              255.785297   \n",
       "ram_power_avg                                                0.981844   \n",
       "cpu_energy_total                                             0.005052   \n",
       "gpu_energy_total                                             0.017239   \n",
       "latency_simulation_simulate                                      True   \n",
       "decoder_config_decoding_mode                                    top_k   \n",
       "total_generated_tokens                                          16384   \n",
       "latency_simulation_delay_max                                      1.5   \n",
       "\n",
       "                                                                    7  \\\n",
       "config_name                         R4_High_Load_Cloud_API_Deployment   \n",
       "experiment_id                                                     230   \n",
       "date_time                               April 11, 2025 at 04:38:09 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       1   \n",
       "batch_size___fixed_batching                                         8   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                     0.05   \n",
       "latency_simulation_simulate_burst                                True   \n",
       "latency_simulation_burst_size                                       5   \n",
       "latency_simulation_burst_interval                                 2.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.002908   \n",
       "total_energy_joules                                      10468.775683   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             1.565035   \n",
       "joules_per_token                                             0.638963   \n",
       "flops_per_joule                                     1619097734.639612   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    56.839973   \n",
       "average_latency_ms_per_batch                              3552.498301   \n",
       "throughput_queries_per_sec                                   2.251936   \n",
       "throughput_tokens_per_sec                                  288.247851   \n",
       "total_energy_kwh_process_0                                   0.002908   \n",
       "total_energy_kwh_process_1                                        NaN   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                               81.048935   \n",
       "ram_power_avg                                                1.081179   \n",
       "cpu_energy_total                                             0.001609   \n",
       "gpu_energy_total                                             0.001284   \n",
       "latency_simulation_simulate                                      True   \n",
       "decoder_config_decoding_mode                                   greedy   \n",
       "total_generated_tokens                                          16384   \n",
       "latency_simulation_delay_max                                      0.2   \n",
       "\n",
       "                                                                    8  \\\n",
       "config_name                             R5_Real_Time_Mobile_Inference   \n",
       "experiment_id                                                     231   \n",
       "date_time                               April 11, 2025 at 04:55:10 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       1   \n",
       "batch_size___fixed_batching                                         1   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.9   \n",
       "latency_simulation_delay_min                                      0.2   \n",
       "latency_simulation_simulate_burst                                True   \n",
       "latency_simulation_burst_size                                       8   \n",
       "latency_simulation_burst_interval                                 5.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                     True   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.045144   \n",
       "total_energy_joules                                     162518.073262   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.086883   \n",
       "joules_per_token                                            11.509779   \n",
       "flops_per_joule                                      104295914.004625   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                   984.640872   \n",
       "average_latency_ms_per_batch                              7692.506816   \n",
       "throughput_queries_per_sec                                   0.129997   \n",
       "throughput_tokens_per_sec                                   14.340254   \n",
       "total_energy_kwh_process_0                                   0.045144   \n",
       "total_energy_kwh_process_1                                        NaN   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                               65.177186   \n",
       "ram_power_avg                                                0.942028   \n",
       "cpu_energy_total                                             0.029285   \n",
       "gpu_energy_total                                             0.015628   \n",
       "latency_simulation_simulate                                      True   \n",
       "decoder_config_decoding_mode                                    top_p   \n",
       "total_generated_tokens                                          14120   \n",
       "latency_simulation_delay_max                                      0.6   \n",
       "\n",
       "                                                                        9  \n",
       "config_name                        R6_Medium_Scale_Language_Model_Serving  \n",
       "experiment_id                                                         232  \n",
       "date_time                                   April 11, 2025 at 04:55:58 PM  \n",
       "model                                  TinyLlama/TinyLlama-1.1B-Chat-v1.0  \n",
       "num_processes                                                           4  \n",
       "batch_size___fixed_batching                                            32  \n",
       "decoder_temperature                                                   1.0  \n",
       "decoder_top_k                                                           0  \n",
       "decoder_top_p                                                         0.0  \n",
       "latency_simulation_delay_min                                         0.01  \n",
       "latency_simulation_simulate_burst                                   False  \n",
       "latency_simulation_burst_size                                           0  \n",
       "latency_simulation_burst_interval                                     0.0  \n",
       "fp_precision                                                torch.float16  \n",
       "quantization                                                        False  \n",
       "load_in_8bit                                                        False  \n",
       "load_in_4bit                                                        False  \n",
       "total_input_tokens                                                  16384  \n",
       "total_params                                                   1100048384  \n",
       "max_input_tokens                                                      128  \n",
       "max_output_tokens                                                     128  \n",
       "number_input_prompts                                                  128  \n",
       "total_energy_kwh                                                 0.008436  \n",
       "total_energy_joules                                          30368.288695  \n",
       "flops                                                      16949970993152  \n",
       "tokens_per_joule                                                  0.53951  \n",
       "joules_per_token                                                 1.853533  \n",
       "flops_per_joule                                          558147058.058945  \n",
       "joules_per_flop                                                       0.0  \n",
       "total_inference_time_sec                                        12.265104  \n",
       "average_latency_ms_per_batch                                  3066.276043  \n",
       "throughput_queries_per_sec                                      10.436112  \n",
       "throughput_tokens_per_sec                                     1335.822327  \n",
       "total_energy_kwh_process_0                                       0.002133  \n",
       "total_energy_kwh_process_1                                       0.002109  \n",
       "total_energy_kwh_process_2                                       0.002101  \n",
       "total_energy_kwh_process_3                                       0.002093  \n",
       "gpu_power_avg                                                  535.599288  \n",
       "ram_power_avg                                                    0.921829  \n",
       "cpu_energy_total                                                 0.001521  \n",
       "gpu_energy_total                                                 0.006904  \n",
       "latency_simulation_simulate                                          True  \n",
       "decoder_config_decoding_mode                                       greedy  \n",
       "total_generated_tokens                                              16384  \n",
       "latency_simulation_delay_max                                          0.1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing grid: 'df_grid_cleaned'\n",
      "Error processing text_generation: 'df_text_generation_cleaned'\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [\n",
    "    \"sharding_strategy\",\n",
    "    \"sharding_config_fsdp_config_use_orig_params\",\n",
    "    \"sharding_config_fsdp_config_cpu_offload\",\n",
    "    \"adaptive_batching\",\n",
    "    \"adaptive_max_tokens\",\n",
    "    \"query_rate\",\n",
    "    \"is_encoder_decoder\",\n",
    "    \"task_type\",\n",
    "    \"available_gpu_count\",\n",
    "    \"gpu_model\",\n",
    "    \"available_cpu_count\",\n",
    "    \"cpu_model\",\n",
    "    \"os\",\n",
    "    \"python_version\",\n",
    "    \"country\",\n",
    "    \"region\",\n",
    "    \"distributed_type\",\n",
    "    \"decode_token_to_text\",\n",
    "    \"inference_type\",\n",
    "    \"backend\",\n",
    "    \"model_arch\",\n",
    "    \"gpu_current_memory_allocated_bytes\",\n",
    "    \"gpu_max_memory_allocated_bytes\",\n",
    "    \"gpu_current_memory_reserved_bytes\",\n",
    "    \"gpu_max_memory_reserved_bytes\",\n",
    "    \"per-process_emissions_0\", \"per-process_emissions_1\", \"per-process_emissions_2\",\"per-process_emissions_3\" # OR IS THIS NICE TO HAVE?\n",
    "]\n",
    "\n",
    "# second round of dropping (at some point come back to these)\n",
    "columns_to_drop_2 = [\n",
    "    \"cpu_usage_percent\",\n",
    "    \"cpu_memory_usage_bytes\",\n",
    "    \"gpu_utilization_percent_0\",\n",
    "    \"gpu_utilization_percent_1\",\n",
    "    \"gpu_utilization_percent_2\",\n",
    "    \"gpu_utilization_percent_3\",\n",
    "    \"gpu_current_memory_allocated_bytes\",\n",
    "    \"gpu_max_memory_allocated_bytes\",\n",
    "    \"cpu_current_memory_allocated_bytes\",\n",
    "    \"cpu_max_memory_allocated_bytes\",\n",
    "    \"cpu_power_process_0\",\n",
    "    \"cpu_power_process_1\",\n",
    "    \"cpu_power_process_2\",\n",
    "    \"cpu_power_process_3\",\n",
    "    \"gpu_power_process_0\",\n",
    "    \"gpu_power_process_1\",\n",
    "    \"gpu_power_process_2\",\n",
    "    \"gpu_power_process_3\",\n",
    "    \"ram_power_process_0\",\n",
    "    \"ram_power_process_1\",\n",
    "    \"ram_power_process_2\",\n",
    "    \"ram_power_process_3\",\n",
    "    \"cpu_energy_process_0\",\n",
    "    \"cpu_energy_process_1\",\n",
    "    \"cpu_energy_process_2\",\n",
    "    \"cpu_energy_process_3\",\n",
    "    \"gpu_energy_process_0\",\n",
    "    \"gpu_energy_process_1\",\n",
    "    \"gpu_energy_process_2\",\n",
    "    \"gpu_energy_process_3\",\n",
    "    \"ram_energy_process_0\",\n",
    "    \"ram_energy_process_1\",\n",
    "    \"ram_energy_process_2\",\n",
    "    \"ram_energy_process_3\",\n",
    "    \"total_energy_joules_process_0\",\n",
    "    \"total_energy_joules_process_1\",\n",
    "    \"total_energy_joules_process_2\",\n",
    "    \"total_energy_joules_process_3\",\n",
    "    \"cpu_power_avg\",\n",
    "    \"ram_energy_total\",\n",
    "    \"models\"\n",
    "]\n",
    "\n",
    "for file in possible_files:\n",
    "    try:\n",
    "        cleaned_var = f\"df_{file}_cleaned\"   # e.g., df_controlled_cleaned\n",
    "        dropped_var = f\"df_{file}_dropped\"     # e.g., df_controlled_dropped\n",
    "        \n",
    "        # Drop the specified columns from the cleaned DataFrame.\n",
    "        globals()[dropped_var] = globals()[cleaned_var].drop(columns=columns_to_drop, errors='ignore')\n",
    "        globals()[dropped_var] = globals()[dropped_var].drop(columns=columns_to_drop_2, errors='ignore')\n",
    "        print(f\"Found & inspecting dropped version: {dropped_var}\")\n",
    "        display(globals()[dropped_var].T)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "df_controlled_dropped has only one unique FLOP value, skipping.\n",
      "--------------------------------------------------\n",
      "\n",
      "df_scenarios_dropped has only one unique FLOP value, skipping.\n",
      "--------------------------------------------------\n",
      "df_grid_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_text_generation_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check all flops are constant\n",
    "\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    \n",
    "    if var_dropped in globals():\n",
    "        try:\n",
    "            df = globals()[var_dropped]\n",
    "            \n",
    "            # Check how many unique flops exist\n",
    "            unique_flops = df['flops'].unique()\n",
    "            \n",
    "            if len(unique_flops) > 1:\n",
    "                print(f\"\\n{var_dropped} has multiple FLOP counts:\")\n",
    "                print(f\"Unique FLOPs: {unique_flops}\")\n",
    "                \n",
    "                # Find rows for each different flop value\n",
    "                for flop_val in unique_flops:\n",
    "                    subset = df[df['flops'] == flop_val]\n",
    "                    config_names = subset['config_name'].unique()\n",
    "                    \n",
    "                    print(f\"\\nFLOP value: {flop_val}\")\n",
    "                    print(f\"Associated config_name(s): {config_names}\")\n",
    "                print(\"-\" * 50)\n",
    "            else:\n",
    "                print(f\"\\n{var_dropped} has only one unique FLOP value, skipping.\")\n",
    "                print(\"-\" * 50)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Problem inspecting {var_dropped}: {e}\")\n",
    "    else:\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_controlled_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_scenarios_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_grid_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_text_generation_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def identify_flop_differentiators(df, flops_col='flops', exclude_cols=None):\n",
    "    \"\"\"\n",
    "    Identify columns that are constant within each FLOP group but differ between groups.\n",
    "    \n",
    "    Parameters:\n",
    "      df (pd.DataFrame): The DataFrame containing the data.\n",
    "      flops_col (str): Name of the column used for grouping the FLOPs.\n",
    "      exclude_cols (list, optional): List of columns to exclude from the comparison.\n",
    "      \n",
    "    Returns:\n",
    "      dict: A dictionary where keys are the column names that differentiate FLOP groups,\n",
    "            and values are dictionaries mapping each unique FLOP value to the constant value\n",
    "            observed in that group.\n",
    "            \n",
    "    Example output:\n",
    "    {\n",
    "      'config_name': {1034544128000: 'A1_Max_Throughput_Exploit', \n",
    "                      16949970993152: 'A5_Parallel_Overdrive'},\n",
    "      'some_other_col': {1034544128000: 'value1', \n",
    "                         16949970993152: 'value2'}\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Optionally exclude some columns, including the flops column itself.\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = []\n",
    "    exclude_cols = set(exclude_cols + [flops_col])\n",
    "    \n",
    "    differentiators = {}\n",
    "    unique_flops = df[flops_col].unique()\n",
    "    \n",
    "    # Loop over each column in df excluding the ones in exclude_cols.\n",
    "    for col in df.columns:\n",
    "        if col in exclude_cols:\n",
    "            continue\n",
    "        \n",
    "        # For each group (by flops), get the unique values for this column.\n",
    "        group_values = {}\n",
    "        valid = True  # assume column is constant per group unless we find more than one unique value.\n",
    "        for flop in unique_flops:\n",
    "            values = df[df[flops_col] == flop][col].unique()\n",
    "            if len(values) == 1:\n",
    "                group_values[flop] = values[0]\n",
    "            else:\n",
    "                # If any FLOP group has more than one value, then this column doesn't differentiate consistently.\n",
    "                valid = False\n",
    "                break\n",
    "        # Check if the column is valid and if it truly differentiates between groups.\n",
    "        if valid and len(set(group_values.values())) > 1:\n",
    "            differentiators[col] = group_values\n",
    "    \n",
    "    return differentiators\n",
    "\n",
    "\n",
    "\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    if var_dropped in globals():\n",
    "        try:\n",
    "            df = globals()[var_dropped]\n",
    "            \n",
    "            # Check if there is more than one FLOP count.\n",
    "            unique_flops = df['flops'].unique()\n",
    "            if len(unique_flops) > 1:\n",
    "                print(f\"\\n{var_dropped} has multiple FLOP counts:\")\n",
    "                print(f\"Unique FLOPs: {unique_flops}\")\n",
    "                \n",
    "                # Identify columns that differ consistently between FLOP groups.\n",
    "                diff_cols = identify_flop_differentiators(df)\n",
    "                if diff_cols:\n",
    "                    print(\"Differentiating columns:\")\n",
    "                    for col, mapping in diff_cols.items():\n",
    "                        print(f\"Column: {col}\")\n",
    "                        for flop, val in mapping.items():\n",
    "                            print(f\"  FLOP {flop}: {val}\")\n",
    "                else:\n",
    "                    print(\"No consistently differentiating columns were found.\")\n",
    "                print(\"-\" * 50)\n",
    "            else:\n",
    "                print(f\"\\n{var_dropped} has only one unique FLOP value, skipping.\")\n",
    "                print(\"-\" * 50)\n",
    "        except Exception as e:\n",
    "            print(f\"Problem inspecting {var_dropped}: {e}\")\n",
    "    else:\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_controlled_dropped does not exist, skipping.\n",
      "df_scenarios_dropped does not exist, skipping.\n",
      "df_grid_dropped does not exist, skipping.\n",
      "df_text_generation_dropped does not exist, skipping.\n"
     ]
    }
   ],
   "source": [
    "# DEFINE NEW VARS\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    \n",
    "    if var_dropped not in globals():\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df = globals()[var_dropped]\n",
    "        \n",
    "        df['flops_per_token'] = df['flops'] / df['total_generated_tokens']\n",
    "        df['energy_per_token_kwh'] = df['total_energy_kwh'] / df['total_generated_tokens']\n",
    "        df['divergence_energy_flops_per_token'] = df['energy_per_token_kwh'] / df['flops_per_token']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {var_dropped}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_controlled_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_scenarios_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_grid_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_text_generation_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# CHECK COLUMN NAMES\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    \n",
    "    if var_dropped not in globals():\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        print(\"-\" * 50)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        df = globals()[var_dropped]\n",
    "        print(df.columns)\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {var_dropped}: {e}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_controlled_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_scenarios_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_grid_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_text_generation_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# CHECK CONFIG NAMES\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    \n",
    "    if var_dropped not in globals():\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        print(\"-\" * 50)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        df = globals()[var_dropped]\n",
    "        print(df['config_name'].unique())\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {var_dropped}: {e}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_controlled_dropped' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 101\u001b[0m\n\u001b[1;32m     98\u001b[0m families \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_processes\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatching\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecis\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatency\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fam \u001b[38;5;129;01min\u001b[39;00m families:\n\u001b[0;32m--> 101\u001b[0m     plot_family(\u001b[43mdf_controlled_dropped\u001b[49m, fam, metric1\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflops_per_token\u001b[39m\u001b[38;5;124m\"\u001b[39m, metric2\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menergy_per_token_kwh\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_controlled_dropped' is not defined"
     ]
    }
   ],
   "source": [
    "#cut this\n",
    "\n",
    "def extract_altered_value(config_name, family):\n",
    "    \"\"\"\n",
    "    Given a config name and a family, extract the altered value.\n",
    "    For each family, a different rule is applied:\n",
    "    \n",
    "    - num_processes: extract the integer after \"num_processes_\"\n",
    "    - batching: extract the integer after \"batching_\"\n",
    "    - precis: extract the precision setting; if quant4 is True, return \"load_in_4bit=True\",\n",
    "              otherwise return the float precision (e.g., \"float32\" or \"float16\")\n",
    "    - decoding: extract the decoder_temperature (as a float) from the config name.\n",
    "    - latency: if the config is exactly \"latency_False\", return \"No latency\"; otherwise, \n",
    "               extract and join all numeric values in the config string.\n",
    "    \"\"\"\n",
    "    if family == \"num_processes\":\n",
    "        m = re.search(r'num_processes_(\\d+)', config_name)\n",
    "        return int(m.group(1)) if m else config_name\n",
    "    \n",
    "    elif family == \"batching\":\n",
    "        m = re.search(r'batching_(\\d+)', config_name)\n",
    "        return int(m.group(1)) if m else config_name\n",
    "    \n",
    "    elif family == \"precis\":\n",
    "        m = re.search(r'precis_(float\\d+)', config_name)\n",
    "        precision = m.group(1) if m else None\n",
    "        # If quant4 is True, we assume load_in_4bit is the relevant setting. COME BACK TO THIS!!!\n",
    "        if \"quant4_True\" in config_name:\n",
    "            return \"load_in_4bit=True\"\n",
    "        else:\n",
    "            return precision\n",
    "        \n",
    "    elif family == \"decoding\":\n",
    "        # This family might have several variants. We extract the decoder_temperature. COME BACK TO\n",
    "        m = re.search(r'decoder_temperature_([\\d\\.]+)', config_name)\n",
    "        return float(m.group(1)) if m else config_name\n",
    "    \n",
    "    elif family == \"latency\":\n",
    "        # If it's simply \"latency_False\", nothing was altered.\n",
    "        if config_name == \"latency_False\":\n",
    "            return \"No latency\"\n",
    "        else:\n",
    "            # Find all numbers (either integer or float) in the string.\n",
    "            numbers = re.findall(r'\\d+\\.\\d+|\\d+', config_name)\n",
    "            return \", \".join(numbers)\n",
    "    else:\n",
    "        return config_name\n",
    "\n",
    "def plot_family(df, family, metric1, metric2):\n",
    "    \"\"\"\n",
    "    For a given family, subset the DataFrame (rows whose config_name starts with family).\n",
    "    Create a new column that holds the altered value for that family, sort the data by that value,\n",
    "    and plot two metrics against this altered value.\n",
    "    \n",
    "    Parameters:\n",
    "      - df: a DataFrame with a \"config_name\" column.\n",
    "      - family: the family string (e.g. \"num_processes\", \"batching\", etc).\n",
    "      - metric1: name of the first metric column to plot on the left Y axis (e.g., \"flops_per_token\").\n",
    "      - metric2: name of the second metric column to plot on the right Y axis (e.g., \"total_energy_kwh\").\n",
    "    \"\"\"\n",
    "    # Subset rows where config_name starts with the family string.\n",
    "    df_family = df[df['config_name'].str.startswith(family)].copy()\n",
    "    \n",
    "    # Apply the parser to create an \"altered_value\" column.\n",
    "    df_family['altered_value'] = df_family['config_name'].apply(lambda x: extract_altered_value(x, family))\n",
    "    \n",
    "    # Attempt to sort by altered_value.\n",
    "    # If the values are numeric, convert them.\n",
    "    try:\n",
    "        df_family['altered_value'] = pd.to_numeric(df_family['altered_value'])\n",
    "    except:\n",
    "        pass  # leave as string if conversion fails\n",
    "    \n",
    "    df_family.sort_values('altered_value', inplace=True)\n",
    "    \n",
    "    # Create a plot with twin y-axes.\n",
    "    fig, ax1 = plt.subplots(figsize=(8,5))\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # Plot metric1 on ax1 and metric2 on ax2.\n",
    "    ax1.plot(df_family['altered_value'], df_family[metric1], marker='o', label=metric1, color='blue')\n",
    "    ax2.plot(df_family['altered_value'], df_family[metric2], marker='s', label=metric2, color='red')\n",
    "    \n",
    "    ax1.set_xlabel(f'{family} configuration')\n",
    "    ax1.set_ylabel(metric1, color='blue')\n",
    "    ax2.set_ylabel(metric2, color='red')\n",
    "    plt.title(f'{family}: {metric1} and {metric2} vs altered setting')\n",
    "    \n",
    "    # Combine the legends.\n",
    "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='best')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "families = [\"num_processes\", \"batching\", \"precis\", \"decoding\", \"latency\"]\n",
    "\n",
    "for fam in families:\n",
    "    plot_family(df_controlled_dropped, fam, metric1=\"flops_per_token\", metric2=\"energy_per_token_kwh\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# RESTART FROM HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR CONTROLLED EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'controlled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;241m==\u001b[39m possible_files[\u001b[43mcontrolled\u001b[49m]:\n\u001b[1;32m      3\u001b[0m     df \u001b[38;5;241m=\u001b[39m df_controlled_dropped\n\u001b[1;32m      5\u001b[0m     configs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_processes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatency\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatching\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecis\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'controlled' is not defined"
     ]
    }
   ],
   "source": [
    "if file == possible_files[controlled]:\n",
    "    \n",
    "    df = df_controlled_dropped\n",
    "    \n",
    "    configs = ['num_processes', 'decoder', 'latency', 'batching', 'precis']\n",
    "    dfs = {config: df[df['config_name'].str.startswith(config)] for config in configs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == possible_files[controlled]:\n",
    "    \n",
    "for name, df in dfs:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # ----- First subplot: Divergence Energy vs Batch Size -----\n",
    "    axes[0].plot(\n",
    "        df['num_processes'],\n",
    "        df['divergence_energy_flops_per_token'],\n",
    "        marker='o', \n",
    "        linestyle='-',\n",
    "        color='orange'\n",
    "    )\n",
    "    axes[0].set_xlabel('Batch Size (Fixed Batching)')\n",
    "    axes[0].set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "    axes[0].set_title(f'Divergence Energy vs Batch Size ({name})')\n",
    "    axes[0].set_xticks(df['num_processes'])\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # ----- Second subplot: Two Y-axes with Energy per Token and FLOPs per Token -----\n",
    "    ax1 = axes[1]\n",
    "    line1, = ax1.plot(\n",
    "        df['num_processes'], \n",
    "        df['energy_per_token_kwh'], \n",
    "        marker='o', \n",
    "        linestyle='-', \n",
    "        color='blue', \n",
    "        label='Energy per Token (kWh)'\n",
    "    )\n",
    "    ax1.set_xlabel('Batch Size (Fixed Batching)')\n",
    "    ax1.set_ylabel('Energy per Token (kWh)', color='blue')\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax1.set_xticks(df['num_processes'])\n",
    "    ax1.set_title(f'Metrics vs Batch Size ({name})')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    line2, = ax2.plot(\n",
    "        df['num_processes'], \n",
    "        df['flops_per_token'], \n",
    "        marker='s', \n",
    "        linestyle='--', \n",
    "        color='red', \n",
    "        label='FLOPs per Token'\n",
    "    )\n",
    "    ax2.set_ylabel('FLOPs per Token', color='red')\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    # Combine legends\n",
    "    lines = [line1, line2]\n",
    "    labels = [line.get_label() for line in lines]\n",
    "    ax1.legend(lines, labels, loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Step 1: Create a new 'precision' column for plotting\n",
    "    def determine_precision(row):\n",
    "        if row.get('load_in_4bit', False):\n",
    "            return 'INT4'\n",
    "        elif row.get('load_in_8bit', False):\n",
    "            return 'INT8'\n",
    "        elif row.get('fp_precision') == 'torch.float16':\n",
    "            return 'FP16'\n",
    "        else:\n",
    "            return 'FP32'\n",
    "\n",
    "    precics_df['precision'] = precics_df.apply(determine_precision, axis=1)\n",
    "\n",
    "    # Step 2: Define custom precision order\n",
    "    precision_order = ['FP32', 'FP16', 'INT8', 'INT4']\n",
    "\n",
    "    # Step 3: Sort the dataframe according to precision order\n",
    "    precics_df['precision'] = pd.Categorical(precics_df['precision'], categories=precision_order, ordered=True)\n",
    "    precics_df = precics_df.sort_values('precision')\n",
    "\n",
    "    # Step 4: Plotting\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # ----- First subplot: Divergence Energy vs Precision -----\n",
    "    axes[0].plot(\n",
    "        precics_df['precision'],\n",
    "        precics_df['divergence_energy_flops_per_token'],\n",
    "        marker='o', \n",
    "        linestyle='-',\n",
    "        color='orange'\n",
    "    )\n",
    "    axes[0].set_xlabel('Precision')\n",
    "    axes[0].set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "    axes[0].set_title('Divergence Energy vs Precision')\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # ----- Second subplot: Two Y-axes with Energy per Token and FLOPs per Token -----\n",
    "    ax1 = axes[1]\n",
    "    line1, = ax1.plot(\n",
    "        precics_df['precision'], \n",
    "        precics_df['energy_per_token_kwh'], \n",
    "        marker='o', \n",
    "        linestyle='-', \n",
    "        color='blue', \n",
    "        label='Energy per Token (kWh)'\n",
    "    )\n",
    "    ax1.set_xlabel('Precision')\n",
    "    ax1.set_ylabel('Energy per Token (kWh)', color='blue')\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax1.set_title('Metrics vs Precision')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    line2, = ax2.plot(\n",
    "        precics_df['precision'], \n",
    "        precics_df['flops_per_token'], \n",
    "        marker='s', \n",
    "        linestyle='--', \n",
    "        color='red', \n",
    "        label='FLOPs per Token'\n",
    "    )\n",
    "    ax2.set_ylabel('FLOPs per Token', color='red')\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    # Combine legends\n",
    "    lines = [line1, line2]\n",
    "    labels = [line.get_label() for line in lines]\n",
    "    ax1.legend(lines, labels, loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == possible_files[controlled]:\n",
    "\n",
    "    # --- Step 1: Filter the dataframe based on the config names ---\n",
    "    config_names = [\n",
    "        'decoding_greedy_decoder_temperature_0',\n",
    "        'decoding_greedy_decoder_temperature_0.7',\n",
    "        'decoding_greedy_decoder_temperature_1.0',\n",
    "        'decoding_greedy_decoder_temperature_1.3',\n",
    "        'decoding_top_k_decoder_top_k_50_decoder_temperature_0',\n",
    "        'decoding_top_k_decoder_top_k_50_decoder_temperature_0.7',\n",
    "        'decoding_top_k_decoder_top_k_50_decoder_temperature_1.0',\n",
    "        'decoding_top_k_decoder_top_k_50_decoder_temperature_1.3',\n",
    "        'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0',\n",
    "        'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.7',\n",
    "        'decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.0',\n",
    "        'decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.3'\n",
    "    ]\n",
    "    filtered_decoding = decoding_df[decoding_df['config_name'].isin(config_names)].copy()\n",
    "\n",
    "    # --- Step 2: Extract method and temperature from the config_name ---\n",
    "    def extract_method_and_temp(config):\n",
    "        if config.startswith(\"decoding_greedy_decoder_temperature_\"):\n",
    "            temp = float(config.split(\"decoding_greedy_decoder_temperature_\")[-1])\n",
    "            return \"greedy\", temp\n",
    "        elif config.startswith(\"decoding_top_k_decoder_top_k_50_decoder_temperature_\"):\n",
    "            temp = float(config.split(\"decoding_top_k_decoder_top_k_50_decoder_temperature_\")[-1])\n",
    "            return \"top_k\", temp\n",
    "        elif config.startswith(\"decoding_top_p_decoder_top_p_0.9_decoder_temperature_\"):\n",
    "            temp = float(config.split(\"decoding_top_p_decoder_top_p_0.9_decoder_temperature_\")[-1])\n",
    "            return \"top_p\", temp\n",
    "        else:\n",
    "            return \"unknown\", None\n",
    "\n",
    "    # Apply the extraction function and assign to new columns\n",
    "    filtered_decoding[['method', 'temperature']] = filtered_decoding['config_name'].apply(\n",
    "        lambda x: pd.Series(extract_method_and_temp(x))\n",
    "    )\n",
    "\n",
    "    # Optionally sort the dataframe by method and temperature for clarity.\n",
    "    filtered_decoding = filtered_decoding.sort_values(['method', 'temperature'])\n",
    "\n",
    "    # --- Step 3: Plotting ---\n",
    "\n",
    "    # Define colors for each method\n",
    "    colors = {\n",
    "        'greedy': 'blue',\n",
    "        'top_k': 'green',\n",
    "        'top_p': 'red'\n",
    "    }\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # --- Left subplot: Divergence Energy vs Temperature ---\n",
    "    ax_left = axes[0]\n",
    "    methods = filtered_decoding['method'].unique()\n",
    "    for m in methods:\n",
    "        subdf = filtered_decoding[filtered_decoding['method'] == m]\n",
    "        ax_left.plot(subdf['temperature'], subdf['divergence_energy_flops_per_token'],\n",
    "                    marker='o', linestyle='-', label=m, color=colors.get(m))\n",
    "    ax_left.set_xlabel('Decoder Temperature')\n",
    "    ax_left.set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "    ax_left.set_title('Divergence Energy vs Decoder Temperature')\n",
    "    ax_left.grid(True)\n",
    "    ax_left.legend(title=\"Method\")\n",
    "\n",
    "    # --- Right subplot: Two Y-axes with Energy per Token and FLOPs per Token ---\n",
    "    ax1 = axes[1]\n",
    "    # Primary axis for Energy per Token\n",
    "    for m in methods:\n",
    "        subdf = filtered_decoding[filtered_decoding['method'] == m]\n",
    "        ax1.plot(subdf['temperature'], subdf['energy_per_token_kwh'],\n",
    "                marker='o', linestyle='-', label=f'{m} Energy', color=colors.get(m))\n",
    "    ax1.set_xlabel('Decoder Temperature')\n",
    "    ax1.set_ylabel('Energy per Token (kWh)', color='black')\n",
    "    ax1.set_title('Metrics vs Decoder Temperature')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Secondary axis for FLOPs per Token\n",
    "    ax2 = ax1.twinx()\n",
    "    for m in methods:\n",
    "        subdf = filtered_decoding[filtered_decoding['method'] == m]\n",
    "        ax2.plot(subdf['temperature'], subdf['flops_per_token'],\n",
    "                marker='s', linestyle='--', label=f'{m} FLOPs', color=colors.get(m))\n",
    "    ax2.set_ylabel('FLOPs per Token', color='black')\n",
    "\n",
    "    # --- Combine legends from both axes ---\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == possible_files[controlled]:\n",
    "\n",
    "    # --- 1. Filter the latency_df to only keep the specified configurations ---\n",
    "    latency_configs = [\n",
    "        'latency_False',\n",
    "        'latency_True_latency_0.05_latency_0.2_latency_False',\n",
    "        'latency_True_latency_0.2_latency_0.6_latency_False',\n",
    "        'latency_True_latency_0.05_latency_0.2_latency_True_latency_4.0_latency_5',\n",
    "        'latency_True_latency_0.2_latency_0.6_latency_True_latency_5.0_latency_8'\n",
    "    ]\n",
    "    latency_filtered = latency_df[latency_df['config_name'].isin(latency_configs)].copy()\n",
    "\n",
    "    # --- 2. Define a function to parse the config string ---\n",
    "    def parse_latency_config(config):\n",
    "        \"\"\"\n",
    "        Parses a latency configuration string and returns a dict with:\n",
    "        - simulate (boolean)\n",
    "        - delay_min (float or None)\n",
    "        - delay_max (float or None)\n",
    "        - simulate_burst (boolean or None)\n",
    "        - burst_size (float or None)\n",
    "        - burst_interval (float or None)\n",
    "        \"\"\"\n",
    "        tokens = config.split('_')\n",
    "        \n",
    "        # There will be extra \"latency\" tokens in the string.\n",
    "        # Look at the total number of tokens:\n",
    "        # For baseline: e.g., \"latency_False\" -> tokens: [\"latency\", \"False\"]\n",
    "        # Without burst: 8 tokens, e.g.:\n",
    "        #   [\"latency\", \"True\", \"latency\", \"0.05\", \"latency\", \"0.2\", \"latency\", \"False\"]\n",
    "        # With burst: 12 tokens, e.g.:\n",
    "        #   [\"latency\", \"True\", \"latency\", \"0.05\", \"latency\", \"0.2\", \"latency\", \"True\", \"latency\", \"4.0\", \"latency\", \"5\"]\n",
    "        res = {}\n",
    "        if len(tokens) == 2:\n",
    "            # Baseline: no simulation\n",
    "            res['simulate'] = (tokens[1] == \"True\")\n",
    "            res['delay_min'] = None\n",
    "            res['delay_max'] = None\n",
    "            res['simulate_burst'] = None\n",
    "            res['burst_size'] = None\n",
    "            res['burst_interval'] = None\n",
    "        elif len(tokens) == 8:\n",
    "            # Without burst: tokens at positions 1, 3, 5, and 7 are our values.\n",
    "            res['simulate'] = (tokens[1] == \"True\")\n",
    "            res['delay_min'] = float(tokens[3])\n",
    "            res['delay_max'] = float(tokens[5])\n",
    "            res['simulate_burst'] = (tokens[7] == \"True\")\n",
    "            res['burst_size'] = None\n",
    "            res['burst_interval'] = None\n",
    "        elif len(tokens) == 12:\n",
    "            # With burst: tokens at positions 1, 3, 5, 7, 9, and 11.\n",
    "            res['simulate'] = (tokens[1] == \"True\")\n",
    "            res['delay_min'] = float(tokens[3])\n",
    "            res['delay_max'] = float(tokens[5])\n",
    "            res['simulate_burst'] = (tokens[7] == \"True\")\n",
    "            res['burst_size'] = float(tokens[9])\n",
    "            res['burst_interval'] = float(tokens[11])\n",
    "        else:\n",
    "            res['simulate'] = None\n",
    "            res['delay_min'] = None\n",
    "            res['delay_max'] = None\n",
    "            res['simulate_burst'] = None\n",
    "            res['burst_size'] = None\n",
    "            res['burst_interval'] = None\n",
    "        return res\n",
    "\n",
    "    # Apply the parser so that we have new columns for the latency parameters\n",
    "    latency_params = latency_filtered['config_name'].apply(lambda x: pd.Series(parse_latency_config(x)))\n",
    "    latency_filtered = pd.concat([latency_filtered, latency_params], axis=1)\n",
    "\n",
    "    # --- 3. Create a user-friendly label for each configuration ---\n",
    "    def make_latency_label(row):\n",
    "        if row['simulate'] is False:\n",
    "            return \"No simulation\"\n",
    "        elif row['simulate'] is True and row['simulate_burst'] is False:\n",
    "            return f\"Sim ({row['delay_min']}-{row['delay_max']})\"\n",
    "        elif row['simulate'] is True and row['simulate_burst'] is True:\n",
    "            return f\"Sim ({row['delay_min']}-{row['delay_max']}) Burst ({row['burst_size']},{row['burst_interval']})\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "\n",
    "    latency_filtered['latency_label'] = latency_filtered.apply(make_latency_label, axis=1)\n",
    "\n",
    "    # --- 4. Order the configurations as desired ---\n",
    "    order_labels = [\n",
    "        \"No simulation\",\n",
    "        \"Sim (0.05-0.2)\",\n",
    "        \"Sim (0.2-0.6)\",\n",
    "        \"Sim (0.05-0.2) Burst (4.0,5)\",\n",
    "        \"Sim (0.2-0.6) Burst (5.0,8)\"\n",
    "    ]\n",
    "    latency_filtered['latency_label'] = pd.Categorical(latency_filtered['latency_label'], \n",
    "                                                        categories=order_labels, ordered=True)\n",
    "    latency_filtered = latency_filtered.sort_values('latency_label')\n",
    "\n",
    "    # --- 5. Create the two subplots ---\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Left Subplot: Divergence Energy vs Latency Configuration (categorical x-axis)\n",
    "    axes[0].plot(\n",
    "        latency_filtered['latency_label'],\n",
    "        latency_filtered['divergence_energy_flops_per_token'],\n",
    "        marker='o',\n",
    "        linestyle='-',\n",
    "        color='orange'\n",
    "    )\n",
    "    axes[0].set_xlabel('Latency Configuration')\n",
    "    axes[0].set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "    axes[0].set_title('Divergence Energy vs Latency Config')\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Right Subplot: Two y-axes for Energy per Token and FLOPs per Token\n",
    "    ax1 = axes[1]\n",
    "    line1, = ax1.plot(\n",
    "        latency_filtered['latency_label'],\n",
    "        latency_filtered['energy_per_token_kwh'],\n",
    "        marker='o',\n",
    "        linestyle='-',\n",
    "        color='blue',\n",
    "        label='Energy per Token (kWh)'\n",
    "    )\n",
    "    ax1.set_xlabel('Latency Configuration')\n",
    "    ax1.set_ylabel('Energy per Token (kWh)', color='blue')\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax1.set_title('Metrics vs Latency Config')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Create secondary y-axis for FLOPs per Token\n",
    "    ax2 = ax1.twinx()\n",
    "    line2, = ax2.plot(\n",
    "        latency_filtered['latency_label'],\n",
    "        latency_filtered['flops_per_token'],\n",
    "        marker='s',\n",
    "        linestyle='--',\n",
    "        color='red',\n",
    "        label='FLOPs per Token'\n",
    "    )\n",
    "    ax2.set_ylabel('FLOPs per Token', color='red')\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    # Combine legends from both axes\n",
    "    lines = [line1, line2]\n",
    "    labels = [line.get_label() for line in lines]\n",
    "    ax1.legend(lines, labels, loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == possible_files[controlled]:\n",
    "    print(f\"var energy: {df_controlled_dropped.total_energy_kwh.max()} / {df_controlled_dropped.total_energy_kwh.min()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORK OUT STANDARD DEVIATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Histogram of raw total_energy_kwh\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_scenarios_dropped['total_energy_kwh'], bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Total Energy (kWh)')\n",
    "plt.xlabel('Total Energy (kWh)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot to spot outliers\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.boxplot(df_scenarios_dropped['total_energy_kwh'], vert=False)\n",
    "plt.title('Boxplot of Total Energy (kWh)')\n",
    "plt.xlabel('Total Energy (kWh)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# If distribution is very skewed: log-transform\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(np.log(df_scenarios_dropped['total_energy_kwh']), bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Log-Transformed Total Energy (kWh)')\n",
    "plt.xlabel('Log(Total Energy (kWh))')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for Scenario Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == possible_files[\"scenario\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scenarios_dropped.total_energy_kwh.max() / df_scenarios_dropped.total_energy_kwh.min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] gets stuck at the main process not aving local energy metrics\n",
    "- [ ] use decorator or helper function to use all_reduce + barrier + logging + timeout handler correctly\n",
    "\n",
    "- [ ] move the run_experiment() into its own dedicated script so it can use accelerate.launch and make use of Terminate_on_errors=True\n",
    "    - [ ] add in try and except clauses and make it robsut to failovers\n",
    "\n",
    "- [ ] work on grid search experiment setup: \n",
    "    - [ ] implement the accelerate launcher (as script) that terminate_on_error=True -> experiment continues and restarts even if it hits an error\n",
    "    - [ ] a grid search through the different variables\n",
    "    - [ ] implement various try an except clauses so that it is robust to keep running and restarting the kernel if necessary\n",
    "    - [ ] get it to wait if it gets stuck then retry again...\n",
    "    - [ ] set up warm up period with dummy content to warm up the cores -> discard initial\n",
    "    - [ ] set up repetition and interleaving of experiment types (see literature)\n",
    "\n",
    "\n",
    "- [ ] check all config types work\n",
    "    - [ ] everything breaks FLOPs (if decoder temp >1  / if input length is longer... many things)\n",
    "    - [ ] doesn't work on more than 2 GPUs\n",
    "    - [ ] adaptive batching doesn't work\n",
    "    - [ ] sort out sharding configs\n",
    "\n",
    "  \n",
    "- [ ] set up chain of reasoning workflow\n",
    "- [ ] do data work: what kind of data makes a difference\n",
    "  - [ ] task complexity\n",
    "\n",
    "- [ ] in the inference function i am generating raw_text_outputs which get assigned to a variable then discarded... this could be a lot of memory: add an ExperimentalConfig\n",
    "\n",
    "- [ ] the text outputs seem determinisitc...\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "- [ ] decoder temp: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
    "    - change this: so that there's the option in the experimental_configs to chose gredy decoding, beam search, random sampling, top-k sampling, top-p sampling\n",
    "        - params: do_sample; temperature, top_p, top_k\n",
    "        - Greedy deocing?\n",
    "        - Beam Search\n",
    "        - random sampling (basic): outputs = model.generate(input_ids, do_sample=True)\n",
    "        - Top-k Sampling (Controlled Randomness): outputs = model.generate(input_ids, do_sample=True, top_k=50)\n",
    "        -  Top-p (Nucleus) Sampling (Dynamic Control): outputs = model.generate(input_ids, do_sample=True, top_p=0.9)\n",
    "\n",
    "- [ ] set up AMD CPU logic (currently only INTEL)\n",
    "- [ ] take the GPU & CPU utilisation metrics within the infernece workflow (currently they are done after all inferences are complete) -> one measurement per batch -> avg over them all for the process\n",
    "\n",
    "# Low priority\n",
    "- [ ] `is_encoder_decoder` shows \"false\" it should be one or the other\n",
    "- [ ] I don't think decoder temp does anything (I don't think it really matters)\n",
    "- [ ] add Carbon Tracker\n",
    "- [ ] add power over time to the metrics\n",
    "- [ ] Measure L2 cash + stalls while system is waiting \n",
    "- [ ] add logic for task-specific metrics in the reporting\n",
    "- [ ] make experimental configs enterable as a YAML file rather than directly\n",
    "- [ ] Add in warm up period before code carbon measurement+ inference run... Also at experiment level: interleave \n",
    "\n",
    "# Done\n",
    "- [x] change codeCarbon log_level to warning \n",
    "- [x] Code Carbon turn off multiple runs in allow_multiple_runs\n",
    "- [x] calculate computation metrics\n",
    "- [x] put the text_gen_inference() into the helper functionn (as it is pretty generic)\n",
    "- [x] us Optimum library \n",
    "- [x] sort out distributed inference using accelerate / vLLM. At the moment it's not working on either\n",
    "- [x] aggregate process metrics \n",
    "    - once it goes to multi-GPU it gets weird - i think this is why half the runs don't work, the other half do\n",
    "    - including assinging the unique ID\n",
    "    - decide which metrics to sum, which to avg\n",
    "- [x] check why the CodeCarbon CSV metrics and the JSON metrics don't align - Answer: because they are per process -> allows me to validate (also check that CodeCarbon don't offer their own aggregation)\n",
    "    - CC can do by machine or by process\n",
    "        - parameter: tracking_mode -> machine measure the power consumptions of the entire machine (defaults) / process try and isolate the tracked processes in isolation\n",
    "- [x] refactor: (i) helper functions; (ii) Object oriented\n",
    "- [x] Change experimental_vars list:\n",
    "    - [x] move the GPU list up to the experiment_setup JSON object (below counts of GPUs)... also get it to validate against which GPUs it actually ran on\n",
    "    - [x] experiment_setup: move the GPU count and type above the CPU count and type\n",
    "- [x] + also add if model in encoder-decoder Vs decoder only model, to see if these behave differently under different optimisations  (save that under experiment set up)\n",
    "- [x] move some of the experiment utils to metrics,py \n",
    "    - [x] rename metrics_results.py\n",
    "    - [x] rename function `aggregate_experiments` to `aggregate_experiment_results`\n",
    "- [x] work out what the GPU and CPU power metrics coming out of CodeCarbon are referring to (avg power draw?)\n",
    "- [x] GPU & CPU power = 'avg across processors' <- add this in (ram power constant)\n",
    "- [x] GPU & CPU energy = sum across processort\n",
    "- [x] NB the RAM energy seems to be wrong (I am summing, but RAM is shared ????)\n",
    "- [x] GPU list: doesn't run on different GPUs (somewhere it's hard coded to 01)\n",
    "- [x] review compute metrics:\n",
    "    - [x] remove cpu vendor \n",
    "    - [x] remove cuda \n",
    "- [x] sort out the print statements in experiments to supress (i) the code carbon output, (ii) the final JSON print\n",
    "- [x] distributed env issues\n",
    "- [x] Add in tunable optimisations into experimental variables: floating points, quantisation, batching, sharding\n",
    "- [x] currently the infernece and compute metrics are taken from main process, but they should probably be taken acorss all processes and averaged\n",
    "- [x] \"number_input_prompts\": null doesn;t make sense\n",
    "- [x] \"used_gpu\": \"cuda:0\" doesn't make sense\n",
    "- [x] the processes are not aggregating into a single experiment (the base experiment is there, but it also enumerates other processes and prints them\n",
    "- [x] clean up (remove) \"experiment_setup\": {}, and  \"experiment_variables\": {},\n",
    "- [x] sort out why the tokens are so many : \"Token indices sequence length is longer than the specified maximum sequence length for this model (7921 > 2048). Running this sequence through the model will result in indexing errors\"\n",
    "- [x] its not counting FLOPs --> change it to calculate FLOPS over whole dataset, NOT JUST SINGLE SAMPLE\n",
    "- [x] FLOPs is currently summed in the aggregation step, but i think it should be taken as a constant across all processes?\n",
    "- [x] review compute metrics:\n",
    "    - [x] sort out memory allocation metrics (they repeat, are they ever different?)\n",
    "    - [x] sort out the gpu_utilisation_percent <- currently it shows overall utilisation by other programmes, but I think that is right? check? [now it seems to be set to always 0... whereas when Silke was running training it was much more variable, did I break something or is notone using the GPUs currently?]\n",
    "- [x] FLOPs monitoring\n",
    "- [x] to experimental_variables: add avg_input_tokens and avg_output_tokens between and within batches / across the overall experiment??\n",
    "- [x] log metrics both at (1) the individual per prompt, (2) the per-batch level, and (3) the experiment level (e.g. number of input/output tokens, energy etc etc)\n",
    "- [x] IT DOESN'T WORK ON MORE THAN 2 GPUS\n",
    "- [x] make some changes between ExperimentConfig and ExperimentRunner\n",
    "    - [x] take the \"inference_fn\" of the notebook_launcher and instead have it determined in the run_experiment flow, by the parameter \"purely_generative\" of the experiment_config object.\n",
    "- [x] from run_gen_inf() remove line `do_sample = True if inference_type == \"reasoning\" else False`\n",
    "- [x] how is final GPU / CPU power calculated by CodeCarbon? is it an avg?\n",
    "- [x] listen to Lynn's call --> decide research question and begin writing it up\n",
    "- [x] sort out aggregate_results method to save into a single JSON file / dataframe\n",
    "    - [x] get this to calculate token efficiency!!!\n",
    "- [x] decode token ids doesn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

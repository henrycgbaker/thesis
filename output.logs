[225890] - 2025-04-10 22:46:23,721 - INFO - Starting Experimental Suite: 'Scenario'
[225890] - 2025-04-10 22:46:23,721 - INFO - Starting Cycle 1 for suite 'Scenario'
[225890] - 2025-04-10 22:46:23,721 - INFO - Cycle 1: Launching configuration-run for 'default'
[225890] - 2025-04-10 22:46:23,721 - INFO - Launching experiment attempt 1
[225890] - 2025-04-10 22:46:23,722 - INFO - Launching experiment with command: accelerate launch --num_processes 1 /home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py --config /tmp/tmpfbmzh2n6.json --launched
[226181] - Running distributed experiment.
[226181] - Loading configuration from /tmp/tmpfbmzh2n6.json
[226181] - Starting configuration run - run attempt 1/1
Accelerator set up
Unique experiment id: 0035
`low_cpu_mem_usage` was None, now default to True since model is quantized.
TinyLlama/TinyLlama-1.1B-Chat-v1.0 loaded using pytorch, with precision float16
Entering wait barrier: after load_model_tokenizer
wait_for_everyone completed within 600 seconds for after load_model_tokenizer.
Exiting wait barrier: after load_model_tokenizer
Original generate method saved.
Model and tokenizer prepared
Entering wait barrier: after model preparation
wait_for_everyone completed within 600 seconds for after model preparation.
Exiting wait barrier: after model preparation
[226181] - [Process 226181] Model is on device: cuda:0
Entering wait barrier: after logging device info
wait_for_everyone completed within 600 seconds for after logging device info.
Exiting wait barrier: after logging device info
Original generate method reassigned
[226181] - [Process 226181] Dummy forward pass complete
Entering wait barrier: after dummy forward pass
wait_for_everyone completed within 600 seconds for after dummy forward pass.
Exiting wait barrier: after dummy forward pass
Warm-up iteration 1 completed.
Warm-up iteration 2 completed.
Warm-up iteration 3 completed.
Entering wait barrier: after warm up
wait_for_everyone completed within 600 seconds for after warm up.
Exiting wait barrier: after warm up
Prompts processed: 100 prompts.
Energy tracking started
Task type: pure_generative
Using fixed batching (non-adaptive): created 7 batches.
[226181] - [Process 226181][GPU 0] — Completed tokenisation of batch 1/7
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[226181] - [Process 226181][GPU 0] — Completed batch inference 1/7
[226181] - [Process 226181][GPU 0] — Completed tokenisation of batch 2/7
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[226181] - [Process 226181][GPU 0] — Completed batch inference 2/7
[226181] - [Process 226181][GPU 0] — Completed tokenisation of batch 3/7
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[226181] - [Process 226181][GPU 0] — Completed batch inference 3/7
[226181] - [Process 226181][GPU 0] — Completed tokenisation of batch 4/7
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[226181] - [Process 226181][GPU 0] — Completed batch inference 4/7
[226181] - [Process 226181][GPU 0] — Completed tokenisation of batch 5/7
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[226181] - [Process 226181][GPU 0] — Completed batch inference 5/7
[226181] - [Process 226181][GPU 0] — Completed tokenisation of batch 6/7
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[226181] - [Process 226181][GPU 0] — Completed batch inference 6/7
[226181] - [Process 226181][GPU 0] — Completed tokenisation of batch 7/7
[226181] - [Process 226181][GPU 0] — Completed batch inference 7/7
[226181] - [Process 226181][GPU 0]: Inference complete
[226181] - [Process 226181][GPU 0]: Energy tracking stopped
Entering wait barrier: after energy tracking stopped
wait_for_everyone completed within 600 seconds for after energy tracking stopped.
Exiting wait barrier: after energy tracking stopped
Decoded token outputs successfully.
Saved outputs
[DEBUG] Enter get_experiment_setup: Experiment ID: 0035
[DEBUG] Exiting get_experiment_setup with result: {'experiment_id': '0035', 'date_time': 'April 10, 2025 at 10:51:46 PM', 'model': 'TinyLlama/TinyLlama-1.1B-Chat-v1.0', 'is_encoder_decoder': False, 'task_type': 'text_generation', 'available_gpu_count': 1, 'gpu_model': '4 x NVIDIA A100-PCIE-40GB', 'available_cpu_count': 128, 'cpu_model': 'AMD EPYC 7742 64-Core Processor', 'os': 'Linux-5.15.0-113-generic-x86_64-with-glibc2.31', 'python_version': '3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]', 'country': 'Germany', 'region': 'saxony'}
[DEBUG] Enter get_experimental_variables: Accelerator index: 0
[DEBUG] Exiting get_experimental_variables with result: {'config_name': 'default', 'max_input_tokens': 500, 'max_output_tokens': 500, 'number_input_prompts': 100, 'decode_token_to_text': True, 'decoder_config': {'decoder_temperature': 1.0, 'decoder_top_k': 0, 'decoder_top_p': 0.0, 'decoding_mode': 'greedy'}, 'query_rate': 1.0, 'latency_simulation': {'simulate': False, 'delay_min': 0, 'delay_max': 0, 'simulate_burst': False, 'burst_interval': 0.0, 'burst_size': 0}, 'fp_precision': 'torch.float16', 'quantisation': {'quantization': True, 'load_in_8bit': True, 'load_in_4bit': False, 'cached_flops_for_quantised_models': 1034544128000}, 'batching_options': {'batch_size___fixed_batching': 16, 'adaptive_batching': False, 'adaptive_max_tokens': 0, 'max_batch_size___adaptive_batching': 0}, 'sharding_config': {'fsdp_config': {'use_orig_params': False, 'cpu_offload': False}, 'sharding_strategy': 'NO_SHARD'}, 'accelerate_config': {'distributed_type': 'DistributedType.MULTI_GPU', 'num_processes': 1}, 'inference_type': 'pure_generative', 'backend': 'pytorch'}
[DEBUG] Enter get_model_architecture: Process ID: 226181
[DEBUG] Exiting get_model_architecture with result: {'total_params': 1100048384, 'architecture': 'Unknown (no config attribute)'}
[226181] - Main process saved (i) experiment setup, (ii) variables, (iii) model architecture.
Experiment-wide meta info saved
[DEBUG] Enter combine_inference_metrics: Accelerator index: 0
[DEBUG] Exiting combine_inference_metrics with result: {'number_input_prompts': 100, 'total_input_tokens': 50000, 'total_generated_tokens': 50000} & {'total_inference_time_sec': 301.8590525710024, 'average_latency_ms_per_batch': 43122.721795857484, 'throughput_queries_per_sec': 0.33128044081592783, 'throughput_tokens_per_sec': 165.6402204079639}
[DEBUG] Enter combine_comp_metrics: Accelerator index: 0
[DEBUG] Using cached FLOPs for quantized model: 1034544128000
[DEBUG] Exiting combine_comp_metrics with result: flops = 1034544128000; memory = {'gpu_current_memory_allocated_bytes': 1576948736, 'gpu_max_memory_allocated_bytes': 1576948736, 'gpu_current_memory_reserved_bytes': 2728394752, 'gpu_max_memory_reserved_bytes': 2728394752}; compute_util = {'gpu_utilization_percent': [14.0, 20.0, 22.0, 15.0], 'cpu_usage_percent': 2.4, 'cpu_memory_usage_bytes': 2704015360}
[226181] - Main process saved inference and computation metrics.
Experiment-wide inference and compute metrics saved
Entering wait barrier: after saving experiment metrics
wait_for_everyone completed within 600 seconds for after saving experiment metrics.
Exiting wait barrier: after saving experiment metrics
[DEBUG] Enter combine_energy_metrics: Process ID: 226181, Local process index: 0
[DEBUG] Energy consumed: 0.017627961337854364 kWh, which equals 63460.66081627571 joules.
[DEBUG] Exiting combine_energy_metrics with result: {'process_id': 226181, 'local_process_index': 0, 'energy_results': {'cpu_power': 112.5, 'gpu_power': 87.53478564714261, 'ram_power': 0.943751335144043, 'cpu_energy': 0.008946577822468499, 'gpu_energy': 0.008610020221344022, 'ram_energy': 7.136329404185562e-05, 'total_energy_kwh': 0.017627961337854364, 'total_energy_joules': 63460.66081627571, 'final_emissions': 0.00671537187165562}}
[226181] - Process 0: Energy metrics combined successfully.
[226181] - [Process 226181][GPU 0] saved its energy metrics.
All local process energy metrics saved
Experiment finished
Destroyed process group successfully
[226181] - Aggregating per-process energy metrics from disk.
[226181] - Aggregated global energy results successfully from disk.
[226181] - Saving configuration run results
[226181] - Configuration run results saved to results/text_generation_results.json
[226181] - Saving configuration run results in tabular format
[226181] - Saving configuration run results
[226181] - Configuration run results saved to results/text_generation_results.json
[226181] - Configuration run tabular results saved to /home/228755@hertie-school.lan/thesis/results/scenarios_results.csv
Starting teardown process...
Distributed package is not available or process group not initialized.
Emptying CUDA cache...
Running garbage collection...
Teardown process complete.
[226181] - Experiment #0035 run succeeded.
[226181] - Experiment run completed successfully.
[225890] - 2025-04-10 22:51:52,227 - INFO - Experiment run succeeded on attempt 1
[225890] - 2025-04-10 22:51:52,227 - INFO - Cycle 1: Configuration-run for 'default' completed successfully.
[225890] - 2025-04-10 22:51:54,229 - INFO - Cycle 1: Launching configuration-run for 'A3_Quantisation_Gaming'
[225890] - 2025-04-10 22:51:54,229 - INFO - Launching experiment attempt 1
[225890] - 2025-04-10 22:51:54,230 - INFO - Launching experiment with command: accelerate launch --num_processes 1 /home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py --config /tmp/tmpk6aldbcl.json --launched
[228818] - Running distributed experiment.
[228818] - Loading configuration from /tmp/tmpk6aldbcl.json
[228818] - Starting configuration run - run attempt 1/1
Accelerator set up
Unique experiment id: 0036
`low_cpu_mem_usage` was None, now default to True since model is quantized.
TinyLlama/TinyLlama-1.1B-Chat-v1.0 loaded using pytorch, with precision float16
Entering wait barrier: after load_model_tokenizer
wait_for_everyone completed within 600 seconds for after load_model_tokenizer.
Exiting wait barrier: after load_model_tokenizer
Original generate method saved.
Model and tokenizer prepared
Entering wait barrier: after model preparation
wait_for_everyone completed within 600 seconds for after model preparation.
Exiting wait barrier: after model preparation
[228818] - [Process 228818] Model is on device: cuda:0
Entering wait barrier: after logging device info
wait_for_everyone completed within 600 seconds for after logging device info.
Exiting wait barrier: after logging device info
Original generate method reassigned
[228818] - [Process 228818] Dummy forward pass complete
Entering wait barrier: after dummy forward pass
wait_for_everyone completed within 600 seconds for after dummy forward pass.
Exiting wait barrier: after dummy forward pass
Warm-up iteration 1 completed.
Warm-up iteration 2 completed.
Warm-up iteration 3 completed.
Entering wait barrier: after warm up
wait_for_everyone completed within 600 seconds for after warm up.
Exiting wait barrier: after warm up
Prompts processed: 100 prompts.
Energy tracking started
Task type: pure_generative
Using fixed batching (non-adaptive): created 2 batches.
[228818] - [Process 228818][GPU 0] — Completed tokenisation of batch 1/2
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[228818] - [Process 228818][GPU 0] — Completed batch inference 1/2
[228818] - [Process 228818][GPU 0] — Completed tokenisation of batch 2/2
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[228818] - [Process 228818][GPU 0] — Completed batch inference 2/2
[228818] - [Process 228818][GPU 0]: Inference complete
[228818] - [Process 228818][GPU 0]: Energy tracking stopped
Entering wait barrier: after energy tracking stopped
wait_for_everyone completed within 600 seconds for after energy tracking stopped.
Exiting wait barrier: after energy tracking stopped
Decoded token outputs successfully.
Saved outputs
[DEBUG] Enter get_experiment_setup: Experiment ID: 0036
[DEBUG] Exiting get_experiment_setup with result: {'experiment_id': '0036', 'date_time': 'April 10, 2025 at 10:53:07 PM', 'model': 'TinyLlama/TinyLlama-1.1B-Chat-v1.0', 'is_encoder_decoder': False, 'task_type': 'text_generation', 'available_gpu_count': 1, 'gpu_model': '4 x NVIDIA A100-PCIE-40GB', 'available_cpu_count': 128, 'cpu_model': 'AMD EPYC 7742 64-Core Processor', 'os': 'Linux-5.15.0-113-generic-x86_64-with-glibc2.31', 'python_version': '3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]', 'country': 'Germany', 'region': 'saxony'}
[DEBUG] Enter get_experimental_variables: Accelerator index: 0
[DEBUG] Exiting get_experimental_variables with result: {'config_name': 'A3_Quantisation_Gaming', 'max_input_tokens': 500, 'max_output_tokens': 500, 'number_input_prompts': 100, 'decode_token_to_text': True, 'decoder_config': {'decoder_temperature': 1.0, 'decoder_top_k': 50, 'decoder_top_p': 0.0, 'decoding_mode': 'top_k'}, 'query_rate': 1.0, 'latency_simulation': {'simulate': False, 'delay_min': 0, 'delay_max': 0, 'simulate_burst': False, 'burst_interval': 0.0, 'burst_size': 0}, 'fp_precision': 'torch.float16', 'quantisation': {'quantization': True, 'load_in_8bit': False, 'load_in_4bit': True, 'cached_flops_for_quantised_models': 1034544128000}, 'batching_options': {'batch_size___fixed_batching': 64, 'adaptive_batching': False, 'adaptive_max_tokens': 0, 'max_batch_size___adaptive_batching': 0}, 'sharding_config': {'fsdp_config': {'use_orig_params': False, 'cpu_offload': False}, 'sharding_strategy': 'NO_SHARD'}, 'accelerate_config': {'distributed_type': 'DistributedType.MULTI_GPU', 'num_processes': 1}, 'inference_type': 'pure_generative', 'backend': 'pytorch'}
[DEBUG] Enter get_model_architecture: Process ID: 228818
[DEBUG] Exiting get_model_architecture with result: {'total_params': 615606272, 'architecture': 'Unknown (no config attribute)'}
[228818] - Main process saved (i) experiment setup, (ii) variables, (iii) model architecture.
Experiment-wide meta info saved
[DEBUG] Enter combine_inference_metrics: Accelerator index: 0
[DEBUG] Exiting combine_inference_metrics with result: {'number_input_prompts': 100, 'total_input_tokens': 50000, 'total_generated_tokens': 50000} & {'total_inference_time_sec': 47.461509197999476, 'average_latency_ms_per_batch': 23730.754598999738, 'throughput_queries_per_sec': 2.1069705049374, 'throughput_tokens_per_sec': 1053.4852524686999}
[DEBUG] Enter combine_comp_metrics: Accelerator index: 0
[DEBUG] Using cached FLOPs for quantized model: 1034544128000
[DEBUG] Exiting combine_comp_metrics with result: flops = 1034544128000; memory = {'gpu_current_memory_allocated_bytes': 1088226816, 'gpu_max_memory_allocated_bytes': 1088226816, 'gpu_current_memory_reserved_bytes': 3982491648, 'gpu_max_memory_reserved_bytes': 3982491648}; compute_util = {'gpu_utilization_percent': [10.0, 18.0, 28.0, 16.0], 'cpu_usage_percent': 1.0, 'cpu_memory_usage_bytes': 2696359936}
[228818] - Main process saved inference and computation metrics.
Experiment-wide inference and compute metrics saved
Entering wait barrier: after saving experiment metrics
wait_for_everyone completed within 600 seconds for after saving experiment metrics.
Exiting wait barrier: after saving experiment metrics
[DEBUG] Enter combine_energy_metrics: Process ID: 228818, Local process index: 0
[DEBUG] Energy consumed: 0.0043122995240415735 kWh, which equals 15524.278286549665 joules.
[DEBUG] Exiting combine_energy_metrics with result: {'process_id': 228818, 'local_process_index': 0, 'energy_results': {'cpu_power': 112.5, 'gpu_power': 198.87830705028506, 'ram_power': 0.9409918785095215, 'cpu_energy': 0.0014776178379997875, 'gpu_energy': 0.0028230217028600013, 'ram_energy': 1.1659983181784104e-05, 'total_energy_kwh': 0.0043122995240415735, 'total_energy_joules': 15524.278286549665, 'final_emissions': 0.0016427705036836375}}
[228818] - Process 0: Energy metrics combined successfully.
[228818] - [Process 228818][GPU 0] saved its energy metrics.
All local process energy metrics saved
Experiment finished
Destroyed process group successfully
[228818] - Aggregating per-process energy metrics from disk.
[228818] - Aggregated global energy results successfully from disk.
[228818] - Saving configuration run results
[228818] - Configuration run results saved to results/text_generation_results.json
[228818] - Saving configuration run results in tabular format
[228818] - Saving configuration run results
[228818] - Configuration run results saved to results/text_generation_results.json
[228818] - Configuration run tabular results saved to /home/228755@hertie-school.lan/thesis/results/scenarios_results.csv
Starting teardown process...
Distributed package is not available or process group not initialized.
Emptying CUDA cache...
Running garbage collection...
Teardown process complete.
[228818] - Experiment #0036 run succeeded.
[228818] - Experiment run completed successfully.
[225890] - 2025-04-10 22:53:14,824 - INFO - Experiment run succeeded on attempt 1
[225890] - 2025-04-10 22:53:14,825 - INFO - Cycle 1: Configuration-run for 'A3_Quantisation_Gaming' completed successfully.
[225890] - 2025-04-10 22:53:16,827 - INFO - Cycle 1: Launching configuration-run for 'R6_Medium_Scale_Language_Model_Serving'
[225890] - 2025-04-10 22:53:16,827 - INFO - Launching experiment attempt 1
[225890] - 2025-04-10 22:53:16,828 - INFO - Launching experiment with command: accelerate launch --num_processes 4 /home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py --config /tmp/tmpvi06qkld.json --launched
[229682] - Running distributed experiment.
[229679] - Running distributed experiment.
[229680] - Running distributed experiment.
[229681] - Running distributed experiment.
[229681] - Loading configuration from /tmp/tmpvi06qkld.json
[229681] - Starting configuration run - run attempt 1/1
[229679] - Loading configuration from /tmp/tmpvi06qkld.json
[229679] - Starting configuration run - run attempt 1/1
[229682] - Loading configuration from /tmp/tmpvi06qkld.json
[229682] - Starting configuration run - run attempt 1/1
[229680] - Loading configuration from /tmp/tmpvi06qkld.json
[229680] - Starting configuration run - run attempt 1/1
Accelerator set up
Unique experiment id: 0037
TinyLlama/TinyLlama-1.1B-Chat-v1.0 loaded using pytorch, with precision float16
Entering wait barrier: after load_model_tokenizer
wait_for_everyone completed within 600 seconds for after load_model_tokenizer.
Exiting wait barrier: after load_model_tokenizer
Original generate method saved.
Model and tokenizer prepared
Entering wait barrier: after model preparation
wait_for_everyone completed within 600 seconds for after model preparation.
Exiting wait barrier: after model preparation
[229680] - [Process 229680] Model is on device: cuda:1
[229682] - [Process 229682] Model is on device: cuda:3
[229681] - [Process 229681] Model is on device: cuda:2
[229679] - [Process 229679] Model is on device: cuda:0
Entering wait barrier: after logging device info
wait_for_everyone completed within 600 seconds for after logging device info.
Exiting wait barrier: after logging device info
Original generate method reassigned
[229681] - [Process 229681] Dummy forward pass complete
[229682] - [Process 229682] Dummy forward pass complete
[229680] - [Process 229680] Dummy forward pass complete
[229679] - [Process 229679] Dummy forward pass complete
Entering wait barrier: after dummy forward pass
wait_for_everyone completed within 600 seconds for after dummy forward pass.
Exiting wait barrier: after dummy forward pass
Warm-up iteration 1 completed.
Warm-up iteration 1 completed.
Warm-up iteration 1 completed.
Warm-up iteration 1 completed.
Warm-up iteration 2 completed.
Warm-up iteration 2 completed.
Warm-up iteration 2 completed.
Warm-up iteration 2 completed.
Warm-up iteration 3 completed.
Entering wait barrier: after warm up
Warm-up iteration 3 completed.
Warm-up iteration 3 completed.
Warm-up iteration 3 completed.
wait_for_everyone completed within 600 seconds for after warm up.
Exiting wait barrier: after warm up
Prompts processed: 100 prompts.
Energy tracking started
Task type: pure_generative
Using fixed batching (non-adaptive): created 4 batches.
[229681] - [Process 229681][GPU 2] — Completed tokenisation of batch 1/4
[229679] - [Process 229679][GPU 0] — Completed tokenisation of batch 1/4
[229682] - [Process 229682][GPU 3] — Completed tokenisation of batch 1/4
[229680] - [Process 229680][GPU 1] — Completed tokenisation of batch 1/4
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[229682] - [Process 229682][GPU 3] — Completed batch inference 1/4
[229682] - [Process 229682][GPU 3] — Completed tokenisation of batch 2/4
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[229681] - [Process 229681][GPU 2] — Completed batch inference 1/4
[229681] - [Process 229681][GPU 2] — Completed tokenisation of batch 2/4
[229680] - [Process 229680][GPU 1] — Completed batch inference 1/4
[229680] - [Process 229680][GPU 1] — Completed tokenisation of batch 2/4
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[229679] - [Process 229679][GPU 0] — Completed batch inference 1/4
[229679] - [Process 229679][GPU 0] — Completed tokenisation of batch 2/4
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[229682] - [Process 229682][GPU 3] — Completed batch inference 2/4
[229682] - [Process 229682][GPU 3] — Completed tokenisation of batch 3/4
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[229681] - [Process 229681][GPU 2] — Completed batch inference 2/4
[229681] - [Process 229681][GPU 2] — Completed tokenisation of batch 3/4
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[229680] - [Process 229680][GPU 1] — Completed batch inference 2/4
[229680] - [Process 229680][GPU 1] — Completed tokenisation of batch 3/4
[229679] - [Process 229679][GPU 0] — Completed batch inference 2/4
[229679] - [Process 229679][GPU 0] — Completed tokenisation of batch 3/4
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[229682] - [Process 229682][GPU 3] — Completed batch inference 3/4
[229682] - [Process 229682][GPU 3] — Completed tokenisation of batch 4/4
[229679] - [Process 229679][GPU 0] — Completed batch inference 3/4
[229679] - [Process 229679][GPU 0] — Completed tokenisation of batch 4/4
[229681] - [Process 229681][GPU 2] — Completed batch inference 3/4
[229681] - [Process 229681][GPU 2] — Completed tokenisation of batch 4/4
[229680] - [Process 229680][GPU 1] — Completed batch inference 3/4
[229680] - [Process 229680][GPU 1] — Completed tokenisation of batch 4/4
[229679] - [Process 229679][GPU 0] — Completed batch inference 4/4
[229679] - [Process 229679][GPU 0]: Inference complete
[229679] - [Process 229679][GPU 0]: Energy tracking stopped
Entering wait barrier: after energy tracking stopped
[229681] - [Process 229681][GPU 2] — Completed batch inference 4/4
[229681] - [Process 229681][GPU 2]: Inference complete
[229682] - [Process 229682][GPU 3] — Completed batch inference 4/4
[229682] - [Process 229682][GPU 3]: Inference complete
[229681] - [Process 229681][GPU 2]: Energy tracking stopped
[229682] - [Process 229682][GPU 3]: Energy tracking stopped
[229680] - [Process 229680][GPU 1] — Completed batch inference 4/4
[229680] - [Process 229680][GPU 1]: Inference complete
[229680] - [Process 229680][GPU 1]: Energy tracking stopped
wait_for_everyone completed within 600 seconds for after energy tracking stopped.
Exiting wait barrier: after energy tracking stopped
Decoded token outputs successfully.
Saved outputs
[DEBUG] Enter get_experiment_setup: Experiment ID: 0037
[DEBUG] Exiting get_experiment_setup with result: {'experiment_id': '0037', 'date_time': 'April 10, 2025 at 10:54:39 PM', 'model': 'TinyLlama/TinyLlama-1.1B-Chat-v1.0', 'is_encoder_decoder': False, 'task_type': 'text_generation', 'available_gpu_count': 4, 'gpu_model': '4 x NVIDIA A100-PCIE-40GB', 'available_cpu_count': 128, 'cpu_model': 'AMD EPYC 7742 64-Core Processor', 'os': 'Linux-5.15.0-113-generic-x86_64-with-glibc2.31', 'python_version': '3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]', 'country': 'Germany', 'region': 'saxony'}
[DEBUG] Enter get_experimental_variables: Accelerator index: 0
[DEBUG] Exiting get_experimental_variables with result: {'config_name': 'R6_Medium_Scale_Language_Model_Serving', 'max_input_tokens': 500, 'max_output_tokens': 500, 'number_input_prompts': 100, 'decode_token_to_text': True, 'decoder_config': {'decoder_temperature': 1.0, 'decoder_top_k': 0, 'decoder_top_p': 0.0, 'decoding_mode': 'greedy'}, 'query_rate': 1.0, 'latency_simulation': {'simulate': True, 'delay_min': 0.01, 'delay_max': 0.1, 'simulate_burst': False, 'burst_interval': 0.0, 'burst_size': 0}, 'fp_precision': 'torch.float16', 'quantisation': {'quantization': False, 'load_in_8bit': False, 'load_in_4bit': False, 'cached_flops_for_quantised_models': 1034544128000}, 'batching_options': {'batch_size___fixed_batching': 32, 'adaptive_batching': False, 'adaptive_max_tokens': 0, 'max_batch_size___adaptive_batching': 0}, 'sharding_config': {'fsdp_config': {'use_orig_params': False, 'cpu_offload': False}, 'sharding_strategy': 'NO_SHARD'}, 'accelerate_config': {'distributed_type': 'DistributedType.MULTI_GPU', 'num_processes': 4}, 'inference_type': 'pure_generative', 'backend': 'pytorch'}
[DEBUG] Enter get_model_architecture: Process ID: 229679
[DEBUG] Exiting get_model_architecture with result: {'total_params': 1100048384, 'architecture': 'Unknown (no config attribute)'}
[229679] - Main process saved (i) experiment setup, (ii) variables, (iii) model architecture.
Experiment-wide meta info saved
[DEBUG] Enter combine_inference_metrics: Accelerator index: 0
[DEBUG] Exiting combine_inference_metrics with result: {'number_input_prompts': 100, 'total_input_tokens': 50000, 'total_generated_tokens': 50000} & {'total_inference_time_sec': 52.00610708599743, 'average_latency_ms_per_batch': 13001.526771499357, 'throughput_queries_per_sec': 1.9228510958268756, 'throughput_tokens_per_sec': 961.4255479134379}
[DEBUG] Enter combine_comp_metrics: Accelerator index: 0
[DEBUG] All samples have length 500. Computing FLOPs for one sample.
[DEBUG] Computed FLOPs for one sample: 517272064000
[DEBUG] Exiting combine_comp_metrics with result: flops = 51727206400000; memory = {'gpu_current_memory_allocated_bytes': 4420391424, 'gpu_max_memory_allocated_bytes': 4420391424, 'gpu_current_memory_reserved_bytes': 6771703808, 'gpu_max_memory_reserved_bytes': 6771703808}; compute_util = {'gpu_utilization_percent': [0.0, 100.0, 100.0, 100.0], 'cpu_usage_percent': 3.3, 'cpu_memory_usage_bytes': 3102441472}
[229679] - Main process saved inference and computation metrics.
Experiment-wide inference and compute metrics saved
Entering wait barrier: after saving experiment metrics
[DEBUG] Enter combine_energy_metrics: Process ID: 229682, Local process index: 3wait_for_everyone completed within 600 seconds for after saving experiment metrics.

[DEBUG] Enter combine_energy_metrics: Process ID: 229680, Local process index: 1[DEBUG] Enter combine_energy_metrics: Process ID: 229681, Local process index: 2[DEBUG] Energy consumed: 0.012415248191521075 kWh, which equals 44694.89348947587 joules.Exiting wait barrier: after saving experiment metrics



[DEBUG] Energy consumed: 0.012331726077862747 kWh, which equals 44394.21388030589 joules.[DEBUG] Energy consumed: 0.012335720553377571 kWh, which equals 44408.59399215926 joules.

[DEBUG] Enter combine_energy_metrics: Process ID: 229679, Local process index: 0[DEBUG] Exiting combine_energy_metrics with result: {'process_id': 229682, 'local_process_index': 3, 'energy_results': {'cpu_power': 112.5, 'gpu_power': 414.05140269105436, 'ram_power': 0.8825597763061523, 'cpu_energy': 0.0015714080055623755, 'gpu_energy': 0.010832847555160008, 'ram_energy': 1.0992630798692087e-05, 'total_energy_kwh': 0.012415248191521075, 'total_energy_joules': 44694.89348947587, 'final_emissions': 0.004729588798559954}}

[DEBUG] Exiting combine_energy_metrics with result: {'process_id': 229681, 'local_process_index': 2, 'energy_results': {'cpu_power': 112.5, 'gpu_power': 467.37945623275704, 'ram_power': 0.8514819145202638, 'cpu_energy': 0.0014927245553435571, 'gpu_energy': 0.01083203533228802, 'ram_energy': 1.0960665746002516e-05, 'total_energy_kwh': 0.012335720553377571, 'total_energy_joules': 44408.59399215926, 'final_emissions': 0.0046992927448091856}}[DEBUG] Energy consumed: 0.012377115841901092 kWh, which equals 44557.61703084393 joules.[DEBUG] Exiting combine_energy_metrics with result: {'process_id': 229680, 'local_process_index': 1, 'energy_results': {'cpu_power': 112.5, 'gpu_power': 373.6431828067259, 'ram_power': 0.881411075592041, 'cpu_energy': 0.0014764196749060831, 'gpu_energy': 0.01084367145270801, 'ram_energy': 1.1634950248648288e-05, 'total_energy_kwh': 0.012331726077862747, 'total_energy_joules': 44394.21388030589, 'final_emissions': 0.004697771049361814}}


[229682] - Process 3: Energy metrics combined successfully.
[DEBUG] Exiting combine_energy_metrics with result: {'process_id': 229679, 'local_process_index': 0, 'energy_results': {'cpu_power': 112.5, 'gpu_power': 918.5627120208545, 'ram_power': 1.0815038681030273, 'cpu_energy': 0.0015479253958437767, 'gpu_energy': 0.010814529207171991, 'ram_energy': 1.466123888532735e-05, 'total_energy_kwh': 0.012377115841901092, 'total_energy_joules': 44557.61703084393, 'final_emissions': 0.004715062279972221}}
[229681] - Process 2: Energy metrics combined successfully.
[229679] - Process 0: Energy metrics combined successfully.
[229680] - Process 1: Energy metrics combined successfully.
[229681] - [Process 229681][GPU 2] saved its energy metrics.
[229682] - [Process 229682][GPU 3] saved its energy metrics.
[229679] - [Process 229679][GPU 0] saved its energy metrics.
All local process energy metrics saved
Experiment finished
[229680] - [Process 229680][GPU 1] saved its energy metrics.
Destroyed process group successfully
[229679] - Aggregating per-process energy metrics from disk.
[229679] - Aggregated global energy results successfully from disk.
[229679] - Saving configuration run results
Starting teardown process...
Distributed package is not available or process group not initialized.
Emptying CUDA cache...Starting teardown process...

Distributed package is not available or process group not initialized.
Emptying CUDA cache...
Starting teardown process...
Distributed package is not available or process group not initialized.
Emptying CUDA cache...
[229679] - Configuration run results saved to results/text_generation_results.json
[229679] - Saving configuration run results in tabular format
[229679] - Saving configuration run results
Running garbage collection...
Running garbage collection...
Running garbage collection...
[229679] - Configuration run results saved to results/text_generation_results.json
[229679] - Configuration run tabular results saved to /home/228755@hertie-school.lan/thesis/results/scenarios_results.csv
Starting teardown process...
Distributed package is not available or process group not initialized.
Emptying CUDA cache...
Running garbage collection...
Teardown process complete.
Teardown process complete.
Teardown process complete.
Teardown process complete.
[229679] - Experiment #0037 run succeeded.
[229679] - Experiment run completed successfully.
[225890] - 2025-04-10 22:54:46,126 - INFO - Experiment run succeeded on attempt 1
[225890] - 2025-04-10 22:54:46,127 - INFO - Cycle 1: Configuration-run for 'R6_Medium_Scale_Language_Model_Serving' completed successfully.
[225890] - 2025-04-10 22:54:48,129 - INFO - Cycle 1: Launching configuration-run for 'R2_Low_Latency_Chatbot_Deployment'
[225890] - 2025-04-10 22:54:48,129 - INFO - Launching experiment attempt 1
[225890] - 2025-04-10 22:54:48,130 - INFO - Launching experiment with command: accelerate launch --num_processes 1 /home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py --config /tmp/tmpl5eijng3.json --launched
[230907] - Running distributed experiment.
[230907] - Loading configuration from /tmp/tmpl5eijng3.json
[230907] - Starting configuration run - run attempt 1/1
Accelerator set up
Unique experiment id: 0038
TinyLlama/TinyLlama-1.1B-Chat-v1.0 loaded using pytorch, with precision float32
Entering wait barrier: after load_model_tokenizer
wait_for_everyone completed within 600 seconds for after load_model_tokenizer.
Exiting wait barrier: after load_model_tokenizer
Original generate method saved.
[230907] - Experiment #0038 run failed on attempt 1: CUDA out of memory. Tried to allocate 4.10 GiB. GPU 0 has a total capacity of 39.39 GiB of which 3.47 GiB is free. Process 218416 has 31.00 GiB memory in use. Including non-PyTorch memory, this process has 4.90 GiB memory in use. Of the allocated memory 4.10 GiB is allocated by PyTorch, and 1.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home/228755@hertie-school.lan/thesis/experiment_orchestration_utils/b_single_config_workflow.py", line 20, in run_single_configuration
    result = runner.run_torch()
  File "/home/228755@hertie-school.lan/thesis/experiment_orchestration_utils/a_experiment_runner_class.py", line 88, in run_torch
    model, tokenizer = accelerator.prepare(model_undistributed, tokenizer)
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/accelerate/accelerator.py", line 1389, in prepare
    result = tuple(
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/accelerate/accelerator.py", line 1390, in <genexpr>
    self._prepare_one(obj, first_pass=True, device_placement=d) for obj, d in zip(args, device_placement)
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/accelerate/accelerator.py", line 1263, in _prepare_one
    return self.prepare_model(obj, device_placement=device_placement)
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/accelerate/accelerator.py", line 1522, in prepare_model
    model = torch.nn.parallel.DistributedDataParallel(
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 839, in __init__
    self._ddp_init_helper(
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/torch/nn/parallel/distributed.py", line 1196, in _ddp_init_helper
    self.reducer = dist.Reducer(
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.10 GiB. GPU 0 has a total capacity of 39.39 GiB of which 3.47 GiB is free. Process 218416 has 31.00 GiB memory in use. Including non-PyTorch memory, this process has 4.90 GiB memory in use. Of the allocated memory 4.10 GiB is allocated by PyTorch, and 1.65 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[230907] - Experiment #0038 run failed after maximum attempts.
[230907] - Experiment run failed.
[rank0]:[W410 22:55:06.142262023 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[225890] - 2025-04-10 22:55:08,896 - INFO - Experiment run succeeded on attempt 1
[225890] - 2025-04-10 22:55:08,897 - INFO - Cycle 1: Configuration-run for 'R2_Low_Latency_Chatbot_Deployment' completed successfully.
[225890] - 2025-04-10 22:55:10,899 - INFO - Cycle 1: Launching configuration-run for 'A1_Max_Throughput_Exploit'
[225890] - 2025-04-10 22:55:10,899 - INFO - Launching experiment attempt 1
[225890] - 2025-04-10 22:55:10,900 - INFO - Launching experiment with command: accelerate launch --num_processes 4 /home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py --config /tmp/tmp5t82vg6p.json --launched
[231272] - Running distributed experiment.
[231273] - Running distributed experiment.
[231270] - Running distributed experiment.
[231271] - Running distributed experiment.
[231273] - Loading configuration from /tmp/tmp5t82vg6p.json
[231273] - Starting configuration run - run attempt 1/1
[231270] - Loading configuration from /tmp/tmp5t82vg6p.json
[231270] - Starting configuration run - run attempt 1/1
[231272] - Loading configuration from /tmp/tmp5t82vg6p.json
[231272] - Starting configuration run - run attempt 1/1
[231271] - Loading configuration from /tmp/tmp5t82vg6p.json
[231271] - Starting configuration run - run attempt 1/1
Accelerator set up
Unique experiment id: 0039
`low_cpu_mem_usage` was None, now default to True since model is quantized.
TinyLlama/TinyLlama-1.1B-Chat-v1.0 loaded using pytorch, with precision float16
Entering wait barrier: after load_model_tokenizer
`low_cpu_mem_usage` was None, now default to True since model is quantized.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
`low_cpu_mem_usage` was None, now default to True since model is quantized.
wait_for_everyone completed within 600 seconds for after load_model_tokenizer.
Exiting wait barrier: after load_model_tokenizer
Original generate method saved.
Model and tokenizer prepared
Entering wait barrier: after model preparation
wait_for_everyone completed within 600 seconds for after model preparation.
Exiting wait barrier: after model preparation
[231270] - [Process 231270] Model is on device: cuda:0
Entering wait barrier: after logging device info
[231271] - [Process 231271] Model is on device: cuda:1
[231273] - [Process 231273] Model is on device: cuda:3
[231272] - [Process 231272] Model is on device: cuda:2
wait_for_everyone completed within 600 seconds for after logging device info.
Exiting wait barrier: after logging device info
Original generate method reassigned
[231270] - [Process 231270] Dummy forward pass complete
Entering wait barrier: after dummy forward pass
[231273] - [Process 231273] Dummy forward pass complete
[231271] - [Process 231271] Dummy forward pass complete
[231272] - [Process 231272] Dummy forward pass complete
wait_for_everyone completed within 600 seconds for after dummy forward pass.
Exiting wait barrier: after dummy forward pass
Warm-up iteration 1 completed.
Warm-up iteration 1 completed.
Warm-up iteration 1 completed.
Warm-up iteration 1 completed.
Warm-up iteration 2 completed.
Warm-up iteration 2 completed.
Warm-up iteration 2 completed.
Warm-up iteration 2 completed.
Warm-up iteration 3 completed.
Warm-up iteration 3 completed.
Warm-up iteration 3 completed.
Warm-up iteration 3 completed.
Entering wait barrier: after warm up
wait_for_everyone completed within 600 seconds for after warm up.
Exiting wait barrier: after warm up
Prompts processed: 100 prompts.
Energy tracking started
Task type: pure_generative
Using fixed batching (non-adaptive): created 1 batches.
[231273] - [Process 231273][GPU 3] — Completed tokenisation of batch 1/1
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[231271] - [Process 231271][GPU 1] — Completed tokenisation of batch 1/1
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[231270] - [Process 231270][GPU 0] — Completed tokenisation of batch 1/1
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
[231272] - [Process 231272][GPU 2] — Completed tokenisation of batch 1/1
A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.
Error during inference: CUDA out of memory. Tried to allocate 538.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 460.62 MiB is free. Process 218416 has 31.00 GiB memory in use. Process 231273 has 416.00 MiB memory in use. Including non-PyTorch memory, this process has 6.68 GiB memory in use. Process 231272 has 416.00 MiB memory in use. Process 231271 has 416.00 MiB memory in use. Of the allocated memory 5.11 GiB is allocated by PyTorch, and 840.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[231270] - Experiment #0039 run failed on attempt 1: CUDA out of memory. Tried to allocate 538.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 460.62 MiB is free. Process 218416 has 31.00 GiB memory in use. Process 231273 has 416.00 MiB memory in use. Including non-PyTorch memory, this process has 6.68 GiB memory in use. Process 231272 has 416.00 MiB memory in use. Process 231271 has 416.00 MiB memory in use. Of the allocated memory 5.11 GiB is allocated by PyTorch, and 840.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Traceback (most recent call last):
  File "/home/228755@hertie-school.lan/thesis/experiment_orchestration_utils/b_single_config_workflow.py", line 20, in run_single_configuration
    result = runner.run_torch()
  File "/home/228755@hertie-school.lan/thesis/experiment_orchestration_utils/a_experiment_runner_class.py", line 126, in run_torch
    token_id_outputs, input_ids, raw_inference_results = run_gen_inference(
  File "/home/228755@hertie-school.lan/thesis/experiment_core_utils/e_inference.py", line 174, in run_gen_inference
    token_id_batch_output = model.generate(batch_encoded["input_ids"],
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/transformers/generation/utils.py", line 2223, in generate
    result = self._sample(
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/transformers/generation/utils.py", line 3211, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/transformers/utils/deprecation.py", line 172, in wrapped_func
    return func(*args, **kwargs)
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 842, in forward
    outputs = self.model(
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 594, in forward
    layer_outputs = decoder_layer(
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 352, in forward
    hidden_states = self.mlp(hidden_states)
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/transformers/models/llama/modeling_llama.py", line 190, in forward
    down_proj = self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/bitsandbytes/nn/modules.py", line 990, in forward
    out = bnb.matmul(x, self.weight, bias=self.bias, state=self.state)
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py", line 509, in matmul
    return MatMul8bitLt.apply(A, B, out, bias, state)
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/torch/autograd/function.py", line 575, in apply
    return super().apply(*args, **kwargs)  # type: ignore[misc]
  File "/home/228755@hertie-school.lan/thesis/thesis/lib/python3.10/site-packages/bitsandbytes/autograd/_functions.py", line 380, in forward
    output = output.addmm(subA, state.subB)
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 538.00 MiB. GPU 0 has a total capacity of 39.39 GiB of which 460.62 MiB is free. Process 218416 has 31.00 GiB memory in use. Process 231273 has 416.00 MiB memory in use. Including non-PyTorch memory, this process has 6.68 GiB memory in use. Process 231272 has 416.00 MiB memory in use. Process 231271 has 416.00 MiB memory in use. Of the allocated memory 5.11 GiB is allocated by PyTorch, and 840.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
[231270] - Experiment #0039 run failed after maximum attempts.
[231270] - Experiment run failed.
[rank0]:[W410 22:55:45.443279363 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())
[231273] - [Process 231273][GPU 3] — Completed batch inference 1/1
[231273] - [Process 231273][GPU 3]: Inference complete
[231273] - [Process 231273][GPU 3]: Energy tracking stopped
[231271] - [Process 231271][GPU 1] — Completed batch inference 1/1
[231271] - [Process 231271][GPU 1]: Inference complete
[231271] - [Process 231271][GPU 1]: Energy tracking stopped
[231272] - [Process 231272][GPU 2] — Completed batch inference 1/1
[231272] - [Process 231272][GPU 2]: Inference complete
[231272] - [Process 231272][GPU 2]: Energy tracking stopped
W0410 22:59:22.534000 231120 torch/distributed/elastic/agent/server/api.py:704] Received Signals.SIGINT death signal, shutting down workers
W0410 22:59:22.535000 231120 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 231271 closing signal SIGINT
W0410 22:59:22.536000 231120 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 231272 closing signal SIGINT
W0410 22:59:22.536000 231120 torch/distributed/elastic/multiprocessing/api.py:897] Sending process 231273 closing signal SIGINT
[rank1]: Traceback (most recent call last):
[rank1]:   File "/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py", line 56, in <module>
[rank1]:     main()
[rank1]:   File "/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py", line 45, in main
[rank1]:     success, result = run_from_file(args.config, prompts)
[rank1]:   File "/home/228755@hertie-school.lan/thesis/experiment_orchestration_utils/c_launcher_utils.py", line 51, in run_from_file
[rank1]:     return run_from_config(config_data, prompts)
[rank1]:   File "/home/228755@hertie-school.lan/thesis/experiment_orchestration_utils/c_launcher_utils.py", line 46, in run_from_config
[rank1]:     return run_single_configuration(runner, max_retries, retry_delay)
[rank1]:   File "/home/228755@hertie-school.lan/thesis/experiment_orchestration_utils/b_single_config_workflow.py", line 20, in run_single_configuration
[rank1]:     result = runner.run_torch()
[rank1]:   File "/home/228755@hertie-school.lan/thesis/experiment_orchestration_utils/a_experiment_runner_class.py", line 142, in run_torch
[rank1]:     safe_wait(accelerator, "after energy tracking stopped")
[rank1]:   File "/home/228755@hertie-school.lan/thesis/experiment_core_utils/a_distributed.py", line 108, in safe_wait
[rank1]:     t.join(timeout)
[rank1]:   File "/usr/lib/python3.10/threading.py", line 1100, in join
[rank1]:     self._wait_for_tstate_lock(timeout=max(timeout, 0))
[rank1]:   File "/usr/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
[rank1]:     if lock.acquire(block, timeout):
[rank1]: KeyboardInterrupt
[rank2]: Traceback (most recent call last):
[rank2]:   File "/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py", line 56, in <module>
[rank2]:     main()
[rank2]:   File "/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py", line 45, in main
[rank2]:     success, result = run_from_file(args.config, prompts)
[rank2]:   File "/home/228755@hertie-school.lan/thesis/experiment_orchestration_utils/c_launcher_utils.py", line 51, in run_from_file
[rank2]:     return run_from_config(config_data, prompts)
[rank2]:   File "/home/228755@hertie-school.lan/thesis/experiment_orchestration_utils/c_launcher_utils.py", line 46, in run_from_config
[rank2]:     return run_single_configuration(runner, max_retries, retry_delay)
[rank2]:   File "/home/228755@hertie-school.lan/thesis/experiment_orchestration_utils/b_single_config_workflow.py", line 20, in run_single_configuration
[rank2]:     result = runner.run_torch()
[rank2]:   File "/home/228755@hertie-school.lan/thesis/experiment_orchestration_utils/a_experiment_runner_class.py", line 142, in run_torch
[rank2]:     safe_wait(accelerator, "after energy tracking stopped")
[rank2]:   File "/home/228755@hertie-school.lan/thesis/experiment_core_utils/a_distributed.py", line 108, in safe_wait
[rank2]:     t.join(timeout)
[rank2]:   File "/usr/lib/python3.10/threading.py", line 1100, in join
[rank2]:     self._wait_for_tstate_lock(timeout=max(timeout, 0))
[rank2]:   File "/usr/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
[rank2]:     if lock.acquire(block, timeout):
[rank2]: KeyboardInterrupt
[rank3]: Traceback (most recent call last):
[rank3]:   File "/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py", line 56, in <module>
[rank3]:     main()
[rank3]:   File "/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py", line 45, in main
[rank3]:     success, result = run_from_file(args.config, prompts)
[rank3]:   File "/home/228755@hertie-school.lan/thesis/experiment_orchestration_utils/c_launcher_utils.py", line 51, in run_from_file
[rank3]:     return run_from_config(config_data, prompts)
[rank3]:   File "/home/228755@hertie-school.lan/thesis/experiment_orchestration_utils/c_launcher_utils.py", line 46, in run_from_config
[rank3]:     return run_single_configuration(runner, max_retries, retry_delay)
[rank3]:   File "/home/228755@hertie-school.lan/thesis/experiment_orchestration_utils/b_single_config_workflow.py", line 20, in run_single_configuration
[rank3]:     result = runner.run_torch()
[rank3]:   File "/home/228755@hertie-school.lan/thesis/experiment_orchestration_utils/a_experiment_runner_class.py", line 142, in run_torch
[rank3]:     safe_wait(accelerator, "after energy tracking stopped")
[rank3]:   File "/home/228755@hertie-school.lan/thesis/experiment_core_utils/a_distributed.py", line 108, in safe_wait
[rank3]:     t.join(timeout)
[rank3]:   File "/usr/lib/python3.10/threading.py", line 1100, in join
[rank3]:     self._wait_for_tstate_lock(timeout=max(timeout, 0))
[rank3]:   File "/usr/lib/python3.10/threading.py", line 1116, in _wait_for_tstate_lock
[rank3]:     if lock.acquire(block, timeout):
[rank3]: KeyboardInterrupt
Traceback (most recent call last):
  File "/home/228755@hertie-school.lan/thesis/MAIN_run_experimental_suite.py", line 86, in <module>
    main()
  File "/home/228755@hertie-school.lan/thesis/MAIN_run_experimental_suite.py", line 80, in main
    run_suite(config_list, suite_name)
  File "/home/228755@hertie-school.lan/thesis/MAIN_run_experimental_suite.py", line 66, in run_suite
    run_cycle(config_list, suite_name, cycle)
  File "/home/228755@hertie-school.lan/thesis/MAIN_run_experimental_suite.py", line 50, in run_cycle
    launch_config_accelerate_cli(config, SINGLE_EXP_SCRIPT, extra_args=["--launched"])
  File "/home/228755@hertie-school.lan/thesis/experiment_orchestration_utils/c_launcher_utils.py", line 86, in launch_config_accelerate_cli
    subprocess.run(cmd, env=env, check=True)
  File "/usr/lib/python3.10/subprocess.py", line 505, in run
    stdout, stderr = process.communicate(input, timeout=timeout)
  File "/usr/lib/python3.10/subprocess.py", line 1146, in communicate
    self.wait()
  File "/usr/lib/python3.10/subprocess.py", line 1209, in wait
    return self._wait(timeout=timeout)
  File "/usr/lib/python3.10/subprocess.py", line 1959, in _wait
    (pid, sts) = self._try_wait(0)
  File "/usr/lib/python3.10/subprocess.py", line 1917, in _try_wait
    (pid, sts) = os.waitpid(self.pid, wait_flags)
KeyboardInterrupt

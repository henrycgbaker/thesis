{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "will later move this into function script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_files = [\"controlled\", \"scenarios\", \"grid\", \"text_generation\"]\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "def process_possible_files(func, *args, **kwargs):\n",
    "    \"\"\"\n",
    "    Loops over the global list 'possible_files', calls the provided function on each file,\n",
    "    and creates a global variable with the naming convention 'df_<file>_cleaned'\n",
    "    to store the resulting DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "        func (callable): A function that takes at least a file name (first argument).\n",
    "        *args: Additional positional arguments that 'func' needs.\n",
    "        **kwargs: Additional keyword arguments that 'func' needs.\n",
    "    \n",
    "    The function will also attempt to display each transposed DataFrame.\n",
    "    \"\"\"\n",
    "    for file in possible_files:\n",
    "        try:\n",
    "            var_name = f\"df_{file}_cleaned\"\n",
    "            # Run the provided function on the file, passing along any additional arguments.\n",
    "            result_df = func(file, *args, **kwargs)\n",
    "            # Dynamically create a global variable with the result.\n",
    "            globals()[var_name] = result_df\n",
    "            print(f\"Found & inspecting: {var_name}\")\n",
    "            display(result_df.T)\n",
    "        except Exception as e:\n",
    "            print(f\"{file} did not process correctly: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inference_metrics_raw_inference_metrics_number_input_prompts\n",
      "variables_quantisation_cached_flops_for_quantised_models\n",
      "setup_is_encoder_decoder\n",
      "variables_config_name\n",
      "variables_batching_options_max_batch_size___adaptive_batching\n",
      "variables_query_rate\n",
      "compute_metrics_flops\n",
      "variables_batching_options_batch_size___fixed_batching\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_3\n",
      "compute_metrics_compute_utilisation_cpu_usage_percent\n",
      "variables_batching_options_adaptive_batching\n",
      "global_energy_metrics_local_process_results_ram_power_process_2\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_2\n",
      "global_energy_metrics_global_experiment_results_ram_energy_total\n",
      "global_energy_metrics_local_process_results_ram_energy_process_2\n",
      "global_energy_metrics_local_process_results_gpu_power_process_3\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_3\n",
      "variables_quantisation_load_in_8bit\n",
      "global_energy_metrics_global_derived_quantities_flops_per_joule\n",
      "variables_decoder_config_decoding_mode\n",
      "global_energy_metrics_per-process_emissions_2\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_2\n",
      "global_energy_metrics_local_process_results_ram_power_process_1\n",
      "global_energy_metrics_global_experiment_results_total_energy_kwh\n",
      "setup_gpu_model\n",
      "variables_inference_type\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_1\n",
      "global_energy_metrics_global_experiment_results_cpu_energy_total\n",
      "inference_metrics_raw_inference_metrics_total_input_tokens\n",
      "global_energy_metrics_global_experiment_results_total_energy_joules\n",
      "model_architecture_total_params\n",
      "global_energy_metrics_per-process_emissions_3\n",
      "setup_os\n",
      "variables_max_input_tokens\n",
      "compute_metrics_memory_gpu_max_memory_reserved_bytes\n",
      "global_energy_metrics_global_derived_quantities_joules_per_token\n",
      "variables_quantisation_load_in_4bit\n",
      "setup_task_type\n",
      "global_energy_metrics_global_derived_quantities_tokens_per_joule\n",
      "inference_metrics_inference_performance_average_latency_ms_per_batch\n",
      "variables_accelerate_config_num_processes\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_0\n",
      "setup_model\n",
      "global_energy_metrics_local_process_results_gpu_power_process_1\n",
      "global_energy_metrics_global_experiment_results_gpu_power_avg\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_0\n",
      "variables_accelerate_config_distributed_type\n",
      "global_energy_metrics_global_derived_quantities_joules_per_flop\n",
      "variables_decoder_config_decoder_top_k\n",
      "global_energy_metrics_local_process_results_ram_power_process_3\n",
      "global_energy_metrics_local_process_results_cpu_power_process_2\n",
      "variables_latency_simulation_simulate\n",
      "global_energy_metrics_local_process_results_gpu_power_process_0\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_2\n",
      "global_energy_metrics_local_process_results_ram_energy_process_0\n",
      "setup_experiment_id\n",
      "variables_latency_simulation_delay_max\n",
      "setup_available_gpu_count\n",
      "variables_decoder_config_decoder_temperature\n",
      "global_energy_metrics_per-process_emissions_0\n",
      "global_energy_metrics_experiment_id\n",
      "variables_sharding_config_sharding_strategy\n",
      "compute_metrics_compute_utilisation_cpu_memory_usage_bytes\n",
      "variables_latency_simulation_burst_size\n",
      "variables_fp_precision\n",
      "global_energy_metrics_local_process_results_cpu_power_process_3\n",
      "global_energy_metrics_local_process_results_ram_power_process_0\n",
      "setup_date_time\n",
      "global_energy_metrics_global_experiment_results_gpu_energy_total\n",
      "inference_metrics_inference_performance_throughput_queries_per_sec\n",
      "compute_metrics_memory_gpu_current_memory_reserved_bytes\n",
      "variables_sharding_config_fsdp_config_use_orig_params\n",
      "variables_decode_token_to_text\n",
      "setup_region\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_3\n",
      "inference_metrics_raw_inference_metrics_total_generated_tokens\n",
      "variables_sharding_config_fsdp_config_cpu_offload\n",
      "global_energy_metrics_local_process_results_cpu_power_process_0\n",
      "global_energy_metrics_local_process_results_gpu_energy_process_3\n",
      "setup_python_version\n",
      "global_energy_metrics_global_experiment_results_ram_power_avg\n",
      "compute_metrics_memory_gpu_max_memory_allocated_bytes\n",
      "global_energy_metrics_local_process_results_total_energy_joules_process_1\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_0\n",
      "setup_cpu_model\n",
      "variables_decoder_config_decoder_top_p\n",
      "variables_latency_simulation_simulate_burst\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_3\n",
      "inference_metrics_inference_performance_total_inference_time_sec\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_1\n",
      "variables_batching_options_adaptive_max_tokens\n",
      "compute_metrics_memory_gpu_current_memory_allocated_bytes\n",
      "variables_latency_simulation_burst_interval\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_1\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_1\n",
      "variables_number_input_prompts\n",
      "global_energy_metrics_global_experiment_results_cpu_power_avg\n",
      "compute_metrics_compute_utilisation_gpu_utilization_percent_2\n",
      "global_energy_metrics_local_process_results_cpu_power_process_1\n",
      "inference_metrics_inference_performance_throughput_tokens_per_sec\n",
      "global_energy_metrics_per-process_emissions_1\n",
      "global_energy_metrics_local_process_results_ram_energy_process_1\n",
      "setup_country\n",
      "variables_latency_simulation_delay_min\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_2\n",
      "global_energy_metrics_local_process_results_cpu_energy_process_0\n",
      "variables_max_output_tokens\n",
      "global_energy_metrics_local_process_results_ram_energy_process_3\n",
      "setup_available_cpu_count\n",
      "model_architecture_architecture\n",
      "variables_backend\n",
      "global_energy_metrics_local_process_results_gpu_power_process_2\n",
      "variables_quantisation_quantization\n",
      "global_energy_metrics_local_process_results_total_energy_kwh_process_0\n"
     ]
    }
   ],
   "source": [
    "notebook_dir = os.getcwd()\n",
    "df = process_possible_files\n",
    "df = pd.read_csv(\"analysis_results/controlled_results.csv\")\n",
    "\n",
    "columns = list(df.columns)\n",
    "for col in columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found & inspecting: df_controlled_cleaned\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>config_name</th>\n",
       "      <td>num_processes_1</td>\n",
       "      <td>num_processes_2</td>\n",
       "      <td>num_processes_3</td>\n",
       "      <td>num_processes_4</td>\n",
       "      <td>batching_1</td>\n",
       "      <td>batching_2</td>\n",
       "      <td>batching_4</td>\n",
       "      <td>batching_8</td>\n",
       "      <td>batching_16</td>\n",
       "      <td>batching_32</td>\n",
       "      <td>batching_64</td>\n",
       "      <td>precis_float32_quant_False_quant8_False_quant4...</td>\n",
       "      <td>precis_float16_quant_False_quant8_False_quant4...</td>\n",
       "      <td>precis_float16_quant_True_quant8_True_quant4_F...</td>\n",
       "      <td>precis_float16_quant_True_quant8_False_quant4_...</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.2</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.4</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.6</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.8</td>\n",
       "      <td>decoding_greedy_decoder_temperature_1.0</td>\n",
       "      <td>decoding_greedy_decoder_temperature_1.2</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>latency_False</td>\n",
       "      <td>latency_True_latency_0.05_latency_0.2_latency_...</td>\n",
       "      <td>latency_True_latency_0.2_latency_0.6_latency_F...</td>\n",
       "      <td>latency_True_latency_0.05_latency_0.2_latency_...</td>\n",
       "      <td>latency_True_latency_0.2_latency_0.6_latency_T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <td>233</td>\n",
       "      <td>234</td>\n",
       "      <td>235</td>\n",
       "      <td>236</td>\n",
       "      <td>237</td>\n",
       "      <td>238</td>\n",
       "      <td>239</td>\n",
       "      <td>240</td>\n",
       "      <td>241</td>\n",
       "      <td>242</td>\n",
       "      <td>243</td>\n",
       "      <td>244</td>\n",
       "      <td>245</td>\n",
       "      <td>246</td>\n",
       "      <td>247</td>\n",
       "      <td>248</td>\n",
       "      <td>249</td>\n",
       "      <td>250</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>256</td>\n",
       "      <td>257</td>\n",
       "      <td>258</td>\n",
       "      <td>259</td>\n",
       "      <td>260</td>\n",
       "      <td>261</td>\n",
       "      <td>262</td>\n",
       "      <td>263</td>\n",
       "      <td>264</td>\n",
       "      <td>265</td>\n",
       "      <td>266</td>\n",
       "      <td>267</td>\n",
       "      <td>268</td>\n",
       "      <td>269</td>\n",
       "      <td>270</td>\n",
       "      <td>271</td>\n",
       "      <td>272</td>\n",
       "      <td>273</td>\n",
       "      <td>274</td>\n",
       "      <td>275</td>\n",
       "      <td>276</td>\n",
       "      <td>277</td>\n",
       "      <td>278</td>\n",
       "      <td>279</td>\n",
       "      <td>280</td>\n",
       "      <td>281</td>\n",
       "      <td>282</td>\n",
       "      <td>283</td>\n",
       "      <td>284</td>\n",
       "      <td>285</td>\n",
       "      <td>286</td>\n",
       "      <td>287</td>\n",
       "      <td>288</td>\n",
       "      <td>289</td>\n",
       "      <td>290</td>\n",
       "      <td>296</td>\n",
       "      <td>297</td>\n",
       "      <td>298</td>\n",
       "      <td>299</td>\n",
       "      <td>300</td>\n",
       "      <td>301</td>\n",
       "      <td>302</td>\n",
       "      <td>303</td>\n",
       "      <td>304</td>\n",
       "      <td>305</td>\n",
       "      <td>306</td>\n",
       "      <td>307</td>\n",
       "      <td>308</td>\n",
       "      <td>309</td>\n",
       "      <td>310</td>\n",
       "      <td>311</td>\n",
       "      <td>312</td>\n",
       "      <td>313</td>\n",
       "      <td>314</td>\n",
       "      <td>315</td>\n",
       "      <td>316</td>\n",
       "      <td>317</td>\n",
       "      <td>318</td>\n",
       "      <td>319</td>\n",
       "      <td>320</td>\n",
       "      <td>321</td>\n",
       "      <td>322</td>\n",
       "      <td>323</td>\n",
       "      <td>328</td>\n",
       "      <td>329</td>\n",
       "      <td>330</td>\n",
       "      <td>331</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <td>April 11, 2025 at 05:02:12 PM</td>\n",
       "      <td>April 11, 2025 at 05:03:25 PM</td>\n",
       "      <td>April 11, 2025 at 05:04:40 PM</td>\n",
       "      <td>April 11, 2025 at 05:05:55 PM</td>\n",
       "      <td>April 11, 2025 at 05:13:02 PM</td>\n",
       "      <td>April 11, 2025 at 05:18:36 PM</td>\n",
       "      <td>April 11, 2025 at 05:21:39 PM</td>\n",
       "      <td>April 11, 2025 at 05:23:23 PM</td>\n",
       "      <td>April 11, 2025 at 05:24:30 PM</td>\n",
       "      <td>April 11, 2025 at 05:25:17 PM</td>\n",
       "      <td>April 11, 2025 at 05:25:56 PM</td>\n",
       "      <td>April 11, 2025 at 05:26:49 PM</td>\n",
       "      <td>April 11, 2025 at 05:27:40 PM</td>\n",
       "      <td>April 11, 2025 at 05:29:22 PM</td>\n",
       "      <td>April 11, 2025 at 05:30:29 PM</td>\n",
       "      <td>April 11, 2025 at 05:31:35 PM</td>\n",
       "      <td>April 11, 2025 at 05:32:41 PM</td>\n",
       "      <td>April 11, 2025 at 05:33:46 PM</td>\n",
       "      <td>April 11, 2025 at 05:34:52 PM</td>\n",
       "      <td>April 11, 2025 at 05:35:58 PM</td>\n",
       "      <td>April 11, 2025 at 05:37:04 PM</td>\n",
       "      <td>April 11, 2025 at 05:38:09 PM</td>\n",
       "      <td>April 11, 2025 at 05:39:42 PM</td>\n",
       "      <td>April 11, 2025 at 05:40:48 PM</td>\n",
       "      <td>April 11, 2025 at 05:41:54 PM</td>\n",
       "      <td>April 11, 2025 at 05:43:00 PM</td>\n",
       "      <td>April 11, 2025 at 05:44:05 PM</td>\n",
       "      <td>April 11, 2025 at 05:45:11 PM</td>\n",
       "      <td>April 11, 2025 at 05:46:17 PM</td>\n",
       "      <td>April 11, 2025 at 05:47:23 PM</td>\n",
       "      <td>April 11, 2025 at 05:48:29 PM</td>\n",
       "      <td>April 11, 2025 at 05:49:38 PM</td>\n",
       "      <td>April 11, 2025 at 05:50:44 PM</td>\n",
       "      <td>April 11, 2025 at 05:51:50 PM</td>\n",
       "      <td>April 11, 2025 at 05:52:55 PM</td>\n",
       "      <td>April 11, 2025 at 05:54:01 PM</td>\n",
       "      <td>April 11, 2025 at 05:55:07 PM</td>\n",
       "      <td>April 11, 2025 at 05:56:12 PM</td>\n",
       "      <td>April 11, 2025 at 05:57:18 PM</td>\n",
       "      <td>April 11, 2025 at 05:58:24 PM</td>\n",
       "      <td>April 11, 2025 at 05:59:29 PM</td>\n",
       "      <td>April 11, 2025 at 06:00:36 PM</td>\n",
       "      <td>April 11, 2025 at 06:01:44 PM</td>\n",
       "      <td>April 11, 2025 at 06:02:51 PM</td>\n",
       "      <td>April 11, 2025 at 06:03:57 PM</td>\n",
       "      <td>April 11, 2025 at 06:05:03 PM</td>\n",
       "      <td>April 11, 2025 at 06:06:10 PM</td>\n",
       "      <td>April 11, 2025 at 06:07:16 PM</td>\n",
       "      <td>April 11, 2025 at 06:08:21 PM</td>\n",
       "      <td>April 11, 2025 at 06:09:27 PM</td>\n",
       "      <td>April 11, 2025 at 06:10:32 PM</td>\n",
       "      <td>April 11, 2025 at 06:11:38 PM</td>\n",
       "      <td>April 11, 2025 at 06:12:45 PM</td>\n",
       "      <td>April 11, 2025 at 06:13:51 PM</td>\n",
       "      <td>April 11, 2025 at 06:14:58 PM</td>\n",
       "      <td>April 11, 2025 at 06:16:04 PM</td>\n",
       "      <td>April 11, 2025 at 06:17:15 PM</td>\n",
       "      <td>April 11, 2025 at 06:20:42 PM</td>\n",
       "      <td>April 11, 2025 at 06:21:47 PM</td>\n",
       "      <td>April 11, 2025 at 06:22:52 PM</td>\n",
       "      <td>April 11, 2025 at 06:23:58 PM</td>\n",
       "      <td>April 11, 2025 at 06:25:04 PM</td>\n",
       "      <td>April 11, 2025 at 06:26:10 PM</td>\n",
       "      <td>April 11, 2025 at 06:27:16 PM</td>\n",
       "      <td>April 11, 2025 at 06:28:21 PM</td>\n",
       "      <td>April 11, 2025 at 06:29:27 PM</td>\n",
       "      <td>April 11, 2025 at 06:30:33 PM</td>\n",
       "      <td>April 11, 2025 at 06:31:40 PM</td>\n",
       "      <td>April 11, 2025 at 06:32:49 PM</td>\n",
       "      <td>April 11, 2025 at 06:33:55 PM</td>\n",
       "      <td>April 11, 2025 at 06:35:01 PM</td>\n",
       "      <td>April 11, 2025 at 06:36:06 PM</td>\n",
       "      <td>April 11, 2025 at 06:37:12 PM</td>\n",
       "      <td>April 11, 2025 at 06:38:18 PM</td>\n",
       "      <td>April 11, 2025 at 06:39:24 PM</td>\n",
       "      <td>April 11, 2025 at 06:40:30 PM</td>\n",
       "      <td>April 11, 2025 at 06:41:37 PM</td>\n",
       "      <td>April 11, 2025 at 06:42:44 PM</td>\n",
       "      <td>April 11, 2025 at 06:43:50 PM</td>\n",
       "      <td>April 11, 2025 at 06:44:56 PM</td>\n",
       "      <td>April 11, 2025 at 06:46:02 PM</td>\n",
       "      <td>April 11, 2025 at 06:47:09 PM</td>\n",
       "      <td>April 11, 2025 at 06:48:16 PM</td>\n",
       "      <td>April 11, 2025 at 06:49:22 PM</td>\n",
       "      <td>April 11, 2025 at 06:50:29 PM</td>\n",
       "      <td>April 11, 2025 at 06:53:27 PM</td>\n",
       "      <td>April 11, 2025 at 06:54:34 PM</td>\n",
       "      <td>April 11, 2025 at 06:55:45 PM</td>\n",
       "      <td>April 11, 2025 at 06:56:55 PM</td>\n",
       "      <td>April 11, 2025 at 06:58:10 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_processes</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size___fixed_batching</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_temperature</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_k</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_p</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate_burst</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_size</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_interval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp_precision</th>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantization</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_8bit</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_4bit</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharding_strategy</th>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharding_config_fsdp_config_use_orig_params</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharding_config_fsdp_config_cpu_offload</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive_batching</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive_max_tokens</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_rate</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_input_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_encoder_decoder</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_type</th>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_gpu_count</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_model</th>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_cpu_count</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_model</th>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>os</th>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python_version</th>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distributed_type</th>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decode_token_to_text</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inference_type</th>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backend</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_params</th>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_arch</th>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_input_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_output_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_input_prompts</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh</th>\n",
       "      <td>0.003973</td>\n",
       "      <td>0.009084</td>\n",
       "      <td>0.014652</td>\n",
       "      <td>0.022451</td>\n",
       "      <td>0.173708</td>\n",
       "      <td>0.121135</td>\n",
       "      <td>0.064102</td>\n",
       "      <td>0.035372</td>\n",
       "      <td>0.021079</td>\n",
       "      <td>0.012114</td>\n",
       "      <td>0.007437</td>\n",
       "      <td>0.021202</td>\n",
       "      <td>0.012864</td>\n",
       "      <td>0.025157</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020611</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>0.021079</td>\n",
       "      <td>0.021087</td>\n",
       "      <td>0.021035</td>\n",
       "      <td>0.021028</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.020493</td>\n",
       "      <td>0.020526</td>\n",
       "      <td>0.020592</td>\n",
       "      <td>0.020612</td>\n",
       "      <td>0.020695</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.021167</td>\n",
       "      <td>0.021317</td>\n",
       "      <td>0.021256</td>\n",
       "      <td>0.021237</td>\n",
       "      <td>0.021173</td>\n",
       "      <td>0.021219</td>\n",
       "      <td>0.021218</td>\n",
       "      <td>0.021238</td>\n",
       "      <td>0.021238</td>\n",
       "      <td>0.021201</td>\n",
       "      <td>0.021264</td>\n",
       "      <td>0.021225</td>\n",
       "      <td>0.021234</td>\n",
       "      <td>0.021319</td>\n",
       "      <td>0.021258</td>\n",
       "      <td>0.021287</td>\n",
       "      <td>0.021207</td>\n",
       "      <td>0.021255</td>\n",
       "      <td>0.021197</td>\n",
       "      <td>0.021211</td>\n",
       "      <td>0.021179</td>\n",
       "      <td>0.02115</td>\n",
       "      <td>0.021163</td>\n",
       "      <td>0.021133</td>\n",
       "      <td>0.021166</td>\n",
       "      <td>0.021162</td>\n",
       "      <td>0.021253</td>\n",
       "      <td>0.021272</td>\n",
       "      <td>0.021315</td>\n",
       "      <td>0.020483</td>\n",
       "      <td>0.020574</td>\n",
       "      <td>0.020635</td>\n",
       "      <td>0.02061</td>\n",
       "      <td>0.021128</td>\n",
       "      <td>0.021085</td>\n",
       "      <td>0.021104</td>\n",
       "      <td>0.021038</td>\n",
       "      <td>0.021123</td>\n",
       "      <td>0.021142</td>\n",
       "      <td>0.021125</td>\n",
       "      <td>0.021159</td>\n",
       "      <td>0.021188</td>\n",
       "      <td>0.021216</td>\n",
       "      <td>0.021275</td>\n",
       "      <td>0.021175</td>\n",
       "      <td>0.021218</td>\n",
       "      <td>0.021133</td>\n",
       "      <td>0.021153</td>\n",
       "      <td>0.021139</td>\n",
       "      <td>0.021052</td>\n",
       "      <td>0.021089</td>\n",
       "      <td>0.021076</td>\n",
       "      <td>0.021173</td>\n",
       "      <td>0.021169</td>\n",
       "      <td>0.021177</td>\n",
       "      <td>0.021209</td>\n",
       "      <td>0.021157</td>\n",
       "      <td>0.020897</td>\n",
       "      <td>0.021343</td>\n",
       "      <td>0.022104</td>\n",
       "      <td>0.022489</td>\n",
       "      <td>0.023464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules</th>\n",
       "      <td>14303.761229</td>\n",
       "      <td>32700.724679</td>\n",
       "      <td>52747.350103</td>\n",
       "      <td>80824.506502</td>\n",
       "      <td>625349.848478</td>\n",
       "      <td>436084.529304</td>\n",
       "      <td>230767.542556</td>\n",
       "      <td>127338.055234</td>\n",
       "      <td>75884.699531</td>\n",
       "      <td>43611.764042</td>\n",
       "      <td>26773.911916</td>\n",
       "      <td>76325.798731</td>\n",
       "      <td>46310.921387</td>\n",
       "      <td>90564.656156</td>\n",
       "      <td>75601.377686</td>\n",
       "      <td>74199.651611</td>\n",
       "      <td>76054.746039</td>\n",
       "      <td>75884.577747</td>\n",
       "      <td>75912.204543</td>\n",
       "      <td>75727.619266</td>\n",
       "      <td>75701.472545</td>\n",
       "      <td>75790.175016</td>\n",
       "      <td>73773.389464</td>\n",
       "      <td>73892.703968</td>\n",
       "      <td>74129.708593</td>\n",
       "      <td>74203.606308</td>\n",
       "      <td>74501.001648</td>\n",
       "      <td>75946.539604</td>\n",
       "      <td>76201.793024</td>\n",
       "      <td>76742.959091</td>\n",
       "      <td>76520.796084</td>\n",
       "      <td>76452.8938</td>\n",
       "      <td>76223.569931</td>\n",
       "      <td>76386.637887</td>\n",
       "      <td>76383.180866</td>\n",
       "      <td>76458.267707</td>\n",
       "      <td>76456.077645</td>\n",
       "      <td>76322.508765</td>\n",
       "      <td>76552.127557</td>\n",
       "      <td>76410.590357</td>\n",
       "      <td>76443.543844</td>\n",
       "      <td>76748.976626</td>\n",
       "      <td>76530.379229</td>\n",
       "      <td>76631.935788</td>\n",
       "      <td>76346.735078</td>\n",
       "      <td>76517.116778</td>\n",
       "      <td>76308.943626</td>\n",
       "      <td>76361.089511</td>\n",
       "      <td>76245.168806</td>\n",
       "      <td>76141.04486</td>\n",
       "      <td>76187.233345</td>\n",
       "      <td>76079.755405</td>\n",
       "      <td>76195.841449</td>\n",
       "      <td>76181.591128</td>\n",
       "      <td>76512.58586</td>\n",
       "      <td>76578.514995</td>\n",
       "      <td>76733.750114</td>\n",
       "      <td>73737.29051</td>\n",
       "      <td>74065.599056</td>\n",
       "      <td>74286.409458</td>\n",
       "      <td>74197.531957</td>\n",
       "      <td>76059.345286</td>\n",
       "      <td>75905.904876</td>\n",
       "      <td>75972.984254</td>\n",
       "      <td>75736.281912</td>\n",
       "      <td>76043.391166</td>\n",
       "      <td>76110.532775</td>\n",
       "      <td>76051.292784</td>\n",
       "      <td>76172.032345</td>\n",
       "      <td>76276.785887</td>\n",
       "      <td>76377.761846</td>\n",
       "      <td>76590.669268</td>\n",
       "      <td>76229.985716</td>\n",
       "      <td>76384.326872</td>\n",
       "      <td>76078.501706</td>\n",
       "      <td>76152.181146</td>\n",
       "      <td>76101.321315</td>\n",
       "      <td>75787.25771</td>\n",
       "      <td>75921.972142</td>\n",
       "      <td>75872.506432</td>\n",
       "      <td>76223.661305</td>\n",
       "      <td>76208.729832</td>\n",
       "      <td>76236.684702</td>\n",
       "      <td>76352.285347</td>\n",
       "      <td>76166.395123</td>\n",
       "      <td>75230.05363</td>\n",
       "      <td>76834.458713</td>\n",
       "      <td>79575.575957</td>\n",
       "      <td>80959.555151</td>\n",
       "      <td>84471.974521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops</th>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens_per_joule</th>\n",
       "      <td>1.145433</td>\n",
       "      <td>0.501029</td>\n",
       "      <td>0.310613</td>\n",
       "      <td>0.202711</td>\n",
       "      <td>0.023441</td>\n",
       "      <td>0.037341</td>\n",
       "      <td>0.070998</td>\n",
       "      <td>0.128665</td>\n",
       "      <td>0.215907</td>\n",
       "      <td>0.375678</td>\n",
       "      <td>0.611939</td>\n",
       "      <td>0.214659</td>\n",
       "      <td>0.353783</td>\n",
       "      <td>0.180909</td>\n",
       "      <td>0.216716</td>\n",
       "      <td>0.22081</td>\n",
       "      <td>0.215424</td>\n",
       "      <td>0.215907</td>\n",
       "      <td>0.215828</td>\n",
       "      <td>0.216354</td>\n",
       "      <td>0.216429</td>\n",
       "      <td>0.216176</td>\n",
       "      <td>0.222085</td>\n",
       "      <td>0.221727</td>\n",
       "      <td>0.221018</td>\n",
       "      <td>0.220798</td>\n",
       "      <td>0.219917</td>\n",
       "      <td>0.215731</td>\n",
       "      <td>0.215008</td>\n",
       "      <td>0.213492</td>\n",
       "      <td>0.214112</td>\n",
       "      <td>0.214302</td>\n",
       "      <td>0.214947</td>\n",
       "      <td>0.214488</td>\n",
       "      <td>0.214497</td>\n",
       "      <td>0.214287</td>\n",
       "      <td>0.214293</td>\n",
       "      <td>0.214668</td>\n",
       "      <td>0.214024</td>\n",
       "      <td>0.214421</td>\n",
       "      <td>0.214328</td>\n",
       "      <td>0.213475</td>\n",
       "      <td>0.214085</td>\n",
       "      <td>0.213801</td>\n",
       "      <td>0.2146</td>\n",
       "      <td>0.214122</td>\n",
       "      <td>0.214706</td>\n",
       "      <td>0.21456</td>\n",
       "      <td>0.214886</td>\n",
       "      <td>0.21518</td>\n",
       "      <td>0.215049</td>\n",
       "      <td>0.215353</td>\n",
       "      <td>0.215025</td>\n",
       "      <td>0.215065</td>\n",
       "      <td>0.214135</td>\n",
       "      <td>0.21395</td>\n",
       "      <td>0.213518</td>\n",
       "      <td>0.222194</td>\n",
       "      <td>0.221209</td>\n",
       "      <td>0.220552</td>\n",
       "      <td>0.220816</td>\n",
       "      <td>0.215411</td>\n",
       "      <td>0.215846</td>\n",
       "      <td>0.215656</td>\n",
       "      <td>0.21633</td>\n",
       "      <td>0.215456</td>\n",
       "      <td>0.215266</td>\n",
       "      <td>0.215434</td>\n",
       "      <td>0.215092</td>\n",
       "      <td>0.214797</td>\n",
       "      <td>0.214513</td>\n",
       "      <td>0.213916</td>\n",
       "      <td>0.214929</td>\n",
       "      <td>0.214494</td>\n",
       "      <td>0.215357</td>\n",
       "      <td>0.215148</td>\n",
       "      <td>0.215292</td>\n",
       "      <td>0.216184</td>\n",
       "      <td>0.215801</td>\n",
       "      <td>0.215941</td>\n",
       "      <td>0.214946</td>\n",
       "      <td>0.214988</td>\n",
       "      <td>0.21491</td>\n",
       "      <td>0.214584</td>\n",
       "      <td>0.215108</td>\n",
       "      <td>0.217785</td>\n",
       "      <td>0.213238</td>\n",
       "      <td>0.205892</td>\n",
       "      <td>0.202373</td>\n",
       "      <td>0.193958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_token</th>\n",
       "      <td>0.873032</td>\n",
       "      <td>1.995894</td>\n",
       "      <td>3.219443</td>\n",
       "      <td>4.933136</td>\n",
       "      <td>42.659789</td>\n",
       "      <td>26.779939</td>\n",
       "      <td>14.084933</td>\n",
       "      <td>7.772098</td>\n",
       "      <td>4.631634</td>\n",
       "      <td>2.661851</td>\n",
       "      <td>1.63415</td>\n",
       "      <td>4.658557</td>\n",
       "      <td>2.826594</td>\n",
       "      <td>5.527628</td>\n",
       "      <td>4.614342</td>\n",
       "      <td>4.528787</td>\n",
       "      <td>4.642013</td>\n",
       "      <td>4.631627</td>\n",
       "      <td>4.633313</td>\n",
       "      <td>4.622047</td>\n",
       "      <td>4.620451</td>\n",
       "      <td>4.625865</td>\n",
       "      <td>4.50277</td>\n",
       "      <td>4.510053</td>\n",
       "      <td>4.524518</td>\n",
       "      <td>4.529029</td>\n",
       "      <td>4.54718</td>\n",
       "      <td>4.635409</td>\n",
       "      <td>4.650988</td>\n",
       "      <td>4.684018</td>\n",
       "      <td>4.670459</td>\n",
       "      <td>4.666314</td>\n",
       "      <td>4.652318</td>\n",
       "      <td>4.66227</td>\n",
       "      <td>4.662059</td>\n",
       "      <td>4.666642</td>\n",
       "      <td>4.666509</td>\n",
       "      <td>4.658356</td>\n",
       "      <td>4.672371</td>\n",
       "      <td>4.663732</td>\n",
       "      <td>4.665744</td>\n",
       "      <td>4.684386</td>\n",
       "      <td>4.671044</td>\n",
       "      <td>4.677242</td>\n",
       "      <td>4.659835</td>\n",
       "      <td>4.670234</td>\n",
       "      <td>4.657528</td>\n",
       "      <td>4.660711</td>\n",
       "      <td>4.653636</td>\n",
       "      <td>4.647281</td>\n",
       "      <td>4.6501</td>\n",
       "      <td>4.64354</td>\n",
       "      <td>4.650625</td>\n",
       "      <td>4.649755</td>\n",
       "      <td>4.669958</td>\n",
       "      <td>4.673982</td>\n",
       "      <td>4.683456</td>\n",
       "      <td>4.500567</td>\n",
       "      <td>4.520605</td>\n",
       "      <td>4.534083</td>\n",
       "      <td>4.528658</td>\n",
       "      <td>4.642294</td>\n",
       "      <td>4.632929</td>\n",
       "      <td>4.637023</td>\n",
       "      <td>4.622576</td>\n",
       "      <td>4.64132</td>\n",
       "      <td>4.645418</td>\n",
       "      <td>4.641803</td>\n",
       "      <td>4.649172</td>\n",
       "      <td>4.655566</td>\n",
       "      <td>4.661729</td>\n",
       "      <td>4.674723</td>\n",
       "      <td>4.652709</td>\n",
       "      <td>4.662129</td>\n",
       "      <td>4.643463</td>\n",
       "      <td>4.64796</td>\n",
       "      <td>4.644856</td>\n",
       "      <td>4.625687</td>\n",
       "      <td>4.633909</td>\n",
       "      <td>4.63089</td>\n",
       "      <td>4.652323</td>\n",
       "      <td>4.651412</td>\n",
       "      <td>4.653118</td>\n",
       "      <td>4.660174</td>\n",
       "      <td>4.648828</td>\n",
       "      <td>4.591678</td>\n",
       "      <td>4.689603</td>\n",
       "      <td>4.856908</td>\n",
       "      <td>4.941379</td>\n",
       "      <td>5.15576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops_per_joule</th>\n",
       "      <td>1185000974.364989</td>\n",
       "      <td>518336249.72279</td>\n",
       "      <td>321342606.972544</td>\n",
       "      <td>209713263.05247</td>\n",
       "      <td>27104781.482585</td>\n",
       "      <td>38868544.637947</td>\n",
       "      <td>73450411.636865</td>\n",
       "      <td>133110019.326187</td>\n",
       "      <td>223364803.416953</td>\n",
       "      <td>388655936.426967</td>\n",
       "      <td>633077864.986458</td>\n",
       "      <td>222073941.90463</td>\n",
       "      <td>366003752.151563</td>\n",
       "      <td>187158784.81295</td>\n",
       "      <td>224201879.805033</td>\n",
       "      <td>228437339.327415</td>\n",
       "      <td>222865394.679583</td>\n",
       "      <td>223365161.886555</td>\n",
       "      <td>223283872.404349</td>\n",
       "      <td>223828124.501124</td>\n",
       "      <td>223905433.056266</td>\n",
       "      <td>223643381.078152</td>\n",
       "      <td>229757248.73563</td>\n",
       "      <td>229386259.846373</td>\n",
       "      <td>228652875.007557</td>\n",
       "      <td>228425164.711328</td>\n",
       "      <td>227513330.26575</td>\n",
       "      <td>223182926.853609</td>\n",
       "      <td>222435330.199059</td>\n",
       "      <td>220866789.524664</td>\n",
       "      <td>221508032.594712</td>\n",
       "      <td>221704766.827728</td>\n",
       "      <td>222371780.91456</td>\n",
       "      <td>221897068.152067</td>\n",
       "      <td>221907110.976747</td>\n",
       "      <td>221689184.198326</td>\n",
       "      <td>221695534.41967</td>\n",
       "      <td>222083514.646961</td>\n",
       "      <td>221417373.154566</td>\n",
       "      <td>221827509.955699</td>\n",
       "      <td>221731883.961792</td>\n",
       "      <td>220849472.375148</td>\n",
       "      <td>221480295.326627</td>\n",
       "      <td>221186778.315872</td>\n",
       "      <td>222013043.200503</td>\n",
       "      <td>221518683.752156</td>\n",
       "      <td>222122993.553691</td>\n",
       "      <td>221971308.970354</td>\n",
       "      <td>222308787.015928</td>\n",
       "      <td>222612797.398213</td>\n",
       "      <td>222477838.462899</td>\n",
       "      <td>222792133.111257</td>\n",
       "      <td>222452704.383082</td>\n",
       "      <td>222494315.782651</td>\n",
       "      <td>221531801.63285</td>\n",
       "      <td>221341077.118197</td>\n",
       "      <td>220893296.207842</td>\n",
       "      <td>229869729.08804</td>\n",
       "      <td>228850791.85564</td>\n",
       "      <td>228170551.204544</td>\n",
       "      <td>228443865.261377</td>\n",
       "      <td>222851918.188743</td>\n",
       "      <td>223302403.426195</td>\n",
       "      <td>223105241.417056</td>\n",
       "      <td>223802523.245601</td>\n",
       "      <td>222898673.155884</td>\n",
       "      <td>222702041.034166</td>\n",
       "      <td>222875514.308708</td>\n",
       "      <td>222522236.459516</td>\n",
       "      <td>222216638.996013</td>\n",
       "      <td>221922855.337331</td>\n",
       "      <td>221305952.215789</td>\n",
       "      <td>222353065.317298</td>\n",
       "      <td>221903781.669947</td>\n",
       "      <td>222795804.50584</td>\n",
       "      <td>222580243.115083</td>\n",
       "      <td>222728997.344947</td>\n",
       "      <td>223651989.862195</td>\n",
       "      <td>223255146.236354</td>\n",
       "      <td>223400699.280619</td>\n",
       "      <td>222371514.343019</td>\n",
       "      <td>222415083.292085</td>\n",
       "      <td>222333526.955779</td>\n",
       "      <td>221996904.429798</td>\n",
       "      <td>222538705.760019</td>\n",
       "      <td>225308506.046856</td>\n",
       "      <td>220603766.552551</td>\n",
       "      <td>213004691.317366</td>\n",
       "      <td>209363440.318309</td>\n",
       "      <td>200657923.402639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_flop</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_inference_time_sec</th>\n",
       "      <td>37.07336</td>\n",
       "      <td>37.114287</td>\n",
       "      <td>37.785984</td>\n",
       "      <td>37.507834</td>\n",
       "      <td>384.649219</td>\n",
       "      <td>292.383712</td>\n",
       "      <td>147.516985</td>\n",
       "      <td>74.266558</td>\n",
       "      <td>37.168908</td>\n",
       "      <td>18.70642</td>\n",
       "      <td>9.628563</td>\n",
       "      <td>22.945557</td>\n",
       "      <td>23.267255</td>\n",
       "      <td>72.234728</td>\n",
       "      <td>37.354927</td>\n",
       "      <td>36.263684</td>\n",
       "      <td>37.233629</td>\n",
       "      <td>36.712846</td>\n",
       "      <td>37.177409</td>\n",
       "      <td>37.286998</td>\n",
       "      <td>36.730154</td>\n",
       "      <td>36.862467</td>\n",
       "      <td>36.388011</td>\n",
       "      <td>36.456038</td>\n",
       "      <td>36.447105</td>\n",
       "      <td>36.306288</td>\n",
       "      <td>36.211281</td>\n",
       "      <td>37.147624</td>\n",
       "      <td>37.538299</td>\n",
       "      <td>37.345801</td>\n",
       "      <td>37.266966</td>\n",
       "      <td>37.24014</td>\n",
       "      <td>37.286302</td>\n",
       "      <td>37.472509</td>\n",
       "      <td>37.066333</td>\n",
       "      <td>37.176715</td>\n",
       "      <td>37.421394</td>\n",
       "      <td>36.979404</td>\n",
       "      <td>37.373825</td>\n",
       "      <td>37.459553</td>\n",
       "      <td>36.784267</td>\n",
       "      <td>37.335853</td>\n",
       "      <td>36.763149</td>\n",
       "      <td>37.198482</td>\n",
       "      <td>36.812719</td>\n",
       "      <td>37.283309</td>\n",
       "      <td>37.419533</td>\n",
       "      <td>37.420523</td>\n",
       "      <td>37.239923</td>\n",
       "      <td>37.278837</td>\n",
       "      <td>37.05608</td>\n",
       "      <td>36.896263</td>\n",
       "      <td>37.303935</td>\n",
       "      <td>37.005236</td>\n",
       "      <td>37.377651</td>\n",
       "      <td>37.014072</td>\n",
       "      <td>37.463349</td>\n",
       "      <td>36.610644</td>\n",
       "      <td>36.43053</td>\n",
       "      <td>36.471863</td>\n",
       "      <td>36.407234</td>\n",
       "      <td>37.230651</td>\n",
       "      <td>37.061346</td>\n",
       "      <td>36.947661</td>\n",
       "      <td>36.866788</td>\n",
       "      <td>36.912187</td>\n",
       "      <td>37.250632</td>\n",
       "      <td>36.874463</td>\n",
       "      <td>37.227124</td>\n",
       "      <td>36.74442</td>\n",
       "      <td>37.353906</td>\n",
       "      <td>36.856164</td>\n",
       "      <td>36.478415</td>\n",
       "      <td>36.804445</td>\n",
       "      <td>36.749301</td>\n",
       "      <td>37.267507</td>\n",
       "      <td>37.349722</td>\n",
       "      <td>36.404344</td>\n",
       "      <td>36.764964</td>\n",
       "      <td>36.751617</td>\n",
       "      <td>36.289531</td>\n",
       "      <td>36.688996</td>\n",
       "      <td>36.790459</td>\n",
       "      <td>36.692678</td>\n",
       "      <td>36.887141</td>\n",
       "      <td>36.504055</td>\n",
       "      <td>37.91957</td>\n",
       "      <td>40.774318</td>\n",
       "      <td>41.930226</td>\n",
       "      <td>45.240207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_latency_ms_per_batch</th>\n",
       "      <td>4634.170037</td>\n",
       "      <td>4639.28586</td>\n",
       "      <td>4723.248003</td>\n",
       "      <td>4688.479238</td>\n",
       "      <td>3005.072024</td>\n",
       "      <td>4568.495493</td>\n",
       "      <td>4609.905773</td>\n",
       "      <td>4641.65987</td>\n",
       "      <td>4646.113508</td>\n",
       "      <td>4676.605061</td>\n",
       "      <td>4814.281646</td>\n",
       "      <td>2868.194596</td>\n",
       "      <td>2908.406936</td>\n",
       "      <td>9029.341061</td>\n",
       "      <td>4669.365846</td>\n",
       "      <td>4532.960497</td>\n",
       "      <td>4654.203603</td>\n",
       "      <td>4589.105755</td>\n",
       "      <td>4647.176079</td>\n",
       "      <td>4660.874719</td>\n",
       "      <td>4591.269241</td>\n",
       "      <td>4607.80839</td>\n",
       "      <td>4548.501365</td>\n",
       "      <td>4557.004705</td>\n",
       "      <td>4555.888145</td>\n",
       "      <td>4538.285978</td>\n",
       "      <td>4526.410158</td>\n",
       "      <td>4643.452946</td>\n",
       "      <td>4692.287417</td>\n",
       "      <td>4668.225076</td>\n",
       "      <td>4658.370769</td>\n",
       "      <td>4655.01752</td>\n",
       "      <td>4660.787711</td>\n",
       "      <td>4684.063664</td>\n",
       "      <td>4633.29158</td>\n",
       "      <td>4647.089355</td>\n",
       "      <td>4677.674297</td>\n",
       "      <td>4622.425475</td>\n",
       "      <td>4671.72815</td>\n",
       "      <td>4682.444169</td>\n",
       "      <td>4598.03337</td>\n",
       "      <td>4666.981563</td>\n",
       "      <td>4595.393663</td>\n",
       "      <td>4649.810295</td>\n",
       "      <td>4601.58986</td>\n",
       "      <td>4660.413619</td>\n",
       "      <td>4677.441662</td>\n",
       "      <td>4677.565389</td>\n",
       "      <td>4654.990417</td>\n",
       "      <td>4659.854676</td>\n",
       "      <td>4632.01002</td>\n",
       "      <td>4612.032873</td>\n",
       "      <td>4662.991815</td>\n",
       "      <td>4625.654561</td>\n",
       "      <td>4672.206413</td>\n",
       "      <td>4626.75899</td>\n",
       "      <td>4682.918639</td>\n",
       "      <td>4576.330444</td>\n",
       "      <td>4553.816217</td>\n",
       "      <td>4558.982923</td>\n",
       "      <td>4550.904239</td>\n",
       "      <td>4653.831399</td>\n",
       "      <td>4632.668298</td>\n",
       "      <td>4618.457622</td>\n",
       "      <td>4608.348549</td>\n",
       "      <td>4614.023335</td>\n",
       "      <td>4656.328988</td>\n",
       "      <td>4609.307881</td>\n",
       "      <td>4653.39056</td>\n",
       "      <td>4593.052498</td>\n",
       "      <td>4669.238309</td>\n",
       "      <td>4607.020464</td>\n",
       "      <td>4559.80192</td>\n",
       "      <td>4600.555674</td>\n",
       "      <td>4593.6626</td>\n",
       "      <td>4658.438392</td>\n",
       "      <td>4668.715262</td>\n",
       "      <td>4550.543062</td>\n",
       "      <td>4595.620491</td>\n",
       "      <td>4593.952187</td>\n",
       "      <td>4536.191409</td>\n",
       "      <td>4586.124506</td>\n",
       "      <td>4598.807349</td>\n",
       "      <td>4586.584774</td>\n",
       "      <td>4610.892601</td>\n",
       "      <td>4563.006856</td>\n",
       "      <td>4739.946273</td>\n",
       "      <td>5096.789718</td>\n",
       "      <td>5241.278282</td>\n",
       "      <td>5655.025877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_queries_per_sec</th>\n",
       "      <td>3.452614</td>\n",
       "      <td>3.448807</td>\n",
       "      <td>3.387499</td>\n",
       "      <td>3.41262</td>\n",
       "      <td>0.332771</td>\n",
       "      <td>0.437781</td>\n",
       "      <td>0.867697</td>\n",
       "      <td>1.723521</td>\n",
       "      <td>3.443739</td>\n",
       "      <td>6.842571</td>\n",
       "      <td>13.29378</td>\n",
       "      <td>5.578422</td>\n",
       "      <td>5.501293</td>\n",
       "      <td>1.772001</td>\n",
       "      <td>3.42659</td>\n",
       "      <td>3.529702</td>\n",
       "      <td>3.437752</td>\n",
       "      <td>3.486518</td>\n",
       "      <td>3.442951</td>\n",
       "      <td>3.432832</td>\n",
       "      <td>3.484875</td>\n",
       "      <td>3.472367</td>\n",
       "      <td>3.517642</td>\n",
       "      <td>3.511078</td>\n",
       "      <td>3.511939</td>\n",
       "      <td>3.52556</td>\n",
       "      <td>3.53481</td>\n",
       "      <td>3.445712</td>\n",
       "      <td>3.409851</td>\n",
       "      <td>3.427427</td>\n",
       "      <td>3.434677</td>\n",
       "      <td>3.437151</td>\n",
       "      <td>3.432896</td>\n",
       "      <td>3.415837</td>\n",
       "      <td>3.453269</td>\n",
       "      <td>3.443015</td>\n",
       "      <td>3.420503</td>\n",
       "      <td>3.461386</td>\n",
       "      <td>3.424857</td>\n",
       "      <td>3.417019</td>\n",
       "      <td>3.479749</td>\n",
       "      <td>3.42834</td>\n",
       "      <td>3.481747</td>\n",
       "      <td>3.441001</td>\n",
       "      <td>3.477059</td>\n",
       "      <td>3.433172</td>\n",
       "      <td>3.420673</td>\n",
       "      <td>3.420583</td>\n",
       "      <td>3.437171</td>\n",
       "      <td>3.433583</td>\n",
       "      <td>3.454224</td>\n",
       "      <td>3.469186</td>\n",
       "      <td>3.431273</td>\n",
       "      <td>3.45897</td>\n",
       "      <td>3.424506</td>\n",
       "      <td>3.458144</td>\n",
       "      <td>3.416673</td>\n",
       "      <td>3.496251</td>\n",
       "      <td>3.513537</td>\n",
       "      <td>3.509555</td>\n",
       "      <td>3.515785</td>\n",
       "      <td>3.438027</td>\n",
       "      <td>3.453733</td>\n",
       "      <td>3.46436</td>\n",
       "      <td>3.47196</td>\n",
       "      <td>3.467689</td>\n",
       "      <td>3.436183</td>\n",
       "      <td>3.471237</td>\n",
       "      <td>3.438353</td>\n",
       "      <td>3.483522</td>\n",
       "      <td>3.426683</td>\n",
       "      <td>3.47296</td>\n",
       "      <td>3.508924</td>\n",
       "      <td>3.477841</td>\n",
       "      <td>3.483059</td>\n",
       "      <td>3.434627</td>\n",
       "      <td>3.427067</td>\n",
       "      <td>3.516064</td>\n",
       "      <td>3.481576</td>\n",
       "      <td>3.48284</td>\n",
       "      <td>3.527188</td>\n",
       "      <td>3.488784</td>\n",
       "      <td>3.479163</td>\n",
       "      <td>3.488434</td>\n",
       "      <td>3.470044</td>\n",
       "      <td>3.50646</td>\n",
       "      <td>3.375566</td>\n",
       "      <td>3.139231</td>\n",
       "      <td>3.05269</td>\n",
       "      <td>2.829342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_tokens_per_sec</th>\n",
       "      <td>441.934582</td>\n",
       "      <td>441.447253</td>\n",
       "      <td>433.599929</td>\n",
       "      <td>436.815414</td>\n",
       "      <td>38.110047</td>\n",
       "      <td>55.693937</td>\n",
       "      <td>111.065177</td>\n",
       "      <td>220.610736</td>\n",
       "      <td>440.798529</td>\n",
       "      <td>875.849029</td>\n",
       "      <td>1701.603812</td>\n",
       "      <td>714.038023</td>\n",
       "      <td>704.16556</td>\n",
       "      <td>226.816108</td>\n",
       "      <td>438.603457</td>\n",
       "      <td>451.801864</td>\n",
       "      <td>440.032318</td>\n",
       "      <td>446.274309</td>\n",
       "      <td>440.697741</td>\n",
       "      <td>439.402499</td>\n",
       "      <td>446.064017</td>\n",
       "      <td>444.462926</td>\n",
       "      <td>450.258192</td>\n",
       "      <td>449.418013</td>\n",
       "      <td>449.528157</td>\n",
       "      <td>451.271694</td>\n",
       "      <td>452.455683</td>\n",
       "      <td>441.051094</td>\n",
       "      <td>436.460902</td>\n",
       "      <td>438.710638</td>\n",
       "      <td>439.638685</td>\n",
       "      <td>439.95538</td>\n",
       "      <td>439.410702</td>\n",
       "      <td>437.227191</td>\n",
       "      <td>442.018372</td>\n",
       "      <td>440.705965</td>\n",
       "      <td>437.824412</td>\n",
       "      <td>443.057441</td>\n",
       "      <td>438.381673</td>\n",
       "      <td>437.378413</td>\n",
       "      <td>445.407816</td>\n",
       "      <td>438.827532</td>\n",
       "      <td>445.663669</td>\n",
       "      <td>440.448076</td>\n",
       "      <td>445.063568</td>\n",
       "      <td>439.445974</td>\n",
       "      <td>437.846188</td>\n",
       "      <td>437.834606</td>\n",
       "      <td>439.957941</td>\n",
       "      <td>439.498684</td>\n",
       "      <td>442.140667</td>\n",
       "      <td>444.055811</td>\n",
       "      <td>439.203001</td>\n",
       "      <td>442.74815</td>\n",
       "      <td>438.336798</td>\n",
       "      <td>442.642464</td>\n",
       "      <td>437.334098</td>\n",
       "      <td>447.520131</td>\n",
       "      <td>449.732686</td>\n",
       "      <td>449.223003</td>\n",
       "      <td>450.020456</td>\n",
       "      <td>440.067511</td>\n",
       "      <td>442.077841</td>\n",
       "      <td>443.438084</td>\n",
       "      <td>444.410829</td>\n",
       "      <td>443.864249</td>\n",
       "      <td>439.831465</td>\n",
       "      <td>444.318334</td>\n",
       "      <td>440.109201</td>\n",
       "      <td>445.890832</td>\n",
       "      <td>438.615437</td>\n",
       "      <td>444.538941</td>\n",
       "      <td>449.142317</td>\n",
       "      <td>445.163616</td>\n",
       "      <td>445.831612</td>\n",
       "      <td>439.632303</td>\n",
       "      <td>438.664576</td>\n",
       "      <td>450.056174</td>\n",
       "      <td>445.641672</td>\n",
       "      <td>445.803508</td>\n",
       "      <td>451.480067</td>\n",
       "      <td>446.564413</td>\n",
       "      <td>445.332854</td>\n",
       "      <td>446.5196</td>\n",
       "      <td>444.165626</td>\n",
       "      <td>448.826851</td>\n",
       "      <td>432.072408</td>\n",
       "      <td>401.821561</td>\n",
       "      <td>390.744374</td>\n",
       "      <td>362.155726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_usage_percent</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_memory_usage_bytes</th>\n",
       "      <td>2647629824</td>\n",
       "      <td>2650619904</td>\n",
       "      <td>2648543232</td>\n",
       "      <td>2675093504</td>\n",
       "      <td>2636230656</td>\n",
       "      <td>2641690624</td>\n",
       "      <td>2644770816</td>\n",
       "      <td>2623025152</td>\n",
       "      <td>2626736128</td>\n",
       "      <td>2625044480</td>\n",
       "      <td>2671489024</td>\n",
       "      <td>2012856320</td>\n",
       "      <td>3100921856</td>\n",
       "      <td>2724073472</td>\n",
       "      <td>2635046912</td>\n",
       "      <td>2635730944</td>\n",
       "      <td>2647302144</td>\n",
       "      <td>2669834240</td>\n",
       "      <td>2646908928</td>\n",
       "      <td>2602528768</td>\n",
       "      <td>2628485120</td>\n",
       "      <td>2651119616</td>\n",
       "      <td>2658959360</td>\n",
       "      <td>2661109760</td>\n",
       "      <td>2658758656</td>\n",
       "      <td>2679640064</td>\n",
       "      <td>2613747712</td>\n",
       "      <td>2676936704</td>\n",
       "      <td>2654609408</td>\n",
       "      <td>2630242304</td>\n",
       "      <td>2654191616</td>\n",
       "      <td>2631348224</td>\n",
       "      <td>2631778304</td>\n",
       "      <td>2632622080</td>\n",
       "      <td>2657443840</td>\n",
       "      <td>2584113152</td>\n",
       "      <td>2657779712</td>\n",
       "      <td>2653810688</td>\n",
       "      <td>2655776768</td>\n",
       "      <td>2629853184</td>\n",
       "      <td>2633043968</td>\n",
       "      <td>2654433280</td>\n",
       "      <td>2634059776</td>\n",
       "      <td>2631974912</td>\n",
       "      <td>2703769600</td>\n",
       "      <td>2629898240</td>\n",
       "      <td>2654392320</td>\n",
       "      <td>2698768384</td>\n",
       "      <td>2679017472</td>\n",
       "      <td>2653843456</td>\n",
       "      <td>2680303616</td>\n",
       "      <td>2592911360</td>\n",
       "      <td>2699710464</td>\n",
       "      <td>2629054464</td>\n",
       "      <td>2676060160</td>\n",
       "      <td>2679005184</td>\n",
       "      <td>2652667904</td>\n",
       "      <td>2638675968</td>\n",
       "      <td>2633592832</td>\n",
       "      <td>2657009664</td>\n",
       "      <td>2613207040</td>\n",
       "      <td>2558296064</td>\n",
       "      <td>2625011712</td>\n",
       "      <td>2649886720</td>\n",
       "      <td>2647212032</td>\n",
       "      <td>2652401664</td>\n",
       "      <td>2694619136</td>\n",
       "      <td>2651906048</td>\n",
       "      <td>2672742400</td>\n",
       "      <td>2628280320</td>\n",
       "      <td>2675462144</td>\n",
       "      <td>2673082368</td>\n",
       "      <td>2555088896</td>\n",
       "      <td>2555072512</td>\n",
       "      <td>2673180672</td>\n",
       "      <td>2674552832</td>\n",
       "      <td>2693410816</td>\n",
       "      <td>2628284416</td>\n",
       "      <td>2672754688</td>\n",
       "      <td>2672275456</td>\n",
       "      <td>2673119232</td>\n",
       "      <td>2648391680</td>\n",
       "      <td>2650079232</td>\n",
       "      <td>2672320512</td>\n",
       "      <td>2671546368</td>\n",
       "      <td>2672652288</td>\n",
       "      <td>2649559040</td>\n",
       "      <td>2599944192</td>\n",
       "      <td>2624958464</td>\n",
       "      <td>2628886528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_current_memory_allocated_bytes</th>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087681536</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>4419853312</td>\n",
       "      <td>1576560640</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_max_memory_allocated_bytes</th>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087681536</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>4419853312</td>\n",
       "      <td>1576560640</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_current_memory_reserved_bytes</th>\n",
       "      <td>1444937728</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1885339648</td>\n",
       "      <td>1895825408</td>\n",
       "      <td>1912602624</td>\n",
       "      <td>1937768448</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1883242496</td>\n",
       "      <td>1881145344</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>6870269952</td>\n",
       "      <td>2883584000</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_max_memory_reserved_bytes</th>\n",
       "      <td>1444937728</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1885339648</td>\n",
       "      <td>1895825408</td>\n",
       "      <td>1912602624</td>\n",
       "      <td>1937768448</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1883242496</td>\n",
       "      <td>1881145344</td>\n",
       "      <td>13212057600</td>\n",
       "      <td>6870269952</td>\n",
       "      <td>2883584000</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "      <td>1929379840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_0</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_0</th>\n",
       "      <td>46.225986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.183246</td>\n",
       "      <td>451.694772</td>\n",
       "      <td>1845.345078</td>\n",
       "      <td>265.284845</td>\n",
       "      <td>290.635406</td>\n",
       "      <td>352.295744</td>\n",
       "      <td>439.982222</td>\n",
       "      <td>501.808212</td>\n",
       "      <td>642.516502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>362.126674</td>\n",
       "      <td>193.829078</td>\n",
       "      <td>267.232863</td>\n",
       "      <td>359.580526</td>\n",
       "      <td>302.087739</td>\n",
       "      <td>454.091294</td>\n",
       "      <td>235.689028</td>\n",
       "      <td>363.206546</td>\n",
       "      <td>438.206965</td>\n",
       "      <td>406.354141</td>\n",
       "      <td>448.785248</td>\n",
       "      <td>272.436821</td>\n",
       "      <td>293.491565</td>\n",
       "      <td>365.781018</td>\n",
       "      <td>493.062977</td>\n",
       "      <td>374.044486</td>\n",
       "      <td>355.870535</td>\n",
       "      <td>373.705112</td>\n",
       "      <td>447.668445</td>\n",
       "      <td>414.377199</td>\n",
       "      <td>253.802369</td>\n",
       "      <td>293.892951</td>\n",
       "      <td>472.989506</td>\n",
       "      <td>681.945871</td>\n",
       "      <td>380.169962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>378.794745</td>\n",
       "      <td>286.888132</td>\n",
       "      <td>444.403374</td>\n",
       "      <td>381.472501</td>\n",
       "      <td>428.733319</td>\n",
       "      <td>471.585162</td>\n",
       "      <td>454.832486</td>\n",
       "      <td>422.869376</td>\n",
       "      <td>350.17244</td>\n",
       "      <td>332.57154</td>\n",
       "      <td>315.612174</td>\n",
       "      <td>317.363182</td>\n",
       "      <td>923.603729</td>\n",
       "      <td>409.629313</td>\n",
       "      <td>370.848616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>365.558725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>341.441136</td>\n",
       "      <td>353.872916</td>\n",
       "      <td>411.098243</td>\n",
       "      <td>376.405244</td>\n",
       "      <td>344.332748</td>\n",
       "      <td>375.385266</td>\n",
       "      <td>0.0</td>\n",
       "      <td>425.000045</td>\n",
       "      <td>380.762067</td>\n",
       "      <td>445.41549</td>\n",
       "      <td>413.456197</td>\n",
       "      <td>411.291746</td>\n",
       "      <td>432.770547</td>\n",
       "      <td>437.84975</td>\n",
       "      <td>307.025731</td>\n",
       "      <td>431.991203</td>\n",
       "      <td>426.052342</td>\n",
       "      <td>432.730412</td>\n",
       "      <td>456.365359</td>\n",
       "      <td>245.784553</td>\n",
       "      <td>328.204462</td>\n",
       "      <td>476.138974</td>\n",
       "      <td>438.794391</td>\n",
       "      <td>419.858841</td>\n",
       "      <td>400.198023</td>\n",
       "      <td>445.124742</td>\n",
       "      <td>451.422046</td>\n",
       "      <td>450.800113</td>\n",
       "      <td>429.573944</td>\n",
       "      <td>431.015804</td>\n",
       "      <td>448.648365</td>\n",
       "      <td>337.65622</td>\n",
       "      <td>376.718852</td>\n",
       "      <td>309.058879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>399.64369</td>\n",
       "      <td>477.04802</td>\n",
       "      <td>261.213255</td>\n",
       "      <td>288.828887</td>\n",
       "      <td>434.526793</td>\n",
       "      <td>350.458868</td>\n",
       "      <td>437.286475</td>\n",
       "      <td>463.419949</td>\n",
       "      <td>663.537588</td>\n",
       "      <td>509.372653</td>\n",
       "      <td>417.073609</td>\n",
       "      <td>236.358817</td>\n",
       "      <td>439.082005</td>\n",
       "      <td>327.361921</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.178394</td>\n",
       "      <td>432.353573</td>\n",
       "      <td>444.31133</td>\n",
       "      <td>448.409327</td>\n",
       "      <td>414.98603</td>\n",
       "      <td>431.225061</td>\n",
       "      <td>0.0</td>\n",
       "      <td>321.607445</td>\n",
       "      <td>336.929049</td>\n",
       "      <td>418.66132</td>\n",
       "      <td>357.389002</td>\n",
       "      <td>710.028922</td>\n",
       "      <td>475.346304</td>\n",
       "      <td>443.753415</td>\n",
       "      <td>430.509635</td>\n",
       "      <td>322.202524</td>\n",
       "      <td>442.729223</td>\n",
       "      <td>431.647898</td>\n",
       "      <td>442.044805</td>\n",
       "      <td>360.432497</td>\n",
       "      <td>384.668493</td>\n",
       "      <td>421.087609</td>\n",
       "      <td>452.731246</td>\n",
       "      <td>411.347198</td>\n",
       "      <td>424.145908</td>\n",
       "      <td>379.261541</td>\n",
       "      <td>413.624059</td>\n",
       "      <td>376.897919</td>\n",
       "      <td>351.581952</td>\n",
       "      <td>430.551457</td>\n",
       "      <td>555.220912</td>\n",
       "      <td>380.306061</td>\n",
       "      <td>314.05251</td>\n",
       "      <td>421.616476</td>\n",
       "      <td>419.143394</td>\n",
       "      <td>319.021322</td>\n",
       "      <td>329.05223</td>\n",
       "      <td>301.527197</td>\n",
       "      <td>604.912311</td>\n",
       "      <td>372.392172</td>\n",
       "      <td>455.482798</td>\n",
       "      <td>336.623811</td>\n",
       "      <td>373.782196</td>\n",
       "      <td>456.835957</td>\n",
       "      <td>443.886307</td>\n",
       "      <td>428.80165</td>\n",
       "      <td>441.49472</td>\n",
       "      <td>340.201984</td>\n",
       "      <td>450.618838</td>\n",
       "      <td>387.108096</td>\n",
       "      <td>431.420727</td>\n",
       "      <td>340.506848</td>\n",
       "      <td>439.351263</td>\n",
       "      <td>1204.841478</td>\n",
       "      <td>382.490162</td>\n",
       "      <td>12.641982</td>\n",
       "      <td>427.414799</td>\n",
       "      <td>427.11676</td>\n",
       "      <td>444.236215</td>\n",
       "      <td>394.972737</td>\n",
       "      <td>362.422683</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>436.921184</td>\n",
       "      <td>438.908964</td>\n",
       "      <td>355.115024</td>\n",
       "      <td>445.062316</td>\n",
       "      <td>308.730628</td>\n",
       "      <td>0.0</td>\n",
       "      <td>428.929856</td>\n",
       "      <td>514.105205</td>\n",
       "      <td>398.189354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.580037</td>\n",
       "      <td>439.561195</td>\n",
       "      <td>263.932183</td>\n",
       "      <td>248.949736</td>\n",
       "      <td>451.202191</td>\n",
       "      <td>295.6267</td>\n",
       "      <td>442.64908</td>\n",
       "      <td>527.83864</td>\n",
       "      <td>702.517296</td>\n",
       "      <td>568.81121</td>\n",
       "      <td>357.376814</td>\n",
       "      <td>185.554921</td>\n",
       "      <td>445.149606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326.411876</td>\n",
       "      <td>264.541795</td>\n",
       "      <td>438.480677</td>\n",
       "      <td>419.13896</td>\n",
       "      <td>397.175881</td>\n",
       "      <td>434.662371</td>\n",
       "      <td>388.546261</td>\n",
       "      <td>436.518678</td>\n",
       "      <td>446.047604</td>\n",
       "      <td>451.461048</td>\n",
       "      <td>439.924221</td>\n",
       "      <td>457.55603</td>\n",
       "      <td>422.8812</td>\n",
       "      <td>709.266375</td>\n",
       "      <td>347.897411</td>\n",
       "      <td>217.730738</td>\n",
       "      <td>788.632968</td>\n",
       "      <td>430.09949</td>\n",
       "      <td>276.181221</td>\n",
       "      <td>405.337089</td>\n",
       "      <td>358.542013</td>\n",
       "      <td>0.0</td>\n",
       "      <td>403.9071</td>\n",
       "      <td>205.681321</td>\n",
       "      <td>433.282785</td>\n",
       "      <td>501.46862</td>\n",
       "      <td>317.722844</td>\n",
       "      <td>350.06484</td>\n",
       "      <td>447.825164</td>\n",
       "      <td>382.79563</td>\n",
       "      <td>426.893541</td>\n",
       "      <td>408.893764</td>\n",
       "      <td>433.474075</td>\n",
       "      <td>437.565913</td>\n",
       "      <td>433.767904</td>\n",
       "      <td>318.393244</td>\n",
       "      <td>433.132011</td>\n",
       "      <td>443.837625</td>\n",
       "      <td>392.778899</td>\n",
       "      <td>5198.2261</td>\n",
       "      <td>404.575946</td>\n",
       "      <td>402.717465</td>\n",
       "      <td>403.492869</td>\n",
       "      <td>396.841016</td>\n",
       "      <td>337.791822</td>\n",
       "      <td>415.740948</td>\n",
       "      <td>443.799849</td>\n",
       "      <td>422.595054</td>\n",
       "      <td>429.670529</td>\n",
       "      <td>438.602573</td>\n",
       "      <td>689.256646</td>\n",
       "      <td>372.684177</td>\n",
       "      <td>431.038816</td>\n",
       "      <td>444.262083</td>\n",
       "      <td>274.373239</td>\n",
       "      <td>286.593649</td>\n",
       "      <td>398.274054</td>\n",
       "      <td>460.131541</td>\n",
       "      <td>445.320858</td>\n",
       "      <td>395.181999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>414.978827</td>\n",
       "      <td>727.718023</td>\n",
       "      <td>628.77378</td>\n",
       "      <td>6.11526</td>\n",
       "      <td>442.085655</td>\n",
       "      <td>447.852378</td>\n",
       "      <td>0.0</td>\n",
       "      <td>421.010265</td>\n",
       "      <td>250.559542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>368.508736</td>\n",
       "      <td>251.841776</td>\n",
       "      <td>337.432713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>444.909567</td>\n",
       "      <td>394.862299</td>\n",
       "      <td>271.286759</td>\n",
       "      <td>256.887233</td>\n",
       "      <td>282.546732</td>\n",
       "      <td>3154.237128</td>\n",
       "      <td>474.98016</td>\n",
       "      <td>702.630409</td>\n",
       "      <td>670.634727</td>\n",
       "      <td>430.279538</td>\n",
       "      <td>201.721599</td>\n",
       "      <td>378.632031</td>\n",
       "      <td>378.216056</td>\n",
       "      <td>309.987301</td>\n",
       "      <td>423.814648</td>\n",
       "      <td>450.938784</td>\n",
       "      <td>424.590529</td>\n",
       "      <td>439.503886</td>\n",
       "      <td>438.774828</td>\n",
       "      <td>432.888458</td>\n",
       "      <td>433.034685</td>\n",
       "      <td>431.404266</td>\n",
       "      <td>844.810036</td>\n",
       "      <td>378.392652</td>\n",
       "      <td>282.526495</td>\n",
       "      <td>425.038283</td>\n",
       "      <td>492.315839</td>\n",
       "      <td>299.915257</td>\n",
       "      <td>392.364762</td>\n",
       "      <td>425.226577</td>\n",
       "      <td>291.424554</td>\n",
       "      <td>276.742668</td>\n",
       "      <td>494.849394</td>\n",
       "      <td>459.866345</td>\n",
       "      <td>422.775592</td>\n",
       "      <td>0.0</td>\n",
       "      <td>437.881287</td>\n",
       "      <td>428.922265</td>\n",
       "      <td>434.36206</td>\n",
       "      <td>300.439741</td>\n",
       "      <td>391.020891</td>\n",
       "      <td>1022.440557</td>\n",
       "      <td>436.966932</td>\n",
       "      <td>367.019625</td>\n",
       "      <td>320.670686</td>\n",
       "      <td>1022.682414</td>\n",
       "      <td>449.57104</td>\n",
       "      <td>430.846078</td>\n",
       "      <td>449.450306</td>\n",
       "      <td>333.298957</td>\n",
       "      <td>349.028145</td>\n",
       "      <td>448.710971</td>\n",
       "      <td>409.635373</td>\n",
       "      <td>454.676106</td>\n",
       "      <td>1092.538148</td>\n",
       "      <td>356.210935</td>\n",
       "      <td>393.136317</td>\n",
       "      <td>431.560015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>302.861984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>438.038049</td>\n",
       "      <td>317.23646</td>\n",
       "      <td>566.217033</td>\n",
       "      <td>368.749821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>443.027977</td>\n",
       "      <td>480.286978</td>\n",
       "      <td>298.200071</td>\n",
       "      <td>441.41002</td>\n",
       "      <td>430.263947</td>\n",
       "      <td>435.171874</td>\n",
       "      <td>402.054679</td>\n",
       "      <td>412.025386</td>\n",
       "      <td>418.59568</td>\n",
       "      <td>329.798916</td>\n",
       "      <td>444.463343</td>\n",
       "      <td>5.655757</td>\n",
       "      <td>338.88163</td>\n",
       "      <td>427.502269</td>\n",
       "      <td>319.781654</td>\n",
       "      <td>394.510423</td>\n",
       "      <td>425.939771</td>\n",
       "      <td>437.76301</td>\n",
       "      <td>359.454104</td>\n",
       "      <td>391.040796</td>\n",
       "      <td>299.517947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_0</th>\n",
       "      <td>0.923219</td>\n",
       "      <td>0.924698</td>\n",
       "      <td>0.924637</td>\n",
       "      <td>0.933897</td>\n",
       "      <td>0.920484</td>\n",
       "      <td>0.921799</td>\n",
       "      <td>0.92254</td>\n",
       "      <td>0.915296</td>\n",
       "      <td>0.916314</td>\n",
       "      <td>0.915423</td>\n",
       "      <td>0.932818</td>\n",
       "      <td>0.701127</td>\n",
       "      <td>1.080447</td>\n",
       "      <td>0.951005</td>\n",
       "      <td>0.919427</td>\n",
       "      <td>0.92031</td>\n",
       "      <td>0.923415</td>\n",
       "      <td>0.931688</td>\n",
       "      <td>0.92351</td>\n",
       "      <td>0.907567</td>\n",
       "      <td>0.916924</td>\n",
       "      <td>0.925408</td>\n",
       "      <td>0.927464</td>\n",
       "      <td>0.928555</td>\n",
       "      <td>0.927516</td>\n",
       "      <td>0.935623</td>\n",
       "      <td>0.91227</td>\n",
       "      <td>0.933765</td>\n",
       "      <td>0.925947</td>\n",
       "      <td>0.917373</td>\n",
       "      <td>0.926202</td>\n",
       "      <td>0.918586</td>\n",
       "      <td>0.918288</td>\n",
       "      <td>0.918451</td>\n",
       "      <td>0.926745</td>\n",
       "      <td>0.901388</td>\n",
       "      <td>0.927495</td>\n",
       "      <td>0.926713</td>\n",
       "      <td>0.926691</td>\n",
       "      <td>0.91753</td>\n",
       "      <td>0.918727</td>\n",
       "      <td>0.926329</td>\n",
       "      <td>0.918722</td>\n",
       "      <td>0.918401</td>\n",
       "      <td>0.944009</td>\n",
       "      <td>0.917481</td>\n",
       "      <td>0.926548</td>\n",
       "      <td>0.941749</td>\n",
       "      <td>0.934743</td>\n",
       "      <td>0.926358</td>\n",
       "      <td>0.934792</td>\n",
       "      <td>0.904341</td>\n",
       "      <td>0.941528</td>\n",
       "      <td>0.917044</td>\n",
       "      <td>0.933247</td>\n",
       "      <td>0.934845</td>\n",
       "      <td>0.925129</td>\n",
       "      <td>0.920481</td>\n",
       "      <td>0.919137</td>\n",
       "      <td>0.927572</td>\n",
       "      <td>0.911714</td>\n",
       "      <td>0.892061</td>\n",
       "      <td>0.916095</td>\n",
       "      <td>0.925326</td>\n",
       "      <td>0.923743</td>\n",
       "      <td>0.925705</td>\n",
       "      <td>0.940257</td>\n",
       "      <td>0.926033</td>\n",
       "      <td>0.932319</td>\n",
       "      <td>0.917496</td>\n",
       "      <td>0.933888</td>\n",
       "      <td>0.933469</td>\n",
       "      <td>0.891782</td>\n",
       "      <td>0.891947</td>\n",
       "      <td>0.932426</td>\n",
       "      <td>0.933356</td>\n",
       "      <td>0.940112</td>\n",
       "      <td>0.916853</td>\n",
       "      <td>0.932661</td>\n",
       "      <td>0.932034</td>\n",
       "      <td>0.93329</td>\n",
       "      <td>0.924657</td>\n",
       "      <td>0.925435</td>\n",
       "      <td>0.933163</td>\n",
       "      <td>0.932327</td>\n",
       "      <td>0.933257</td>\n",
       "      <td>0.924099</td>\n",
       "      <td>0.907279</td>\n",
       "      <td>0.916534</td>\n",
       "      <td>0.916922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.974962</td>\n",
       "      <td>0.979108</td>\n",
       "      <td>0.967558</td>\n",
       "      <td>0.957427</td>\n",
       "      <td>0.972463</td>\n",
       "      <td>0.958551</td>\n",
       "      <td>0.969581</td>\n",
       "      <td>0.959045</td>\n",
       "      <td>0.972944</td>\n",
       "      <td>0.970612</td>\n",
       "      <td>0.647849</td>\n",
       "      <td>0.879257</td>\n",
       "      <td>0.98946</td>\n",
       "      <td>0.935027</td>\n",
       "      <td>0.97417</td>\n",
       "      <td>0.97847</td>\n",
       "      <td>0.975049</td>\n",
       "      <td>0.983285</td>\n",
       "      <td>0.969295</td>\n",
       "      <td>0.970323</td>\n",
       "      <td>0.97565</td>\n",
       "      <td>0.972663</td>\n",
       "      <td>0.971523</td>\n",
       "      <td>0.954426</td>\n",
       "      <td>0.955655</td>\n",
       "      <td>0.946471</td>\n",
       "      <td>0.960453</td>\n",
       "      <td>0.971366</td>\n",
       "      <td>0.96142</td>\n",
       "      <td>0.977783</td>\n",
       "      <td>0.971503</td>\n",
       "      <td>0.986293</td>\n",
       "      <td>0.976789</td>\n",
       "      <td>0.976504</td>\n",
       "      <td>0.978292</td>\n",
       "      <td>0.980896</td>\n",
       "      <td>0.963976</td>\n",
       "      <td>0.976686</td>\n",
       "      <td>0.979952</td>\n",
       "      <td>0.961384</td>\n",
       "      <td>0.968472</td>\n",
       "      <td>0.980553</td>\n",
       "      <td>0.983927</td>\n",
       "      <td>0.954592</td>\n",
       "      <td>0.985913</td>\n",
       "      <td>0.984175</td>\n",
       "      <td>0.967901</td>\n",
       "      <td>0.953061</td>\n",
       "      <td>0.986286</td>\n",
       "      <td>0.972486</td>\n",
       "      <td>0.971967</td>\n",
       "      <td>0.978151</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.965379</td>\n",
       "      <td>0.981613</td>\n",
       "      <td>0.980614</td>\n",
       "      <td>0.962577</td>\n",
       "      <td>0.964226</td>\n",
       "      <td>0.964715</td>\n",
       "      <td>0.974084</td>\n",
       "      <td>0.970702</td>\n",
       "      <td>0.975101</td>\n",
       "      <td>0.979301</td>\n",
       "      <td>0.975008</td>\n",
       "      <td>0.973769</td>\n",
       "      <td>0.97764</td>\n",
       "      <td>0.968097</td>\n",
       "      <td>0.968764</td>\n",
       "      <td>0.97891</td>\n",
       "      <td>0.971193</td>\n",
       "      <td>0.950386</td>\n",
       "      <td>0.978639</td>\n",
       "      <td>0.97508</td>\n",
       "      <td>0.979026</td>\n",
       "      <td>0.966282</td>\n",
       "      <td>0.967378</td>\n",
       "      <td>0.975384</td>\n",
       "      <td>0.966641</td>\n",
       "      <td>0.97876</td>\n",
       "      <td>0.977371</td>\n",
       "      <td>0.978248</td>\n",
       "      <td>0.97839</td>\n",
       "      <td>0.958782</td>\n",
       "      <td>0.967273</td>\n",
       "      <td>0.960325</td>\n",
       "      <td>0.971034</td>\n",
       "      <td>0.976394</td>\n",
       "      <td>0.967009</td>\n",
       "      <td>0.975125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.959252</td>\n",
       "      <td>0.975623</td>\n",
       "      <td>0.970041</td>\n",
       "      <td>0.958992</td>\n",
       "      <td>0.981384</td>\n",
       "      <td>0.96701</td>\n",
       "      <td>0.977444</td>\n",
       "      <td>0.975926</td>\n",
       "      <td>0.97516</td>\n",
       "      <td>0.651335</td>\n",
       "      <td>0.871181</td>\n",
       "      <td>0.98913</td>\n",
       "      <td>0.959318</td>\n",
       "      <td>0.96314</td>\n",
       "      <td>0.968931</td>\n",
       "      <td>0.978212</td>\n",
       "      <td>0.970443</td>\n",
       "      <td>0.976447</td>\n",
       "      <td>0.976032</td>\n",
       "      <td>0.966662</td>\n",
       "      <td>0.954529</td>\n",
       "      <td>0.95418</td>\n",
       "      <td>0.974506</td>\n",
       "      <td>0.960734</td>\n",
       "      <td>0.971133</td>\n",
       "      <td>0.979754</td>\n",
       "      <td>0.978035</td>\n",
       "      <td>0.976421</td>\n",
       "      <td>0.968572</td>\n",
       "      <td>0.98462</td>\n",
       "      <td>0.96053</td>\n",
       "      <td>0.945581</td>\n",
       "      <td>0.961812</td>\n",
       "      <td>0.979966</td>\n",
       "      <td>0.979702</td>\n",
       "      <td>0.981365</td>\n",
       "      <td>0.959756</td>\n",
       "      <td>0.98504</td>\n",
       "      <td>0.972659</td>\n",
       "      <td>0.963116</td>\n",
       "      <td>0.963903</td>\n",
       "      <td>0.977972</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>0.976903</td>\n",
       "      <td>0.978172</td>\n",
       "      <td>0.961749</td>\n",
       "      <td>0.98567</td>\n",
       "      <td>0.980696</td>\n",
       "      <td>0.971967</td>\n",
       "      <td>0.960423</td>\n",
       "      <td>0.961812</td>\n",
       "      <td>0.976028</td>\n",
       "      <td>0.960342</td>\n",
       "      <td>0.963628</td>\n",
       "      <td>0.975812</td>\n",
       "      <td>0.954326</td>\n",
       "      <td>0.945306</td>\n",
       "      <td>0.972187</td>\n",
       "      <td>0.970469</td>\n",
       "      <td>0.97094</td>\n",
       "      <td>0.970745</td>\n",
       "      <td>0.975157</td>\n",
       "      <td>0.975384</td>\n",
       "      <td>0.959013</td>\n",
       "      <td>0.979092</td>\n",
       "      <td>0.958949</td>\n",
       "      <td>0.967794</td>\n",
       "      <td>0.958819</td>\n",
       "      <td>0.951211</td>\n",
       "      <td>0.970722</td>\n",
       "      <td>0.959099</td>\n",
       "      <td>0.970475</td>\n",
       "      <td>0.96735</td>\n",
       "      <td>0.975263</td>\n",
       "      <td>0.975361</td>\n",
       "      <td>0.97452</td>\n",
       "      <td>0.975077</td>\n",
       "      <td>0.975183</td>\n",
       "      <td>0.971103</td>\n",
       "      <td>0.971146</td>\n",
       "      <td>0.962791</td>\n",
       "      <td>0.958433</td>\n",
       "      <td>0.975482</td>\n",
       "      <td>0.978653</td>\n",
       "      <td>0.966449</td>\n",
       "      <td>0.968425</td>\n",
       "      <td>0.960388</td>\n",
       "      <td>0.978689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.958188</td>\n",
       "      <td>0.95641</td>\n",
       "      <td>0.975244</td>\n",
       "      <td>0.969596</td>\n",
       "      <td>0.966668</td>\n",
       "      <td>0.966551</td>\n",
       "      <td>0.974513</td>\n",
       "      <td>0.941787</td>\n",
       "      <td>0.655709</td>\n",
       "      <td>0.882301</td>\n",
       "      <td>0.978004</td>\n",
       "      <td>0.975047</td>\n",
       "      <td>0.954191</td>\n",
       "      <td>0.978478</td>\n",
       "      <td>0.967136</td>\n",
       "      <td>0.978328</td>\n",
       "      <td>0.970631</td>\n",
       "      <td>0.974958</td>\n",
       "      <td>0.959171</td>\n",
       "      <td>0.966505</td>\n",
       "      <td>0.961859</td>\n",
       "      <td>0.966983</td>\n",
       "      <td>0.954899</td>\n",
       "      <td>0.962502</td>\n",
       "      <td>0.976695</td>\n",
       "      <td>0.980337</td>\n",
       "      <td>0.959867</td>\n",
       "      <td>0.968442</td>\n",
       "      <td>0.97154</td>\n",
       "      <td>0.96832</td>\n",
       "      <td>0.968677</td>\n",
       "      <td>0.967459</td>\n",
       "      <td>0.972433</td>\n",
       "      <td>0.960255</td>\n",
       "      <td>0.961176</td>\n",
       "      <td>0.976587</td>\n",
       "      <td>0.976274</td>\n",
       "      <td>0.968619</td>\n",
       "      <td>0.978915</td>\n",
       "      <td>0.980208</td>\n",
       "      <td>0.968333</td>\n",
       "      <td>0.976315</td>\n",
       "      <td>0.968366</td>\n",
       "      <td>0.972176</td>\n",
       "      <td>0.96798</td>\n",
       "      <td>0.980298</td>\n",
       "      <td>0.960148</td>\n",
       "      <td>0.984993</td>\n",
       "      <td>0.980103</td>\n",
       "      <td>0.971927</td>\n",
       "      <td>0.979986</td>\n",
       "      <td>0.972628</td>\n",
       "      <td>0.968555</td>\n",
       "      <td>0.961116</td>\n",
       "      <td>0.974882</td>\n",
       "      <td>0.969814</td>\n",
       "      <td>0.957418</td>\n",
       "      <td>0.969471</td>\n",
       "      <td>0.950123</td>\n",
       "      <td>0.959052</td>\n",
       "      <td>0.959023</td>\n",
       "      <td>0.95885</td>\n",
       "      <td>0.978872</td>\n",
       "      <td>0.961999</td>\n",
       "      <td>0.974575</td>\n",
       "      <td>0.95017</td>\n",
       "      <td>0.976079</td>\n",
       "      <td>0.971163</td>\n",
       "      <td>0.978679</td>\n",
       "      <td>0.96194</td>\n",
       "      <td>0.969779</td>\n",
       "      <td>0.977466</td>\n",
       "      <td>0.959431</td>\n",
       "      <td>0.975379</td>\n",
       "      <td>0.97675</td>\n",
       "      <td>0.974532</td>\n",
       "      <td>0.968601</td>\n",
       "      <td>0.969011</td>\n",
       "      <td>0.974924</td>\n",
       "      <td>0.966389</td>\n",
       "      <td>0.966486</td>\n",
       "      <td>0.974414</td>\n",
       "      <td>0.978829</td>\n",
       "      <td>0.97928</td>\n",
       "      <td>0.974869</td>\n",
       "      <td>0.975692</td>\n",
       "      <td>0.975831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_0</th>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.00118</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>0.001025</td>\n",
       "      <td>0.01072</td>\n",
       "      <td>0.009017</td>\n",
       "      <td>0.004551</td>\n",
       "      <td>0.002237</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.00058</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.00115</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.00116</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.00114</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.00114</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.00113</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.001259</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>0.001398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001179</td>\n",
       "      <td>0.000921</td>\n",
       "      <td>0.001016</td>\n",
       "      <td>0.010701</td>\n",
       "      <td>0.009048</td>\n",
       "      <td>0.004503</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.000581</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000728</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.00227</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.00115</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.00114</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.00114</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.00115</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.001167</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.00112</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.00113</td>\n",
       "      <td>0.00115</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.00114</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.00113</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001208</td>\n",
       "      <td>0.001224</td>\n",
       "      <td>0.001274</td>\n",
       "      <td>0.001375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000913</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.010694</td>\n",
       "      <td>0.009147</td>\n",
       "      <td>0.004559</td>\n",
       "      <td>0.00224</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000718</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.002257</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.00114</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.001119</td>\n",
       "      <td>0.001121</td>\n",
       "      <td>0.001106</td>\n",
       "      <td>0.001112</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.001141</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.00115</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.001169</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.001143</td>\n",
       "      <td>0.00114</td>\n",
       "      <td>0.00115</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.00113</td>\n",
       "      <td>0.00114</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.001138</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.00114</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.001177</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.00115</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.001254</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.001408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001066</td>\n",
       "      <td>0.010674</td>\n",
       "      <td>0.008998</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>0.002264</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.002235</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.001135</td>\n",
       "      <td>0.00114</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>0.00111</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.001117</td>\n",
       "      <td>0.001124</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.001142</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.00115</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.00115</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.001162</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.00114</td>\n",
       "      <td>0.001114</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>0.001103</td>\n",
       "      <td>0.001172</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>0.001148</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.001153</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001131</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.001133</td>\n",
       "      <td>0.00114</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.001134</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.001155</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.001149</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.00116</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.00117</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.001283</td>\n",
       "      <td>0.001436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_0</th>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.004005</td>\n",
       "      <td>0.004561</td>\n",
       "      <td>0.032477</td>\n",
       "      <td>0.021072</td>\n",
       "      <td>0.01144</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.001563</td>\n",
       "      <td>0.004537</td>\n",
       "      <td>0.002521</td>\n",
       "      <td>0.003987</td>\n",
       "      <td>0.00413</td>\n",
       "      <td>0.004023</td>\n",
       "      <td>0.004121</td>\n",
       "      <td>0.004083</td>\n",
       "      <td>0.00414</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>0.004042</td>\n",
       "      <td>0.004042</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>0.004141</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.004172</td>\n",
       "      <td>0.004174</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.004151</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.004126</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.00416</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>0.00415</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.004005</td>\n",
       "      <td>0.004005</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>0.00404</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.004138</td>\n",
       "      <td>0.004141</td>\n",
       "      <td>0.00411</td>\n",
       "      <td>0.004141</td>\n",
       "      <td>0.00412</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>0.00413</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.004166</td>\n",
       "      <td>0.004073</td>\n",
       "      <td>0.00408</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>0.00406</td>\n",
       "      <td>0.00412</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>0.004347</td>\n",
       "      <td>0.00443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003353</td>\n",
       "      <td>0.003928</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.032675</td>\n",
       "      <td>0.021143</td>\n",
       "      <td>0.011337</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.00411</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.004602</td>\n",
       "      <td>0.002489</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>0.004074</td>\n",
       "      <td>0.004033</td>\n",
       "      <td>0.004111</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.004118</td>\n",
       "      <td>0.004061</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>0.004014</td>\n",
       "      <td>0.004042</td>\n",
       "      <td>0.004063</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.004128</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.004146</td>\n",
       "      <td>0.00413</td>\n",
       "      <td>0.00416</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.00416</td>\n",
       "      <td>0.00416</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.00414</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>0.00402</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>0.004114</td>\n",
       "      <td>0.00411</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0.00418</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>0.00417</td>\n",
       "      <td>0.00417</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.00411</td>\n",
       "      <td>0.00409</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.00416</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>0.004099</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.00428</td>\n",
       "      <td>0.00437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003924</td>\n",
       "      <td>0.004569</td>\n",
       "      <td>0.032842</td>\n",
       "      <td>0.021438</td>\n",
       "      <td>0.011484</td>\n",
       "      <td>0.006569</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.001554</td>\n",
       "      <td>0.004562</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>0.004039</td>\n",
       "      <td>0.004074</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.004122</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>0.004126</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>0.004003</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.00403</td>\n",
       "      <td>0.004002</td>\n",
       "      <td>0.004013</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004189</td>\n",
       "      <td>0.00415</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>0.004128</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.004169</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.004148</td>\n",
       "      <td>0.004164</td>\n",
       "      <td>0.00416</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.004175</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.004124</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.004087</td>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.004175</td>\n",
       "      <td>0.003993</td>\n",
       "      <td>0.003999</td>\n",
       "      <td>0.004037</td>\n",
       "      <td>0.004069</td>\n",
       "      <td>0.004118</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.004114</td>\n",
       "      <td>0.004125</td>\n",
       "      <td>0.004112</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.004122</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.004166</td>\n",
       "      <td>0.004127</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.00417</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.004121</td>\n",
       "      <td>0.00411</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.004145</td>\n",
       "      <td>0.00413</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>0.004295</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>0.004469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.032593</td>\n",
       "      <td>0.021032</td>\n",
       "      <td>0.011524</td>\n",
       "      <td>0.006649</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.001559</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.00246</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>0.004013</td>\n",
       "      <td>0.004114</td>\n",
       "      <td>0.004087</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.004104</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.003995</td>\n",
       "      <td>0.003976</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>0.004062</td>\n",
       "      <td>0.004177</td>\n",
       "      <td>0.00413</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004172</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.00414</td>\n",
       "      <td>0.004146</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.004134</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>0.004127</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.004175</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.004171</td>\n",
       "      <td>0.004142</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.004102</td>\n",
       "      <td>0.004123</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.004158</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.004136</td>\n",
       "      <td>0.00417</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.003961</td>\n",
       "      <td>0.004027</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>0.003967</td>\n",
       "      <td>0.004146</td>\n",
       "      <td>0.004164</td>\n",
       "      <td>0.004147</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.004133</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.004146</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>0.004144</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.004129</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.00414</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.004163</td>\n",
       "      <td>0.004157</td>\n",
       "      <td>0.004186</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.00407</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.004273</td>\n",
       "      <td>0.004307</td>\n",
       "      <td>0.004539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_0</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.00006</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_0</th>\n",
       "      <td>0.003973</td>\n",
       "      <td>0.004542</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.005594</td>\n",
       "      <td>0.04328</td>\n",
       "      <td>0.030147</td>\n",
       "      <td>0.01602</td>\n",
       "      <td>0.008813</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>0.003248</td>\n",
       "      <td>0.006229</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.005151</td>\n",
       "      <td>0.00528</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.00517</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.00517</td>\n",
       "      <td>0.005295</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>0.00534</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.00533</td>\n",
       "      <td>0.005341</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.005335</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>0.005282</td>\n",
       "      <td>0.005281</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.005317</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.005281</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.00536</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005171</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.00532</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.00529</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.005287</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.005328</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.005171</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.005647</td>\n",
       "      <td>0.005837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004542</td>\n",
       "      <td>0.004858</td>\n",
       "      <td>0.00558</td>\n",
       "      <td>0.04346</td>\n",
       "      <td>0.030251</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.005167</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.005257</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.00512</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>0.00525</td>\n",
       "      <td>0.00533</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.00528</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>0.005295</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.00526</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.005335</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>0.005148</td>\n",
       "      <td>0.00522</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.005295</td>\n",
       "      <td>0.005266</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.005257</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.00532</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.005281</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>0.005328</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.00537</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>0.005755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004846</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>0.043619</td>\n",
       "      <td>0.030646</td>\n",
       "      <td>0.016074</td>\n",
       "      <td>0.008825</td>\n",
       "      <td>0.005238</td>\n",
       "      <td>0.00299</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.005138</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>0.005116</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>0.005203</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.005355</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.005276</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.00534</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>0.005281</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>0.005235</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>0.00531</td>\n",
       "      <td>0.005334</td>\n",
       "      <td>0.005125</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.00525</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.00526</td>\n",
       "      <td>0.005287</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.005264</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.00533</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>0.00568</td>\n",
       "      <td>0.005886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>0.043349</td>\n",
       "      <td>0.030091</td>\n",
       "      <td>0.016138</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.00186</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.006265</td>\n",
       "      <td>0.005278</td>\n",
       "      <td>0.005138</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.00523</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.005244</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.005119</td>\n",
       "      <td>0.005112</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.005151</td>\n",
       "      <td>0.005193</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.00529</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>0.00531</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>0.005317</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.005336</td>\n",
       "      <td>0.00532</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.00533</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.00516</td>\n",
       "      <td>0.005077</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.005328</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.005237</td>\n",
       "      <td>0.00531</td>\n",
       "      <td>0.00529</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.005335</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>0.005305</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.00525</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.00521</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.00532</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.005354</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>0.005599</td>\n",
       "      <td>0.005986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_0</th>\n",
       "      <td>14303.761229</td>\n",
       "      <td>16350.453749</td>\n",
       "      <td>17810.380299</td>\n",
       "      <td>20137.8923</td>\n",
       "      <td>155809.262017</td>\n",
       "      <td>108529.153346</td>\n",
       "      <td>57671.185141</td>\n",
       "      <td>31727.093463</td>\n",
       "      <td>19065.067902</td>\n",
       "      <td>10946.135651</td>\n",
       "      <td>6715.284842</td>\n",
       "      <td>19028.761287</td>\n",
       "      <td>11692.697823</td>\n",
       "      <td>22424.153873</td>\n",
       "      <td>19052.493231</td>\n",
       "      <td>18543.177523</td>\n",
       "      <td>19009.732329</td>\n",
       "      <td>18819.325871</td>\n",
       "      <td>19065.481858</td>\n",
       "      <td>19040.885156</td>\n",
       "      <td>18904.127078</td>\n",
       "      <td>18984.102044</td>\n",
       "      <td>18413.707198</td>\n",
       "      <td>18613.564912</td>\n",
       "      <td>18636.922288</td>\n",
       "      <td>18620.172839</td>\n",
       "      <td>18612.694662</td>\n",
       "      <td>19063.728589</td>\n",
       "      <td>19136.439804</td>\n",
       "      <td>19248.542739</td>\n",
       "      <td>19223.067962</td>\n",
       "      <td>19161.22448</td>\n",
       "      <td>19189.409224</td>\n",
       "      <td>19225.800509</td>\n",
       "      <td>19086.003121</td>\n",
       "      <td>19101.943858</td>\n",
       "      <td>19126.656941</td>\n",
       "      <td>19205.568716</td>\n",
       "      <td>19154.084108</td>\n",
       "      <td>19291.922007</td>\n",
       "      <td>19092.695642</td>\n",
       "      <td>19216.41514</td>\n",
       "      <td>19016.269205</td>\n",
       "      <td>19012.966579</td>\n",
       "      <td>19055.110853</td>\n",
       "      <td>19132.354055</td>\n",
       "      <td>19171.210806</td>\n",
       "      <td>19176.17093</td>\n",
       "      <td>19142.898472</td>\n",
       "      <td>19137.312494</td>\n",
       "      <td>19075.879761</td>\n",
       "      <td>19012.654067</td>\n",
       "      <td>19067.346013</td>\n",
       "      <td>19092.375499</td>\n",
       "      <td>19126.276281</td>\n",
       "      <td>19093.869891</td>\n",
       "      <td>19296.046228</td>\n",
       "      <td>18509.363655</td>\n",
       "      <td>18501.078699</td>\n",
       "      <td>18615.405968</td>\n",
       "      <td>18618.990353</td>\n",
       "      <td>19152.250372</td>\n",
       "      <td>19053.868524</td>\n",
       "      <td>19042.145496</td>\n",
       "      <td>19043.141063</td>\n",
       "      <td>18929.209214</td>\n",
       "      <td>19077.205396</td>\n",
       "      <td>18947.580139</td>\n",
       "      <td>19134.959869</td>\n",
       "      <td>19032.337276</td>\n",
       "      <td>19193.338335</td>\n",
       "      <td>19047.87437</td>\n",
       "      <td>18929.021732</td>\n",
       "      <td>19053.081992</td>\n",
       "      <td>18985.975025</td>\n",
       "      <td>19164.202496</td>\n",
       "      <td>19182.208722</td>\n",
       "      <td>18747.298287</td>\n",
       "      <td>18810.358063</td>\n",
       "      <td>18941.583765</td>\n",
       "      <td>18675.883055</td>\n",
       "      <td>18941.955974</td>\n",
       "      <td>19030.879498</td>\n",
       "      <td>18881.480268</td>\n",
       "      <td>19083.031099</td>\n",
       "      <td>18614.504031</td>\n",
       "      <td>19170.370322</td>\n",
       "      <td>20099.074693</td>\n",
       "      <td>20329.463438</td>\n",
       "      <td>21013.466101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>16350.27093</td>\n",
       "      <td>17489.819214</td>\n",
       "      <td>20087.148309</td>\n",
       "      <td>156455.068943</td>\n",
       "      <td>108904.579548</td>\n",
       "      <td>57132.785251</td>\n",
       "      <td>31696.43932</td>\n",
       "      <td>18923.077153</td>\n",
       "      <td>10951.018236</td>\n",
       "      <td>6693.110076</td>\n",
       "      <td>19200.551045</td>\n",
       "      <td>11524.181864</td>\n",
       "      <td>22862.637004</td>\n",
       "      <td>18767.881847</td>\n",
       "      <td>18599.512419</td>\n",
       "      <td>19066.924468</td>\n",
       "      <td>19077.483681</td>\n",
       "      <td>18960.619637</td>\n",
       "      <td>18720.254459</td>\n",
       "      <td>18923.632368</td>\n",
       "      <td>18923.329727</td>\n",
       "      <td>18433.45926</td>\n",
       "      <td>18360.078347</td>\n",
       "      <td>18608.24352</td>\n",
       "      <td>18621.859381</td>\n",
       "      <td>18715.010011</td>\n",
       "      <td>18899.344582</td>\n",
       "      <td>19186.543281</td>\n",
       "      <td>19168.657713</td>\n",
       "      <td>18842.386631</td>\n",
       "      <td>18995.69519</td>\n",
       "      <td>18876.521194</td>\n",
       "      <td>19090.668839</td>\n",
       "      <td>19009.741793</td>\n",
       "      <td>19145.302364</td>\n",
       "      <td>19062.508343</td>\n",
       "      <td>19132.260477</td>\n",
       "      <td>19171.255272</td>\n",
       "      <td>18935.273001</td>\n",
       "      <td>19105.740666</td>\n",
       "      <td>19173.626968</td>\n",
       "      <td>19111.19253</td>\n",
       "      <td>19154.981092</td>\n",
       "      <td>19069.906614</td>\n",
       "      <td>19168.558212</td>\n",
       "      <td>19204.924812</td>\n",
       "      <td>18947.844242</td>\n",
       "      <td>19103.648467</td>\n",
       "      <td>19144.179634</td>\n",
       "      <td>19135.605227</td>\n",
       "      <td>19040.657486</td>\n",
       "      <td>19041.700805</td>\n",
       "      <td>19136.618278</td>\n",
       "      <td>19266.894827</td>\n",
       "      <td>19185.402485</td>\n",
       "      <td>19165.994588</td>\n",
       "      <td>18479.38123</td>\n",
       "      <td>18479.87284</td>\n",
       "      <td>18474.427509</td>\n",
       "      <td>18531.185246</td>\n",
       "      <td>18791.945325</td>\n",
       "      <td>18771.968275</td>\n",
       "      <td>18920.52465</td>\n",
       "      <td>18895.203018</td>\n",
       "      <td>19061.079818</td>\n",
       "      <td>18956.401671</td>\n",
       "      <td>18811.48899</td>\n",
       "      <td>18995.771879</td>\n",
       "      <td>19221.418975</td>\n",
       "      <td>18923.596267</td>\n",
       "      <td>19171.806801</td>\n",
       "      <td>19152.672692</td>\n",
       "      <td>19269.219419</td>\n",
       "      <td>18970.171059</td>\n",
       "      <td>18895.402353</td>\n",
       "      <td>18819.385955</td>\n",
       "      <td>19010.531237</td>\n",
       "      <td>19073.909792</td>\n",
       "      <td>19073.771602</td>\n",
       "      <td>19181.377666</td>\n",
       "      <td>19128.951509</td>\n",
       "      <td>19089.259507</td>\n",
       "      <td>19111.902011</td>\n",
       "      <td>18929.349811</td>\n",
       "      <td>18928.400783</td>\n",
       "      <td>19332.671469</td>\n",
       "      <td>19566.465463</td>\n",
       "      <td>20028.173657</td>\n",
       "      <td>20718.303797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17447.150591</td>\n",
       "      <td>20320.487492</td>\n",
       "      <td>157030.133364</td>\n",
       "      <td>110324.101507</td>\n",
       "      <td>57866.769826</td>\n",
       "      <td>31771.194872</td>\n",
       "      <td>18855.157924</td>\n",
       "      <td>10762.797135</td>\n",
       "      <td>6669.778843</td>\n",
       "      <td>19020.551765</td>\n",
       "      <td>11697.259898</td>\n",
       "      <td>22724.614278</td>\n",
       "      <td>18781.051648</td>\n",
       "      <td>18559.512238</td>\n",
       "      <td>19005.080966</td>\n",
       "      <td>19161.453476</td>\n",
       "      <td>18947.84309</td>\n",
       "      <td>18918.645607</td>\n",
       "      <td>18995.788813</td>\n",
       "      <td>18963.333301</td>\n",
       "      <td>18497.529283</td>\n",
       "      <td>18516.525825</td>\n",
       "      <td>18568.780196</td>\n",
       "      <td>18416.462053</td>\n",
       "      <td>18476.741718</td>\n",
       "      <td>18731.514339</td>\n",
       "      <td>18837.102858</td>\n",
       "      <td>19170.857594</td>\n",
       "      <td>19278.754826</td>\n",
       "      <td>19095.977762</td>\n",
       "      <td>19128.826764</td>\n",
       "      <td>18994.107682</td>\n",
       "      <td>19143.614827</td>\n",
       "      <td>19106.037192</td>\n",
       "      <td>19222.203597</td>\n",
       "      <td>19212.271122</td>\n",
       "      <td>19112.163224</td>\n",
       "      <td>19158.979839</td>\n",
       "      <td>19104.624211</td>\n",
       "      <td>19158.787423</td>\n",
       "      <td>19192.083487</td>\n",
       "      <td>19311.365352</td>\n",
       "      <td>19053.888752</td>\n",
       "      <td>19133.267371</td>\n",
       "      <td>18843.83803</td>\n",
       "      <td>19050.10442</td>\n",
       "      <td>18896.079822</td>\n",
       "      <td>18984.270665</td>\n",
       "      <td>19010.643524</td>\n",
       "      <td>19176.321637</td>\n",
       "      <td>18903.883849</td>\n",
       "      <td>18844.935383</td>\n",
       "      <td>19059.455407</td>\n",
       "      <td>19115.723661</td>\n",
       "      <td>19201.971299</td>\n",
       "      <td>18450.715658</td>\n",
       "      <td>18466.800785</td>\n",
       "      <td>18619.730542</td>\n",
       "      <td>18769.323365</td>\n",
       "      <td>18941.291583</td>\n",
       "      <td>18899.731584</td>\n",
       "      <td>18917.602859</td>\n",
       "      <td>18944.771835</td>\n",
       "      <td>18937.608421</td>\n",
       "      <td>19032.511786</td>\n",
       "      <td>19165.724582</td>\n",
       "      <td>18963.323375</td>\n",
       "      <td>19051.106107</td>\n",
       "      <td>19156.894533</td>\n",
       "      <td>19164.081105</td>\n",
       "      <td>19121.446342</td>\n",
       "      <td>18963.184184</td>\n",
       "      <td>19149.415966</td>\n",
       "      <td>19194.163638</td>\n",
       "      <td>19069.860852</td>\n",
       "      <td>18965.528726</td>\n",
       "      <td>18949.288594</td>\n",
       "      <td>19100.353559</td>\n",
       "      <td>19189.043717</td>\n",
       "      <td>18986.38066</td>\n",
       "      <td>19023.745609</td>\n",
       "      <td>19084.977902</td>\n",
       "      <td>19072.870024</td>\n",
       "      <td>18918.230356</td>\n",
       "      <td>19219.497474</td>\n",
       "      <td>20008.375337</td>\n",
       "      <td>20446.391921</td>\n",
       "      <td>21191.396944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20278.978401</td>\n",
       "      <td>156055.384153</td>\n",
       "      <td>108326.694902</td>\n",
       "      <td>58096.802338</td>\n",
       "      <td>32143.327578</td>\n",
       "      <td>19041.396553</td>\n",
       "      <td>10951.81302</td>\n",
       "      <td>6695.738156</td>\n",
       "      <td>19075.934633</td>\n",
       "      <td>11396.781802</td>\n",
       "      <td>22553.251001</td>\n",
       "      <td>18999.95096</td>\n",
       "      <td>18497.449432</td>\n",
       "      <td>18973.008275</td>\n",
       "      <td>18826.314719</td>\n",
       "      <td>18938.259958</td>\n",
       "      <td>19047.834044</td>\n",
       "      <td>18877.924286</td>\n",
       "      <td>18919.409945</td>\n",
       "      <td>18428.693723</td>\n",
       "      <td>18402.534883</td>\n",
       "      <td>18315.762589</td>\n",
       "      <td>18545.112036</td>\n",
       "      <td>18696.555257</td>\n",
       "      <td>19251.952093</td>\n",
       "      <td>19041.707081</td>\n",
       "      <td>19154.901046</td>\n",
       "      <td>19176.586665</td>\n",
       "      <td>19199.996368</td>\n",
       "      <td>19028.812749</td>\n",
       "      <td>19076.060858</td>\n",
       "      <td>19143.821125</td>\n",
       "      <td>19104.984294</td>\n",
       "      <td>19044.708764</td>\n",
       "      <td>18772.40845</td>\n",
       "      <td>19114.624953</td>\n",
       "      <td>19024.41551</td>\n",
       "      <td>19140.483325</td>\n",
       "      <td>19200.147094</td>\n",
       "      <td>19210.834007</td>\n",
       "      <td>19152.622766</td>\n",
       "      <td>19167.828859</td>\n",
       "      <td>19082.93714</td>\n",
       "      <td>19088.969977</td>\n",
       "      <td>19186.96992</td>\n",
       "      <td>19102.542045</td>\n",
       "      <td>18875.282068</td>\n",
       "      <td>18965.104834</td>\n",
       "      <td>18850.122215</td>\n",
       "      <td>19182.910783</td>\n",
       "      <td>19107.661969</td>\n",
       "      <td>19059.959346</td>\n",
       "      <td>19183.518958</td>\n",
       "      <td>19069.737999</td>\n",
       "      <td>18297.829967</td>\n",
       "      <td>18617.846733</td>\n",
       "      <td>18576.84544</td>\n",
       "      <td>18278.032992</td>\n",
       "      <td>19173.858006</td>\n",
       "      <td>19180.336493</td>\n",
       "      <td>19092.711249</td>\n",
       "      <td>18853.165997</td>\n",
       "      <td>19115.493712</td>\n",
       "      <td>19044.413921</td>\n",
       "      <td>19126.499074</td>\n",
       "      <td>19077.977221</td>\n",
       "      <td>18971.923528</td>\n",
       "      <td>19103.932711</td>\n",
       "      <td>19206.906992</td>\n",
       "      <td>19026.84495</td>\n",
       "      <td>19098.841276</td>\n",
       "      <td>18972.939656</td>\n",
       "      <td>18898.412659</td>\n",
       "      <td>19029.865786</td>\n",
       "      <td>19063.89946</td>\n",
       "      <td>19088.415694</td>\n",
       "      <td>18756.797505</td>\n",
       "      <td>19177.356867</td>\n",
       "      <td>19151.441688</td>\n",
       "      <td>19092.800088</td>\n",
       "      <td>19273.925165</td>\n",
       "      <td>19081.144189</td>\n",
       "      <td>18768.91846</td>\n",
       "      <td>19111.919449</td>\n",
       "      <td>19901.660465</td>\n",
       "      <td>20155.526135</td>\n",
       "      <td>21548.80768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_avg</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_avg</th>\n",
       "      <td>46.225986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.802324</td>\n",
       "      <td>453.303389</td>\n",
       "      <td>691.338204</td>\n",
       "      <td>268.587557</td>\n",
       "      <td>358.312906</td>\n",
       "      <td>320.232011</td>\n",
       "      <td>1118.538726</td>\n",
       "      <td>492.01174</td>\n",
       "      <td>677.800449</td>\n",
       "      <td>437.204647</td>\n",
       "      <td>391.714159</td>\n",
       "      <td>204.366104</td>\n",
       "      <td>382.524126</td>\n",
       "      <td>266.289626</td>\n",
       "      <td>234.621729</td>\n",
       "      <td>285.611934</td>\n",
       "      <td>391.571721</td>\n",
       "      <td>409.822402</td>\n",
       "      <td>429.799515</td>\n",
       "      <td>432.050167</td>\n",
       "      <td>421.301499</td>\n",
       "      <td>393.303811</td>\n",
       "      <td>292.735859</td>\n",
       "      <td>495.914887</td>\n",
       "      <td>412.077225</td>\n",
       "      <td>383.197083</td>\n",
       "      <td>390.294755</td>\n",
       "      <td>571.329062</td>\n",
       "      <td>392.706854</td>\n",
       "      <td>367.056529</td>\n",
       "      <td>474.542887</td>\n",
       "      <td>334.40488</td>\n",
       "      <td>367.160655</td>\n",
       "      <td>503.445063</td>\n",
       "      <td>410.155781</td>\n",
       "      <td>195.802022</td>\n",
       "      <td>291.842585</td>\n",
       "      <td>337.884587</td>\n",
       "      <td>439.834917</td>\n",
       "      <td>432.162595</td>\n",
       "      <td>367.760453</td>\n",
       "      <td>397.983108</td>\n",
       "      <td>584.680567</td>\n",
       "      <td>404.882464</td>\n",
       "      <td>373.916889</td>\n",
       "      <td>373.171862</td>\n",
       "      <td>581.747394</td>\n",
       "      <td>396.201549</td>\n",
       "      <td>525.567555</td>\n",
       "      <td>399.772335</td>\n",
       "      <td>389.105744</td>\n",
       "      <td>277.971773</td>\n",
       "      <td>384.025206</td>\n",
       "      <td>1477.347167</td>\n",
       "      <td>451.401374</td>\n",
       "      <td>555.380175</td>\n",
       "      <td>406.571211</td>\n",
       "      <td>375.751597</td>\n",
       "      <td>371.866695</td>\n",
       "      <td>311.990543</td>\n",
       "      <td>297.637035</td>\n",
       "      <td>319.099187</td>\n",
       "      <td>422.491341</td>\n",
       "      <td>385.364127</td>\n",
       "      <td>529.887179</td>\n",
       "      <td>384.95846</td>\n",
       "      <td>323.807523</td>\n",
       "      <td>416.411664</td>\n",
       "      <td>375.259303</td>\n",
       "      <td>555.406601</td>\n",
       "      <td>412.056644</td>\n",
       "      <td>333.941971</td>\n",
       "      <td>441.068223</td>\n",
       "      <td>367.534498</td>\n",
       "      <td>296.116516</td>\n",
       "      <td>426.171555</td>\n",
       "      <td>464.683503</td>\n",
       "      <td>373.273991</td>\n",
       "      <td>102.99226</td>\n",
       "      <td>415.753303</td>\n",
       "      <td>441.421415</td>\n",
       "      <td>281.424198</td>\n",
       "      <td>422.539237</td>\n",
       "      <td>354.061436</td>\n",
       "      <td>221.602844</td>\n",
       "      <td>373.637229</td>\n",
       "      <td>383.426657</td>\n",
       "      <td>336.049723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_avg</th>\n",
       "      <td>0.923219</td>\n",
       "      <td>0.94983</td>\n",
       "      <td>0.954332</td>\n",
       "      <td>0.958816</td>\n",
       "      <td>0.951091</td>\n",
       "      <td>0.957124</td>\n",
       "      <td>0.958018</td>\n",
       "      <td>0.954639</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.959702</td>\n",
       "      <td>0.955094</td>\n",
       "      <td>0.664005</td>\n",
       "      <td>0.928296</td>\n",
       "      <td>0.9769</td>\n",
       "      <td>0.947205</td>\n",
       "      <td>0.952953</td>\n",
       "      <td>0.962324</td>\n",
       "      <td>0.963021</td>\n",
       "      <td>0.963892</td>\n",
       "      <td>0.955985</td>\n",
       "      <td>0.959559</td>\n",
       "      <td>0.956723</td>\n",
       "      <td>0.95529</td>\n",
       "      <td>0.954029</td>\n",
       "      <td>0.955858</td>\n",
       "      <td>0.951728</td>\n",
       "      <td>0.948094</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>0.963921</td>\n",
       "      <td>0.95377</td>\n",
       "      <td>0.96025</td>\n",
       "      <td>0.961562</td>\n",
       "      <td>0.958358</td>\n",
       "      <td>0.952374</td>\n",
       "      <td>0.95813</td>\n",
       "      <td>0.95802</td>\n",
       "      <td>0.962087</td>\n",
       "      <td>0.958308</td>\n",
       "      <td>0.95993</td>\n",
       "      <td>0.964699</td>\n",
       "      <td>0.955347</td>\n",
       "      <td>0.959208</td>\n",
       "      <td>0.960846</td>\n",
       "      <td>0.962158</td>\n",
       "      <td>0.962879</td>\n",
       "      <td>0.962166</td>\n",
       "      <td>0.965268</td>\n",
       "      <td>0.959845</td>\n",
       "      <td>0.963443</td>\n",
       "      <td>0.963372</td>\n",
       "      <td>0.966059</td>\n",
       "      <td>0.954208</td>\n",
       "      <td>0.963354</td>\n",
       "      <td>0.962415</td>\n",
       "      <td>0.957899</td>\n",
       "      <td>0.96216</td>\n",
       "      <td>0.960668</td>\n",
       "      <td>0.953066</td>\n",
       "      <td>0.949621</td>\n",
       "      <td>0.955473</td>\n",
       "      <td>0.956434</td>\n",
       "      <td>0.945956</td>\n",
       "      <td>0.955248</td>\n",
       "      <td>0.959702</td>\n",
       "      <td>0.958246</td>\n",
       "      <td>0.95934</td>\n",
       "      <td>0.964747</td>\n",
       "      <td>0.956913</td>\n",
       "      <td>0.954762</td>\n",
       "      <td>0.957826</td>\n",
       "      <td>0.956864</td>\n",
       "      <td>0.958314</td>\n",
       "      <td>0.947865</td>\n",
       "      <td>0.95182</td>\n",
       "      <td>0.964067</td>\n",
       "      <td>0.958583</td>\n",
       "      <td>0.964557</td>\n",
       "      <td>0.960877</td>\n",
       "      <td>0.962227</td>\n",
       "      <td>0.963644</td>\n",
       "      <td>0.962694</td>\n",
       "      <td>0.962244</td>\n",
       "      <td>0.958251</td>\n",
       "      <td>0.954216</td>\n",
       "      <td>0.962374</td>\n",
       "      <td>0.962766</td>\n",
       "      <td>0.960215</td>\n",
       "      <td>0.956742</td>\n",
       "      <td>0.954906</td>\n",
       "      <td>0.961642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_total</th>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.004173</td>\n",
       "      <td>0.042788</td>\n",
       "      <td>0.03621</td>\n",
       "      <td>0.018196</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>0.004569</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.00899</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.004507</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>0.004612</td>\n",
       "      <td>0.004569</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.00454</td>\n",
       "      <td>0.004495</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.00447</td>\n",
       "      <td>0.004483</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>0.004592</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.004563</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.004617</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.004581</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.004604</td>\n",
       "      <td>0.004579</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>0.00456</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.004564</td>\n",
       "      <td>0.004612</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.004497</td>\n",
       "      <td>0.004512</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>0.004586</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>0.00456</td>\n",
       "      <td>0.004529</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>0.004589</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>0.004589</td>\n",
       "      <td>0.004586</td>\n",
       "      <td>0.00454</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>0.004586</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>0.004984</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>0.005617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_total</th>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>0.011857</td>\n",
       "      <td>0.018244</td>\n",
       "      <td>0.130587</td>\n",
       "      <td>0.084684</td>\n",
       "      <td>0.045785</td>\n",
       "      <td>0.026333</td>\n",
       "      <td>0.01648</td>\n",
       "      <td>0.009785</td>\n",
       "      <td>0.006235</td>\n",
       "      <td>0.018275</td>\n",
       "      <td>0.009992</td>\n",
       "      <td>0.016105</td>\n",
       "      <td>0.016397</td>\n",
       "      <td>0.016074</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>0.016436</td>\n",
       "      <td>0.016487</td>\n",
       "      <td>0.016428</td>\n",
       "      <td>0.01645</td>\n",
       "      <td>0.016483</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.016032</td>\n",
       "      <td>0.016062</td>\n",
       "      <td>0.016112</td>\n",
       "      <td>0.016181</td>\n",
       "      <td>0.016497</td>\n",
       "      <td>0.016523</td>\n",
       "      <td>0.016694</td>\n",
       "      <td>0.016637</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.016579</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.016596</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>0.01659</td>\n",
       "      <td>0.016545</td>\n",
       "      <td>0.016591</td>\n",
       "      <td>0.016613</td>\n",
       "      <td>0.016648</td>\n",
       "      <td>0.016684</td>\n",
       "      <td>0.016649</td>\n",
       "      <td>0.016622</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>0.016612</td>\n",
       "      <td>0.016566</td>\n",
       "      <td>0.016577</td>\n",
       "      <td>0.016571</td>\n",
       "      <td>0.016538</td>\n",
       "      <td>0.016558</td>\n",
       "      <td>0.016539</td>\n",
       "      <td>0.016522</td>\n",
       "      <td>0.016496</td>\n",
       "      <td>0.016597</td>\n",
       "      <td>0.016642</td>\n",
       "      <td>0.01669</td>\n",
       "      <td>0.015956</td>\n",
       "      <td>0.016032</td>\n",
       "      <td>0.016109</td>\n",
       "      <td>0.016096</td>\n",
       "      <td>0.016511</td>\n",
       "      <td>0.016489</td>\n",
       "      <td>0.016512</td>\n",
       "      <td>0.016479</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.016522</td>\n",
       "      <td>0.016523</td>\n",
       "      <td>0.016553</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.016596</td>\n",
       "      <td>0.016658</td>\n",
       "      <td>0.016605</td>\n",
       "      <td>0.016603</td>\n",
       "      <td>0.016546</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>0.016534</td>\n",
       "      <td>0.016466</td>\n",
       "      <td>0.016465</td>\n",
       "      <td>0.016487</td>\n",
       "      <td>0.016491</td>\n",
       "      <td>0.016573</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.016591</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.016585</td>\n",
       "      <td>0.017087</td>\n",
       "      <td>0.017301</td>\n",
       "      <td>0.017808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_total</th>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.00024</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.00002</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_0</th>\n",
       "      <td>0.001514</td>\n",
       "      <td>0.00173</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.002131</td>\n",
       "      <td>0.016556</td>\n",
       "      <td>0.011463</td>\n",
       "      <td>0.006103</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.000708</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.001206</td>\n",
       "      <td>0.002419</td>\n",
       "      <td>0.001987</td>\n",
       "      <td>0.001964</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.001981</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.00195</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>0.00198</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.00203</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.00203</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.00203</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.001958</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.00201</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.002117</td>\n",
       "      <td>0.002151</td>\n",
       "      <td>0.002224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00173</td>\n",
       "      <td>0.001885</td>\n",
       "      <td>0.002126</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>0.011524</td>\n",
       "      <td>0.006046</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.001158</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.001938</td>\n",
       "      <td>0.001971</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.00204</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.00203</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.00203</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.001952</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.00203</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>0.001999</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.001991</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.001976</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>0.002119</td>\n",
       "      <td>0.002192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001846</td>\n",
       "      <td>0.00215</td>\n",
       "      <td>0.016488</td>\n",
       "      <td>0.011674</td>\n",
       "      <td>0.006148</td>\n",
       "      <td>0.003357</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.001238</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>0.002011</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.00201</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.001943</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.001982</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.00201</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.00201</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.002034</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.001997</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>0.001955</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.002005</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.002008</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.00203</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.001998</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.002003</td>\n",
       "      <td>0.002046</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>0.002242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.016514</td>\n",
       "      <td>0.011484</td>\n",
       "      <td>0.006123</td>\n",
       "      <td>0.003362</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.001947</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.001962</td>\n",
       "      <td>0.00197</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002012</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.002032</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>0.001956</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.002028</td>\n",
       "      <td>0.002007</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.002016</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>0.002021</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.002017</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>0.00203</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.00202</td>\n",
       "      <td>0.00204</td>\n",
       "      <td>0.002019</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.002029</td>\n",
       "      <td>0.002071</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.00228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_config_decoding_mode</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_generated_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>14659</td>\n",
       "      <td>16284</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                            0   \\\n",
       "config_name                                                                    num_processes_1   \n",
       "experiment_id                                                                              233   \n",
       "date_time                                                        April 11, 2025 at 05:02:12 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                1   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.003973   \n",
       "total_energy_joules                                                               14303.761229   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      1.145433   \n",
       "joules_per_token                                                                      0.873032   \n",
       "flops_per_joule                                                              1185000974.364989   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              37.07336   \n",
       "average_latency_ms_per_batch                                                       4634.170037   \n",
       "throughput_queries_per_sec                                                            3.452614   \n",
       "throughput_tokens_per_sec                                                           441.934582   \n",
       "cpu_usage_percent                                                                          1.0   \n",
       "cpu_memory_usage_bytes                                                              2647629824   \n",
       "gpu_utilization_percent_0                                                                  4.0   \n",
       "gpu_utilization_percent_1                                                                  9.0   \n",
       "gpu_utilization_percent_2                                                                 10.0   \n",
       "gpu_utilization_percent_3                                                                 10.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1444937728   \n",
       "gpu_max_memory_reserved_bytes                                                       1444937728   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                        NaN   \n",
       "cpu_power_process_2                                                                        NaN   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                  46.225986   \n",
       "gpu_power_process_1                                                                        NaN   \n",
       "gpu_power_process_2                                                                        NaN   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   0.923219   \n",
       "ram_power_process_1                                                                        NaN   \n",
       "ram_power_process_2                                                                        NaN   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                  0.001241   \n",
       "cpu_energy_process_1                                                                       NaN   \n",
       "cpu_energy_process_2                                                                       NaN   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                  0.002724   \n",
       "gpu_energy_process_1                                                                       NaN   \n",
       "gpu_energy_process_2                                                                       NaN   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                  0.000009   \n",
       "ram_energy_process_1                                                                       NaN   \n",
       "ram_energy_process_2                                                                       NaN   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.003973   \n",
       "total_energy_kwh_process_1                                                                 NaN   \n",
       "total_energy_kwh_process_2                                                                 NaN   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                     14303.761229   \n",
       "total_energy_joules_process_1                                                              NaN   \n",
       "total_energy_joules_process_2                                                              NaN   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        46.225986   \n",
       "ram_power_avg                                                                         0.923219   \n",
       "cpu_energy_total                                                                      0.001241   \n",
       "gpu_energy_total                                                                      0.002724   \n",
       "ram_energy_total                                                                      0.000009   \n",
       "per-process_emissions_0                                                               0.001514   \n",
       "per-process_emissions_1                                                                    NaN   \n",
       "per-process_emissions_2                                                                    NaN   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            1   \\\n",
       "config_name                                                                    num_processes_2   \n",
       "experiment_id                                                                              234   \n",
       "date_time                                                        April 11, 2025 at 05:03:25 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                2   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.009084   \n",
       "total_energy_joules                                                               32700.724679   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.501029   \n",
       "joules_per_token                                                                      1.995894   \n",
       "flops_per_joule                                                                518336249.72279   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.114287   \n",
       "average_latency_ms_per_batch                                                        4639.28586   \n",
       "throughput_queries_per_sec                                                            3.448807   \n",
       "throughput_tokens_per_sec                                                           441.447253   \n",
       "cpu_usage_percent                                                                          1.9   \n",
       "cpu_memory_usage_bytes                                                              2650619904   \n",
       "gpu_utilization_percent_0                                                                  2.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                  3.0   \n",
       "gpu_utilization_percent_3                                                                  4.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                        NaN   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                        0.0   \n",
       "gpu_power_process_1                                                                        0.0   \n",
       "gpu_power_process_2                                                                        NaN   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   0.924698   \n",
       "ram_power_process_1                                                                   0.974962   \n",
       "ram_power_process_2                                                                        NaN   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                   0.00118   \n",
       "cpu_energy_process_1                                                                  0.001179   \n",
       "cpu_energy_process_2                                                                       NaN   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                  0.003353   \n",
       "gpu_energy_process_1                                                                  0.003353   \n",
       "gpu_energy_process_2                                                                       NaN   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                  0.000009   \n",
       "ram_energy_process_1                                                                   0.00001   \n",
       "ram_energy_process_2                                                                       NaN   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.004542   \n",
       "total_energy_kwh_process_1                                                            0.004542   \n",
       "total_energy_kwh_process_2                                                                 NaN   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                     16350.453749   \n",
       "total_energy_joules_process_1                                                      16350.27093   \n",
       "total_energy_joules_process_2                                                              NaN   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                              0.0   \n",
       "ram_power_avg                                                                          0.94983   \n",
       "cpu_energy_total                                                                      0.002359   \n",
       "gpu_energy_total                                                                      0.006706   \n",
       "ram_energy_total                                                                      0.000019   \n",
       "per-process_emissions_0                                                                0.00173   \n",
       "per-process_emissions_1                                                                0.00173   \n",
       "per-process_emissions_2                                                                    NaN   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            2   \\\n",
       "config_name                                                                    num_processes_3   \n",
       "experiment_id                                                                              235   \n",
       "date_time                                                        April 11, 2025 at 05:04:40 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                3   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.014652   \n",
       "total_energy_joules                                                               52747.350103   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.310613   \n",
       "joules_per_token                                                                      3.219443   \n",
       "flops_per_joule                                                               321342606.972544   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.785984   \n",
       "average_latency_ms_per_batch                                                       4723.248003   \n",
       "throughput_queries_per_sec                                                            3.387499   \n",
       "throughput_tokens_per_sec                                                           433.599929   \n",
       "cpu_usage_percent                                                                          2.7   \n",
       "cpu_memory_usage_bytes                                                              2648543232   \n",
       "gpu_utilization_percent_0                                                                  1.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                  2.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                 441.183246   \n",
       "gpu_power_process_1                                                                  399.64369   \n",
       "gpu_power_process_2                                                                  13.580037   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   0.924637   \n",
       "ram_power_process_1                                                                   0.979108   \n",
       "ram_power_process_2                                                                   0.959252   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                  0.000934   \n",
       "cpu_energy_process_1                                                                  0.000921   \n",
       "cpu_energy_process_2                                                                  0.000913   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                  0.004005   \n",
       "gpu_energy_process_1                                                                  0.003928   \n",
       "gpu_energy_process_2                                                                  0.003924   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000009   \n",
       "ram_energy_process_2                                                                  0.000009   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.004947   \n",
       "total_energy_kwh_process_1                                                            0.004858   \n",
       "total_energy_kwh_process_2                                                            0.004846   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                     17810.380299   \n",
       "total_energy_joules_process_1                                                     17489.819214   \n",
       "total_energy_joules_process_2                                                     17447.150591   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       284.802324   \n",
       "ram_power_avg                                                                         0.954332   \n",
       "cpu_energy_total                                                                      0.002769   \n",
       "gpu_energy_total                                                                      0.011857   \n",
       "ram_energy_total                                                                      0.000027   \n",
       "per-process_emissions_0                                                               0.001851   \n",
       "per-process_emissions_1                                                               0.001885   \n",
       "per-process_emissions_2                                                               0.001846   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            3   \\\n",
       "config_name                                                                    num_processes_4   \n",
       "experiment_id                                                                              236   \n",
       "date_time                                                        April 11, 2025 at 05:05:55 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022451   \n",
       "total_energy_joules                                                               80824.506502   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.202711   \n",
       "joules_per_token                                                                      4.933136   \n",
       "flops_per_joule                                                                209713263.05247   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.507834   \n",
       "average_latency_ms_per_batch                                                       4688.479238   \n",
       "throughput_queries_per_sec                                                             3.41262   \n",
       "throughput_tokens_per_sec                                                           436.815414   \n",
       "cpu_usage_percent                                                                          3.8   \n",
       "cpu_memory_usage_bytes                                                              2675093504   \n",
       "gpu_utilization_percent_0                                                                  1.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 451.694772   \n",
       "gpu_power_process_1                                                                  477.04802   \n",
       "gpu_power_process_2                                                                 439.561195   \n",
       "gpu_power_process_3                                                                 444.909567   \n",
       "ram_power_process_0                                                                   0.933897   \n",
       "ram_power_process_1                                                                   0.967558   \n",
       "ram_power_process_2                                                                   0.975623   \n",
       "ram_power_process_3                                                                   0.958188   \n",
       "cpu_energy_process_0                                                                  0.001025   \n",
       "cpu_energy_process_1                                                                  0.001016   \n",
       "cpu_energy_process_2                                                                  0.001066   \n",
       "cpu_energy_process_3                                                                  0.001066   \n",
       "gpu_energy_process_0                                                                  0.004561   \n",
       "gpu_energy_process_1                                                                  0.004555   \n",
       "gpu_energy_process_2                                                                  0.004569   \n",
       "gpu_energy_process_3                                                                  0.004558   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000009   \n",
       "ram_energy_process_2                                                                  0.000009   \n",
       "ram_energy_process_3                                                                  0.000009   \n",
       "total_energy_kwh_process_0                                                            0.005594   \n",
       "total_energy_kwh_process_1                                                             0.00558   \n",
       "total_energy_kwh_process_2                                                            0.005645   \n",
       "total_energy_kwh_process_3                                                            0.005633   \n",
       "total_energy_joules_process_0                                                       20137.8923   \n",
       "total_energy_joules_process_1                                                     20087.148309   \n",
       "total_energy_joules_process_2                                                     20320.487492   \n",
       "total_energy_joules_process_3                                                     20278.978401   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       453.303389   \n",
       "ram_power_avg                                                                         0.958816   \n",
       "cpu_energy_total                                                                      0.004173   \n",
       "gpu_energy_total                                                                      0.018244   \n",
       "ram_energy_total                                                                      0.000035   \n",
       "per-process_emissions_0                                                               0.002131   \n",
       "per-process_emissions_1                                                               0.002126   \n",
       "per-process_emissions_2                                                                0.00215   \n",
       "per-process_emissions_3                                                               0.002146   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            4   \\\n",
       "config_name                                                                         batching_1   \n",
       "experiment_id                                                                              237   \n",
       "date_time                                                        April 11, 2025 at 05:13:02 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                  1   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.173708   \n",
       "total_energy_joules                                                              625349.848478   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.023441   \n",
       "joules_per_token                                                                     42.659789   \n",
       "flops_per_joule                                                                27104781.482585   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                            384.649219   \n",
       "average_latency_ms_per_batch                                                       3005.072024   \n",
       "throughput_queries_per_sec                                                            0.332771   \n",
       "throughput_tokens_per_sec                                                            38.110047   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2636230656   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087681536   \n",
       "gpu_max_memory_allocated_bytes                                                      1087681536   \n",
       "gpu_current_memory_reserved_bytes                                                   1885339648   \n",
       "gpu_max_memory_reserved_bytes                                                       1885339648   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                1845.345078   \n",
       "gpu_power_process_1                                                                 261.213255   \n",
       "gpu_power_process_2                                                                 263.932183   \n",
       "gpu_power_process_3                                                                 394.862299   \n",
       "ram_power_process_0                                                                   0.920484   \n",
       "ram_power_process_1                                                                   0.957427   \n",
       "ram_power_process_2                                                                   0.970041   \n",
       "ram_power_process_3                                                                    0.95641   \n",
       "cpu_energy_process_0                                                                   0.01072   \n",
       "cpu_energy_process_1                                                                  0.010701   \n",
       "cpu_energy_process_2                                                                  0.010694   \n",
       "cpu_energy_process_3                                                                  0.010674   \n",
       "gpu_energy_process_0                                                                  0.032477   \n",
       "gpu_energy_process_1                                                                  0.032675   \n",
       "gpu_energy_process_2                                                                  0.032842   \n",
       "gpu_energy_process_3                                                                  0.032593   \n",
       "ram_energy_process_0                                                                  0.000083   \n",
       "ram_energy_process_1                                                                  0.000084   \n",
       "ram_energy_process_2                                                                  0.000084   \n",
       "ram_energy_process_3                                                                  0.000083   \n",
       "total_energy_kwh_process_0                                                             0.04328   \n",
       "total_energy_kwh_process_1                                                             0.04346   \n",
       "total_energy_kwh_process_2                                                            0.043619   \n",
       "total_energy_kwh_process_3                                                            0.043349   \n",
       "total_energy_joules_process_0                                                    155809.262017   \n",
       "total_energy_joules_process_1                                                    156455.068943   \n",
       "total_energy_joules_process_2                                                    157030.133364   \n",
       "total_energy_joules_process_3                                                    156055.384153   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       691.338204   \n",
       "ram_power_avg                                                                         0.951091   \n",
       "cpu_energy_total                                                                      0.042788   \n",
       "gpu_energy_total                                                                      0.130587   \n",
       "ram_energy_total                                                                      0.000334   \n",
       "per-process_emissions_0                                                               0.016556   \n",
       "per-process_emissions_1                                                               0.016617   \n",
       "per-process_emissions_2                                                               0.016488   \n",
       "per-process_emissions_3                                                               0.016514   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   14659   \n",
       "\n",
       "                                                                                            5   \\\n",
       "config_name                                                                         batching_2   \n",
       "experiment_id                                                                              238   \n",
       "date_time                                                        April 11, 2025 at 05:18:36 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                  2   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.121135   \n",
       "total_energy_joules                                                              436084.529304   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.037341   \n",
       "joules_per_token                                                                     26.779939   \n",
       "flops_per_joule                                                                38868544.637947   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                            292.383712   \n",
       "average_latency_ms_per_batch                                                       4568.495493   \n",
       "throughput_queries_per_sec                                                            0.437781   \n",
       "throughput_tokens_per_sec                                                            55.693937   \n",
       "cpu_usage_percent                                                                          2.5   \n",
       "cpu_memory_usage_bytes                                                              2641690624   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1895825408   \n",
       "gpu_max_memory_reserved_bytes                                                       1895825408   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 265.284845   \n",
       "gpu_power_process_1                                                                 288.828887   \n",
       "gpu_power_process_2                                                                 248.949736   \n",
       "gpu_power_process_3                                                                 271.286759   \n",
       "ram_power_process_0                                                                   0.921799   \n",
       "ram_power_process_1                                                                   0.972463   \n",
       "ram_power_process_2                                                                   0.958992   \n",
       "ram_power_process_3                                                                   0.975244   \n",
       "cpu_energy_process_0                                                                  0.009017   \n",
       "cpu_energy_process_1                                                                  0.009048   \n",
       "cpu_energy_process_2                                                                  0.009147   \n",
       "cpu_energy_process_3                                                                  0.008998   \n",
       "gpu_energy_process_0                                                                  0.021072   \n",
       "gpu_energy_process_1                                                                  0.021143   \n",
       "gpu_energy_process_2                                                                  0.021438   \n",
       "gpu_energy_process_3                                                                  0.021032   \n",
       "ram_energy_process_0                                                                  0.000058   \n",
       "ram_energy_process_1                                                                  0.000061   \n",
       "ram_energy_process_2                                                                   0.00006   \n",
       "ram_energy_process_3                                                                  0.000061   \n",
       "total_energy_kwh_process_0                                                            0.030147   \n",
       "total_energy_kwh_process_1                                                            0.030251   \n",
       "total_energy_kwh_process_2                                                            0.030646   \n",
       "total_energy_kwh_process_3                                                            0.030091   \n",
       "total_energy_joules_process_0                                                    108529.153346   \n",
       "total_energy_joules_process_1                                                    108904.579548   \n",
       "total_energy_joules_process_2                                                    110324.101507   \n",
       "total_energy_joules_process_3                                                    108326.694902   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       268.587557   \n",
       "ram_power_avg                                                                         0.957124   \n",
       "cpu_energy_total                                                                       0.03621   \n",
       "gpu_energy_total                                                                      0.084684   \n",
       "ram_energy_total                                                                       0.00024   \n",
       "per-process_emissions_0                                                               0.011463   \n",
       "per-process_emissions_1                                                               0.011524   \n",
       "per-process_emissions_2                                                               0.011674   \n",
       "per-process_emissions_3                                                               0.011484   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16284   \n",
       "\n",
       "                                                                                            6   \\\n",
       "config_name                                                                         batching_4   \n",
       "experiment_id                                                                              239   \n",
       "date_time                                                        April 11, 2025 at 05:21:39 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                  4   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.064102   \n",
       "total_energy_joules                                                              230767.542556   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.070998   \n",
       "joules_per_token                                                                     14.084933   \n",
       "flops_per_joule                                                                73450411.636865   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                            147.516985   \n",
       "average_latency_ms_per_batch                                                       4609.905773   \n",
       "throughput_queries_per_sec                                                            0.867697   \n",
       "throughput_tokens_per_sec                                                           111.065177   \n",
       "cpu_usage_percent                                                                          2.5   \n",
       "cpu_memory_usage_bytes                                                              2644770816   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                 99.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                 81.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1912602624   \n",
       "gpu_max_memory_reserved_bytes                                                       1912602624   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 290.635406   \n",
       "gpu_power_process_1                                                                 434.526793   \n",
       "gpu_power_process_2                                                                 451.202191   \n",
       "gpu_power_process_3                                                                 256.887233   \n",
       "ram_power_process_0                                                                    0.92254   \n",
       "ram_power_process_1                                                                   0.958551   \n",
       "ram_power_process_2                                                                   0.981384   \n",
       "ram_power_process_3                                                                   0.969596   \n",
       "cpu_energy_process_0                                                                  0.004551   \n",
       "cpu_energy_process_1                                                                  0.004503   \n",
       "cpu_energy_process_2                                                                  0.004559   \n",
       "cpu_energy_process_3                                                                  0.004583   \n",
       "gpu_energy_process_0                                                                   0.01144   \n",
       "gpu_energy_process_1                                                                  0.011337   \n",
       "gpu_energy_process_2                                                                  0.011484   \n",
       "gpu_energy_process_3                                                                  0.011524   \n",
       "ram_energy_process_0                                                                  0.000029   \n",
       "ram_energy_process_1                                                                   0.00003   \n",
       "ram_energy_process_2                                                                  0.000031   \n",
       "ram_energy_process_3                                                                  0.000031   \n",
       "total_energy_kwh_process_0                                                             0.01602   \n",
       "total_energy_kwh_process_1                                                             0.01587   \n",
       "total_energy_kwh_process_2                                                            0.016074   \n",
       "total_energy_kwh_process_3                                                            0.016138   \n",
       "total_energy_joules_process_0                                                     57671.185141   \n",
       "total_energy_joules_process_1                                                     57132.785251   \n",
       "total_energy_joules_process_2                                                     57866.769826   \n",
       "total_energy_joules_process_3                                                     58096.802338   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       358.312906   \n",
       "ram_power_avg                                                                         0.958018   \n",
       "cpu_energy_total                                                                      0.018196   \n",
       "gpu_energy_total                                                                      0.045785   \n",
       "ram_energy_total                                                                      0.000121   \n",
       "per-process_emissions_0                                                               0.006103   \n",
       "per-process_emissions_1                                                               0.006046   \n",
       "per-process_emissions_2                                                               0.006148   \n",
       "per-process_emissions_3                                                               0.006123   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            7   \\\n",
       "config_name                                                                         batching_8   \n",
       "experiment_id                                                                              240   \n",
       "date_time                                                        April 11, 2025 at 05:23:23 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                  8   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.035372   \n",
       "total_energy_joules                                                              127338.055234   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.128665   \n",
       "joules_per_token                                                                      7.772098   \n",
       "flops_per_joule                                                               133110019.326187   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             74.266558   \n",
       "average_latency_ms_per_batch                                                        4641.65987   \n",
       "throughput_queries_per_sec                                                            1.723521   \n",
       "throughput_tokens_per_sec                                                           220.610736   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2623025152   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                 99.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1937768448   \n",
       "gpu_max_memory_reserved_bytes                                                       1937768448   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 352.295744   \n",
       "gpu_power_process_1                                                                 350.458868   \n",
       "gpu_power_process_2                                                                   295.6267   \n",
       "gpu_power_process_3                                                                 282.546732   \n",
       "ram_power_process_0                                                                   0.915296   \n",
       "ram_power_process_1                                                                   0.969581   \n",
       "ram_power_process_2                                                                    0.96701   \n",
       "ram_power_process_3                                                                   0.966668   \n",
       "cpu_energy_process_0                                                                  0.002237   \n",
       "cpu_energy_process_1                                                                  0.002234   \n",
       "cpu_energy_process_2                                                                   0.00224   \n",
       "cpu_energy_process_3                                                                  0.002264   \n",
       "gpu_energy_process_0                                                                  0.006561   \n",
       "gpu_energy_process_1                                                                  0.006554   \n",
       "gpu_energy_process_2                                                                  0.006569   \n",
       "gpu_energy_process_3                                                                  0.006649   \n",
       "ram_energy_process_0                                                                  0.000015   \n",
       "ram_energy_process_1                                                                  0.000016   \n",
       "ram_energy_process_2                                                                  0.000016   \n",
       "ram_energy_process_3                                                                  0.000016   \n",
       "total_energy_kwh_process_0                                                            0.008813   \n",
       "total_energy_kwh_process_1                                                            0.008805   \n",
       "total_energy_kwh_process_2                                                            0.008825   \n",
       "total_energy_kwh_process_3                                                            0.008929   \n",
       "total_energy_joules_process_0                                                     31727.093463   \n",
       "total_energy_joules_process_1                                                      31696.43932   \n",
       "total_energy_joules_process_2                                                     31771.194872   \n",
       "total_energy_joules_process_3                                                     32143.327578   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       320.232011   \n",
       "ram_power_avg                                                                         0.954639   \n",
       "cpu_energy_total                                                                      0.008976   \n",
       "gpu_energy_total                                                                      0.026333   \n",
       "ram_energy_total                                                                      0.000063   \n",
       "per-process_emissions_0                                                               0.003401   \n",
       "per-process_emissions_1                                                               0.003354   \n",
       "per-process_emissions_2                                                               0.003357   \n",
       "per-process_emissions_3                                                               0.003362   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            8   \\\n",
       "config_name                                                                        batching_16   \n",
       "experiment_id                                                                              241   \n",
       "date_time                                                        April 11, 2025 at 05:24:30 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021079   \n",
       "total_energy_joules                                                               75884.699531   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215907   \n",
       "joules_per_token                                                                      4.631634   \n",
       "flops_per_joule                                                               223364803.416953   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.168908   \n",
       "average_latency_ms_per_batch                                                       4646.113508   \n",
       "throughput_queries_per_sec                                                            3.443739   \n",
       "throughput_tokens_per_sec                                                           440.798529   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2626736128   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 439.982222   \n",
       "gpu_power_process_1                                                                 437.286475   \n",
       "gpu_power_process_2                                                                  442.64908   \n",
       "gpu_power_process_3                                                                3154.237128   \n",
       "ram_power_process_0                                                                   0.916314   \n",
       "ram_power_process_1                                                                   0.959045   \n",
       "ram_power_process_2                                                                   0.977444   \n",
       "ram_power_process_3                                                                   0.966551   \n",
       "cpu_energy_process_0                                                                  0.001149   \n",
       "cpu_energy_process_1                                                                  0.001139   \n",
       "cpu_energy_process_2                                                                  0.001133   \n",
       "cpu_energy_process_3                                                                  0.001147   \n",
       "gpu_energy_process_0                                                                  0.004139   \n",
       "gpu_energy_process_1                                                                   0.00411   \n",
       "gpu_energy_process_2                                                                  0.004097   \n",
       "gpu_energy_process_3                                                                  0.004134   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005296   \n",
       "total_energy_kwh_process_1                                                            0.005256   \n",
       "total_energy_kwh_process_2                                                            0.005238   \n",
       "total_energy_kwh_process_3                                                            0.005289   \n",
       "total_energy_joules_process_0                                                     19065.067902   \n",
       "total_energy_joules_process_1                                                     18923.077153   \n",
       "total_energy_joules_process_2                                                     18855.157924   \n",
       "total_energy_joules_process_3                                                     19041.396553   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1118.538726   \n",
       "ram_power_avg                                                                         0.954839   \n",
       "cpu_energy_total                                                                      0.004569   \n",
       "gpu_energy_total                                                                       0.01648   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002017   \n",
       "per-process_emissions_1                                                               0.001995   \n",
       "per-process_emissions_2                                                               0.002015   \n",
       "per-process_emissions_3                                                               0.002002   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            9   \\\n",
       "config_name                                                                        batching_32   \n",
       "experiment_id                                                                              242   \n",
       "date_time                                                        April 11, 2025 at 05:25:17 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 32   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.012114   \n",
       "total_energy_joules                                                               43611.764042   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.375678   \n",
       "joules_per_token                                                                      2.661851   \n",
       "flops_per_joule                                                               388655936.426967   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              18.70642   \n",
       "average_latency_ms_per_batch                                                       4676.605061   \n",
       "throughput_queries_per_sec                                                            6.842571   \n",
       "throughput_tokens_per_sec                                                           875.849029   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2625044480   \n",
       "gpu_utilization_percent_0                                                                 16.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1883242496   \n",
       "gpu_max_memory_reserved_bytes                                                       1883242496   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 501.808212   \n",
       "gpu_power_process_1                                                                 463.419949   \n",
       "gpu_power_process_2                                                                  527.83864   \n",
       "gpu_power_process_3                                                                  474.98016   \n",
       "ram_power_process_0                                                                   0.915423   \n",
       "ram_power_process_1                                                                   0.972944   \n",
       "ram_power_process_2                                                                   0.975926   \n",
       "ram_power_process_3                                                                   0.974513   \n",
       "cpu_energy_process_0                                                                   0.00058   \n",
       "cpu_energy_process_1                                                                  0.000581   \n",
       "cpu_energy_process_2                                                                  0.000571   \n",
       "cpu_energy_process_3                                                                  0.000582   \n",
       "gpu_energy_process_0                                                                  0.002456   \n",
       "gpu_energy_process_1                                                                  0.002457   \n",
       "gpu_energy_process_2                                                                  0.002415   \n",
       "gpu_energy_process_3                                                                  0.002456   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.003041   \n",
       "total_energy_kwh_process_1                                                            0.003042   \n",
       "total_energy_kwh_process_2                                                             0.00299   \n",
       "total_energy_kwh_process_3                                                            0.003042   \n",
       "total_energy_joules_process_0                                                     10946.135651   \n",
       "total_energy_joules_process_1                                                     10951.018236   \n",
       "total_energy_joules_process_2                                                     10762.797135   \n",
       "total_energy_joules_process_3                                                      10951.81302   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        492.01174   \n",
       "ram_power_avg                                                                         0.959702   \n",
       "cpu_energy_total                                                                      0.002314   \n",
       "gpu_energy_total                                                                      0.009785   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.001159   \n",
       "per-process_emissions_1                                                               0.001158   \n",
       "per-process_emissions_2                                                               0.001159   \n",
       "per-process_emissions_3                                                               0.001139   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            10  \\\n",
       "config_name                                                                        batching_64   \n",
       "experiment_id                                                                              243   \n",
       "date_time                                                        April 11, 2025 at 05:25:56 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 64   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.007437   \n",
       "total_energy_joules                                                               26773.911916   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.611939   \n",
       "joules_per_token                                                                       1.63415   \n",
       "flops_per_joule                                                               633077864.986458   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              9.628563   \n",
       "average_latency_ms_per_batch                                                       4814.281646   \n",
       "throughput_queries_per_sec                                                            13.29378   \n",
       "throughput_tokens_per_sec                                                          1701.603812   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2671489024   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1881145344   \n",
       "gpu_max_memory_reserved_bytes                                                       1881145344   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 642.516502   \n",
       "gpu_power_process_1                                                                 663.537588   \n",
       "gpu_power_process_2                                                                 702.517296   \n",
       "gpu_power_process_3                                                                 702.630409   \n",
       "ram_power_process_0                                                                   0.932818   \n",
       "ram_power_process_1                                                                   0.970612   \n",
       "ram_power_process_2                                                                    0.97516   \n",
       "ram_power_process_3                                                                   0.941787   \n",
       "cpu_energy_process_0                                                                  0.000301   \n",
       "cpu_energy_process_1                                                                  0.000298   \n",
       "cpu_energy_process_2                                                                  0.000297   \n",
       "cpu_energy_process_3                                                                  0.000299   \n",
       "gpu_energy_process_0                                                                  0.001563   \n",
       "gpu_energy_process_1                                                                  0.001559   \n",
       "gpu_energy_process_2                                                                  0.001554   \n",
       "gpu_energy_process_3                                                                  0.001559   \n",
       "ram_energy_process_0                                                                  0.000002   \n",
       "ram_energy_process_1                                                                  0.000002   \n",
       "ram_energy_process_2                                                                  0.000002   \n",
       "ram_energy_process_3                                                                  0.000002   \n",
       "total_energy_kwh_process_0                                                            0.001865   \n",
       "total_energy_kwh_process_1                                                            0.001859   \n",
       "total_energy_kwh_process_2                                                            0.001853   \n",
       "total_energy_kwh_process_3                                                             0.00186   \n",
       "total_energy_joules_process_0                                                      6715.284842   \n",
       "total_energy_joules_process_1                                                      6693.110076   \n",
       "total_energy_joules_process_2                                                      6669.778843   \n",
       "total_energy_joules_process_3                                                      6695.738156   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       677.800449   \n",
       "ram_power_avg                                                                         0.955094   \n",
       "cpu_energy_total                                                                      0.001194   \n",
       "gpu_energy_total                                                                      0.006235   \n",
       "ram_energy_total                                                                      0.000008   \n",
       "per-process_emissions_0                                                               0.000708   \n",
       "per-process_emissions_1                                                               0.000706   \n",
       "per-process_emissions_2                                                               0.000709   \n",
       "per-process_emissions_3                                                               0.000711   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            11  \\\n",
       "config_name                                  precis_float32_quant_False_quant8_False_quant4...   \n",
       "experiment_id                                                                              244   \n",
       "date_time                                                        April 11, 2025 at 05:26:49 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021202   \n",
       "total_energy_joules                                                               76325.798731   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214659   \n",
       "joules_per_token                                                                      4.658557   \n",
       "flops_per_joule                                                                222073941.90463   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             22.945557   \n",
       "average_latency_ms_per_batch                                                       2868.194596   \n",
       "throughput_queries_per_sec                                                            5.578422   \n",
       "throughput_tokens_per_sec                                                           714.038023   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2012856320   \n",
       "gpu_utilization_percent_0                                                                  6.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  13212057600   \n",
       "gpu_max_memory_reserved_bytes                                                      13212057600   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                        0.0   \n",
       "gpu_power_process_1                                                                 509.372653   \n",
       "gpu_power_process_2                                                                  568.81121   \n",
       "gpu_power_process_3                                                                 670.634727   \n",
       "ram_power_process_0                                                                   0.701127   \n",
       "ram_power_process_1                                                                   0.647849   \n",
       "ram_power_process_2                                                                   0.651335   \n",
       "ram_power_process_3                                                                   0.655709   \n",
       "cpu_energy_process_0                                                                  0.000745   \n",
       "cpu_energy_process_1                                                                  0.000728   \n",
       "cpu_energy_process_2                                                                  0.000718   \n",
       "cpu_energy_process_3                                                                  0.000721   \n",
       "gpu_energy_process_0                                                                  0.004537   \n",
       "gpu_energy_process_1                                                                  0.004602   \n",
       "gpu_energy_process_2                                                                  0.004562   \n",
       "gpu_energy_process_3                                                                  0.004574   \n",
       "ram_energy_process_0                                                                  0.000004   \n",
       "ram_energy_process_1                                                                  0.000004   \n",
       "ram_energy_process_2                                                                  0.000004   \n",
       "ram_energy_process_3                                                                  0.000004   \n",
       "total_energy_kwh_process_0                                                            0.005286   \n",
       "total_energy_kwh_process_1                                                            0.005333   \n",
       "total_energy_kwh_process_2                                                            0.005283   \n",
       "total_energy_kwh_process_3                                                            0.005299   \n",
       "total_energy_joules_process_0                                                     19028.761287   \n",
       "total_energy_joules_process_1                                                     19200.551045   \n",
       "total_energy_joules_process_2                                                     19020.551765   \n",
       "total_energy_joules_process_3                                                     19075.934633   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       437.204647   \n",
       "ram_power_avg                                                                         0.664005   \n",
       "cpu_energy_total                                                                      0.002912   \n",
       "gpu_energy_total                                                                      0.018275   \n",
       "ram_energy_total                                                                      0.000015   \n",
       "per-process_emissions_0                                                               0.002013   \n",
       "per-process_emissions_1                                                               0.002014   \n",
       "per-process_emissions_2                                                               0.002032   \n",
       "per-process_emissions_3                                                               0.002019   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            12  \\\n",
       "config_name                                  precis_float16_quant_False_quant8_False_quant4...   \n",
       "experiment_id                                                                              245   \n",
       "date_time                                                        April 11, 2025 at 05:27:40 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.012864   \n",
       "total_energy_joules                                                               46310.921387   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.353783   \n",
       "joules_per_token                                                                      2.826594   \n",
       "flops_per_joule                                                               366003752.151563   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             23.267255   \n",
       "average_latency_ms_per_batch                                                       2908.406936   \n",
       "throughput_queries_per_sec                                                            5.501293   \n",
       "throughput_tokens_per_sec                                                            704.16556   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              3100921856   \n",
       "gpu_utilization_percent_0                                                                  4.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  4419853312   \n",
       "gpu_max_memory_allocated_bytes                                                      4419853312   \n",
       "gpu_current_memory_reserved_bytes                                                   6870269952   \n",
       "gpu_max_memory_reserved_bytes                                                       6870269952   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 362.126674   \n",
       "gpu_power_process_1                                                                 417.073609   \n",
       "gpu_power_process_2                                                                 357.376814   \n",
       "gpu_power_process_3                                                                 430.279538   \n",
       "ram_power_process_0                                                                   1.080447   \n",
       "ram_power_process_1                                                                   0.879257   \n",
       "ram_power_process_2                                                                   0.871181   \n",
       "ram_power_process_3                                                                   0.882301   \n",
       "cpu_energy_process_0                                                                  0.000721   \n",
       "cpu_energy_process_1                                                                  0.000708   \n",
       "cpu_energy_process_2                                                                  0.000722   \n",
       "cpu_energy_process_3                                                                  0.000701   \n",
       "gpu_energy_process_0                                                                  0.002521   \n",
       "gpu_energy_process_1                                                                  0.002489   \n",
       "gpu_energy_process_2                                                                  0.002523   \n",
       "gpu_energy_process_3                                                                   0.00246   \n",
       "ram_energy_process_0                                                                  0.000006   \n",
       "ram_energy_process_1                                                                  0.000005   \n",
       "ram_energy_process_2                                                                  0.000005   \n",
       "ram_energy_process_3                                                                  0.000005   \n",
       "total_energy_kwh_process_0                                                            0.003248   \n",
       "total_energy_kwh_process_1                                                            0.003201   \n",
       "total_energy_kwh_process_2                                                            0.003249   \n",
       "total_energy_kwh_process_3                                                            0.003166   \n",
       "total_energy_joules_process_0                                                     11692.697823   \n",
       "total_energy_joules_process_1                                                     11524.181864   \n",
       "total_energy_joules_process_2                                                     11697.259898   \n",
       "total_energy_joules_process_3                                                     11396.781802   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       391.714159   \n",
       "ram_power_avg                                                                         0.928296   \n",
       "cpu_energy_total                                                                      0.002852   \n",
       "gpu_energy_total                                                                      0.009992   \n",
       "ram_energy_total                                                                       0.00002   \n",
       "per-process_emissions_0                                                               0.001206   \n",
       "per-process_emissions_1                                                               0.001237   \n",
       "per-process_emissions_2                                                               0.001238   \n",
       "per-process_emissions_3                                                               0.001219   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            13  \\\n",
       "config_name                                  precis_float16_quant_True_quant8_True_quant4_F...   \n",
       "experiment_id                                                                              246   \n",
       "date_time                                                        April 11, 2025 at 05:29:22 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                              True   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.025157   \n",
       "total_energy_joules                                                               90564.656156   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.180909   \n",
       "joules_per_token                                                                      5.527628   \n",
       "flops_per_joule                                                                187158784.81295   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             72.234728   \n",
       "average_latency_ms_per_batch                                                       9029.341061   \n",
       "throughput_queries_per_sec                                                            1.772001   \n",
       "throughput_tokens_per_sec                                                           226.816108   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2724073472   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1576560640   \n",
       "gpu_max_memory_allocated_bytes                                                      1576560640   \n",
       "gpu_current_memory_reserved_bytes                                                   2883584000   \n",
       "gpu_max_memory_reserved_bytes                                                       2883584000   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 193.829078   \n",
       "gpu_power_process_1                                                                 236.358817   \n",
       "gpu_power_process_2                                                                 185.554921   \n",
       "gpu_power_process_3                                                                 201.721599   \n",
       "ram_power_process_0                                                                   0.951005   \n",
       "ram_power_process_1                                                                    0.98946   \n",
       "ram_power_process_2                                                                    0.98913   \n",
       "ram_power_process_3                                                                   0.978004   \n",
       "cpu_energy_process_0                                                                  0.002227   \n",
       "cpu_energy_process_1                                                                   0.00227   \n",
       "cpu_energy_process_2                                                                  0.002257   \n",
       "cpu_energy_process_3                                                                  0.002235   \n",
       "gpu_energy_process_0                                                                  0.003987   \n",
       "gpu_energy_process_1                                                                  0.004065   \n",
       "gpu_energy_process_2                                                                  0.004039   \n",
       "gpu_energy_process_3                                                                  0.004015   \n",
       "ram_energy_process_0                                                                  0.000015   \n",
       "ram_energy_process_1                                                                  0.000016   \n",
       "ram_energy_process_2                                                                  0.000016   \n",
       "ram_energy_process_3                                                                  0.000015   \n",
       "total_energy_kwh_process_0                                                            0.006229   \n",
       "total_energy_kwh_process_1                                                            0.006351   \n",
       "total_energy_kwh_process_2                                                            0.006312   \n",
       "total_energy_kwh_process_3                                                            0.006265   \n",
       "total_energy_joules_process_0                                                     22424.153873   \n",
       "total_energy_joules_process_1                                                     22862.637004   \n",
       "total_energy_joules_process_2                                                     22724.614278   \n",
       "total_energy_joules_process_3                                                     22553.251001   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       204.366104   \n",
       "ram_power_avg                                                                           0.9769   \n",
       "cpu_energy_total                                                                       0.00899   \n",
       "gpu_energy_total                                                                      0.016105   \n",
       "ram_energy_total                                                                      0.000062   \n",
       "per-process_emissions_0                                                               0.002419   \n",
       "per-process_emissions_1                                                               0.002387   \n",
       "per-process_emissions_2                                                               0.002373   \n",
       "per-process_emissions_3                                                               0.002405   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            14  \\\n",
       "config_name                                  precis_float16_quant_True_quant8_False_quant4_...   \n",
       "experiment_id                                                                              247   \n",
       "date_time                                                        April 11, 2025 at 05:30:29 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                         0.021   \n",
       "total_energy_joules                                                               75601.377686   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.216716   \n",
       "joules_per_token                                                                      4.614342   \n",
       "flops_per_joule                                                               224201879.805033   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.354927   \n",
       "average_latency_ms_per_batch                                                       4669.365846   \n",
       "throughput_queries_per_sec                                                             3.42659   \n",
       "throughput_tokens_per_sec                                                           438.603457   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2635046912   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 267.232863   \n",
       "gpu_power_process_1                                                                 439.082005   \n",
       "gpu_power_process_2                                                                 445.149606   \n",
       "gpu_power_process_3                                                                 378.632031   \n",
       "ram_power_process_0                                                                   0.919427   \n",
       "ram_power_process_1                                                                   0.935027   \n",
       "ram_power_process_2                                                                   0.959318   \n",
       "ram_power_process_3                                                                   0.975047   \n",
       "cpu_energy_process_0                                                                  0.001155   \n",
       "cpu_energy_process_1                                                                  0.001132   \n",
       "cpu_energy_process_2                                                                  0.001135   \n",
       "cpu_energy_process_3                                                                  0.001151   \n",
       "gpu_energy_process_0                                                                   0.00413   \n",
       "gpu_energy_process_1                                                                  0.004074   \n",
       "gpu_energy_process_2                                                                  0.004074   \n",
       "gpu_energy_process_3                                                                  0.004119   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000007   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005292   \n",
       "total_energy_kwh_process_1                                                            0.005213   \n",
       "total_energy_kwh_process_2                                                            0.005217   \n",
       "total_energy_kwh_process_3                                                            0.005278   \n",
       "total_energy_joules_process_0                                                     19052.493231   \n",
       "total_energy_joules_process_1                                                     18767.881847   \n",
       "total_energy_joules_process_2                                                     18781.051648   \n",
       "total_energy_joules_process_3                                                      18999.95096   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       382.524126   \n",
       "ram_power_avg                                                                         0.947205   \n",
       "cpu_energy_total                                                                      0.004573   \n",
       "gpu_energy_total                                                                      0.016397   \n",
       "ram_energy_total                                                                       0.00003   \n",
       "per-process_emissions_0                                                               0.001987   \n",
       "per-process_emissions_1                                                               0.001986   \n",
       "per-process_emissions_2                                                               0.002011   \n",
       "per-process_emissions_3                                                               0.002016   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            15  \\\n",
       "config_name                                              decoding_greedy_decoder_temperature_0   \n",
       "experiment_id                                                                              248   \n",
       "date_time                                                        April 11, 2025 at 05:31:35 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.020611   \n",
       "total_energy_joules                                                               74199.651611   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                       0.22081   \n",
       "joules_per_token                                                                      4.528787   \n",
       "flops_per_joule                                                               228437339.327415   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.263684   \n",
       "average_latency_ms_per_batch                                                       4532.960497   \n",
       "throughput_queries_per_sec                                                            3.529702   \n",
       "throughput_tokens_per_sec                                                           451.801864   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2635730944   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 359.580526   \n",
       "gpu_power_process_1                                                                 327.361921   \n",
       "gpu_power_process_2                                                                        0.0   \n",
       "gpu_power_process_3                                                                 378.216056   \n",
       "ram_power_process_0                                                                    0.92031   \n",
       "ram_power_process_1                                                                    0.97417   \n",
       "ram_power_process_2                                                                    0.96314   \n",
       "ram_power_process_3                                                                   0.954191   \n",
       "cpu_energy_process_0                                                                  0.001121   \n",
       "cpu_energy_process_1                                                                  0.001126   \n",
       "cpu_energy_process_2                                                                  0.001144   \n",
       "cpu_energy_process_3                                                                  0.001117   \n",
       "gpu_energy_process_0                                                                  0.004023   \n",
       "gpu_energy_process_1                                                                  0.004033   \n",
       "gpu_energy_process_2                                                                  0.004004   \n",
       "gpu_energy_process_3                                                                  0.004013   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005151   \n",
       "total_energy_kwh_process_1                                                            0.005167   \n",
       "total_energy_kwh_process_2                                                            0.005155   \n",
       "total_energy_kwh_process_3                                                            0.005138   \n",
       "total_energy_joules_process_0                                                     18543.177523   \n",
       "total_energy_joules_process_1                                                     18599.512419   \n",
       "total_energy_joules_process_2                                                     18559.512238   \n",
       "total_energy_joules_process_3                                                     18497.449432   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       266.289626   \n",
       "ram_power_avg                                                                         0.952953   \n",
       "cpu_energy_total                                                                      0.004507   \n",
       "gpu_energy_total                                                                      0.016074   \n",
       "ram_energy_total                                                                       0.00003   \n",
       "per-process_emissions_0                                                               0.001964   \n",
       "per-process_emissions_1                                                               0.001962   \n",
       "per-process_emissions_2                                                               0.001968   \n",
       "per-process_emissions_3                                                               0.001957   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            16  \\\n",
       "config_name                                            decoding_greedy_decoder_temperature_0.2   \n",
       "experiment_id                                                                              249   \n",
       "date_time                                                        April 11, 2025 at 05:32:41 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021126   \n",
       "total_energy_joules                                                               76054.746039   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215424   \n",
       "joules_per_token                                                                      4.642013   \n",
       "flops_per_joule                                                               222865394.679583   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.233629   \n",
       "average_latency_ms_per_batch                                                       4654.203603   \n",
       "throughput_queries_per_sec                                                            3.437752   \n",
       "throughput_tokens_per_sec                                                           440.032318   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2647302144   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 302.087739   \n",
       "gpu_power_process_1                                                                        0.0   \n",
       "gpu_power_process_2                                                                 326.411876   \n",
       "gpu_power_process_3                                                                 309.987301   \n",
       "ram_power_process_0                                                                   0.923415   \n",
       "ram_power_process_1                                                                    0.97847   \n",
       "ram_power_process_2                                                                   0.968931   \n",
       "ram_power_process_3                                                                   0.978478   \n",
       "cpu_energy_process_0                                                                  0.001152   \n",
       "cpu_energy_process_1                                                                  0.001177   \n",
       "cpu_energy_process_2                                                                  0.001149   \n",
       "cpu_energy_process_3                                                                  0.001148   \n",
       "gpu_energy_process_0                                                                  0.004121   \n",
       "gpu_energy_process_1                                                                  0.004111   \n",
       "gpu_energy_process_2                                                                  0.004122   \n",
       "gpu_energy_process_3                                                                  0.004114   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                             0.00528   \n",
       "total_energy_kwh_process_1                                                            0.005296   \n",
       "total_energy_kwh_process_2                                                            0.005279   \n",
       "total_energy_kwh_process_3                                                             0.00527   \n",
       "total_energy_joules_process_0                                                     19009.732329   \n",
       "total_energy_joules_process_1                                                     19066.924468   \n",
       "total_energy_joules_process_2                                                     19005.080966   \n",
       "total_energy_joules_process_3                                                     18973.008275   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       234.621729   \n",
       "ram_power_avg                                                                         0.962324   \n",
       "cpu_energy_total                                                                      0.004626   \n",
       "gpu_energy_total                                                                      0.016469   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002012   \n",
       "per-process_emissions_1                                                               0.002011   \n",
       "per-process_emissions_2                                                               0.002008   \n",
       "per-process_emissions_3                                                               0.002018   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            17  \\\n",
       "config_name                                            decoding_greedy_decoder_temperature_0.4   \n",
       "experiment_id                                                                              250   \n",
       "date_time                                                        April 11, 2025 at 05:33:46 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021079   \n",
       "total_energy_joules                                                               75884.577747   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215907   \n",
       "joules_per_token                                                                      4.631627   \n",
       "flops_per_joule                                                               223365161.886555   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.712846   \n",
       "average_latency_ms_per_batch                                                       4589.105755   \n",
       "throughput_queries_per_sec                                                            3.486518   \n",
       "throughput_tokens_per_sec                                                           446.274309   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2669834240   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 454.091294   \n",
       "gpu_power_process_1                                                                        0.0   \n",
       "gpu_power_process_2                                                                 264.541795   \n",
       "gpu_power_process_3                                                                 423.814648   \n",
       "ram_power_process_0                                                                   0.931688   \n",
       "ram_power_process_1                                                                   0.975049   \n",
       "ram_power_process_2                                                                   0.978212   \n",
       "ram_power_process_3                                                                   0.967136   \n",
       "cpu_energy_process_0                                                                  0.001137   \n",
       "cpu_energy_process_1                                                                  0.001178   \n",
       "cpu_energy_process_2                                                                  0.001162   \n",
       "cpu_energy_process_3                                                                  0.001135   \n",
       "gpu_energy_process_0                                                                  0.004083   \n",
       "gpu_energy_process_1                                                                  0.004113   \n",
       "gpu_energy_process_2                                                                  0.004152   \n",
       "gpu_energy_process_3                                                                  0.004087   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005228   \n",
       "total_energy_kwh_process_1                                                            0.005299   \n",
       "total_energy_kwh_process_2                                                            0.005323   \n",
       "total_energy_kwh_process_3                                                             0.00523   \n",
       "total_energy_joules_process_0                                                     18819.325871   \n",
       "total_energy_joules_process_1                                                     19077.483681   \n",
       "total_energy_joules_process_2                                                     19161.453476   \n",
       "total_energy_joules_process_3                                                     18826.314719   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       285.611934   \n",
       "ram_power_avg                                                                         0.963021   \n",
       "cpu_energy_total                                                                      0.004612   \n",
       "gpu_energy_total                                                                      0.016436   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.001991   \n",
       "per-process_emissions_1                                                               0.002019   \n",
       "per-process_emissions_2                                                               0.002028   \n",
       "per-process_emissions_3                                                               0.001992   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            18  \\\n",
       "config_name                                            decoding_greedy_decoder_temperature_0.6   \n",
       "experiment_id                                                                              251   \n",
       "date_time                                                        April 11, 2025 at 05:34:52 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021087   \n",
       "total_energy_joules                                                               75912.204543   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215828   \n",
       "joules_per_token                                                                      4.633313   \n",
       "flops_per_joule                                                               223283872.404349   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.177409   \n",
       "average_latency_ms_per_batch                                                       4647.176079   \n",
       "throughput_queries_per_sec                                                            3.442951   \n",
       "throughput_tokens_per_sec                                                           440.697741   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2646908928   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 235.689028   \n",
       "gpu_power_process_1                                                                 441.178394   \n",
       "gpu_power_process_2                                                                 438.480677   \n",
       "gpu_power_process_3                                                                 450.938784   \n",
       "ram_power_process_0                                                                    0.92351   \n",
       "ram_power_process_1                                                                   0.983285   \n",
       "ram_power_process_2                                                                   0.970443   \n",
       "ram_power_process_3                                                                   0.978328   \n",
       "cpu_energy_process_0                                                                  0.001148   \n",
       "cpu_energy_process_1                                                                  0.001141   \n",
       "cpu_energy_process_2                                                                   0.00114   \n",
       "cpu_energy_process_3                                                                   0.00114   \n",
       "gpu_energy_process_0                                                                   0.00414   \n",
       "gpu_energy_process_1                                                                  0.004118   \n",
       "gpu_energy_process_2                                                                  0.004115   \n",
       "gpu_energy_process_3                                                                  0.004113   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005296   \n",
       "total_energy_kwh_process_1                                                            0.005267   \n",
       "total_energy_kwh_process_2                                                            0.005263   \n",
       "total_energy_kwh_process_3                                                            0.005261   \n",
       "total_energy_joules_process_0                                                     19065.481858   \n",
       "total_energy_joules_process_1                                                     18960.619637   \n",
       "total_energy_joules_process_2                                                      18947.84309   \n",
       "total_energy_joules_process_3                                                     18938.259958   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       391.571721   \n",
       "ram_power_avg                                                                         0.963892   \n",
       "cpu_energy_total                                                                      0.004569   \n",
       "gpu_energy_total                                                                      0.016487   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002005   \n",
       "per-process_emissions_1                                                               0.002006   \n",
       "per-process_emissions_2                                                               0.002017   \n",
       "per-process_emissions_3                                                               0.002004   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            19  \\\n",
       "config_name                                            decoding_greedy_decoder_temperature_0.8   \n",
       "experiment_id                                                                              252   \n",
       "date_time                                                        April 11, 2025 at 05:35:58 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021035   \n",
       "total_energy_joules                                                               75727.619266   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.216354   \n",
       "joules_per_token                                                                      4.622047   \n",
       "flops_per_joule                                                               223828124.501124   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.286998   \n",
       "average_latency_ms_per_batch                                                       4660.874719   \n",
       "throughput_queries_per_sec                                                            3.432832   \n",
       "throughput_tokens_per_sec                                                           439.402499   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2602528768   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                 94.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 363.206546   \n",
       "gpu_power_process_1                                                                 432.353573   \n",
       "gpu_power_process_2                                                                  419.13896   \n",
       "gpu_power_process_3                                                                 424.590529   \n",
       "ram_power_process_0                                                                   0.907567   \n",
       "ram_power_process_1                                                                   0.969295   \n",
       "ram_power_process_2                                                                   0.976447   \n",
       "ram_power_process_3                                                                   0.970631   \n",
       "cpu_energy_process_0                                                                   0.00115   \n",
       "cpu_energy_process_1                                                                  0.001131   \n",
       "cpu_energy_process_2                                                                  0.001143   \n",
       "cpu_energy_process_3                                                                  0.001152   \n",
       "gpu_energy_process_0                                                                  0.004131   \n",
       "gpu_energy_process_1                                                                  0.004061   \n",
       "gpu_energy_process_2                                                                  0.004104   \n",
       "gpu_energy_process_3                                                                  0.004131   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005289   \n",
       "total_energy_kwh_process_1                                                              0.0052   \n",
       "total_energy_kwh_process_2                                                            0.005255   \n",
       "total_energy_kwh_process_3                                                            0.005291   \n",
       "total_energy_joules_process_0                                                     19040.885156   \n",
       "total_energy_joules_process_1                                                     18720.254459   \n",
       "total_energy_joules_process_2                                                     18918.645607   \n",
       "total_energy_joules_process_3                                                     19047.834044   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       409.822402   \n",
       "ram_power_avg                                                                         0.955985   \n",
       "cpu_energy_total                                                                      0.004577   \n",
       "gpu_energy_total                                                                      0.016428   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.001981   \n",
       "per-process_emissions_1                                                               0.002015   \n",
       "per-process_emissions_2                                                               0.002016   \n",
       "per-process_emissions_3                                                               0.002002   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            20  \\\n",
       "config_name                                            decoding_greedy_decoder_temperature_1.0   \n",
       "experiment_id                                                                              253   \n",
       "date_time                                                        April 11, 2025 at 05:37:04 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021028   \n",
       "total_energy_joules                                                               75701.472545   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.216429   \n",
       "joules_per_token                                                                      4.620451   \n",
       "flops_per_joule                                                               223905433.056266   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.730154   \n",
       "average_latency_ms_per_batch                                                       4591.269241   \n",
       "throughput_queries_per_sec                                                            3.484875   \n",
       "throughput_tokens_per_sec                                                           446.064017   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2628485120   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 438.206965   \n",
       "gpu_power_process_1                                                                  444.31133   \n",
       "gpu_power_process_2                                                                 397.175881   \n",
       "gpu_power_process_3                                                                 439.503886   \n",
       "ram_power_process_0                                                                   0.916924   \n",
       "ram_power_process_1                                                                   0.970323   \n",
       "ram_power_process_2                                                                   0.976032   \n",
       "ram_power_process_3                                                                   0.974958   \n",
       "cpu_energy_process_0                                                                  0.001136   \n",
       "cpu_energy_process_1                                                                  0.001137   \n",
       "cpu_energy_process_2                                                                  0.001143   \n",
       "cpu_energy_process_3                                                                  0.001133   \n",
       "gpu_energy_process_0                                                                  0.004108   \n",
       "gpu_energy_process_1                                                                  0.004112   \n",
       "gpu_energy_process_2                                                                  0.004126   \n",
       "gpu_energy_process_3                                                                  0.004104   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005251   \n",
       "total_energy_kwh_process_1                                                            0.005257   \n",
       "total_energy_kwh_process_2                                                            0.005277   \n",
       "total_energy_kwh_process_3                                                            0.005244   \n",
       "total_energy_joules_process_0                                                     18904.127078   \n",
       "total_energy_joules_process_1                                                     18923.632368   \n",
       "total_energy_joules_process_2                                                     18995.788813   \n",
       "total_energy_joules_process_3                                                     18877.924286   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       429.799515   \n",
       "ram_power_avg                                                                         0.959559   \n",
       "cpu_energy_total                                                                      0.004548   \n",
       "gpu_energy_total                                                                       0.01645   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002002   \n",
       "per-process_emissions_1                                                               0.001998   \n",
       "per-process_emissions_2                                                                0.00201   \n",
       "per-process_emissions_3                                                                  0.002   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            21  \\\n",
       "config_name                                            decoding_greedy_decoder_temperature_1.2   \n",
       "experiment_id                                                                              254   \n",
       "date_time                                                        April 11, 2025 at 05:38:09 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021053   \n",
       "total_energy_joules                                                               75790.175016   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.216176   \n",
       "joules_per_token                                                                      4.625865   \n",
       "flops_per_joule                                                               223643381.078152   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.862467   \n",
       "average_latency_ms_per_batch                                                        4607.80839   \n",
       "throughput_queries_per_sec                                                            3.472367   \n",
       "throughput_tokens_per_sec                                                           444.462926   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2651119616   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 406.354141   \n",
       "gpu_power_process_1                                                                 448.409327   \n",
       "gpu_power_process_2                                                                 434.662371   \n",
       "gpu_power_process_3                                                                 438.774828   \n",
       "ram_power_process_0                                                                   0.925408   \n",
       "ram_power_process_1                                                                    0.97565   \n",
       "ram_power_process_2                                                                   0.966662   \n",
       "ram_power_process_3                                                                   0.959171   \n",
       "cpu_energy_process_0                                                                  0.001137   \n",
       "cpu_energy_process_1                                                                  0.001133   \n",
       "cpu_energy_process_2                                                                  0.001137   \n",
       "cpu_energy_process_3                                                                  0.001132   \n",
       "gpu_energy_process_0                                                                  0.004129   \n",
       "gpu_energy_process_1                                                                  0.004115   \n",
       "gpu_energy_process_2                                                                  0.004123   \n",
       "gpu_energy_process_3                                                                  0.004115   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005273   \n",
       "total_energy_kwh_process_1                                                            0.005256   \n",
       "total_energy_kwh_process_2                                                            0.005268   \n",
       "total_energy_kwh_process_3                                                            0.005255   \n",
       "total_energy_joules_process_0                                                     18984.102044   \n",
       "total_energy_joules_process_1                                                     18923.329727   \n",
       "total_energy_joules_process_2                                                     18963.333301   \n",
       "total_energy_joules_process_3                                                     18919.409945   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       432.050167   \n",
       "ram_power_avg                                                                         0.956723   \n",
       "cpu_energy_total                                                                       0.00454   \n",
       "gpu_energy_total                                                                      0.016483   \n",
       "ram_energy_total                                                                       0.00003   \n",
       "per-process_emissions_0                                                               0.002009   \n",
       "per-process_emissions_1                                                               0.002007   \n",
       "per-process_emissions_2                                                               0.002002   \n",
       "per-process_emissions_3                                                               0.002002   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            22  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                              256   \n",
       "date_time                                                        April 11, 2025 at 05:39:42 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                               20   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.020493   \n",
       "total_energy_joules                                                               73773.389464   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.222085   \n",
       "joules_per_token                                                                       4.50277   \n",
       "flops_per_joule                                                                229757248.73563   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.388011   \n",
       "average_latency_ms_per_batch                                                       4548.501365   \n",
       "throughput_queries_per_sec                                                            3.517642   \n",
       "throughput_tokens_per_sec                                                           450.258192   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2658959360   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 448.785248   \n",
       "gpu_power_process_1                                                                  414.98603   \n",
       "gpu_power_process_2                                                                 388.546261   \n",
       "gpu_power_process_3                                                                 432.888458   \n",
       "ram_power_process_0                                                                   0.927464   \n",
       "ram_power_process_1                                                                   0.972663   \n",
       "ram_power_process_2                                                                   0.954529   \n",
       "ram_power_process_3                                                                   0.966505   \n",
       "cpu_energy_process_0                                                                  0.001122   \n",
       "cpu_energy_process_1                                                                  0.001123   \n",
       "cpu_energy_process_2                                                                  0.001128   \n",
       "cpu_energy_process_3                                                                  0.001122   \n",
       "gpu_energy_process_0                                                                  0.003986   \n",
       "gpu_energy_process_1                                                                  0.003989   \n",
       "gpu_energy_process_2                                                                  0.004003   \n",
       "gpu_energy_process_3                                                                  0.003989   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000007   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005115   \n",
       "total_energy_kwh_process_1                                                             0.00512   \n",
       "total_energy_kwh_process_2                                                            0.005138   \n",
       "total_energy_kwh_process_3                                                            0.005119   \n",
       "total_energy_joules_process_0                                                     18413.707198   \n",
       "total_energy_joules_process_1                                                      18433.45926   \n",
       "total_energy_joules_process_2                                                     18497.529283   \n",
       "total_energy_joules_process_3                                                     18428.693723   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       421.301499   \n",
       "ram_power_avg                                                                          0.95529   \n",
       "cpu_energy_total                                                                      0.004495   \n",
       "gpu_energy_total                                                                      0.015968   \n",
       "ram_energy_total                                                                       0.00003   \n",
       "per-process_emissions_0                                                                0.00195   \n",
       "per-process_emissions_1                                                               0.001951   \n",
       "per-process_emissions_2                                                               0.001957   \n",
       "per-process_emissions_3                                                               0.001949   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            23  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                              257   \n",
       "date_time                                                        April 11, 2025 at 05:40:48 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.020526   \n",
       "total_energy_joules                                                               73892.703968   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.221727   \n",
       "joules_per_token                                                                      4.510053   \n",
       "flops_per_joule                                                               229386259.846373   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.456038   \n",
       "average_latency_ms_per_batch                                                       4557.004705   \n",
       "throughput_queries_per_sec                                                            3.511078   \n",
       "throughput_tokens_per_sec                                                           449.418013   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2661109760   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 272.436821   \n",
       "gpu_power_process_1                                                                 431.225061   \n",
       "gpu_power_process_2                                                                 436.518678   \n",
       "gpu_power_process_3                                                                 433.034685   \n",
       "ram_power_process_0                                                                   0.928555   \n",
       "ram_power_process_1                                                                   0.971523   \n",
       "ram_power_process_2                                                                    0.95418   \n",
       "ram_power_process_3                                                                   0.961859   \n",
       "cpu_energy_process_0                                                                  0.001127   \n",
       "cpu_energy_process_1                                                                  0.001108   \n",
       "cpu_energy_process_2                                                                  0.001119   \n",
       "cpu_energy_process_3                                                                   0.00111   \n",
       "gpu_energy_process_0                                                                  0.004037   \n",
       "gpu_energy_process_1                                                                  0.003984   \n",
       "gpu_energy_process_2                                                                  0.004016   \n",
       "gpu_energy_process_3                                                                  0.003995   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                             0.00517   \n",
       "total_energy_kwh_process_1                                                              0.0051   \n",
       "total_energy_kwh_process_2                                                            0.005143   \n",
       "total_energy_kwh_process_3                                                            0.005112   \n",
       "total_energy_joules_process_0                                                     18613.564912   \n",
       "total_energy_joules_process_1                                                     18360.078347   \n",
       "total_energy_joules_process_2                                                     18516.525825   \n",
       "total_energy_joules_process_3                                                     18402.534883   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       393.303811   \n",
       "ram_power_avg                                                                         0.954029   \n",
       "cpu_energy_total                                                                      0.004464   \n",
       "gpu_energy_total                                                                      0.016032   \n",
       "ram_energy_total                                                                       0.00003   \n",
       "per-process_emissions_0                                                                0.00197   \n",
       "per-process_emissions_1                                                               0.001959   \n",
       "per-process_emissions_2                                                               0.001943   \n",
       "per-process_emissions_3                                                               0.001947   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            24  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                              258   \n",
       "date_time                                                        April 11, 2025 at 05:41:54 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                              100   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.020592   \n",
       "total_energy_joules                                                               74129.708593   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.221018   \n",
       "joules_per_token                                                                      4.524518   \n",
       "flops_per_joule                                                               228652875.007557   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.447105   \n",
       "average_latency_ms_per_batch                                                       4555.888145   \n",
       "throughput_queries_per_sec                                                            3.511939   \n",
       "throughput_tokens_per_sec                                                           449.528157   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2658758656   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 293.491565   \n",
       "gpu_power_process_1                                                                        0.0   \n",
       "gpu_power_process_2                                                                 446.047604   \n",
       "gpu_power_process_3                                                                 431.404266   \n",
       "ram_power_process_0                                                                   0.927516   \n",
       "ram_power_process_1                                                                   0.954426   \n",
       "ram_power_process_2                                                                   0.974506   \n",
       "ram_power_process_3                                                                   0.966983   \n",
       "cpu_energy_process_0                                                                  0.001128   \n",
       "cpu_energy_process_1                                                                  0.001148   \n",
       "cpu_energy_process_2                                                                  0.001121   \n",
       "cpu_energy_process_3                                                                  0.001104   \n",
       "gpu_energy_process_0                                                                  0.004042   \n",
       "gpu_energy_process_1                                                                  0.004014   \n",
       "gpu_energy_process_2                                                                   0.00403   \n",
       "gpu_energy_process_3                                                                  0.003976   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000007   \n",
       "total_energy_kwh_process_0                                                            0.005177   \n",
       "total_energy_kwh_process_1                                                            0.005169   \n",
       "total_energy_kwh_process_2                                                            0.005158   \n",
       "total_energy_kwh_process_3                                                            0.005088   \n",
       "total_energy_joules_process_0                                                     18636.922288   \n",
       "total_energy_joules_process_1                                                      18608.24352   \n",
       "total_energy_joules_process_2                                                     18568.780196   \n",
       "total_energy_joules_process_3                                                     18315.762589   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       292.735859   \n",
       "ram_power_avg                                                                         0.955858   \n",
       "cpu_energy_total                                                                        0.0045   \n",
       "gpu_energy_total                                                                      0.016062   \n",
       "ram_energy_total                                                                       0.00003   \n",
       "per-process_emissions_0                                                               0.001969   \n",
       "per-process_emissions_1                                                               0.001938   \n",
       "per-process_emissions_2                                                               0.001972   \n",
       "per-process_emissions_3                                                               0.001965   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            25  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                              259   \n",
       "date_time                                                        April 11, 2025 at 05:43:00 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                              200   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.020612   \n",
       "total_energy_joules                                                               74203.606308   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.220798   \n",
       "joules_per_token                                                                      4.529029   \n",
       "flops_per_joule                                                               228425164.711328   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.306288   \n",
       "average_latency_ms_per_batch                                                       4538.285978   \n",
       "throughput_queries_per_sec                                                             3.52556   \n",
       "throughput_tokens_per_sec                                                           451.271694   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2679640064   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                 83.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 365.781018   \n",
       "gpu_power_process_1                                                                 321.607445   \n",
       "gpu_power_process_2                                                                 451.461048   \n",
       "gpu_power_process_3                                                                 844.810036   \n",
       "ram_power_process_0                                                                   0.935623   \n",
       "ram_power_process_1                                                                   0.955655   \n",
       "ram_power_process_2                                                                   0.960734   \n",
       "ram_power_process_3                                                                   0.954899   \n",
       "cpu_energy_process_0                                                                  0.001123   \n",
       "cpu_energy_process_1                                                                  0.001124   \n",
       "cpu_energy_process_2                                                                  0.001106   \n",
       "cpu_energy_process_3                                                                  0.001117   \n",
       "gpu_energy_process_0                                                                  0.004042   \n",
       "gpu_energy_process_1                                                                  0.004042   \n",
       "gpu_energy_process_2                                                                  0.004002   \n",
       "gpu_energy_process_3                                                                  0.004027   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000007   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005172   \n",
       "total_energy_kwh_process_1                                                            0.005173   \n",
       "total_energy_kwh_process_2                                                            0.005116   \n",
       "total_energy_kwh_process_3                                                            0.005151   \n",
       "total_energy_joules_process_0                                                     18620.172839   \n",
       "total_energy_joules_process_1                                                     18621.859381   \n",
       "total_energy_joules_process_2                                                     18416.462053   \n",
       "total_energy_joules_process_3                                                     18545.112036   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       495.914887   \n",
       "ram_power_avg                                                                         0.951728   \n",
       "cpu_energy_total                                                                       0.00447   \n",
       "gpu_energy_total                                                                      0.016112   \n",
       "ram_energy_total                                                                       0.00003   \n",
       "per-process_emissions_0                                                                0.00197   \n",
       "per-process_emissions_1                                                               0.001971   \n",
       "per-process_emissions_2                                                               0.001949   \n",
       "per-process_emissions_3                                                               0.001962   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            26  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                              260   \n",
       "date_time                                                        April 11, 2025 at 05:44:05 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                              500   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.020695   \n",
       "total_energy_joules                                                               74501.001648   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.219917   \n",
       "joules_per_token                                                                       4.54718   \n",
       "flops_per_joule                                                                227513330.26575   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.211281   \n",
       "average_latency_ms_per_batch                                                       4526.410158   \n",
       "throughput_queries_per_sec                                                             3.53481   \n",
       "throughput_tokens_per_sec                                                           452.455683   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2613747712   \n",
       "gpu_utilization_percent_0                                                                  5.0   \n",
       "gpu_utilization_percent_1                                                                 77.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 493.062977   \n",
       "gpu_power_process_1                                                                 336.929049   \n",
       "gpu_power_process_2                                                                 439.924221   \n",
       "gpu_power_process_3                                                                 378.392652   \n",
       "ram_power_process_0                                                                    0.91227   \n",
       "ram_power_process_1                                                                   0.946471   \n",
       "ram_power_process_2                                                                   0.971133   \n",
       "ram_power_process_3                                                                   0.962502   \n",
       "cpu_energy_process_0                                                                  0.001119   \n",
       "cpu_energy_process_1                                                                  0.001128   \n",
       "cpu_energy_process_2                                                                  0.001112   \n",
       "cpu_energy_process_3                                                                  0.001124   \n",
       "gpu_energy_process_0                                                                  0.004044   \n",
       "gpu_energy_process_1                                                                  0.004063   \n",
       "gpu_energy_process_2                                                                  0.004013   \n",
       "gpu_energy_process_3                                                                  0.004062   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000007   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                             0.00517   \n",
       "total_energy_kwh_process_1                                                            0.005199   \n",
       "total_energy_kwh_process_2                                                            0.005132   \n",
       "total_energy_kwh_process_3                                                            0.005193   \n",
       "total_energy_joules_process_0                                                     18612.694662   \n",
       "total_energy_joules_process_1                                                     18715.010011   \n",
       "total_energy_joules_process_2                                                     18476.741718   \n",
       "total_energy_joules_process_3                                                     18696.555257   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       412.077225   \n",
       "ram_power_avg                                                                         0.948094   \n",
       "cpu_energy_total                                                                      0.004483   \n",
       "gpu_energy_total                                                                      0.016181   \n",
       "ram_energy_total                                                                       0.00003   \n",
       "per-process_emissions_0                                                                0.00198   \n",
       "per-process_emissions_1                                                               0.001978   \n",
       "per-process_emissions_2                                                               0.001955   \n",
       "per-process_emissions_3                                                                0.00197   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            27  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                              261   \n",
       "date_time                                                        April 11, 2025 at 05:45:11 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                               20   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021096   \n",
       "total_energy_joules                                                               75946.539604   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215731   \n",
       "joules_per_token                                                                      4.635409   \n",
       "flops_per_joule                                                               223182926.853609   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.147624   \n",
       "average_latency_ms_per_batch                                                       4643.452946   \n",
       "throughput_queries_per_sec                                                            3.445712   \n",
       "throughput_tokens_per_sec                                                           441.051094   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2676936704   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 374.044486   \n",
       "gpu_power_process_1                                                                  418.66132   \n",
       "gpu_power_process_2                                                                  457.55603   \n",
       "gpu_power_process_3                                                                 282.526495   \n",
       "ram_power_process_0                                                                   0.933765   \n",
       "ram_power_process_1                                                                   0.960453   \n",
       "ram_power_process_2                                                                   0.979754   \n",
       "ram_power_process_3                                                                   0.976695   \n",
       "cpu_energy_process_0                                                                  0.001147   \n",
       "cpu_energy_process_1                                                                  0.001135   \n",
       "cpu_energy_process_2                                                                  0.001123   \n",
       "cpu_energy_process_3                                                                  0.001163   \n",
       "gpu_energy_process_0                                                                  0.004141   \n",
       "gpu_energy_process_1                                                                  0.004107   \n",
       "gpu_energy_process_2                                                                  0.004072   \n",
       "gpu_energy_process_3                                                                  0.004177   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005295   \n",
       "total_energy_kwh_process_1                                                             0.00525   \n",
       "total_energy_kwh_process_2                                                            0.005203   \n",
       "total_energy_kwh_process_3                                                            0.005348   \n",
       "total_energy_joules_process_0                                                     19063.728589   \n",
       "total_energy_joules_process_1                                                     18899.344582   \n",
       "total_energy_joules_process_2                                                     18731.514339   \n",
       "total_energy_joules_process_3                                                     19251.952093   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       383.197083   \n",
       "ram_power_avg                                                                         0.962667   \n",
       "cpu_energy_total                                                                      0.004568   \n",
       "gpu_energy_total                                                                      0.016497   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                                  0.002   \n",
       "per-process_emissions_1                                                               0.002017   \n",
       "per-process_emissions_2                                                               0.001982   \n",
       "per-process_emissions_3                                                               0.002037   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            28  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                              262   \n",
       "date_time                                                        April 11, 2025 at 05:46:17 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021167   \n",
       "total_energy_joules                                                               76201.793024   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215008   \n",
       "joules_per_token                                                                      4.650988   \n",
       "flops_per_joule                                                               222435330.199059   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.538299   \n",
       "average_latency_ms_per_batch                                                       4692.287417   \n",
       "throughput_queries_per_sec                                                            3.409851   \n",
       "throughput_tokens_per_sec                                                           436.460902   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2654609408   \n",
       "gpu_utilization_percent_0                                                                 18.0   \n",
       "gpu_utilization_percent_1                                                                 84.0   \n",
       "gpu_utilization_percent_2                                                                 99.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 355.870535   \n",
       "gpu_power_process_1                                                                 357.389002   \n",
       "gpu_power_process_2                                                                   422.8812   \n",
       "gpu_power_process_3                                                                 425.038283   \n",
       "ram_power_process_0                                                                   0.925947   \n",
       "ram_power_process_1                                                                   0.971366   \n",
       "ram_power_process_2                                                                   0.978035   \n",
       "ram_power_process_3                                                                   0.980337   \n",
       "cpu_energy_process_0                                                                  0.001157   \n",
       "cpu_energy_process_1                                                                  0.001164   \n",
       "cpu_energy_process_2                                                                  0.001141   \n",
       "cpu_energy_process_3                                                                  0.001152   \n",
       "gpu_energy_process_0                                                                  0.004151   \n",
       "gpu_energy_process_1                                                                  0.004158   \n",
       "gpu_energy_process_2                                                                  0.004084   \n",
       "gpu_energy_process_3                                                                   0.00413   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005316   \n",
       "total_energy_kwh_process_1                                                             0.00533   \n",
       "total_energy_kwh_process_2                                                            0.005233   \n",
       "total_energy_kwh_process_3                                                            0.005289   \n",
       "total_energy_joules_process_0                                                     19136.439804   \n",
       "total_energy_joules_process_1                                                     19186.543281   \n",
       "total_energy_joules_process_2                                                     18837.102858   \n",
       "total_energy_joules_process_3                                                     19041.707081   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       390.294755   \n",
       "ram_power_avg                                                                         0.963921   \n",
       "cpu_energy_total                                                                      0.004614   \n",
       "gpu_energy_total                                                                      0.016523   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                                0.00203   \n",
       "per-process_emissions_1                                                               0.002015   \n",
       "per-process_emissions_2                                                               0.001993   \n",
       "per-process_emissions_3                                                               0.002025   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            29  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                              263   \n",
       "date_time                                                        April 11, 2025 at 05:47:23 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                              100   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021317   \n",
       "total_energy_joules                                                               76742.959091   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.213492   \n",
       "joules_per_token                                                                      4.684018   \n",
       "flops_per_joule                                                               220866789.524664   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.345801   \n",
       "average_latency_ms_per_batch                                                       4668.225076   \n",
       "throughput_queries_per_sec                                                            3.427427   \n",
       "throughput_tokens_per_sec                                                           438.710638   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2630242304   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 373.705112   \n",
       "gpu_power_process_1                                                                 710.028922   \n",
       "gpu_power_process_2                                                                 709.266375   \n",
       "gpu_power_process_3                                                                 492.315839   \n",
       "ram_power_process_0                                                                   0.917373   \n",
       "ram_power_process_1                                                                    0.96142   \n",
       "ram_power_process_2                                                                   0.976421   \n",
       "ram_power_process_3                                                                   0.959867   \n",
       "cpu_energy_process_0                                                                  0.001154   \n",
       "cpu_energy_process_1                                                                  0.001146   \n",
       "cpu_energy_process_2                                                                  0.001146   \n",
       "cpu_energy_process_3                                                                  0.001146   \n",
       "gpu_energy_process_0                                                                  0.004186   \n",
       "gpu_energy_process_1                                                                  0.004171   \n",
       "gpu_energy_process_2                                                                  0.004171   \n",
       "gpu_energy_process_3                                                                  0.004167   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005347   \n",
       "total_energy_kwh_process_1                                                            0.005325   \n",
       "total_energy_kwh_process_2                                                            0.005325   \n",
       "total_energy_kwh_process_3                                                            0.005321   \n",
       "total_energy_joules_process_0                                                     19248.542739   \n",
       "total_energy_joules_process_1                                                     19168.657713   \n",
       "total_energy_joules_process_2                                                     19170.857594   \n",
       "total_energy_joules_process_3                                                     19154.901046   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       571.329062   \n",
       "ram_power_avg                                                                          0.95377   \n",
       "cpu_energy_total                                                                      0.004592   \n",
       "gpu_energy_total                                                                      0.016694   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002028   \n",
       "per-process_emissions_1                                                               0.002029   \n",
       "per-process_emissions_2                                                               0.002027   \n",
       "per-process_emissions_3                                                               0.002037   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            30  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                              264   \n",
       "date_time                                                        April 11, 2025 at 05:48:29 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                              200   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021256   \n",
       "total_energy_joules                                                               76520.796084   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214112   \n",
       "joules_per_token                                                                      4.670459   \n",
       "flops_per_joule                                                               221508032.594712   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.266966   \n",
       "average_latency_ms_per_batch                                                       4658.370769   \n",
       "throughput_queries_per_sec                                                            3.434677   \n",
       "throughput_tokens_per_sec                                                           439.638685   \n",
       "cpu_usage_percent                                                                          3.1   \n",
       "cpu_memory_usage_bytes                                                              2654191616   \n",
       "gpu_utilization_percent_0                                                                 15.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                 86.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 447.668445   \n",
       "gpu_power_process_1                                                                 475.346304   \n",
       "gpu_power_process_2                                                                 347.897411   \n",
       "gpu_power_process_3                                                                 299.915257   \n",
       "ram_power_process_0                                                                   0.926202   \n",
       "ram_power_process_1                                                                   0.977783   \n",
       "ram_power_process_2                                                                   0.968572   \n",
       "ram_power_process_3                                                                   0.968442   \n",
       "cpu_energy_process_0                                                                  0.001154   \n",
       "cpu_energy_process_1                                                                  0.001129   \n",
       "cpu_energy_process_2                                                                  0.001158   \n",
       "cpu_energy_process_3                                                                  0.001147   \n",
       "gpu_energy_process_0                                                                  0.004179   \n",
       "gpu_energy_process_1                                                                  0.004097   \n",
       "gpu_energy_process_2                                                                  0.004189   \n",
       "gpu_energy_process_3                                                                  0.004172   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                             0.00534   \n",
       "total_energy_kwh_process_1                                                            0.005234   \n",
       "total_energy_kwh_process_2                                                            0.005355   \n",
       "total_energy_kwh_process_3                                                            0.005327   \n",
       "total_energy_joules_process_0                                                     19223.067962   \n",
       "total_energy_joules_process_1                                                     18842.386631   \n",
       "total_energy_joules_process_2                                                     19278.754826   \n",
       "total_energy_joules_process_3                                                     19176.586665   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       392.706854   \n",
       "ram_power_avg                                                                          0.96025   \n",
       "cpu_energy_total                                                                      0.004588   \n",
       "gpu_energy_total                                                                      0.016637   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002029   \n",
       "per-process_emissions_1                                                                0.00204   \n",
       "per-process_emissions_2                                                               0.002034   \n",
       "per-process_emissions_3                                                               0.001994   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            31  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                              265   \n",
       "date_time                                                        April 11, 2025 at 05:49:38 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                              500   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021237   \n",
       "total_energy_joules                                                                 76452.8938   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214302   \n",
       "joules_per_token                                                                      4.666314   \n",
       "flops_per_joule                                                               221704766.827728   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              37.24014   \n",
       "average_latency_ms_per_batch                                                        4655.01752   \n",
       "throughput_queries_per_sec                                                            3.437151   \n",
       "throughput_tokens_per_sec                                                            439.95538   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2631348224   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                 84.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 414.377199   \n",
       "gpu_power_process_1                                                                 443.753415   \n",
       "gpu_power_process_2                                                                 217.730738   \n",
       "gpu_power_process_3                                                                 392.364762   \n",
       "ram_power_process_0                                                                   0.918586   \n",
       "ram_power_process_1                                                                   0.971503   \n",
       "ram_power_process_2                                                                    0.98462   \n",
       "ram_power_process_3                                                                    0.97154   \n",
       "cpu_energy_process_0                                                                  0.001152   \n",
       "cpu_energy_process_1                                                                  0.001141   \n",
       "cpu_energy_process_2                                                                  0.001147   \n",
       "cpu_energy_process_3                                                                  0.001155   \n",
       "gpu_energy_process_0                                                                  0.004163   \n",
       "gpu_energy_process_1                                                                  0.004128   \n",
       "gpu_energy_process_2                                                                   0.00415   \n",
       "gpu_energy_process_3                                                                  0.004171   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005323   \n",
       "total_energy_kwh_process_1                                                            0.005277   \n",
       "total_energy_kwh_process_2                                                            0.005304   \n",
       "total_energy_kwh_process_3                                                            0.005333   \n",
       "total_energy_joules_process_0                                                      19161.22448   \n",
       "total_energy_joules_process_1                                                      18995.69519   \n",
       "total_energy_joules_process_2                                                     19095.977762   \n",
       "total_energy_joules_process_3                                                     19199.996368   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       367.056529   \n",
       "ram_power_avg                                                                         0.961562   \n",
       "cpu_energy_total                                                                      0.004594   \n",
       "gpu_energy_total                                                                      0.016611   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002028   \n",
       "per-process_emissions_1                                                               0.002021   \n",
       "per-process_emissions_2                                                                0.00201   \n",
       "per-process_emissions_3                                                               0.002032   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            32  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                              266   \n",
       "date_time                                                        April 11, 2025 at 05:50:44 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                               20   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021173   \n",
       "total_energy_joules                                                               76223.569931   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214947   \n",
       "joules_per_token                                                                      4.652318   \n",
       "flops_per_joule                                                                222371780.91456   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.286302   \n",
       "average_latency_ms_per_batch                                                       4660.787711   \n",
       "throughput_queries_per_sec                                                            3.432896   \n",
       "throughput_tokens_per_sec                                                           439.410702   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2631778304   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 253.802369   \n",
       "gpu_power_process_1                                                                 430.509635   \n",
       "gpu_power_process_2                                                                 788.632968   \n",
       "gpu_power_process_3                                                                 425.226577   \n",
       "ram_power_process_0                                                                   0.918288   \n",
       "ram_power_process_1                                                                   0.986293   \n",
       "ram_power_process_2                                                                    0.96053   \n",
       "ram_power_process_3                                                                    0.96832   \n",
       "cpu_energy_process_0                                                                  0.001151   \n",
       "cpu_energy_process_1                                                                  0.001129   \n",
       "cpu_energy_process_2                                                                  0.001145   \n",
       "cpu_energy_process_3                                                                  0.001139   \n",
       "gpu_energy_process_0                                                                  0.004172   \n",
       "gpu_energy_process_1                                                                  0.004106   \n",
       "gpu_energy_process_2                                                                  0.004161   \n",
       "gpu_energy_process_3                                                                   0.00414   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                             0.00533   \n",
       "total_energy_kwh_process_1                                                            0.005243   \n",
       "total_energy_kwh_process_2                                                            0.005314   \n",
       "total_energy_kwh_process_3                                                            0.005286   \n",
       "total_energy_joules_process_0                                                     19189.409224   \n",
       "total_energy_joules_process_1                                                     18876.521194   \n",
       "total_energy_joules_process_2                                                     19128.826764   \n",
       "total_energy_joules_process_3                                                     19028.812749   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       474.542887   \n",
       "ram_power_avg                                                                         0.958358   \n",
       "cpu_energy_total                                                                      0.004563   \n",
       "gpu_energy_total                                                                      0.016579   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.001998   \n",
       "per-process_emissions_1                                                               0.002031   \n",
       "per-process_emissions_2                                                               0.002014   \n",
       "per-process_emissions_3                                                               0.002024   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            33  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                              267   \n",
       "date_time                                                        April 11, 2025 at 05:51:50 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021219   \n",
       "total_energy_joules                                                               76386.637887   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214488   \n",
       "joules_per_token                                                                       4.66227   \n",
       "flops_per_joule                                                               221897068.152067   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.472509   \n",
       "average_latency_ms_per_batch                                                       4684.063664   \n",
       "throughput_queries_per_sec                                                            3.415837   \n",
       "throughput_tokens_per_sec                                                           437.227191   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2632622080   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 293.892951   \n",
       "gpu_power_process_1                                                                 322.202524   \n",
       "gpu_power_process_2                                                                  430.09949   \n",
       "gpu_power_process_3                                                                 291.424554   \n",
       "ram_power_process_0                                                                   0.918451   \n",
       "ram_power_process_1                                                                   0.976789   \n",
       "ram_power_process_2                                                                   0.945581   \n",
       "ram_power_process_3                                                                   0.968677   \n",
       "cpu_energy_process_0                                                                  0.001159   \n",
       "cpu_energy_process_1                                                                  0.001149   \n",
       "cpu_energy_process_2                                                                  0.001141   \n",
       "cpu_energy_process_3                                                                  0.001145   \n",
       "gpu_energy_process_0                                                                  0.004174   \n",
       "gpu_energy_process_1                                                                  0.004146   \n",
       "gpu_energy_process_2                                                                  0.004128   \n",
       "gpu_energy_process_3                                                                  0.004146   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005341   \n",
       "total_energy_kwh_process_1                                                            0.005303   \n",
       "total_energy_kwh_process_2                                                            0.005276   \n",
       "total_energy_kwh_process_3                                                            0.005299   \n",
       "total_energy_joules_process_0                                                     19225.800509   \n",
       "total_energy_joules_process_1                                                     19090.668839   \n",
       "total_energy_joules_process_2                                                     18994.107682   \n",
       "total_energy_joules_process_3                                                     19076.060858   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        334.40488   \n",
       "ram_power_avg                                                                         0.952374   \n",
       "cpu_energy_total                                                                      0.004593   \n",
       "gpu_energy_total                                                                      0.016594   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002019   \n",
       "per-process_emissions_1                                                               0.002034   \n",
       "per-process_emissions_2                                                                0.00201   \n",
       "per-process_emissions_3                                                                0.00202   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            34  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                              268   \n",
       "date_time                                                        April 11, 2025 at 05:52:55 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                              100   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021218   \n",
       "total_energy_joules                                                               76383.180866   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214497   \n",
       "joules_per_token                                                                      4.662059   \n",
       "flops_per_joule                                                               221907110.976747   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.066333   \n",
       "average_latency_ms_per_batch                                                        4633.29158   \n",
       "throughput_queries_per_sec                                                            3.453269   \n",
       "throughput_tokens_per_sec                                                           442.018372   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2657443840   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                 74.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 472.989506   \n",
       "gpu_power_process_1                                                                 442.729223   \n",
       "gpu_power_process_2                                                                 276.181221   \n",
       "gpu_power_process_3                                                                 276.742668   \n",
       "ram_power_process_0                                                                   0.926745   \n",
       "ram_power_process_1                                                                   0.976504   \n",
       "ram_power_process_2                                                                   0.961812   \n",
       "ram_power_process_3                                                                   0.967459   \n",
       "cpu_energy_process_0                                                                  0.001145   \n",
       "cpu_energy_process_1                                                                  0.001142   \n",
       "cpu_energy_process_2                                                                  0.001152   \n",
       "cpu_energy_process_3                                                                  0.001152   \n",
       "gpu_energy_process_0                                                                  0.004149   \n",
       "gpu_energy_process_1                                                                   0.00413   \n",
       "gpu_energy_process_2                                                                  0.004158   \n",
       "gpu_energy_process_3                                                                  0.004158   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005302   \n",
       "total_energy_kwh_process_1                                                             0.00528   \n",
       "total_energy_kwh_process_2                                                            0.005318   \n",
       "total_energy_kwh_process_3                                                            0.005318   \n",
       "total_energy_joules_process_0                                                     19086.003121   \n",
       "total_energy_joules_process_1                                                     19009.741793   \n",
       "total_energy_joules_process_2                                                     19143.614827   \n",
       "total_energy_joules_process_3                                                     19143.821125   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       367.160655   \n",
       "ram_power_avg                                                                          0.95813   \n",
       "cpu_energy_total                                                                      0.004591   \n",
       "gpu_energy_total                                                                      0.016596   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                                0.00202   \n",
       "per-process_emissions_1                                                               0.002026   \n",
       "per-process_emissions_2                                                               0.002026   \n",
       "per-process_emissions_3                                                               0.002012   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            35  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                              269   \n",
       "date_time                                                        April 11, 2025 at 05:54:01 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                              200   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021238   \n",
       "total_energy_joules                                                               76458.267707   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214287   \n",
       "joules_per_token                                                                      4.666642   \n",
       "flops_per_joule                                                               221689184.198326   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.176715   \n",
       "average_latency_ms_per_batch                                                       4647.089355   \n",
       "throughput_queries_per_sec                                                            3.443015   \n",
       "throughput_tokens_per_sec                                                           440.705965   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2584113152   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 681.945871   \n",
       "gpu_power_process_1                                                                 431.647898   \n",
       "gpu_power_process_2                                                                 405.337089   \n",
       "gpu_power_process_3                                                                 494.849394   \n",
       "ram_power_process_0                                                                   0.901388   \n",
       "ram_power_process_1                                                                   0.978292   \n",
       "ram_power_process_2                                                                   0.979966   \n",
       "ram_power_process_3                                                                   0.972433   \n",
       "cpu_energy_process_0                                                                  0.001147   \n",
       "cpu_energy_process_1                                                                  0.001151   \n",
       "cpu_energy_process_2                                                                  0.001147   \n",
       "cpu_energy_process_3                                                                  0.001146   \n",
       "gpu_energy_process_0                                                                  0.004152   \n",
       "gpu_energy_process_1                                                                   0.00416   \n",
       "gpu_energy_process_2                                                                  0.004153   \n",
       "gpu_energy_process_3                                                                  0.004153   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005306   \n",
       "total_energy_kwh_process_1                                                            0.005318   \n",
       "total_energy_kwh_process_2                                                            0.005307   \n",
       "total_energy_kwh_process_3                                                            0.005307   \n",
       "total_energy_joules_process_0                                                     19101.943858   \n",
       "total_energy_joules_process_1                                                     19145.302364   \n",
       "total_energy_joules_process_2                                                     19106.037192   \n",
       "total_energy_joules_process_3                                                     19104.984294   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       503.445063   \n",
       "ram_power_avg                                                                          0.95802   \n",
       "cpu_energy_total                                                                      0.004591   \n",
       "gpu_energy_total                                                                      0.016617   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002021   \n",
       "per-process_emissions_1                                                               0.002022   \n",
       "per-process_emissions_2                                                               0.002026   \n",
       "per-process_emissions_3                                                               0.002022   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            36  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                              270   \n",
       "date_time                                                        April 11, 2025 at 05:55:07 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                              500   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021238   \n",
       "total_energy_joules                                                               76456.077645   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214293   \n",
       "joules_per_token                                                                      4.666509   \n",
       "flops_per_joule                                                                221695534.41967   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.421394   \n",
       "average_latency_ms_per_batch                                                       4677.674297   \n",
       "throughput_queries_per_sec                                                            3.420503   \n",
       "throughput_tokens_per_sec                                                           437.824412   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2657779712   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 380.169962   \n",
       "gpu_power_process_1                                                                 442.044805   \n",
       "gpu_power_process_2                                                                 358.542013   \n",
       "gpu_power_process_3                                                                 459.866345   \n",
       "ram_power_process_0                                                                   0.927495   \n",
       "ram_power_process_1                                                                   0.980896   \n",
       "ram_power_process_2                                                                   0.979702   \n",
       "ram_power_process_3                                                                   0.960255   \n",
       "cpu_energy_process_0                                                                  0.001155   \n",
       "cpu_energy_process_1                                                                  0.001151   \n",
       "cpu_energy_process_2                                                                  0.001163   \n",
       "cpu_energy_process_3                                                                  0.001148   \n",
       "gpu_energy_process_0                                                                  0.004151   \n",
       "gpu_energy_process_1                                                                  0.004137   \n",
       "gpu_energy_process_2                                                                  0.004169   \n",
       "gpu_energy_process_3                                                                  0.004134   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005313   \n",
       "total_energy_kwh_process_1                                                            0.005295   \n",
       "total_energy_kwh_process_2                                                             0.00534   \n",
       "total_energy_kwh_process_3                                                             0.00529   \n",
       "total_energy_joules_process_0                                                     19126.656941   \n",
       "total_energy_joules_process_1                                                     19062.508343   \n",
       "total_energy_joules_process_2                                                     19222.203597   \n",
       "total_energy_joules_process_3                                                     19044.708764   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       410.155781   \n",
       "ram_power_avg                                                                         0.962087   \n",
       "cpu_energy_total                                                                      0.004617   \n",
       "gpu_energy_total                                                                       0.01659   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002017   \n",
       "per-process_emissions_1                                                               0.002015   \n",
       "per-process_emissions_2                                                               0.002034   \n",
       "per-process_emissions_3                                                               0.002024   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            37  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                              271   \n",
       "date_time                                                        April 11, 2025 at 05:56:12 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                               20   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021201   \n",
       "total_energy_joules                                                               76322.508765   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214668   \n",
       "joules_per_token                                                                      4.658356   \n",
       "flops_per_joule                                                               222083514.646961   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.979404   \n",
       "average_latency_ms_per_batch                                                       4622.425475   \n",
       "throughput_queries_per_sec                                                            3.461386   \n",
       "throughput_tokens_per_sec                                                           443.057441   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2653810688   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                        0.0   \n",
       "gpu_power_process_1                                                                 360.432497   \n",
       "gpu_power_process_2                                                                        0.0   \n",
       "gpu_power_process_3                                                                 422.775592   \n",
       "ram_power_process_0                                                                   0.926713   \n",
       "ram_power_process_1                                                                   0.963976   \n",
       "ram_power_process_2                                                                   0.981365   \n",
       "ram_power_process_3                                                                   0.961176   \n",
       "cpu_energy_process_0                                                                  0.001176   \n",
       "cpu_energy_process_1                                                                  0.001147   \n",
       "cpu_energy_process_2                                                                  0.001177   \n",
       "cpu_energy_process_3                                                                  0.001125   \n",
       "gpu_energy_process_0                                                                  0.004152   \n",
       "gpu_energy_process_1                                                                   0.00416   \n",
       "gpu_energy_process_2                                                                  0.004152   \n",
       "gpu_energy_process_3                                                                  0.004082   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005335   \n",
       "total_energy_kwh_process_1                                                            0.005315   \n",
       "total_energy_kwh_process_2                                                            0.005337   \n",
       "total_energy_kwh_process_3                                                            0.005215   \n",
       "total_energy_joules_process_0                                                     19205.568716   \n",
       "total_energy_joules_process_1                                                     19132.260477   \n",
       "total_energy_joules_process_2                                                     19212.271122   \n",
       "total_energy_joules_process_3                                                      18772.40845   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       195.802022   \n",
       "ram_power_avg                                                                         0.958308   \n",
       "cpu_energy_total                                                                      0.004625   \n",
       "gpu_energy_total                                                                      0.016545   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002033   \n",
       "per-process_emissions_1                                                               0.002032   \n",
       "per-process_emissions_2                                                               0.001986   \n",
       "per-process_emissions_3                                                               0.002025   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            38  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                              272   \n",
       "date_time                                                        April 11, 2025 at 05:57:18 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021264   \n",
       "total_energy_joules                                                               76552.127557   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214024   \n",
       "joules_per_token                                                                      4.672371   \n",
       "flops_per_joule                                                               221417373.154566   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.373825   \n",
       "average_latency_ms_per_batch                                                        4671.72815   \n",
       "throughput_queries_per_sec                                                            3.424857   \n",
       "throughput_tokens_per_sec                                                           438.381673   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2655776768   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                 76.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 378.794745   \n",
       "gpu_power_process_1                                                                 384.668493   \n",
       "gpu_power_process_2                                                                   403.9071   \n",
       "gpu_power_process_3                                                                        0.0   \n",
       "ram_power_process_0                                                                   0.926691   \n",
       "ram_power_process_1                                                                   0.976686   \n",
       "ram_power_process_2                                                                   0.959756   \n",
       "ram_power_process_3                                                                   0.976587   \n",
       "cpu_energy_process_0                                                                  0.001157   \n",
       "cpu_energy_process_1                                                                  0.001157   \n",
       "cpu_energy_process_2                                                                  0.001153   \n",
       "cpu_energy_process_3                                                                  0.001175   \n",
       "gpu_energy_process_0                                                                  0.004156   \n",
       "gpu_energy_process_1                                                                   0.00416   \n",
       "gpu_energy_process_2                                                                  0.004148   \n",
       "gpu_energy_process_3                                                                  0.004127   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005321   \n",
       "total_energy_kwh_process_1                                                            0.005325   \n",
       "total_energy_kwh_process_2                                                            0.005309   \n",
       "total_energy_kwh_process_3                                                             0.00531   \n",
       "total_energy_joules_process_0                                                     19154.084108   \n",
       "total_energy_joules_process_1                                                     19171.255272   \n",
       "total_energy_joules_process_2                                                     19112.163224   \n",
       "total_energy_joules_process_3                                                     19114.624953   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       291.842585   \n",
       "ram_power_avg                                                                          0.95993   \n",
       "cpu_energy_total                                                                      0.004642   \n",
       "gpu_energy_total                                                                      0.016591   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002027   \n",
       "per-process_emissions_1                                                               0.002022   \n",
       "per-process_emissions_2                                                               0.002023   \n",
       "per-process_emissions_3                                                               0.002029   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            39  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                              273   \n",
       "date_time                                                        April 11, 2025 at 05:58:24 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                              100   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021225   \n",
       "total_energy_joules                                                               76410.590357   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214421   \n",
       "joules_per_token                                                                      4.663732   \n",
       "flops_per_joule                                                               221827509.955699   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.459553   \n",
       "average_latency_ms_per_batch                                                       4682.444169   \n",
       "throughput_queries_per_sec                                                            3.417019   \n",
       "throughput_tokens_per_sec                                                           437.378413   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2629853184   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                 99.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 286.888132   \n",
       "gpu_power_process_1                                                                 421.087609   \n",
       "gpu_power_process_2                                                                 205.681321   \n",
       "gpu_power_process_3                                                                 437.881287   \n",
       "ram_power_process_0                                                                    0.91753   \n",
       "ram_power_process_1                                                                   0.979952   \n",
       "ram_power_process_2                                                                    0.98504   \n",
       "ram_power_process_3                                                                   0.976274   \n",
       "cpu_energy_process_0                                                                   0.00116   \n",
       "cpu_energy_process_1                                                                  0.001135   \n",
       "cpu_energy_process_2                                                                  0.001149   \n",
       "cpu_energy_process_3                                                                  0.001137   \n",
       "gpu_energy_process_0                                                                  0.004192   \n",
       "gpu_energy_process_1                                                                  0.004117   \n",
       "gpu_energy_process_2                                                                  0.004164   \n",
       "gpu_energy_process_3                                                                  0.004139   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005359   \n",
       "total_energy_kwh_process_1                                                             0.00526   \n",
       "total_energy_kwh_process_2                                                            0.005322   \n",
       "total_energy_kwh_process_3                                                            0.005285   \n",
       "total_energy_joules_process_0                                                     19291.922007   \n",
       "total_energy_joules_process_1                                                     18935.273001   \n",
       "total_energy_joules_process_2                                                     19158.979839   \n",
       "total_energy_joules_process_3                                                      19024.41551   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       337.884587   \n",
       "ram_power_avg                                                                         0.964699   \n",
       "cpu_energy_total                                                                      0.004581   \n",
       "gpu_energy_total                                                                      0.016613   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002004   \n",
       "per-process_emissions_1                                                               0.002041   \n",
       "per-process_emissions_2                                                               0.002027   \n",
       "per-process_emissions_3                                                               0.002013   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            40  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                              274   \n",
       "date_time                                                        April 11, 2025 at 05:59:29 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                              200   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021234   \n",
       "total_energy_joules                                                               76443.543844   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214328   \n",
       "joules_per_token                                                                      4.665744   \n",
       "flops_per_joule                                                               221731883.961792   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.784267   \n",
       "average_latency_ms_per_batch                                                        4598.03337   \n",
       "throughput_queries_per_sec                                                            3.479749   \n",
       "throughput_tokens_per_sec                                                           445.407816   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2633043968   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 444.403374   \n",
       "gpu_power_process_1                                                                 452.731246   \n",
       "gpu_power_process_2                                                                 433.282785   \n",
       "gpu_power_process_3                                                                 428.922265   \n",
       "ram_power_process_0                                                                   0.918727   \n",
       "ram_power_process_1                                                                   0.961384   \n",
       "ram_power_process_2                                                                   0.972659   \n",
       "ram_power_process_3                                                                   0.968619   \n",
       "cpu_energy_process_0                                                                  0.001138   \n",
       "cpu_energy_process_1                                                                  0.001136   \n",
       "cpu_energy_process_2                                                                  0.001139   \n",
       "cpu_energy_process_3                                                                  0.001142   \n",
       "gpu_energy_process_0                                                                  0.004158   \n",
       "gpu_energy_process_1                                                                  0.004163   \n",
       "gpu_energy_process_2                                                                   0.00416   \n",
       "gpu_energy_process_3                                                                  0.004167   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005304   \n",
       "total_energy_kwh_process_1                                                            0.005307   \n",
       "total_energy_kwh_process_2                                                            0.005307   \n",
       "total_energy_kwh_process_3                                                            0.005317   \n",
       "total_energy_joules_process_0                                                     19092.695642   \n",
       "total_energy_joules_process_1                                                     19105.740666   \n",
       "total_energy_joules_process_2                                                     19104.624211   \n",
       "total_energy_joules_process_3                                                     19140.483325   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       439.834917   \n",
       "ram_power_avg                                                                         0.955347   \n",
       "cpu_energy_total                                                                      0.004556   \n",
       "gpu_energy_total                                                                      0.016648   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002022   \n",
       "per-process_emissions_1                                                                0.00202   \n",
       "per-process_emissions_2                                                               0.002022   \n",
       "per-process_emissions_3                                                               0.002025   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            41  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                              275   \n",
       "date_time                                                        April 11, 2025 at 06:00:36 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                              500   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021319   \n",
       "total_energy_joules                                                               76748.976626   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.213475   \n",
       "joules_per_token                                                                      4.684386   \n",
       "flops_per_joule                                                               220849472.375148   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.335853   \n",
       "average_latency_ms_per_batch                                                       4666.981563   \n",
       "throughput_queries_per_sec                                                             3.42834   \n",
       "throughput_tokens_per_sec                                                           438.827532   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2654433280   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 381.472501   \n",
       "gpu_power_process_1                                                                 411.347198   \n",
       "gpu_power_process_2                                                                  501.46862   \n",
       "gpu_power_process_3                                                                  434.36206   \n",
       "ram_power_process_0                                                                   0.926329   \n",
       "ram_power_process_1                                                                   0.968472   \n",
       "ram_power_process_2                                                                   0.963116   \n",
       "ram_power_process_3                                                                   0.978915   \n",
       "cpu_energy_process_0                                                                  0.001153   \n",
       "cpu_energy_process_1                                                                   0.00115   \n",
       "cpu_energy_process_2                                                                   0.00115   \n",
       "cpu_energy_process_3                                                                  0.001151   \n",
       "gpu_energy_process_0                                                                  0.004177   \n",
       "gpu_energy_process_1                                                                  0.004168   \n",
       "gpu_energy_process_2                                                                  0.004163   \n",
       "gpu_energy_process_3                                                                  0.004175   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005338   \n",
       "total_energy_kwh_process_1                                                            0.005326   \n",
       "total_energy_kwh_process_2                                                            0.005322   \n",
       "total_energy_kwh_process_3                                                            0.005333   \n",
       "total_energy_joules_process_0                                                      19216.41514   \n",
       "total_energy_joules_process_1                                                     19173.626968   \n",
       "total_energy_joules_process_2                                                     19158.787423   \n",
       "total_energy_joules_process_3                                                     19200.147094   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       432.162595   \n",
       "ram_power_avg                                                                         0.959208   \n",
       "cpu_energy_total                                                                      0.004604   \n",
       "gpu_energy_total                                                                      0.016684   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002032   \n",
       "per-process_emissions_1                                                               0.002029   \n",
       "per-process_emissions_2                                                               0.002033   \n",
       "per-process_emissions_3                                                               0.002027   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            42  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                              276   \n",
       "date_time                                                        April 11, 2025 at 06:01:44 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                               20   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021258   \n",
       "total_energy_joules                                                               76530.379229   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214085   \n",
       "joules_per_token                                                                      4.671044   \n",
       "flops_per_joule                                                               221480295.326627   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.763149   \n",
       "average_latency_ms_per_batch                                                       4595.393663   \n",
       "throughput_queries_per_sec                                                            3.481747   \n",
       "throughput_tokens_per_sec                                                           445.663669   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2634059776   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                 90.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 428.733319   \n",
       "gpu_power_process_1                                                                 424.145908   \n",
       "gpu_power_process_2                                                                 317.722844   \n",
       "gpu_power_process_3                                                                 300.439741   \n",
       "ram_power_process_0                                                                   0.918722   \n",
       "ram_power_process_1                                                                   0.980553   \n",
       "ram_power_process_2                                                                   0.963903   \n",
       "ram_power_process_3                                                                   0.980208   \n",
       "cpu_energy_process_0                                                                  0.001138   \n",
       "cpu_energy_process_1                                                                  0.001143   \n",
       "cpu_energy_process_2                                                                  0.001148   \n",
       "cpu_energy_process_3                                                                   0.00115   \n",
       "gpu_energy_process_0                                                                  0.004137   \n",
       "gpu_energy_process_1                                                                  0.004158   \n",
       "gpu_energy_process_2                                                                  0.004175   \n",
       "gpu_energy_process_3                                                                  0.004178   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005282   \n",
       "total_energy_kwh_process_1                                                            0.005309   \n",
       "total_energy_kwh_process_2                                                            0.005331   \n",
       "total_energy_kwh_process_3                                                            0.005336   \n",
       "total_energy_joules_process_0                                                     19016.269205   \n",
       "total_energy_joules_process_1                                                      19111.19253   \n",
       "total_energy_joules_process_2                                                     19192.083487   \n",
       "total_energy_joules_process_3                                                     19210.834007   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       367.760453   \n",
       "ram_power_avg                                                                         0.960846   \n",
       "cpu_energy_total                                                                      0.004579   \n",
       "gpu_energy_total                                                                      0.016649   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002031   \n",
       "per-process_emissions_1                                                               0.002022   \n",
       "per-process_emissions_2                                                               0.002033   \n",
       "per-process_emissions_3                                                               0.002012   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            43  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                              277   \n",
       "date_time                                                        April 11, 2025 at 06:02:51 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021287   \n",
       "total_energy_joules                                                               76631.935788   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.213801   \n",
       "joules_per_token                                                                      4.677242   \n",
       "flops_per_joule                                                               221186778.315872   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.198482   \n",
       "average_latency_ms_per_batch                                                       4649.810295   \n",
       "throughput_queries_per_sec                                                            3.441001   \n",
       "throughput_tokens_per_sec                                                           440.448076   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2631974912   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 471.585162   \n",
       "gpu_power_process_1                                                                 379.261541   \n",
       "gpu_power_process_2                                                                  350.06484   \n",
       "gpu_power_process_3                                                                 391.020891   \n",
       "ram_power_process_0                                                                   0.918401   \n",
       "ram_power_process_1                                                                   0.983927   \n",
       "ram_power_process_2                                                                   0.977972   \n",
       "ram_power_process_3                                                                   0.968333   \n",
       "cpu_energy_process_0                                                                  0.001148   \n",
       "cpu_energy_process_1                                                                  0.001159   \n",
       "cpu_energy_process_2                                                                  0.001169   \n",
       "cpu_energy_process_3                                                                  0.001158   \n",
       "gpu_energy_process_0                                                                  0.004126   \n",
       "gpu_energy_process_1                                                                  0.004154   \n",
       "gpu_energy_process_2                                                                  0.004187   \n",
       "gpu_energy_process_3                                                                  0.004154   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005281   \n",
       "total_energy_kwh_process_1                                                            0.005321   \n",
       "total_energy_kwh_process_2                                                            0.005364   \n",
       "total_energy_kwh_process_3                                                             0.00532   \n",
       "total_energy_joules_process_0                                                     19012.966579   \n",
       "total_energy_joules_process_1                                                     19154.981092   \n",
       "total_energy_joules_process_2                                                     19311.365352   \n",
       "total_energy_joules_process_3                                                     19152.622766   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       397.983108   \n",
       "ram_power_avg                                                                         0.962158   \n",
       "cpu_energy_total                                                                      0.004634   \n",
       "gpu_energy_total                                                                      0.016622   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002044   \n",
       "per-process_emissions_1                                                               0.002027   \n",
       "per-process_emissions_2                                                               0.002027   \n",
       "per-process_emissions_3                                                               0.002012   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            44  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                              278   \n",
       "date_time                                                        April 11, 2025 at 06:03:57 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                              100   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021207   \n",
       "total_energy_joules                                                               76346.735078   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                        0.2146   \n",
       "joules_per_token                                                                      4.659835   \n",
       "flops_per_joule                                                               222013043.200503   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.812719   \n",
       "average_latency_ms_per_batch                                                        4601.58986   \n",
       "throughput_queries_per_sec                                                            3.477059   \n",
       "throughput_tokens_per_sec                                                           445.063568   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2703769600   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 454.832486   \n",
       "gpu_power_process_1                                                                 413.624059   \n",
       "gpu_power_process_2                                                                 447.825164   \n",
       "gpu_power_process_3                                                                1022.440557   \n",
       "ram_power_process_0                                                                   0.944009   \n",
       "ram_power_process_1                                                                   0.954592   \n",
       "ram_power_process_2                                                                     0.9766   \n",
       "ram_power_process_3                                                                   0.976315   \n",
       "cpu_energy_process_0                                                                  0.001138   \n",
       "cpu_energy_process_1                                                                   0.00114   \n",
       "cpu_energy_process_2                                                                  0.001136   \n",
       "cpu_energy_process_3                                                                  0.001145   \n",
       "gpu_energy_process_0                                                                  0.004148   \n",
       "gpu_energy_process_1                                                                  0.004149   \n",
       "gpu_energy_process_2                                                                  0.004149   \n",
       "gpu_energy_process_3                                                                  0.004171   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005293   \n",
       "total_energy_kwh_process_1                                                            0.005297   \n",
       "total_energy_kwh_process_2                                                            0.005293   \n",
       "total_energy_kwh_process_3                                                            0.005324   \n",
       "total_energy_joules_process_0                                                     19055.110853   \n",
       "total_energy_joules_process_1                                                     19069.906614   \n",
       "total_energy_joules_process_2                                                     19053.888752   \n",
       "total_energy_joules_process_3                                                     19167.828859   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       584.680567   \n",
       "ram_power_avg                                                                         0.962879   \n",
       "cpu_energy_total                                                                       0.00456   \n",
       "gpu_energy_total                                                                      0.016617   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002018   \n",
       "per-process_emissions_1                                                               0.002016   \n",
       "per-process_emissions_2                                                               0.002016   \n",
       "per-process_emissions_3                                                               0.002028   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            45  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                              279   \n",
       "date_time                                                        April 11, 2025 at 06:05:03 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                              200   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021255   \n",
       "total_energy_joules                                                               76517.116778   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214122   \n",
       "joules_per_token                                                                      4.670234   \n",
       "flops_per_joule                                                               221518683.752156   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.283309   \n",
       "average_latency_ms_per_batch                                                       4660.413619   \n",
       "throughput_queries_per_sec                                                            3.433172   \n",
       "throughput_tokens_per_sec                                                           439.445974   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2629898240   \n",
       "gpu_utilization_percent_0                                                                 27.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 422.869376   \n",
       "gpu_power_process_1                                                                 376.897919   \n",
       "gpu_power_process_2                                                                  382.79563   \n",
       "gpu_power_process_3                                                                 436.966932   \n",
       "ram_power_process_0                                                                   0.917481   \n",
       "ram_power_process_1                                                                   0.985913   \n",
       "ram_power_process_2                                                                   0.976903   \n",
       "ram_power_process_3                                                                   0.968366   \n",
       "cpu_energy_process_0                                                                  0.001154   \n",
       "cpu_energy_process_1                                                                  0.001154   \n",
       "cpu_energy_process_2                                                                  0.001154   \n",
       "cpu_energy_process_3                                                                  0.001151   \n",
       "gpu_energy_process_0                                                                  0.004153   \n",
       "gpu_energy_process_1                                                                  0.004163   \n",
       "gpu_energy_process_2                                                                  0.004153   \n",
       "gpu_energy_process_3                                                                  0.004142   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005315   \n",
       "total_energy_kwh_process_1                                                            0.005325   \n",
       "total_energy_kwh_process_2                                                            0.005315   \n",
       "total_energy_kwh_process_3                                                            0.005301   \n",
       "total_energy_joules_process_0                                                     19132.354055   \n",
       "total_energy_joules_process_1                                                     19168.558212   \n",
       "total_energy_joules_process_2                                                     19133.267371   \n",
       "total_energy_joules_process_3                                                      19082.93714   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       404.882464   \n",
       "ram_power_avg                                                                         0.962166   \n",
       "cpu_energy_total                                                                      0.004611   \n",
       "gpu_energy_total                                                                      0.016612   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002025   \n",
       "per-process_emissions_1                                                               0.002028   \n",
       "per-process_emissions_2                                                               0.002025   \n",
       "per-process_emissions_3                                                               0.002019   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            46  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                              280   \n",
       "date_time                                                        April 11, 2025 at 06:06:10 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                              500   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021197   \n",
       "total_energy_joules                                                               76308.943626   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214706   \n",
       "joules_per_token                                                                      4.657528   \n",
       "flops_per_joule                                                               222122993.553691   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.419533   \n",
       "average_latency_ms_per_batch                                                       4677.441662   \n",
       "throughput_queries_per_sec                                                            3.420673   \n",
       "throughput_tokens_per_sec                                                           437.846188   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2654392320   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  350.17244   \n",
       "gpu_power_process_1                                                                 351.581952   \n",
       "gpu_power_process_2                                                                 426.893541   \n",
       "gpu_power_process_3                                                                 367.019625   \n",
       "ram_power_process_0                                                                   0.926548   \n",
       "ram_power_process_1                                                                   0.984175   \n",
       "ram_power_process_2                                                                   0.978172   \n",
       "ram_power_process_3                                                                   0.972176   \n",
       "cpu_energy_process_0                                                                  0.001158   \n",
       "cpu_energy_process_1                                                                  0.001159   \n",
       "cpu_energy_process_2                                                                  0.001133   \n",
       "cpu_energy_process_3                                                                   0.00115   \n",
       "gpu_energy_process_0                                                                   0.00416   \n",
       "gpu_energy_process_1                                                                  0.004168   \n",
       "gpu_energy_process_2                                                                  0.004094   \n",
       "gpu_energy_process_3                                                                  0.004144   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005325   \n",
       "total_energy_kwh_process_1                                                            0.005335   \n",
       "total_energy_kwh_process_2                                                            0.005234   \n",
       "total_energy_kwh_process_3                                                            0.005302   \n",
       "total_energy_joules_process_0                                                     19171.210806   \n",
       "total_energy_joules_process_1                                                     19204.924812   \n",
       "total_energy_joules_process_2                                                      18843.83803   \n",
       "total_energy_joules_process_3                                                     19088.969977   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       373.916889   \n",
       "ram_power_avg                                                                         0.965268   \n",
       "cpu_energy_total                                                                        0.0046   \n",
       "gpu_energy_total                                                                      0.016566   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.001994   \n",
       "per-process_emissions_1                                                               0.002029   \n",
       "per-process_emissions_2                                                               0.002032   \n",
       "per-process_emissions_3                                                                0.00202   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            47  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                              281   \n",
       "date_time                                                        April 11, 2025 at 06:07:16 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                               20   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021211   \n",
       "total_energy_joules                                                               76361.089511   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                       0.21456   \n",
       "joules_per_token                                                                      4.660711   \n",
       "flops_per_joule                                                               221971308.970354   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.420523   \n",
       "average_latency_ms_per_batch                                                       4677.565389   \n",
       "throughput_queries_per_sec                                                            3.420583   \n",
       "throughput_tokens_per_sec                                                           437.834606   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2698768384   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  332.57154   \n",
       "gpu_power_process_1                                                                 430.551457   \n",
       "gpu_power_process_2                                                                 408.893764   \n",
       "gpu_power_process_3                                                                 320.670686   \n",
       "ram_power_process_0                                                                   0.941749   \n",
       "ram_power_process_1                                                                   0.967901   \n",
       "ram_power_process_2                                                                   0.961749   \n",
       "ram_power_process_3                                                                    0.96798   \n",
       "cpu_energy_process_0                                                                  0.001157   \n",
       "cpu_energy_process_1                                                                   0.00114   \n",
       "cpu_energy_process_2                                                                  0.001148   \n",
       "cpu_energy_process_3                                                                  0.001157   \n",
       "gpu_energy_process_0                                                                  0.004162   \n",
       "gpu_energy_process_1                                                                  0.004115   \n",
       "gpu_energy_process_2                                                                  0.004135   \n",
       "gpu_energy_process_3                                                                  0.004165   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005327   \n",
       "total_energy_kwh_process_1                                                            0.005263   \n",
       "total_energy_kwh_process_2                                                            0.005292   \n",
       "total_energy_kwh_process_3                                                             0.00533   \n",
       "total_energy_joules_process_0                                                      19176.17093   \n",
       "total_energy_joules_process_1                                                     18947.844242   \n",
       "total_energy_joules_process_2                                                      19050.10442   \n",
       "total_energy_joules_process_3                                                      19186.96992   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       373.171862   \n",
       "ram_power_avg                                                                         0.959845   \n",
       "cpu_energy_total                                                                      0.004603   \n",
       "gpu_energy_total                                                                      0.016577   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                                0.00203   \n",
       "per-process_emissions_1                                                               0.002005   \n",
       "per-process_emissions_2                                                               0.002016   \n",
       "per-process_emissions_3                                                               0.002029   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            48  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                              282   \n",
       "date_time                                                        April 11, 2025 at 06:08:21 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021179   \n",
       "total_energy_joules                                                               76245.168806   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214886   \n",
       "joules_per_token                                                                      4.653636   \n",
       "flops_per_joule                                                               222308787.015928   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.239923   \n",
       "average_latency_ms_per_batch                                                       4654.990417   \n",
       "throughput_queries_per_sec                                                            3.437171   \n",
       "throughput_tokens_per_sec                                                           439.957941   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2679017472   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 315.612174   \n",
       "gpu_power_process_1                                                                 555.220912   \n",
       "gpu_power_process_2                                                                 433.474075   \n",
       "gpu_power_process_3                                                                1022.682414   \n",
       "ram_power_process_0                                                                   0.934743   \n",
       "ram_power_process_1                                                                   0.953061   \n",
       "ram_power_process_2                                                                    0.98567   \n",
       "ram_power_process_3                                                                   0.980298   \n",
       "cpu_energy_process_0                                                                  0.001149   \n",
       "cpu_energy_process_1                                                                  0.001147   \n",
       "cpu_energy_process_2                                                                  0.001135   \n",
       "cpu_energy_process_3                                                                  0.001147   \n",
       "gpu_energy_process_0                                                                  0.004161   \n",
       "gpu_energy_process_1                                                                  0.004152   \n",
       "gpu_energy_process_2                                                                  0.004106   \n",
       "gpu_energy_process_3                                                                  0.004152   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005317   \n",
       "total_energy_kwh_process_1                                                            0.005307   \n",
       "total_energy_kwh_process_2                                                            0.005249   \n",
       "total_energy_kwh_process_3                                                            0.005306   \n",
       "total_energy_joules_process_0                                                     19142.898472   \n",
       "total_energy_joules_process_1                                                     19103.648467   \n",
       "total_energy_joules_process_2                                                     18896.079822   \n",
       "total_energy_joules_process_3                                                     19102.542045   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       581.747394   \n",
       "ram_power_avg                                                                         0.963443   \n",
       "cpu_energy_total                                                                      0.004577   \n",
       "gpu_energy_total                                                                      0.016571   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002026   \n",
       "per-process_emissions_1                                                               0.002022   \n",
       "per-process_emissions_2                                                               0.002021   \n",
       "per-process_emissions_3                                                                  0.002   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            49  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                              283   \n",
       "date_time                                                        April 11, 2025 at 06:09:27 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                              100   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                       0.02115   \n",
       "total_energy_joules                                                                76141.04486   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                       0.21518   \n",
       "joules_per_token                                                                      4.647281   \n",
       "flops_per_joule                                                               222612797.398213   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.278837   \n",
       "average_latency_ms_per_batch                                                       4659.854676   \n",
       "throughput_queries_per_sec                                                            3.433583   \n",
       "throughput_tokens_per_sec                                                           439.498684   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2653843456   \n",
       "gpu_utilization_percent_0                                                                 10.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 317.363182   \n",
       "gpu_power_process_1                                                                 380.306061   \n",
       "gpu_power_process_2                                                                 437.565913   \n",
       "gpu_power_process_3                                                                  449.57104   \n",
       "ram_power_process_0                                                                   0.926358   \n",
       "ram_power_process_1                                                                   0.986286   \n",
       "ram_power_process_2                                                                   0.980696   \n",
       "ram_power_process_3                                                                   0.960148   \n",
       "cpu_energy_process_0                                                                  0.001153   \n",
       "cpu_energy_process_1                                                                  0.001153   \n",
       "cpu_energy_process_2                                                                  0.001142   \n",
       "cpu_energy_process_3                                                                  0.001133   \n",
       "gpu_energy_process_0                                                                  0.004155   \n",
       "gpu_energy_process_1                                                                  0.004157   \n",
       "gpu_energy_process_2                                                                  0.004124   \n",
       "gpu_energy_process_3                                                                  0.004102   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005316   \n",
       "total_energy_kwh_process_1                                                            0.005318   \n",
       "total_energy_kwh_process_2                                                            0.005273   \n",
       "total_energy_kwh_process_3                                                            0.005243   \n",
       "total_energy_joules_process_0                                                     19137.312494   \n",
       "total_energy_joules_process_1                                                     19144.179634   \n",
       "total_energy_joules_process_2                                                     18984.270665   \n",
       "total_energy_joules_process_3                                                     18875.282068   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       396.201549   \n",
       "ram_power_avg                                                                         0.963372   \n",
       "cpu_energy_total                                                                      0.004582   \n",
       "gpu_energy_total                                                                      0.016538   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002009   \n",
       "per-process_emissions_1                                                               0.002026   \n",
       "per-process_emissions_2                                                               0.001997   \n",
       "per-process_emissions_3                                                               0.002025   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            50  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                              284   \n",
       "date_time                                                        April 11, 2025 at 06:10:32 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                              200   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021163   \n",
       "total_energy_joules                                                               76187.233345   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215049   \n",
       "joules_per_token                                                                        4.6501   \n",
       "flops_per_joule                                                               222477838.462899   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              37.05608   \n",
       "average_latency_ms_per_batch                                                        4632.01002   \n",
       "throughput_queries_per_sec                                                            3.454224   \n",
       "throughput_tokens_per_sec                                                           442.140667   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2680303616   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 923.603729   \n",
       "gpu_power_process_1                                                                  314.05251   \n",
       "gpu_power_process_2                                                                 433.767904   \n",
       "gpu_power_process_3                                                                 430.846078   \n",
       "ram_power_process_0                                                                   0.934792   \n",
       "ram_power_process_1                                                                   0.972486   \n",
       "ram_power_process_2                                                                   0.971967   \n",
       "ram_power_process_3                                                                   0.984993   \n",
       "cpu_energy_process_0                                                                  0.001146   \n",
       "cpu_energy_process_1                                                                   0.00115   \n",
       "cpu_energy_process_2                                                                  0.001142   \n",
       "cpu_energy_process_3                                                                  0.001137   \n",
       "gpu_energy_process_0                                                                  0.004145   \n",
       "gpu_energy_process_1                                                                  0.004158   \n",
       "gpu_energy_process_2                                                                  0.004131   \n",
       "gpu_energy_process_3                                                                  0.004123   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005299   \n",
       "total_energy_kwh_process_1                                                            0.005315   \n",
       "total_energy_kwh_process_2                                                            0.005281   \n",
       "total_energy_kwh_process_3                                                            0.005268   \n",
       "total_energy_joules_process_0                                                     19075.879761   \n",
       "total_energy_joules_process_1                                                     19135.605227   \n",
       "total_energy_joules_process_2                                                     19010.643524   \n",
       "total_energy_joules_process_3                                                     18965.104834   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       525.567555   \n",
       "ram_power_avg                                                                         0.966059   \n",
       "cpu_energy_total                                                                      0.004574   \n",
       "gpu_energy_total                                                                      0.016558   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002019   \n",
       "per-process_emissions_1                                                               0.002025   \n",
       "per-process_emissions_2                                                               0.002012   \n",
       "per-process_emissions_3                                                               0.002007   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            51  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                              285   \n",
       "date_time                                                        April 11, 2025 at 06:11:38 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                              500   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021133   \n",
       "total_energy_joules                                                               76079.755405   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215353   \n",
       "joules_per_token                                                                       4.64354   \n",
       "flops_per_joule                                                               222792133.111257   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.896263   \n",
       "average_latency_ms_per_batch                                                       4612.032873   \n",
       "throughput_queries_per_sec                                                            3.469186   \n",
       "throughput_tokens_per_sec                                                           444.055811   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2592911360   \n",
       "gpu_utilization_percent_0                                                                  2.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                 98.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 409.629313   \n",
       "gpu_power_process_1                                                                 421.616476   \n",
       "gpu_power_process_2                                                                 318.393244   \n",
       "gpu_power_process_3                                                                 449.450306   \n",
       "ram_power_process_0                                                                   0.904341   \n",
       "ram_power_process_1                                                                   0.971967   \n",
       "ram_power_process_2                                                                   0.960423   \n",
       "ram_power_process_3                                                                   0.980103   \n",
       "cpu_energy_process_0                                                                   0.00114   \n",
       "cpu_energy_process_1                                                                  0.001141   \n",
       "cpu_energy_process_2                                                                  0.001154   \n",
       "cpu_energy_process_3                                                                  0.001128   \n",
       "gpu_energy_process_0                                                                  0.004134   \n",
       "gpu_energy_process_1                                                                   0.00414   \n",
       "gpu_energy_process_2                                                                  0.004165   \n",
       "gpu_energy_process_3                                                                    0.0041   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005281   \n",
       "total_energy_kwh_process_1                                                            0.005289   \n",
       "total_energy_kwh_process_2                                                            0.005327   \n",
       "total_energy_kwh_process_3                                                            0.005236   \n",
       "total_energy_joules_process_0                                                     19012.654067   \n",
       "total_energy_joules_process_1                                                     19040.657486   \n",
       "total_energy_joules_process_2                                                     19176.321637   \n",
       "total_energy_joules_process_3                                                     18850.122215   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       399.772335   \n",
       "ram_power_avg                                                                         0.954208   \n",
       "cpu_energy_total                                                                      0.004564   \n",
       "gpu_energy_total                                                                      0.016539   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002012   \n",
       "per-process_emissions_1                                                               0.002015   \n",
       "per-process_emissions_2                                                               0.002029   \n",
       "per-process_emissions_3                                                               0.001995   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            52  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                              286   \n",
       "date_time                                                        April 11, 2025 at 06:12:45 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                               20   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021166   \n",
       "total_energy_joules                                                               76195.841449   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215025   \n",
       "joules_per_token                                                                      4.650625   \n",
       "flops_per_joule                                                               222452704.383082   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.303935   \n",
       "average_latency_ms_per_batch                                                       4662.991815   \n",
       "throughput_queries_per_sec                                                            3.431273   \n",
       "throughput_tokens_per_sec                                                           439.203001   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2699710464   \n",
       "gpu_utilization_percent_0                                                                 13.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 370.848616   \n",
       "gpu_power_process_1                                                                 419.143394   \n",
       "gpu_power_process_2                                                                 433.132011   \n",
       "gpu_power_process_3                                                                 333.298957   \n",
       "ram_power_process_0                                                                   0.941528   \n",
       "ram_power_process_1                                                                   0.978151   \n",
       "ram_power_process_2                                                                   0.961812   \n",
       "ram_power_process_3                                                                   0.971927   \n",
       "cpu_energy_process_0                                                                  0.001154   \n",
       "cpu_energy_process_1                                                                  0.001152   \n",
       "cpu_energy_process_2                                                                  0.001143   \n",
       "cpu_energy_process_3                                                                  0.001162   \n",
       "gpu_energy_process_0                                                                  0.004135   \n",
       "gpu_energy_process_1                                                                  0.004129   \n",
       "gpu_energy_process_2                                                                    0.0041   \n",
       "gpu_energy_process_3                                                                  0.004158   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005296   \n",
       "total_energy_kwh_process_1                                                            0.005289   \n",
       "total_energy_kwh_process_2                                                            0.005251   \n",
       "total_energy_kwh_process_3                                                            0.005329   \n",
       "total_energy_joules_process_0                                                     19067.346013   \n",
       "total_energy_joules_process_1                                                     19041.700805   \n",
       "total_energy_joules_process_2                                                     18903.883849   \n",
       "total_energy_joules_process_3                                                     19182.910783   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       389.105744   \n",
       "ram_power_avg                                                                         0.963354   \n",
       "cpu_energy_total                                                                      0.004612   \n",
       "gpu_energy_total                                                                      0.016522   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                                  0.002   \n",
       "per-process_emissions_1                                                                0.00203   \n",
       "per-process_emissions_2                                                               0.002015   \n",
       "per-process_emissions_3                                                               0.002018   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            53  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                              287   \n",
       "date_time                                                        April 11, 2025 at 06:13:51 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021162   \n",
       "total_energy_joules                                                               76181.591128   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215065   \n",
       "joules_per_token                                                                      4.649755   \n",
       "flops_per_joule                                                               222494315.782651   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.005236   \n",
       "average_latency_ms_per_batch                                                       4625.654561   \n",
       "throughput_queries_per_sec                                                             3.45897   \n",
       "throughput_tokens_per_sec                                                            442.74815   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2629054464   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                 99.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                        0.0   \n",
       "gpu_power_process_1                                                                 319.021322   \n",
       "gpu_power_process_2                                                                 443.837625   \n",
       "gpu_power_process_3                                                                 349.028145   \n",
       "ram_power_process_0                                                                   0.917044   \n",
       "ram_power_process_1                                                                     0.9766   \n",
       "ram_power_process_2                                                                   0.976028   \n",
       "ram_power_process_3                                                                   0.979986   \n",
       "cpu_energy_process_0                                                                  0.001179   \n",
       "cpu_energy_process_1                                                                  0.001159   \n",
       "cpu_energy_process_2                                                                   0.00114   \n",
       "cpu_energy_process_3                                                                  0.001157   \n",
       "gpu_energy_process_0                                                                  0.004117   \n",
       "gpu_energy_process_1                                                                  0.004149   \n",
       "gpu_energy_process_2                                                                  0.004087   \n",
       "gpu_energy_process_3                                                                  0.004143   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005303   \n",
       "total_energy_kwh_process_1                                                            0.005316   \n",
       "total_energy_kwh_process_2                                                            0.005235   \n",
       "total_energy_kwh_process_3                                                            0.005308   \n",
       "total_energy_joules_process_0                                                     19092.375499   \n",
       "total_energy_joules_process_1                                                     19136.618278   \n",
       "total_energy_joules_process_2                                                     18844.935383   \n",
       "total_energy_joules_process_3                                                     19107.661969   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       277.971773   \n",
       "ram_power_avg                                                                         0.962415   \n",
       "cpu_energy_total                                                                      0.004634   \n",
       "gpu_energy_total                                                                      0.016496   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                                0.00202   \n",
       "per-process_emissions_1                                                               0.001994   \n",
       "per-process_emissions_2                                                               0.002022   \n",
       "per-process_emissions_3                                                               0.002025   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            54  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                              288   \n",
       "date_time                                                        April 11, 2025 at 06:14:58 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                              100   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021253   \n",
       "total_energy_joules                                                                76512.58586   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214135   \n",
       "joules_per_token                                                                      4.669958   \n",
       "flops_per_joule                                                                221531801.63285   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.377651   \n",
       "average_latency_ms_per_batch                                                       4672.206413   \n",
       "throughput_queries_per_sec                                                            3.424506   \n",
       "throughput_tokens_per_sec                                                           438.336798   \n",
       "cpu_usage_percent                                                                          2.5   \n",
       "cpu_memory_usage_bytes                                                              2676060160   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                 99.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 365.558725   \n",
       "gpu_power_process_1                                                                  329.05223   \n",
       "gpu_power_process_2                                                                 392.778899   \n",
       "gpu_power_process_3                                                                 448.710971   \n",
       "ram_power_process_0                                                                   0.933247   \n",
       "ram_power_process_1                                                                   0.965379   \n",
       "ram_power_process_2                                                                   0.960342   \n",
       "ram_power_process_3                                                                   0.972628   \n",
       "cpu_energy_process_0                                                                  0.001157   \n",
       "cpu_energy_process_1                                                                  0.001167   \n",
       "cpu_energy_process_2                                                                   0.00115   \n",
       "cpu_energy_process_3                                                                  0.001151   \n",
       "gpu_energy_process_0                                                                  0.004148   \n",
       "gpu_energy_process_1                                                                  0.004177   \n",
       "gpu_energy_process_2                                                                  0.004137   \n",
       "gpu_energy_process_3                                                                  0.004136   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005313   \n",
       "total_energy_kwh_process_1                                                            0.005352   \n",
       "total_energy_kwh_process_2                                                            0.005294   \n",
       "total_energy_kwh_process_3                                                            0.005294   \n",
       "total_energy_joules_process_0                                                     19126.276281   \n",
       "total_energy_joules_process_1                                                     19266.894827   \n",
       "total_energy_joules_process_2                                                     19059.455407   \n",
       "total_energy_joules_process_3                                                     19059.959346   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       384.025206   \n",
       "ram_power_avg                                                                         0.957899   \n",
       "cpu_energy_total                                                                      0.004625   \n",
       "gpu_energy_total                                                                      0.016597   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002017   \n",
       "per-process_emissions_1                                                               0.002017   \n",
       "per-process_emissions_2                                                               0.002039   \n",
       "per-process_emissions_3                                                               0.002024   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            55  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                              289   \n",
       "date_time                                                        April 11, 2025 at 06:16:04 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                              200   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021272   \n",
       "total_energy_joules                                                               76578.514995   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                       0.21395   \n",
       "joules_per_token                                                                      4.673982   \n",
       "flops_per_joule                                                               221341077.118197   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.014072   \n",
       "average_latency_ms_per_batch                                                        4626.75899   \n",
       "throughput_queries_per_sec                                                            3.458144   \n",
       "throughput_tokens_per_sec                                                           442.642464   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2679005184   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                 85.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                        0.0   \n",
       "gpu_power_process_1                                                                 301.527197   \n",
       "gpu_power_process_2                                                                  5198.2261   \n",
       "gpu_power_process_3                                                                 409.635373   \n",
       "ram_power_process_0                                                                   0.934845   \n",
       "ram_power_process_1                                                                   0.981613   \n",
       "ram_power_process_2                                                                   0.963628   \n",
       "ram_power_process_3                                                                   0.968555   \n",
       "cpu_energy_process_0                                                                  0.001146   \n",
       "cpu_energy_process_1                                                                  0.001153   \n",
       "cpu_energy_process_2                                                                  0.001148   \n",
       "cpu_energy_process_3                                                                  0.001151   \n",
       "gpu_energy_process_0                                                                   0.00415   \n",
       "gpu_energy_process_1                                                                  0.004168   \n",
       "gpu_energy_process_2                                                                  0.004154   \n",
       "gpu_energy_process_3                                                                   0.00417   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005304   \n",
       "total_energy_kwh_process_1                                                            0.005329   \n",
       "total_energy_kwh_process_2                                                             0.00531   \n",
       "total_energy_kwh_process_3                                                            0.005329   \n",
       "total_energy_joules_process_0                                                     19093.869891   \n",
       "total_energy_joules_process_1                                                     19185.402485   \n",
       "total_energy_joules_process_2                                                     19115.723661   \n",
       "total_energy_joules_process_3                                                     19183.518958   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1477.347167   \n",
       "ram_power_avg                                                                          0.96216   \n",
       "cpu_energy_total                                                                      0.004598   \n",
       "gpu_energy_total                                                                      0.016642   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                                0.00203   \n",
       "per-process_emissions_1                                                                0.00203   \n",
       "per-process_emissions_2                                                               0.002021   \n",
       "per-process_emissions_3                                                               0.002023   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            56  \\\n",
       "config_name                                  decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                              290   \n",
       "date_time                                                        April 11, 2025 at 06:17:15 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                              500   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021315   \n",
       "total_energy_joules                                                               76733.750114   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.213518   \n",
       "joules_per_token                                                                      4.683456   \n",
       "flops_per_joule                                                               220893296.207842   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.463349   \n",
       "average_latency_ms_per_batch                                                       4682.918639   \n",
       "throughput_queries_per_sec                                                            3.416673   \n",
       "throughput_tokens_per_sec                                                           437.334098   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2652667904   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 341.441136   \n",
       "gpu_power_process_1                                                                 604.912311   \n",
       "gpu_power_process_2                                                                 404.575946   \n",
       "gpu_power_process_3                                                                 454.676106   \n",
       "ram_power_process_0                                                                   0.925129   \n",
       "ram_power_process_1                                                                   0.980614   \n",
       "ram_power_process_2                                                                   0.975812   \n",
       "ram_power_process_3                                                                   0.961116   \n",
       "cpu_energy_process_0                                                                  0.001157   \n",
       "cpu_energy_process_1                                                                  0.001145   \n",
       "cpu_energy_process_2                                                                  0.001151   \n",
       "cpu_energy_process_3                                                                   0.00114   \n",
       "gpu_energy_process_0                                                                  0.004196   \n",
       "gpu_energy_process_1                                                                  0.004171   \n",
       "gpu_energy_process_2                                                                  0.004175   \n",
       "gpu_energy_process_3                                                                  0.004149   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                             0.00536   \n",
       "total_energy_kwh_process_1                                                            0.005324   \n",
       "total_energy_kwh_process_2                                                            0.005334   \n",
       "total_energy_kwh_process_3                                                            0.005297   \n",
       "total_energy_joules_process_0                                                     19296.046228   \n",
       "total_energy_joules_process_1                                                     19165.994588   \n",
       "total_energy_joules_process_2                                                     19201.971299   \n",
       "total_energy_joules_process_3                                                     19069.737999   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       451.401374   \n",
       "ram_power_avg                                                                         0.960668   \n",
       "cpu_energy_total                                                                      0.004594   \n",
       "gpu_energy_total                                                                       0.01669   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002042   \n",
       "per-process_emissions_1                                                               0.002018   \n",
       "per-process_emissions_2                                                               0.002028   \n",
       "per-process_emissions_3                                                               0.002032   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            57  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                              296   \n",
       "date_time                                                        April 11, 2025 at 06:20:42 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.7   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.020483   \n",
       "total_energy_joules                                                                73737.29051   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.222194   \n",
       "joules_per_token                                                                      4.500567   \n",
       "flops_per_joule                                                                229869729.08804   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.610644   \n",
       "average_latency_ms_per_batch                                                       4576.330444   \n",
       "throughput_queries_per_sec                                                            3.496251   \n",
       "throughput_tokens_per_sec                                                           447.520131   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2638675968   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                 99.0   \n",
       "gpu_utilization_percent_2                                                                 99.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 353.872916   \n",
       "gpu_power_process_1                                                                 372.392172   \n",
       "gpu_power_process_2                                                                 402.717465   \n",
       "gpu_power_process_3                                                                1092.538148   \n",
       "ram_power_process_0                                                                   0.920481   \n",
       "ram_power_process_1                                                                   0.962577   \n",
       "ram_power_process_2                                                                   0.954326   \n",
       "ram_power_process_3                                                                   0.974882   \n",
       "cpu_energy_process_0                                                                  0.001129   \n",
       "cpu_energy_process_1                                                                  0.001128   \n",
       "cpu_energy_process_2                                                                  0.001125   \n",
       "cpu_energy_process_3                                                                  0.001114   \n",
       "gpu_energy_process_0                                                                  0.004005   \n",
       "gpu_energy_process_1                                                                  0.003997   \n",
       "gpu_energy_process_2                                                                  0.003993   \n",
       "gpu_energy_process_3                                                                  0.003961   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005141   \n",
       "total_energy_kwh_process_1                                                            0.005133   \n",
       "total_energy_kwh_process_2                                                            0.005125   \n",
       "total_energy_kwh_process_3                                                            0.005083   \n",
       "total_energy_joules_process_0                                                     18509.363655   \n",
       "total_energy_joules_process_1                                                      18479.38123   \n",
       "total_energy_joules_process_2                                                     18450.715658   \n",
       "total_energy_joules_process_3                                                     18297.829967   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       555.380175   \n",
       "ram_power_avg                                                                         0.953066   \n",
       "cpu_energy_total                                                                      0.004497   \n",
       "gpu_energy_total                                                                      0.015956   \n",
       "ram_energy_total                                                                       0.00003   \n",
       "per-process_emissions_0                                                               0.001955   \n",
       "per-process_emissions_1                                                               0.001952   \n",
       "per-process_emissions_2                                                               0.001959   \n",
       "per-process_emissions_3                                                               0.001936   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            58  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                              297   \n",
       "date_time                                                        April 11, 2025 at 06:21:47 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.8   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.020574   \n",
       "total_energy_joules                                                               74065.599056   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.221209   \n",
       "joules_per_token                                                                      4.520605   \n",
       "flops_per_joule                                                                228850791.85564   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              36.43053   \n",
       "average_latency_ms_per_batch                                                       4553.816217   \n",
       "throughput_queries_per_sec                                                            3.513537   \n",
       "throughput_tokens_per_sec                                                           449.732686   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2633592832   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 411.098243   \n",
       "gpu_power_process_1                                                                 455.482798   \n",
       "gpu_power_process_2                                                                 403.492869   \n",
       "gpu_power_process_3                                                                 356.210935   \n",
       "ram_power_process_0                                                                   0.919137   \n",
       "ram_power_process_1                                                                   0.964226   \n",
       "ram_power_process_2                                                                   0.945306   \n",
       "ram_power_process_3                                                                   0.969814   \n",
       "cpu_energy_process_0                                                                  0.001127   \n",
       "cpu_energy_process_1                                                                  0.001125   \n",
       "cpu_energy_process_2                                                                  0.001123   \n",
       "cpu_energy_process_3                                                                  0.001137   \n",
       "gpu_energy_process_0                                                                  0.004005   \n",
       "gpu_energy_process_1                                                                     0.004   \n",
       "gpu_energy_process_2                                                                  0.003999   \n",
       "gpu_energy_process_3                                                                  0.004027   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000007   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005139   \n",
       "total_energy_kwh_process_1                                                            0.005133   \n",
       "total_energy_kwh_process_2                                                             0.00513   \n",
       "total_energy_kwh_process_3                                                            0.005172   \n",
       "total_energy_joules_process_0                                                     18501.078699   \n",
       "total_energy_joules_process_1                                                      18479.87284   \n",
       "total_energy_joules_process_2                                                     18466.800785   \n",
       "total_energy_joules_process_3                                                     18617.846733   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       406.571211   \n",
       "ram_power_avg                                                                         0.949621   \n",
       "cpu_energy_total                                                                      0.004512   \n",
       "gpu_energy_total                                                                      0.016032   \n",
       "ram_energy_total                                                                       0.00003   \n",
       "per-process_emissions_0                                                               0.001958   \n",
       "per-process_emissions_1                                                               0.001954   \n",
       "per-process_emissions_2                                                                0.00197   \n",
       "per-process_emissions_3                                                               0.001956   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            59  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                              298   \n",
       "date_time                                                        April 11, 2025 at 06:22:52 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.020635   \n",
       "total_energy_joules                                                               74286.409458   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.220552   \n",
       "joules_per_token                                                                      4.534083   \n",
       "flops_per_joule                                                               228170551.204544   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.471863   \n",
       "average_latency_ms_per_batch                                                       4558.982923   \n",
       "throughput_queries_per_sec                                                            3.509555   \n",
       "throughput_tokens_per_sec                                                           449.223003   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2657009664   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 376.405244   \n",
       "gpu_power_process_1                                                                 336.623811   \n",
       "gpu_power_process_2                                                                 396.841016   \n",
       "gpu_power_process_3                                                                 393.136317   \n",
       "ram_power_process_0                                                                   0.927572   \n",
       "ram_power_process_1                                                                   0.964715   \n",
       "ram_power_process_2                                                                   0.972187   \n",
       "ram_power_process_3                                                                   0.957418   \n",
       "cpu_energy_process_0                                                                  0.001127   \n",
       "cpu_energy_process_1                                                                  0.001118   \n",
       "cpu_energy_process_2                                                                  0.001127   \n",
       "cpu_energy_process_3                                                                  0.001125   \n",
       "gpu_energy_process_0                                                                  0.004037   \n",
       "gpu_energy_process_1                                                                  0.004006   \n",
       "gpu_energy_process_2                                                                  0.004037   \n",
       "gpu_energy_process_3                                                                  0.004028   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005171   \n",
       "total_energy_kwh_process_1                                                            0.005132   \n",
       "total_energy_kwh_process_2                                                            0.005172   \n",
       "total_energy_kwh_process_3                                                             0.00516   \n",
       "total_energy_joules_process_0                                                     18615.405968   \n",
       "total_energy_joules_process_1                                                     18474.427509   \n",
       "total_energy_joules_process_2                                                     18619.730542   \n",
       "total_energy_joules_process_3                                                      18576.84544   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       375.751597   \n",
       "ram_power_avg                                                                         0.955473   \n",
       "cpu_energy_total                                                                      0.004496   \n",
       "gpu_energy_total                                                                      0.016109   \n",
       "ram_energy_total                                                                       0.00003   \n",
       "per-process_emissions_0                                                                0.00197   \n",
       "per-process_emissions_1                                                                0.00197   \n",
       "per-process_emissions_2                                                               0.001955   \n",
       "per-process_emissions_3                                                               0.001966   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            60  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                              299   \n",
       "date_time                                                        April 11, 2025 at 06:23:58 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                             0.98   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                       0.02061   \n",
       "total_energy_joules                                                               74197.531957   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.220816   \n",
       "joules_per_token                                                                      4.528658   \n",
       "flops_per_joule                                                               228443865.261377   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.407234   \n",
       "average_latency_ms_per_batch                                                       4550.904239   \n",
       "throughput_queries_per_sec                                                            3.515785   \n",
       "throughput_tokens_per_sec                                                           450.020456   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2613207040   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 344.332748   \n",
       "gpu_power_process_1                                                                 373.782196   \n",
       "gpu_power_process_2                                                                 337.791822   \n",
       "gpu_power_process_3                                                                 431.560015   \n",
       "ram_power_process_0                                                                   0.911714   \n",
       "ram_power_process_1                                                                   0.974084   \n",
       "ram_power_process_2                                                                   0.970469   \n",
       "ram_power_process_3                                                                   0.969471   \n",
       "cpu_energy_process_0                                                                  0.001125   \n",
       "cpu_energy_process_1                                                                   0.00112   \n",
       "cpu_energy_process_2                                                                  0.001137   \n",
       "cpu_energy_process_3                                                                  0.001103   \n",
       "gpu_energy_process_0                                                                   0.00404   \n",
       "gpu_energy_process_1                                                                   0.00402   \n",
       "gpu_energy_process_2                                                                  0.004069   \n",
       "gpu_energy_process_3                                                                  0.003967   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005172   \n",
       "total_energy_kwh_process_1                                                            0.005148   \n",
       "total_energy_kwh_process_2                                                            0.005214   \n",
       "total_energy_kwh_process_3                                                            0.005077   \n",
       "total_energy_joules_process_0                                                     18618.990353   \n",
       "total_energy_joules_process_1                                                     18531.185246   \n",
       "total_energy_joules_process_2                                                     18769.323365   \n",
       "total_energy_joules_process_3                                                     18278.032992   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       371.866695   \n",
       "ram_power_avg                                                                         0.956434   \n",
       "cpu_energy_total                                                                      0.004484   \n",
       "gpu_energy_total                                                                      0.016096   \n",
       "ram_energy_total                                                                       0.00003   \n",
       "per-process_emissions_0                                                                0.00197   \n",
       "per-process_emissions_1                                                               0.001934   \n",
       "per-process_emissions_2                                                               0.001961   \n",
       "per-process_emissions_3                                                               0.001986   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            61  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                              300   \n",
       "date_time                                                        April 11, 2025 at 06:25:04 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.7   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021128   \n",
       "total_energy_joules                                                               76059.345286   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215411   \n",
       "joules_per_token                                                                      4.642294   \n",
       "flops_per_joule                                                               222851918.188743   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.230651   \n",
       "average_latency_ms_per_batch                                                       4653.831399   \n",
       "throughput_queries_per_sec                                                            3.438027   \n",
       "throughput_tokens_per_sec                                                           440.067511   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2558296064   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 375.385266   \n",
       "gpu_power_process_1                                                                 456.835957   \n",
       "gpu_power_process_2                                                                 415.740948   \n",
       "gpu_power_process_3                                                                        0.0   \n",
       "ram_power_process_0                                                                   0.892061   \n",
       "ram_power_process_1                                                                   0.970702   \n",
       "ram_power_process_2                                                                    0.97094   \n",
       "ram_power_process_3                                                                   0.950123   \n",
       "cpu_energy_process_0                                                                  0.001152   \n",
       "cpu_energy_process_1                                                                  0.001126   \n",
       "cpu_energy_process_2                                                                  0.001136   \n",
       "cpu_energy_process_3                                                                  0.001172   \n",
       "gpu_energy_process_0                                                                  0.004161   \n",
       "gpu_energy_process_1                                                                  0.004086   \n",
       "gpu_energy_process_2                                                                  0.004118   \n",
       "gpu_energy_process_3                                                                  0.004146   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                             0.00532   \n",
       "total_energy_kwh_process_1                                                             0.00522   \n",
       "total_energy_kwh_process_2                                                            0.005261   \n",
       "total_energy_kwh_process_3                                                            0.005326   \n",
       "total_energy_joules_process_0                                                     19152.250372   \n",
       "total_energy_joules_process_1                                                     18791.945325   \n",
       "total_energy_joules_process_2                                                     18941.291583   \n",
       "total_energy_joules_process_3                                                     19173.858006   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       311.990543   \n",
       "ram_power_avg                                                                         0.945956   \n",
       "cpu_energy_total                                                                      0.004586   \n",
       "gpu_energy_total                                                                      0.016511   \n",
       "ram_energy_total                                                                       0.00003   \n",
       "per-process_emissions_0                                                               0.002004   \n",
       "per-process_emissions_1                                                               0.001989   \n",
       "per-process_emissions_2                                                               0.002029   \n",
       "per-process_emissions_3                                                               0.002027   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            62  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                              301   \n",
       "date_time                                                        April 11, 2025 at 06:26:10 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.8   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021085   \n",
       "total_energy_joules                                                               75905.904876   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215846   \n",
       "joules_per_token                                                                      4.632929   \n",
       "flops_per_joule                                                               223302403.426195   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.061346   \n",
       "average_latency_ms_per_batch                                                       4632.668298   \n",
       "throughput_queries_per_sec                                                            3.453733   \n",
       "throughput_tokens_per_sec                                                           442.077841   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2625011712   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                        0.0   \n",
       "gpu_power_process_1                                                                 443.886307   \n",
       "gpu_power_process_2                                                                 443.799849   \n",
       "gpu_power_process_3                                                                 302.861984   \n",
       "ram_power_process_0                                                                   0.916095   \n",
       "ram_power_process_1                                                                   0.975101   \n",
       "ram_power_process_2                                                                   0.970745   \n",
       "ram_power_process_3                                                                   0.959052   \n",
       "cpu_energy_process_0                                                                  0.001148   \n",
       "cpu_energy_process_1                                                                  0.001125   \n",
       "cpu_energy_process_2                                                                  0.001136   \n",
       "cpu_energy_process_3                                                                  0.001156   \n",
       "gpu_energy_process_0                                                                  0.004137   \n",
       "gpu_energy_process_1                                                                  0.004082   \n",
       "gpu_energy_process_2                                                                  0.004106   \n",
       "gpu_energy_process_3                                                                  0.004164   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005293   \n",
       "total_energy_kwh_process_1                                                            0.005214   \n",
       "total_energy_kwh_process_2                                                             0.00525   \n",
       "total_energy_kwh_process_3                                                            0.005328   \n",
       "total_energy_joules_process_0                                                     19053.868524   \n",
       "total_energy_joules_process_1                                                     18771.968275   \n",
       "total_energy_joules_process_2                                                     18899.731584   \n",
       "total_energy_joules_process_3                                                     19180.336493   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       297.637035   \n",
       "ram_power_avg                                                                         0.955248   \n",
       "cpu_energy_total                                                                      0.004565   \n",
       "gpu_energy_total                                                                      0.016489   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                                  0.002   \n",
       "per-process_emissions_1                                                                0.00203   \n",
       "per-process_emissions_2                                                               0.001986   \n",
       "per-process_emissions_3                                                               0.002016   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            63  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                              302   \n",
       "date_time                                                        April 11, 2025 at 06:27:16 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021104   \n",
       "total_energy_joules                                                               75972.984254   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215656   \n",
       "joules_per_token                                                                      4.637023   \n",
       "flops_per_joule                                                               223105241.417056   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.947661   \n",
       "average_latency_ms_per_batch                                                       4618.457622   \n",
       "throughput_queries_per_sec                                                             3.46436   \n",
       "throughput_tokens_per_sec                                                           443.438084   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2649886720   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 425.000045   \n",
       "gpu_power_process_1                                                                  428.80165   \n",
       "gpu_power_process_2                                                                 422.595054   \n",
       "gpu_power_process_3                                                                        0.0   \n",
       "ram_power_process_0                                                                   0.925326   \n",
       "ram_power_process_1                                                                   0.979301   \n",
       "ram_power_process_2                                                                   0.975157   \n",
       "ram_power_process_3                                                                   0.959023   \n",
       "cpu_energy_process_0                                                                  0.001144   \n",
       "cpu_energy_process_1                                                                  0.001134   \n",
       "cpu_energy_process_2                                                                  0.001133   \n",
       "cpu_energy_process_3                                                                  0.001148   \n",
       "gpu_energy_process_0                                                                  0.004138   \n",
       "gpu_energy_process_1                                                                  0.004114   \n",
       "gpu_energy_process_2                                                                  0.004114   \n",
       "gpu_energy_process_3                                                                  0.004147   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005289   \n",
       "total_energy_kwh_process_1                                                            0.005256   \n",
       "total_energy_kwh_process_2                                                            0.005255   \n",
       "total_energy_kwh_process_3                                                            0.005304   \n",
       "total_energy_joules_process_0                                                     19042.145496   \n",
       "total_energy_joules_process_1                                                      18920.52465   \n",
       "total_energy_joules_process_2                                                     18917.602859   \n",
       "total_energy_joules_process_3                                                     19092.711249   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       319.099187   \n",
       "ram_power_avg                                                                         0.959702   \n",
       "cpu_energy_total                                                                       0.00456   \n",
       "gpu_energy_total                                                                      0.016512   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002002   \n",
       "per-process_emissions_1                                                                0.00202   \n",
       "per-process_emissions_2                                                               0.002015   \n",
       "per-process_emissions_3                                                               0.002002   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            64  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                              303   \n",
       "date_time                                                        April 11, 2025 at 06:28:21 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                             0.98   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021038   \n",
       "total_energy_joules                                                               75736.281912   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                       0.21633   \n",
       "joules_per_token                                                                      4.622576   \n",
       "flops_per_joule                                                               223802523.245601   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.866788   \n",
       "average_latency_ms_per_batch                                                       4608.348549   \n",
       "throughput_queries_per_sec                                                             3.47196   \n",
       "throughput_tokens_per_sec                                                           444.410829   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2647212032   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 380.762067   \n",
       "gpu_power_process_1                                                                  441.49472   \n",
       "gpu_power_process_2                                                                 429.670529   \n",
       "gpu_power_process_3                                                                 438.038049   \n",
       "ram_power_process_0                                                                   0.923743   \n",
       "ram_power_process_1                                                                   0.975008   \n",
       "ram_power_process_2                                                                   0.975384   \n",
       "ram_power_process_3                                                                    0.95885   \n",
       "cpu_energy_process_0                                                                  0.001141   \n",
       "cpu_energy_process_1                                                                   0.00113   \n",
       "cpu_energy_process_2                                                                   0.00113   \n",
       "cpu_energy_process_3                                                                  0.001127   \n",
       "gpu_energy_process_0                                                                  0.004141   \n",
       "gpu_energy_process_1                                                                   0.00411   \n",
       "gpu_energy_process_2                                                                  0.004125   \n",
       "gpu_energy_process_3                                                                  0.004103   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                             0.00529   \n",
       "total_energy_kwh_process_1                                                            0.005249   \n",
       "total_energy_kwh_process_2                                                            0.005262   \n",
       "total_energy_kwh_process_3                                                            0.005237   \n",
       "total_energy_joules_process_0                                                     19043.141063   \n",
       "total_energy_joules_process_1                                                     18895.203018   \n",
       "total_energy_joules_process_2                                                     18944.771835   \n",
       "total_energy_joules_process_3                                                     18853.165997   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       422.491341   \n",
       "ram_power_avg                                                                         0.958246   \n",
       "cpu_energy_total                                                                      0.004529   \n",
       "gpu_energy_total                                                                      0.016479   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.001995   \n",
       "per-process_emissions_1                                                               0.001999   \n",
       "per-process_emissions_2                                                               0.002005   \n",
       "per-process_emissions_3                                                               0.002015   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            65  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                              304   \n",
       "date_time                                                        April 11, 2025 at 06:29:27 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.7   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021123   \n",
       "total_energy_joules                                                               76043.391166   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215456   \n",
       "joules_per_token                                                                       4.64132   \n",
       "flops_per_joule                                                               222898673.155884   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.912187   \n",
       "average_latency_ms_per_batch                                                       4614.023335   \n",
       "throughput_queries_per_sec                                                            3.467689   \n",
       "throughput_tokens_per_sec                                                           443.864249   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2652401664   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  445.41549   \n",
       "gpu_power_process_1                                                                 340.201984   \n",
       "gpu_power_process_2                                                                 438.602573   \n",
       "gpu_power_process_3                                                                  317.23646   \n",
       "ram_power_process_0                                                                   0.925705   \n",
       "ram_power_process_1                                                                   0.973769   \n",
       "ram_power_process_2                                                                   0.959013   \n",
       "ram_power_process_3                                                                   0.978872   \n",
       "cpu_energy_process_0                                                                   0.00114   \n",
       "cpu_energy_process_1                                                                   0.00115   \n",
       "cpu_energy_process_2                                                                   0.00114   \n",
       "cpu_energy_process_3                                                                  0.001153   \n",
       "gpu_energy_process_0                                                                   0.00411   \n",
       "gpu_energy_process_1                                                                  0.004137   \n",
       "gpu_energy_process_2                                                                  0.004112   \n",
       "gpu_energy_process_3                                                                  0.004149   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005258   \n",
       "total_energy_kwh_process_1                                                            0.005295   \n",
       "total_energy_kwh_process_2                                                             0.00526   \n",
       "total_energy_kwh_process_3                                                             0.00531   \n",
       "total_energy_joules_process_0                                                     18929.209214   \n",
       "total_energy_joules_process_1                                                     19061.079818   \n",
       "total_energy_joules_process_2                                                     18937.608421   \n",
       "total_energy_joules_process_3                                                     19115.493712   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       385.364127   \n",
       "ram_power_avg                                                                          0.95934   \n",
       "cpu_energy_total                                                                      0.004583   \n",
       "gpu_energy_total                                                                      0.016509   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002017   \n",
       "per-process_emissions_1                                                               0.002004   \n",
       "per-process_emissions_2                                                               0.002003   \n",
       "per-process_emissions_3                                                               0.002023   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            66  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                              305   \n",
       "date_time                                                        April 11, 2025 at 06:30:33 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.8   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021142   \n",
       "total_energy_joules                                                               76110.532775   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215266   \n",
       "joules_per_token                                                                      4.645418   \n",
       "flops_per_joule                                                               222702041.034166   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.250632   \n",
       "average_latency_ms_per_batch                                                       4656.328988   \n",
       "throughput_queries_per_sec                                                            3.436183   \n",
       "throughput_tokens_per_sec                                                           439.831465   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2694619136   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 413.456197   \n",
       "gpu_power_process_1                                                                 450.618838   \n",
       "gpu_power_process_2                                                                 689.256646   \n",
       "gpu_power_process_3                                                                 566.217033   \n",
       "ram_power_process_0                                                                   0.940257   \n",
       "ram_power_process_1                                                                    0.97764   \n",
       "ram_power_process_2                                                                   0.979092   \n",
       "ram_power_process_3                                                                   0.961999   \n",
       "cpu_energy_process_0                                                                  0.001151   \n",
       "cpu_energy_process_1                                                                  0.001142   \n",
       "cpu_energy_process_2                                                                  0.001147   \n",
       "cpu_energy_process_3                                                                  0.001149   \n",
       "gpu_energy_process_0                                                                  0.004141   \n",
       "gpu_energy_process_1                                                                  0.004116   \n",
       "gpu_energy_process_2                                                                  0.004131   \n",
       "gpu_energy_process_3                                                                  0.004133   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005299   \n",
       "total_energy_kwh_process_1                                                            0.005266   \n",
       "total_energy_kwh_process_2                                                            0.005287   \n",
       "total_energy_kwh_process_3                                                             0.00529   \n",
       "total_energy_joules_process_0                                                     19077.205396   \n",
       "total_energy_joules_process_1                                                     18956.401671   \n",
       "total_energy_joules_process_2                                                     19032.511786   \n",
       "total_energy_joules_process_3                                                     19044.413921   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       529.887179   \n",
       "ram_power_avg                                                                         0.964747   \n",
       "cpu_energy_total                                                                      0.004589   \n",
       "gpu_energy_total                                                                      0.016522   \n",
       "ram_energy_total                                                                      0.000032   \n",
       "per-process_emissions_0                                                               0.002015   \n",
       "per-process_emissions_1                                                               0.002006   \n",
       "per-process_emissions_2                                                               0.002019   \n",
       "per-process_emissions_3                                                               0.002014   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            67  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                              306   \n",
       "date_time                                                        April 11, 2025 at 06:31:40 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021125   \n",
       "total_energy_joules                                                               76051.292784   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215434   \n",
       "joules_per_token                                                                      4.641803   \n",
       "flops_per_joule                                                               222875514.308708   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.874463   \n",
       "average_latency_ms_per_batch                                                       4609.307881   \n",
       "throughput_queries_per_sec                                                            3.471237   \n",
       "throughput_tokens_per_sec                                                           444.318334   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2651906048   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                 91.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 411.291746   \n",
       "gpu_power_process_1                                                                 387.108096   \n",
       "gpu_power_process_2                                                                 372.684177   \n",
       "gpu_power_process_3                                                                 368.749821   \n",
       "ram_power_process_0                                                                   0.926033   \n",
       "ram_power_process_1                                                                   0.968097   \n",
       "ram_power_process_2                                                                   0.958949   \n",
       "ram_power_process_3                                                                   0.974575   \n",
       "cpu_energy_process_0                                                                  0.001136   \n",
       "cpu_energy_process_1                                                                  0.001132   \n",
       "cpu_energy_process_2                                                                  0.001153   \n",
       "cpu_energy_process_3                                                                  0.001151   \n",
       "gpu_energy_process_0                                                                   0.00412   \n",
       "gpu_energy_process_1                                                                  0.004086   \n",
       "gpu_energy_process_2                                                                  0.004163   \n",
       "gpu_energy_process_3                                                                  0.004154   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005263   \n",
       "total_energy_kwh_process_1                                                            0.005225   \n",
       "total_energy_kwh_process_2                                                            0.005324   \n",
       "total_energy_kwh_process_3                                                            0.005313   \n",
       "total_energy_joules_process_0                                                     18947.580139   \n",
       "total_energy_joules_process_1                                                      18811.48899   \n",
       "total_energy_joules_process_2                                                     19165.724582   \n",
       "total_energy_joules_process_3                                                     19126.499074   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        384.95846   \n",
       "ram_power_avg                                                                         0.956913   \n",
       "cpu_energy_total                                                                      0.004571   \n",
       "gpu_energy_total                                                                      0.016523   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002005   \n",
       "per-process_emissions_1                                                               0.001991   \n",
       "per-process_emissions_2                                                               0.002024   \n",
       "per-process_emissions_3                                                               0.002028   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            68  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                              307   \n",
       "date_time                                                        April 11, 2025 at 06:32:49 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.4   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                             0.98   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021159   \n",
       "total_energy_joules                                                               76172.032345   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215092   \n",
       "joules_per_token                                                                      4.649172   \n",
       "flops_per_joule                                                               222522236.459516   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.227124   \n",
       "average_latency_ms_per_batch                                                        4653.39056   \n",
       "throughput_queries_per_sec                                                            3.438353   \n",
       "throughput_tokens_per_sec                                                           440.109201   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2672742400   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 432.770547   \n",
       "gpu_power_process_1                                                                 431.420727   \n",
       "gpu_power_process_2                                                                 431.038816   \n",
       "gpu_power_process_3                                                                        0.0   \n",
       "ram_power_process_0                                                                   0.932319   \n",
       "ram_power_process_1                                                                   0.968764   \n",
       "ram_power_process_2                                                                   0.967794   \n",
       "ram_power_process_3                                                                    0.95017   \n",
       "cpu_energy_process_0                                                                  0.001151   \n",
       "cpu_energy_process_1                                                                   0.00114   \n",
       "cpu_energy_process_2                                                                  0.001138   \n",
       "cpu_energy_process_3                                                                  0.001146   \n",
       "gpu_energy_process_0                                                                  0.004157   \n",
       "gpu_energy_process_1                                                                  0.004129   \n",
       "gpu_energy_process_2                                                                  0.004122   \n",
       "gpu_energy_process_3                                                                  0.004146   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005315   \n",
       "total_energy_kwh_process_1                                                            0.005277   \n",
       "total_energy_kwh_process_2                                                            0.005268   \n",
       "total_energy_kwh_process_3                                                            0.005299   \n",
       "total_energy_joules_process_0                                                     19134.959869   \n",
       "total_energy_joules_process_1                                                     18995.771879   \n",
       "total_energy_joules_process_2                                                     18963.323375   \n",
       "total_energy_joules_process_3                                                     19077.977221   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       323.807523   \n",
       "ram_power_avg                                                                         0.954762   \n",
       "cpu_energy_total                                                                      0.004575   \n",
       "gpu_energy_total                                                                      0.016553   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                                0.00201   \n",
       "per-process_emissions_1                                                               0.002025   \n",
       "per-process_emissions_2                                                               0.002019   \n",
       "per-process_emissions_3                                                               0.002007   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            69  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                              308   \n",
       "date_time                                                        April 11, 2025 at 06:33:55 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.7   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021188   \n",
       "total_energy_joules                                                               76276.785887   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214797   \n",
       "joules_per_token                                                                      4.655566   \n",
       "flops_per_joule                                                               222216638.996013   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              36.74442   \n",
       "average_latency_ms_per_batch                                                       4593.052498   \n",
       "throughput_queries_per_sec                                                            3.483522   \n",
       "throughput_tokens_per_sec                                                           445.890832   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2628280320   \n",
       "gpu_utilization_percent_0                                                                 19.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  437.84975   \n",
       "gpu_power_process_1                                                                 340.506848   \n",
       "gpu_power_process_2                                                                 444.262083   \n",
       "gpu_power_process_3                                                                 443.027977   \n",
       "ram_power_process_0                                                                   0.917496   \n",
       "ram_power_process_1                                                                    0.97891   \n",
       "ram_power_process_2                                                                   0.958819   \n",
       "ram_power_process_3                                                                   0.976079   \n",
       "cpu_energy_process_0                                                                  0.001138   \n",
       "cpu_energy_process_1                                                                  0.001151   \n",
       "cpu_energy_process_2                                                                  0.001138   \n",
       "cpu_energy_process_3                                                                  0.001131   \n",
       "gpu_energy_process_0                                                                  0.004142   \n",
       "gpu_energy_process_1                                                                   0.00418   \n",
       "gpu_energy_process_2                                                                  0.004147   \n",
       "gpu_energy_process_3                                                                  0.004131   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005287   \n",
       "total_energy_kwh_process_1                                                            0.005339   \n",
       "total_energy_kwh_process_2                                                            0.005292   \n",
       "total_energy_kwh_process_3                                                             0.00527   \n",
       "total_energy_joules_process_0                                                     19032.337276   \n",
       "total_energy_joules_process_1                                                     19221.418975   \n",
       "total_energy_joules_process_2                                                     19051.106107   \n",
       "total_energy_joules_process_3                                                     18971.923528   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       416.411664   \n",
       "ram_power_avg                                                                         0.957826   \n",
       "cpu_energy_total                                                                      0.004557   \n",
       "gpu_energy_total                                                                        0.0166   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002014   \n",
       "per-process_emissions_1                                                               0.002034   \n",
       "per-process_emissions_2                                                               0.002008   \n",
       "per-process_emissions_3                                                               0.002016   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            70  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                              309   \n",
       "date_time                                                        April 11, 2025 at 06:35:01 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.8   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021216   \n",
       "total_energy_joules                                                               76377.761846   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214513   \n",
       "joules_per_token                                                                      4.661729   \n",
       "flops_per_joule                                                               221922855.337331   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.353906   \n",
       "average_latency_ms_per_batch                                                       4669.238309   \n",
       "throughput_queries_per_sec                                                            3.426683   \n",
       "throughput_tokens_per_sec                                                           438.615437   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2675462144   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                 99.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 307.025731   \n",
       "gpu_power_process_1                                                                 439.351263   \n",
       "gpu_power_process_2                                                                 274.373239   \n",
       "gpu_power_process_3                                                                 480.286978   \n",
       "ram_power_process_0                                                                   0.933888   \n",
       "ram_power_process_1                                                                   0.971193   \n",
       "ram_power_process_2                                                                   0.951211   \n",
       "ram_power_process_3                                                                   0.971163   \n",
       "cpu_energy_process_0                                                                  0.001155   \n",
       "cpu_energy_process_1                                                                  0.001137   \n",
       "cpu_energy_process_2                                                                  0.001151   \n",
       "cpu_energy_process_3                                                                  0.001146   \n",
       "gpu_energy_process_0                                                                  0.004169   \n",
       "gpu_energy_process_1                                                                  0.004112   \n",
       "gpu_energy_process_2                                                                  0.004162   \n",
       "gpu_energy_process_3                                                                  0.004152   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005331   \n",
       "total_energy_kwh_process_1                                                            0.005257   \n",
       "total_energy_kwh_process_2                                                            0.005321   \n",
       "total_energy_kwh_process_3                                                            0.005307   \n",
       "total_energy_joules_process_0                                                     19193.338335   \n",
       "total_energy_joules_process_1                                                     18923.596267   \n",
       "total_energy_joules_process_2                                                     19156.894533   \n",
       "total_energy_joules_process_3                                                     19103.932711   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       375.259303   \n",
       "ram_power_avg                                                                         0.956864   \n",
       "cpu_energy_total                                                                      0.004589   \n",
       "gpu_energy_total                                                                      0.016596   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002031   \n",
       "per-process_emissions_1                                                               0.002022   \n",
       "per-process_emissions_2                                                               0.002027   \n",
       "per-process_emissions_3                                                               0.002002   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            71  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                              310   \n",
       "date_time                                                        April 11, 2025 at 06:36:06 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021275   \n",
       "total_energy_joules                                                               76590.669268   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.213916   \n",
       "joules_per_token                                                                      4.674723   \n",
       "flops_per_joule                                                               221305952.215789   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.856164   \n",
       "average_latency_ms_per_batch                                                       4607.020464   \n",
       "throughput_queries_per_sec                                                             3.47296   \n",
       "throughput_tokens_per_sec                                                           444.538941   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2673082368   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 431.991203   \n",
       "gpu_power_process_1                                                                1204.841478   \n",
       "gpu_power_process_2                                                                 286.593649   \n",
       "gpu_power_process_3                                                                 298.200071   \n",
       "ram_power_process_0                                                                   0.933469   \n",
       "ram_power_process_1                                                                   0.950386   \n",
       "ram_power_process_2                                                                   0.970722   \n",
       "ram_power_process_3                                                                   0.978679   \n",
       "cpu_energy_process_0                                                                  0.001139   \n",
       "cpu_energy_process_1                                                                  0.001148   \n",
       "cpu_energy_process_2                                                                  0.001148   \n",
       "cpu_energy_process_3                                                                  0.001152   \n",
       "gpu_energy_process_0                                                                  0.004145   \n",
       "gpu_energy_process_1                                                                   0.00417   \n",
       "gpu_energy_process_2                                                                  0.004168   \n",
       "gpu_energy_process_3                                                                  0.004176   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005291   \n",
       "total_energy_kwh_process_1                                                            0.005326   \n",
       "total_energy_kwh_process_2                                                            0.005323   \n",
       "total_energy_kwh_process_3                                                            0.005335   \n",
       "total_energy_joules_process_0                                                      19047.87437   \n",
       "total_energy_joules_process_1                                                     19171.806801   \n",
       "total_energy_joules_process_2                                                     19164.081105   \n",
       "total_energy_joules_process_3                                                     19206.906992   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       555.406601   \n",
       "ram_power_avg                                                                         0.958314   \n",
       "cpu_energy_total                                                                      0.004586   \n",
       "gpu_energy_total                                                                      0.016658   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002029   \n",
       "per-process_emissions_1                                                               0.002028   \n",
       "per-process_emissions_2                                                               0.002032   \n",
       "per-process_emissions_3                                                               0.002016   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            72  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                              311   \n",
       "date_time                                                        April 11, 2025 at 06:37:12 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.6   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                             0.98   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021175   \n",
       "total_energy_joules                                                               76229.985716   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214929   \n",
       "joules_per_token                                                                      4.652709   \n",
       "flops_per_joule                                                               222353065.317298   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.478415   \n",
       "average_latency_ms_per_batch                                                        4559.80192   \n",
       "throughput_queries_per_sec                                                            3.508924   \n",
       "throughput_tokens_per_sec                                                           449.142317   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2555088896   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                 92.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 426.052342   \n",
       "gpu_power_process_1                                                                 382.490162   \n",
       "gpu_power_process_2                                                                 398.274054   \n",
       "gpu_power_process_3                                                                  441.41002   \n",
       "ram_power_process_0                                                                   0.891782   \n",
       "ram_power_process_1                                                                   0.978639   \n",
       "ram_power_process_2                                                                   0.959099   \n",
       "ram_power_process_3                                                                    0.96194   \n",
       "cpu_energy_process_0                                                                  0.001126   \n",
       "cpu_energy_process_1                                                                  0.001142   \n",
       "cpu_energy_process_2                                                                  0.001138   \n",
       "cpu_energy_process_3                                                                  0.001133   \n",
       "gpu_energy_process_0                                                                  0.004125   \n",
       "gpu_energy_process_1                                                                   0.00417   \n",
       "gpu_energy_process_2                                                                  0.004166   \n",
       "gpu_energy_process_3                                                                  0.004144   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005258   \n",
       "total_energy_kwh_process_1                                                             0.00532   \n",
       "total_energy_kwh_process_2                                                            0.005312   \n",
       "total_energy_kwh_process_3                                                            0.005285   \n",
       "total_energy_joules_process_0                                                     18929.021732   \n",
       "total_energy_joules_process_1                                                     19152.672692   \n",
       "total_energy_joules_process_2                                                     19121.446342   \n",
       "total_energy_joules_process_3                                                      19026.84495   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       412.056644   \n",
       "ram_power_avg                                                                         0.947865   \n",
       "cpu_energy_total                                                                       0.00454   \n",
       "gpu_energy_total                                                                      0.016605   \n",
       "ram_energy_total                                                                       0.00003   \n",
       "per-process_emissions_0                                                               0.002003   \n",
       "per-process_emissions_1                                                               0.002013   \n",
       "per-process_emissions_2                                                               0.002023   \n",
       "per-process_emissions_3                                                               0.002027   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            73  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                              312   \n",
       "date_time                                                        April 11, 2025 at 06:38:18 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.7   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021218   \n",
       "total_energy_joules                                                               76384.326872   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214494   \n",
       "joules_per_token                                                                      4.662129   \n",
       "flops_per_joule                                                               221903781.669947   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.804445   \n",
       "average_latency_ms_per_batch                                                       4600.555674   \n",
       "throughput_queries_per_sec                                                            3.477841   \n",
       "throughput_tokens_per_sec                                                           445.163616   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2555072512   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 432.730412   \n",
       "gpu_power_process_1                                                                  12.641982   \n",
       "gpu_power_process_2                                                                 460.131541   \n",
       "gpu_power_process_3                                                                 430.263947   \n",
       "ram_power_process_0                                                                   0.891947   \n",
       "ram_power_process_1                                                                    0.97508   \n",
       "ram_power_process_2                                                                   0.970475   \n",
       "ram_power_process_3                                                                   0.969779   \n",
       "cpu_energy_process_0                                                                  0.001138   \n",
       "cpu_energy_process_1                                                                  0.001173   \n",
       "cpu_energy_process_2                                                                  0.001132   \n",
       "cpu_energy_process_3                                                                   0.00114   \n",
       "gpu_energy_process_0                                                                  0.004148   \n",
       "gpu_energy_process_1                                                                  0.004171   \n",
       "gpu_energy_process_2                                                                  0.004127   \n",
       "gpu_energy_process_3                                                                  0.004157   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005293   \n",
       "total_energy_kwh_process_1                                                            0.005353   \n",
       "total_energy_kwh_process_2                                                            0.005268   \n",
       "total_energy_kwh_process_3                                                            0.005305   \n",
       "total_energy_joules_process_0                                                     19053.081992   \n",
       "total_energy_joules_process_1                                                     19269.219419   \n",
       "total_energy_joules_process_2                                                     18963.184184   \n",
       "total_energy_joules_process_3                                                     19098.841276   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       333.941971   \n",
       "ram_power_avg                                                                          0.95182   \n",
       "cpu_energy_total                                                                      0.004584   \n",
       "gpu_energy_total                                                                      0.016603   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002007   \n",
       "per-process_emissions_1                                                               0.002039   \n",
       "per-process_emissions_2                                                               0.002016   \n",
       "per-process_emissions_3                                                               0.002021   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            74  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                              313   \n",
       "date_time                                                        April 11, 2025 at 06:39:24 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.8   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021133   \n",
       "total_energy_joules                                                               76078.501706   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215357   \n",
       "joules_per_token                                                                      4.643463   \n",
       "flops_per_joule                                                                222795804.50584   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.749301   \n",
       "average_latency_ms_per_batch                                                         4593.6626   \n",
       "throughput_queries_per_sec                                                            3.483059   \n",
       "throughput_tokens_per_sec                                                           445.831612   \n",
       "cpu_usage_percent                                                                          2.5   \n",
       "cpu_memory_usage_bytes                                                              2673180672   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                 97.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 456.365359   \n",
       "gpu_power_process_1                                                                 427.414799   \n",
       "gpu_power_process_2                                                                 445.320858   \n",
       "gpu_power_process_3                                                                 435.171874   \n",
       "ram_power_process_0                                                                   0.932426   \n",
       "ram_power_process_1                                                                   0.979026   \n",
       "ram_power_process_2                                                                    0.96735   \n",
       "ram_power_process_3                                                                   0.977466   \n",
       "cpu_energy_process_0                                                                  0.001136   \n",
       "cpu_energy_process_1                                                                  0.001137   \n",
       "cpu_energy_process_2                                                                  0.001149   \n",
       "cpu_energy_process_3                                                                  0.001134   \n",
       "gpu_energy_process_0                                                                   0.00413   \n",
       "gpu_energy_process_1                                                                  0.004125   \n",
       "gpu_energy_process_2                                                                  0.004162   \n",
       "gpu_energy_process_3                                                                  0.004129   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005274   \n",
       "total_energy_kwh_process_1                                                            0.005269   \n",
       "total_energy_kwh_process_2                                                            0.005319   \n",
       "total_energy_kwh_process_3                                                             0.00527   \n",
       "total_energy_joules_process_0                                                     18985.975025   \n",
       "total_energy_joules_process_1                                                     18970.171059   \n",
       "total_energy_joules_process_2                                                     19149.415966   \n",
       "total_energy_joules_process_3                                                     18972.939656   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       441.068223   \n",
       "ram_power_avg                                                                         0.964067   \n",
       "cpu_energy_total                                                                      0.004556   \n",
       "gpu_energy_total                                                                      0.016546   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002008   \n",
       "per-process_emissions_1                                                               0.002007   \n",
       "per-process_emissions_2                                                               0.002026   \n",
       "per-process_emissions_3                                                               0.002009   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            75  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                              314   \n",
       "date_time                                                        April 11, 2025 at 06:40:30 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021153   \n",
       "total_energy_joules                                                               76152.181146   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215148   \n",
       "joules_per_token                                                                       4.64796   \n",
       "flops_per_joule                                                               222580243.115083   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.267507   \n",
       "average_latency_ms_per_batch                                                       4658.438392   \n",
       "throughput_queries_per_sec                                                            3.434627   \n",
       "throughput_tokens_per_sec                                                           439.632303   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2674552832   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 245.784553   \n",
       "gpu_power_process_1                                                                  427.11676   \n",
       "gpu_power_process_2                                                                 395.181999   \n",
       "gpu_power_process_3                                                                 402.054679   \n",
       "ram_power_process_0                                                                   0.933356   \n",
       "ram_power_process_1                                                                   0.966282   \n",
       "ram_power_process_2                                                                   0.975263   \n",
       "ram_power_process_3                                                                   0.959431   \n",
       "cpu_energy_process_0                                                                  0.001152   \n",
       "cpu_energy_process_1                                                                  0.001131   \n",
       "cpu_energy_process_2                                                                  0.001154   \n",
       "cpu_energy_process_3                                                                  0.001134   \n",
       "gpu_energy_process_0                                                                  0.004163   \n",
       "gpu_energy_process_1                                                                   0.00411   \n",
       "gpu_energy_process_2                                                                   0.00417   \n",
       "gpu_energy_process_3                                                                  0.004108   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005323   \n",
       "total_energy_kwh_process_1                                                            0.005249   \n",
       "total_energy_kwh_process_2                                                            0.005332   \n",
       "total_energy_kwh_process_3                                                             0.00525   \n",
       "total_energy_joules_process_0                                                     19164.202496   \n",
       "total_energy_joules_process_1                                                     18895.402353   \n",
       "total_energy_joules_process_2                                                     19194.163638   \n",
       "total_energy_joules_process_3                                                     18898.412659   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       367.534498   \n",
       "ram_power_avg                                                                         0.958583   \n",
       "cpu_energy_total                                                                      0.004571   \n",
       "gpu_energy_total                                                                      0.016551   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002028   \n",
       "per-process_emissions_1                                                               0.002031   \n",
       "per-process_emissions_2                                                                  0.002   \n",
       "per-process_emissions_3                                                                  0.002   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            76  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                              315   \n",
       "date_time                                                        April 11, 2025 at 06:41:37 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        0.8   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                             0.98   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021139   \n",
       "total_energy_joules                                                               76101.321315   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215292   \n",
       "joules_per_token                                                                      4.644856   \n",
       "flops_per_joule                                                               222728997.344947   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             37.349722   \n",
       "average_latency_ms_per_batch                                                       4668.715262   \n",
       "throughput_queries_per_sec                                                            3.427067   \n",
       "throughput_tokens_per_sec                                                           438.664576   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2693410816   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 328.204462   \n",
       "gpu_power_process_1                                                                 444.236215   \n",
       "gpu_power_process_2                                                                        0.0   \n",
       "gpu_power_process_3                                                                 412.025386   \n",
       "ram_power_process_0                                                                   0.940112   \n",
       "ram_power_process_1                                                                   0.967378   \n",
       "ram_power_process_2                                                                   0.975361   \n",
       "ram_power_process_3                                                                   0.975379   \n",
       "cpu_energy_process_0                                                                  0.001155   \n",
       "cpu_energy_process_1                                                                   0.00113   \n",
       "cpu_energy_process_2                                                                  0.001146   \n",
       "cpu_energy_process_3                                                                  0.001144   \n",
       "gpu_energy_process_0                                                                  0.004166   \n",
       "gpu_energy_process_1                                                                   0.00409   \n",
       "gpu_energy_process_2                                                                  0.004143   \n",
       "gpu_energy_process_3                                                                  0.004135   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005328   \n",
       "total_energy_kwh_process_1                                                            0.005228   \n",
       "total_energy_kwh_process_2                                                            0.005297   \n",
       "total_energy_kwh_process_3                                                            0.005286   \n",
       "total_energy_joules_process_0                                                     19182.208722   \n",
       "total_energy_joules_process_1                                                     18819.385955   \n",
       "total_energy_joules_process_2                                                     19069.860852   \n",
       "total_energy_joules_process_3                                                     19029.865786   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       296.116516   \n",
       "ram_power_avg                                                                         0.964557   \n",
       "cpu_energy_total                                                                      0.004574   \n",
       "gpu_energy_total                                                                      0.016534   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.001991   \n",
       "per-process_emissions_1                                                               0.002018   \n",
       "per-process_emissions_2                                                                0.00203   \n",
       "per-process_emissions_3                                                               0.002014   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            77  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                              316   \n",
       "date_time                                                        April 11, 2025 at 06:42:44 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.7   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021052   \n",
       "total_energy_joules                                                                75787.25771   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.216184   \n",
       "joules_per_token                                                                      4.625687   \n",
       "flops_per_joule                                                               223651989.862195   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.404344   \n",
       "average_latency_ms_per_batch                                                       4550.543062   \n",
       "throughput_queries_per_sec                                                            3.516064   \n",
       "throughput_tokens_per_sec                                                           450.056174   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2628284416   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 476.138974   \n",
       "gpu_power_process_1                                                                 394.972737   \n",
       "gpu_power_process_2                                                                 414.978827   \n",
       "gpu_power_process_3                                                                  418.59568   \n",
       "ram_power_process_0                                                                   0.916853   \n",
       "ram_power_process_1                                                                   0.975384   \n",
       "ram_power_process_2                                                                    0.97452   \n",
       "ram_power_process_3                                                                    0.97675   \n",
       "cpu_energy_process_0                                                                  0.001127   \n",
       "cpu_energy_process_1                                                                  0.001143   \n",
       "cpu_energy_process_2                                                                   0.00114   \n",
       "cpu_energy_process_3                                                                  0.001145   \n",
       "gpu_energy_process_0                                                                  0.004073   \n",
       "gpu_energy_process_1                                                                  0.004129   \n",
       "gpu_energy_process_2                                                                  0.004121   \n",
       "gpu_energy_process_3                                                                  0.004143   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005208   \n",
       "total_energy_kwh_process_1                                                            0.005281   \n",
       "total_energy_kwh_process_2                                                            0.005268   \n",
       "total_energy_kwh_process_3                                                            0.005296   \n",
       "total_energy_joules_process_0                                                     18747.298287   \n",
       "total_energy_joules_process_1                                                     19010.531237   \n",
       "total_energy_joules_process_2                                                     18965.528726   \n",
       "total_energy_joules_process_3                                                      19063.89946   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       426.171555   \n",
       "ram_power_avg                                                                         0.960877   \n",
       "cpu_energy_total                                                                      0.004555   \n",
       "gpu_energy_total                                                                      0.016466   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002012   \n",
       "per-process_emissions_1                                                               0.002007   \n",
       "per-process_emissions_2                                                               0.001984   \n",
       "per-process_emissions_3                                                               0.002017   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            78  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                              317   \n",
       "date_time                                                        April 11, 2025 at 06:43:50 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.8   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021089   \n",
       "total_energy_joules                                                               75921.972142   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215801   \n",
       "joules_per_token                                                                      4.633909   \n",
       "flops_per_joule                                                               223255146.236354   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.764964   \n",
       "average_latency_ms_per_batch                                                       4595.620491   \n",
       "throughput_queries_per_sec                                                            3.481576   \n",
       "throughput_tokens_per_sec                                                           445.641672   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2672754688   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 438.794391   \n",
       "gpu_power_process_1                                                                 362.422683   \n",
       "gpu_power_process_2                                                                 727.718023   \n",
       "gpu_power_process_3                                                                 329.798916   \n",
       "ram_power_process_0                                                                   0.932661   \n",
       "ram_power_process_1                                                                   0.966641   \n",
       "ram_power_process_2                                                                   0.975077   \n",
       "ram_power_process_3                                                                   0.974532   \n",
       "cpu_energy_process_0                                                                  0.001137   \n",
       "cpu_energy_process_1                                                                  0.001155   \n",
       "cpu_energy_process_2                                                                  0.001146   \n",
       "cpu_energy_process_3                                                                  0.001155   \n",
       "gpu_energy_process_0                                                                   0.00408   \n",
       "gpu_energy_process_1                                                                  0.004135   \n",
       "gpu_energy_process_2                                                                   0.00411   \n",
       "gpu_energy_process_3                                                                   0.00414   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005225   \n",
       "total_energy_kwh_process_1                                                            0.005298   \n",
       "total_energy_kwh_process_2                                                            0.005264   \n",
       "total_energy_kwh_process_3                                                            0.005302   \n",
       "total_energy_joules_process_0                                                     18810.358063   \n",
       "total_energy_joules_process_1                                                     19073.909792   \n",
       "total_energy_joules_process_2                                                     18949.288594   \n",
       "total_energy_joules_process_3                                                     19088.415694   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       464.683503   \n",
       "ram_power_avg                                                                         0.962227   \n",
       "cpu_energy_total                                                                      0.004593   \n",
       "gpu_energy_total                                                                      0.016465   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002005   \n",
       "per-process_emissions_1                                                               0.001991   \n",
       "per-process_emissions_2                                                                0.00202   \n",
       "per-process_emissions_3                                                               0.002018   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            79  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                              318   \n",
       "date_time                                                        April 11, 2025 at 06:44:56 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021076   \n",
       "total_energy_joules                                                               75872.506432   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215941   \n",
       "joules_per_token                                                                       4.63089   \n",
       "flops_per_joule                                                               223400699.280619   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.751617   \n",
       "average_latency_ms_per_batch                                                       4593.952187   \n",
       "throughput_queries_per_sec                                                             3.48284   \n",
       "throughput_tokens_per_sec                                                           445.803508   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2672275456   \n",
       "gpu_utilization_percent_0                                                                 23.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                 88.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 419.858841   \n",
       "gpu_power_process_1                                                                        0.0   \n",
       "gpu_power_process_2                                                                  628.77378   \n",
       "gpu_power_process_3                                                                 444.463343   \n",
       "ram_power_process_0                                                                   0.932034   \n",
       "ram_power_process_1                                                                    0.97876   \n",
       "ram_power_process_2                                                                   0.975183   \n",
       "ram_power_process_3                                                                   0.968601   \n",
       "cpu_energy_process_0                                                                  0.001138   \n",
       "cpu_energy_process_1                                                                  0.001145   \n",
       "cpu_energy_process_2                                                                  0.001149   \n",
       "cpu_energy_process_3                                                                  0.001126   \n",
       "gpu_energy_process_0                                                                  0.004116   \n",
       "gpu_energy_process_1                                                                  0.004145   \n",
       "gpu_energy_process_2                                                                  0.004149   \n",
       "gpu_energy_process_3                                                                  0.004077   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005262   \n",
       "total_energy_kwh_process_1                                                            0.005298   \n",
       "total_energy_kwh_process_2                                                            0.005306   \n",
       "total_energy_kwh_process_3                                                             0.00521   \n",
       "total_energy_joules_process_0                                                     18941.583765   \n",
       "total_energy_joules_process_1                                                     19073.771602   \n",
       "total_energy_joules_process_2                                                     19100.353559   \n",
       "total_energy_joules_process_3                                                     18756.797505   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       373.273991   \n",
       "ram_power_avg                                                                         0.963644   \n",
       "cpu_energy_total                                                                      0.004558   \n",
       "gpu_energy_total                                                                      0.016487   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.001985   \n",
       "per-process_emissions_1                                                               0.002021   \n",
       "per-process_emissions_2                                                               0.002018   \n",
       "per-process_emissions_3                                                               0.002004   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            80  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                              319   \n",
       "date_time                                                        April 11, 2025 at 06:46:02 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                             0.98   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021173   \n",
       "total_energy_joules                                                               76223.661305   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214946   \n",
       "joules_per_token                                                                      4.652323   \n",
       "flops_per_joule                                                               222371514.343019   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.289531   \n",
       "average_latency_ms_per_batch                                                       4536.191409   \n",
       "throughput_queries_per_sec                                                            3.527188   \n",
       "throughput_tokens_per_sec                                                           451.480067   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2673119232   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 400.198023   \n",
       "gpu_power_process_1                                                                        0.0   \n",
       "gpu_power_process_2                                                                    6.11526   \n",
       "gpu_power_process_3                                                                   5.655757   \n",
       "ram_power_process_0                                                                    0.93329   \n",
       "ram_power_process_1                                                                   0.977371   \n",
       "ram_power_process_2                                                                   0.971103   \n",
       "ram_power_process_3                                                                   0.969011   \n",
       "cpu_energy_process_0                                                                  0.001121   \n",
       "cpu_energy_process_1                                                                  0.001177   \n",
       "cpu_energy_process_2                                                                  0.001177   \n",
       "cpu_energy_process_3                                                                  0.001176   \n",
       "gpu_energy_process_0                                                                   0.00406   \n",
       "gpu_energy_process_1                                                                  0.004143   \n",
       "gpu_energy_process_2                                                                  0.004145   \n",
       "gpu_energy_process_3                                                                  0.004143   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005188   \n",
       "total_energy_kwh_process_1                                                            0.005328   \n",
       "total_energy_kwh_process_2                                                             0.00533   \n",
       "total_energy_kwh_process_3                                                            0.005327   \n",
       "total_energy_joules_process_0                                                     18675.883055   \n",
       "total_energy_joules_process_1                                                     19181.377666   \n",
       "total_energy_joules_process_2                                                     19189.043717   \n",
       "total_energy_joules_process_3                                                     19177.356867   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        102.99226   \n",
       "ram_power_avg                                                                         0.962694   \n",
       "cpu_energy_total                                                                      0.004651   \n",
       "gpu_energy_total                                                                      0.016491   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002031   \n",
       "per-process_emissions_1                                                               0.001976   \n",
       "per-process_emissions_2                                                               0.002029   \n",
       "per-process_emissions_3                                                                0.00203   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            81  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                              320   \n",
       "date_time                                                        April 11, 2025 at 06:47:09 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.7   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021169   \n",
       "total_energy_joules                                                               76208.729832   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214988   \n",
       "joules_per_token                                                                      4.651412   \n",
       "flops_per_joule                                                               222415083.292085   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.688996   \n",
       "average_latency_ms_per_batch                                                       4586.124506   \n",
       "throughput_queries_per_sec                                                            3.488784   \n",
       "throughput_tokens_per_sec                                                           446.564413   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2648391680   \n",
       "gpu_utilization_percent_0                                                                  9.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                 89.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 445.124742   \n",
       "gpu_power_process_1                                                                 436.921184   \n",
       "gpu_power_process_2                                                                 442.085655   \n",
       "gpu_power_process_3                                                                  338.88163   \n",
       "ram_power_process_0                                                                   0.924657   \n",
       "ram_power_process_1                                                                   0.978248   \n",
       "ram_power_process_2                                                                   0.971146   \n",
       "ram_power_process_3                                                                   0.974924   \n",
       "cpu_energy_process_0                                                                  0.001134   \n",
       "cpu_energy_process_1                                                                  0.001146   \n",
       "cpu_energy_process_2                                                                  0.001136   \n",
       "cpu_energy_process_3                                                                  0.001149   \n",
       "gpu_energy_process_0                                                                   0.00412   \n",
       "gpu_energy_process_1                                                                   0.00416   \n",
       "gpu_energy_process_2                                                                   0.00413   \n",
       "gpu_energy_process_3                                                                  0.004163   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005262   \n",
       "total_energy_kwh_process_1                                                            0.005314   \n",
       "total_energy_kwh_process_2                                                            0.005274   \n",
       "total_energy_kwh_process_3                                                             0.00532   \n",
       "total_energy_joules_process_0                                                     18941.955974   \n",
       "total_energy_joules_process_1                                                     19128.951509   \n",
       "total_energy_joules_process_2                                                      18986.38066   \n",
       "total_energy_joules_process_3                                                     19151.441688   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       415.753303   \n",
       "ram_power_avg                                                                         0.962244   \n",
       "cpu_energy_total                                                                      0.004565   \n",
       "gpu_energy_total                                                                      0.016573   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002024   \n",
       "per-process_emissions_1                                                               0.002004   \n",
       "per-process_emissions_2                                                               0.002027   \n",
       "per-process_emissions_3                                                               0.002009   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            82  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                              321   \n",
       "date_time                                                        April 11, 2025 at 06:48:16 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.8   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021177   \n",
       "total_energy_joules                                                               76236.684702   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                       0.21491   \n",
       "joules_per_token                                                                      4.653118   \n",
       "flops_per_joule                                                               222333526.955779   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.790459   \n",
       "average_latency_ms_per_batch                                                       4598.807349   \n",
       "throughput_queries_per_sec                                                            3.479163   \n",
       "throughput_tokens_per_sec                                                           445.332854   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2650079232   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 451.422046   \n",
       "gpu_power_process_1                                                                 438.908964   \n",
       "gpu_power_process_2                                                                 447.852378   \n",
       "gpu_power_process_3                                                                 427.502269   \n",
       "ram_power_process_0                                                                   0.925435   \n",
       "ram_power_process_1                                                                    0.97839   \n",
       "ram_power_process_2                                                                   0.962791   \n",
       "ram_power_process_3                                                                   0.966389   \n",
       "cpu_energy_process_0                                                                  0.001134   \n",
       "cpu_energy_process_1                                                                  0.001138   \n",
       "cpu_energy_process_2                                                                  0.001134   \n",
       "cpu_energy_process_3                                                                  0.001139   \n",
       "gpu_energy_process_0                                                                  0.004145   \n",
       "gpu_energy_process_1                                                                  0.004157   \n",
       "gpu_energy_process_2                                                                  0.004143   \n",
       "gpu_energy_process_3                                                                  0.004157   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005286   \n",
       "total_energy_kwh_process_1                                                            0.005303   \n",
       "total_energy_kwh_process_2                                                            0.005284   \n",
       "total_energy_kwh_process_3                                                            0.005304   \n",
       "total_energy_joules_process_0                                                     19030.879498   \n",
       "total_energy_joules_process_1                                                     19089.259507   \n",
       "total_energy_joules_process_2                                                     19023.745609   \n",
       "total_energy_joules_process_3                                                     19092.800088   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       441.421415   \n",
       "ram_power_avg                                                                         0.958251   \n",
       "cpu_energy_total                                                                      0.004546   \n",
       "gpu_energy_total                                                                        0.0166   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002014   \n",
       "per-process_emissions_1                                                                0.00202   \n",
       "per-process_emissions_2                                                               0.002013   \n",
       "per-process_emissions_3                                                                0.00202   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            83  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                              322   \n",
       "date_time                                                        April 11, 2025 at 06:49:22 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021209   \n",
       "total_energy_joules                                                               76352.285347   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.214584   \n",
       "joules_per_token                                                                      4.660174   \n",
       "flops_per_joule                                                               221996904.429798   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.692678   \n",
       "average_latency_ms_per_batch                                                       4586.584774   \n",
       "throughput_queries_per_sec                                                            3.488434   \n",
       "throughput_tokens_per_sec                                                             446.5196   \n",
       "cpu_usage_percent                                                                          2.3   \n",
       "cpu_memory_usage_bytes                                                              2672320512   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 450.800113   \n",
       "gpu_power_process_1                                                                 355.115024   \n",
       "gpu_power_process_2                                                                        0.0   \n",
       "gpu_power_process_3                                                                 319.781654   \n",
       "ram_power_process_0                                                                   0.933163   \n",
       "ram_power_process_1                                                                   0.958782   \n",
       "ram_power_process_2                                                                   0.958433   \n",
       "ram_power_process_3                                                                   0.966486   \n",
       "cpu_energy_process_0                                                                  0.001132   \n",
       "cpu_energy_process_1                                                                  0.001148   \n",
       "cpu_energy_process_2                                                                  0.001147   \n",
       "cpu_energy_process_3                                                                   0.00116   \n",
       "gpu_energy_process_0                                                                  0.004106   \n",
       "gpu_energy_process_1                                                                  0.004153   \n",
       "gpu_energy_process_2                                                                  0.004147   \n",
       "gpu_energy_process_3                                                                  0.004186   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005245   \n",
       "total_energy_kwh_process_1                                                            0.005309   \n",
       "total_energy_kwh_process_2                                                            0.005301   \n",
       "total_energy_kwh_process_3                                                            0.005354   \n",
       "total_energy_joules_process_0                                                     18881.480268   \n",
       "total_energy_joules_process_1                                                     19111.902011   \n",
       "total_energy_joules_process_2                                                     19084.977902   \n",
       "total_energy_joules_process_3                                                     19273.925165   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       281.424198   \n",
       "ram_power_avg                                                                         0.954216   \n",
       "cpu_energy_total                                                                      0.004586   \n",
       "gpu_energy_total                                                                      0.016591   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                                0.00202   \n",
       "per-process_emissions_1                                                               0.002022   \n",
       "per-process_emissions_2                                                               0.001998   \n",
       "per-process_emissions_3                                                                0.00204   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            84  \\\n",
       "config_name                                  decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                              323   \n",
       "date_time                                                        April 11, 2025 at 06:50:29 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.2   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                             0.98   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021157   \n",
       "total_energy_joules                                                               76166.395123   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.215108   \n",
       "joules_per_token                                                                      4.648828   \n",
       "flops_per_joule                                                               222538705.760019   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.887141   \n",
       "average_latency_ms_per_batch                                                       4610.892601   \n",
       "throughput_queries_per_sec                                                            3.470044   \n",
       "throughput_tokens_per_sec                                                           444.165626   \n",
       "cpu_usage_percent                                                                          2.5   \n",
       "cpu_memory_usage_bytes                                                              2671546368   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 429.573944   \n",
       "gpu_power_process_1                                                                 445.062316   \n",
       "gpu_power_process_2                                                                 421.010265   \n",
       "gpu_power_process_3                                                                 394.510423   \n",
       "ram_power_process_0                                                                   0.932327   \n",
       "ram_power_process_1                                                                   0.967273   \n",
       "ram_power_process_2                                                                   0.975482   \n",
       "ram_power_process_3                                                                   0.974414   \n",
       "cpu_energy_process_0                                                                  0.001139   \n",
       "cpu_energy_process_1                                                                  0.001132   \n",
       "cpu_energy_process_2                                                                  0.001139   \n",
       "cpu_energy_process_3                                                                  0.001139   \n",
       "gpu_energy_process_0                                                                  0.004155   \n",
       "gpu_energy_process_1                                                                  0.004119   \n",
       "gpu_energy_process_2                                                                  0.004152   \n",
       "gpu_energy_process_3                                                                  0.004153   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005301   \n",
       "total_energy_kwh_process_1                                                            0.005258   \n",
       "total_energy_kwh_process_2                                                            0.005298   \n",
       "total_energy_kwh_process_3                                                              0.0053   \n",
       "total_energy_joules_process_0                                                     19083.031099   \n",
       "total_energy_joules_process_1                                                     18929.349811   \n",
       "total_energy_joules_process_2                                                     19072.870024   \n",
       "total_energy_joules_process_3                                                     19081.144189   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       422.539237   \n",
       "ram_power_avg                                                                         0.962374   \n",
       "cpu_energy_total                                                                      0.004548   \n",
       "gpu_energy_total                                                                      0.016578   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                               0.002018   \n",
       "per-process_emissions_1                                                               0.002019   \n",
       "per-process_emissions_2                                                               0.002003   \n",
       "per-process_emissions_3                                                               0.002019   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            85  \\\n",
       "config_name                                                                      latency_False   \n",
       "experiment_id                                                                              328   \n",
       "date_time                                                        April 11, 2025 at 06:53:27 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.020897   \n",
       "total_energy_joules                                                                75230.05363   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.217785   \n",
       "joules_per_token                                                                      4.591678   \n",
       "flops_per_joule                                                               225308506.046856   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             36.504055   \n",
       "average_latency_ms_per_batch                                                       4563.006856   \n",
       "throughput_queries_per_sec                                                             3.50646   \n",
       "throughput_tokens_per_sec                                                           448.826851   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2672652288   \n",
       "gpu_utilization_percent_0                                                                  2.0   \n",
       "gpu_utilization_percent_1                                                                 84.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 431.015804   \n",
       "gpu_power_process_1                                                                 308.730628   \n",
       "gpu_power_process_2                                                                 250.559542   \n",
       "gpu_power_process_3                                                                 425.939771   \n",
       "ram_power_process_0                                                                   0.933257   \n",
       "ram_power_process_1                                                                   0.960325   \n",
       "ram_power_process_2                                                                   0.978653   \n",
       "ram_power_process_3                                                                   0.978829   \n",
       "cpu_energy_process_0                                                                   0.00113   \n",
       "cpu_energy_process_1                                                                  0.001151   \n",
       "cpu_energy_process_2                                                                   0.00115   \n",
       "cpu_energy_process_3                                                                  0.001136   \n",
       "gpu_energy_process_0                                                                  0.004034   \n",
       "gpu_energy_process_1                                                                  0.004099   \n",
       "gpu_energy_process_2                                                                  0.004097   \n",
       "gpu_energy_process_3                                                                   0.00407   \n",
       "ram_energy_process_0                                                                  0.000007   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005171   \n",
       "total_energy_kwh_process_1                                                            0.005258   \n",
       "total_energy_kwh_process_2                                                            0.005255   \n",
       "total_energy_kwh_process_3                                                            0.005214   \n",
       "total_energy_joules_process_0                                                     18614.504031   \n",
       "total_energy_joules_process_1                                                     18928.400783   \n",
       "total_energy_joules_process_2                                                     18918.230356   \n",
       "total_energy_joules_process_3                                                      18768.91846   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       354.061436   \n",
       "ram_power_avg                                                                         0.962766   \n",
       "cpu_energy_total                                                                      0.004566   \n",
       "gpu_energy_total                                                                        0.0163   \n",
       "ram_energy_total                                                                      0.000031   \n",
       "per-process_emissions_0                                                                0.00197   \n",
       "per-process_emissions_1                                                               0.001986   \n",
       "per-process_emissions_2                                                               0.002003   \n",
       "per-process_emissions_3                                                               0.002002   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            86  \\\n",
       "config_name                                  latency_True_latency_0.05_latency_0.2_latency_...   \n",
       "experiment_id                                                                              329   \n",
       "date_time                                                        April 11, 2025 at 06:54:34 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                              0.05   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.021343   \n",
       "total_energy_joules                                                               76834.458713   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.213238   \n",
       "joules_per_token                                                                      4.689603   \n",
       "flops_per_joule                                                               220603766.552551   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              37.91957   \n",
       "average_latency_ms_per_batch                                                       4739.946273   \n",
       "throughput_queries_per_sec                                                            3.375566   \n",
       "throughput_tokens_per_sec                                                           432.072408   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2649559040   \n",
       "gpu_utilization_percent_0                                                                 31.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 448.648365   \n",
       "gpu_power_process_1                                                                        0.0   \n",
       "gpu_power_process_2                                                                        0.0   \n",
       "gpu_power_process_3                                                                  437.76301   \n",
       "ram_power_process_0                                                                   0.924099   \n",
       "ram_power_process_1                                                                   0.971034   \n",
       "ram_power_process_2                                                                   0.966449   \n",
       "ram_power_process_3                                                                    0.97928   \n",
       "cpu_energy_process_0                                                                  0.001173   \n",
       "cpu_energy_process_1                                                                  0.001208   \n",
       "cpu_energy_process_2                                                                  0.001176   \n",
       "cpu_energy_process_3                                                                   0.00117   \n",
       "gpu_energy_process_0                                                                  0.004145   \n",
       "gpu_energy_process_1                                                                  0.004154   \n",
       "gpu_energy_process_2                                                                  0.004155   \n",
       "gpu_energy_process_3                                                                  0.004131   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000008   \n",
       "ram_energy_process_2                                                                  0.000008   \n",
       "ram_energy_process_3                                                                  0.000008   \n",
       "total_energy_kwh_process_0                                                            0.005325   \n",
       "total_energy_kwh_process_1                                                             0.00537   \n",
       "total_energy_kwh_process_2                                                            0.005339   \n",
       "total_energy_kwh_process_3                                                            0.005309   \n",
       "total_energy_joules_process_0                                                     19170.370322   \n",
       "total_energy_joules_process_1                                                     19332.671469   \n",
       "total_energy_joules_process_2                                                     19219.497474   \n",
       "total_energy_joules_process_3                                                     19111.919449   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       221.602844   \n",
       "ram_power_avg                                                                         0.960215   \n",
       "cpu_energy_total                                                                      0.004726   \n",
       "gpu_energy_total                                                                      0.016585   \n",
       "ram_energy_total                                                                      0.000032   \n",
       "per-process_emissions_0                                                               0.002034   \n",
       "per-process_emissions_1                                                               0.002022   \n",
       "per-process_emissions_2                                                               0.002046   \n",
       "per-process_emissions_3                                                               0.002029   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_simulate                                                               True   \n",
       "latency_simulation_delay_max                                                               0.2   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            87  \\\n",
       "config_name                                  latency_True_latency_0.2_latency_0.6_latency_F...   \n",
       "experiment_id                                                                              330   \n",
       "date_time                                                        April 11, 2025 at 06:55:45 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.2   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022104   \n",
       "total_energy_joules                                                               79575.575957   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.205892   \n",
       "joules_per_token                                                                      4.856908   \n",
       "flops_per_joule                                                               213004691.317366   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             40.774318   \n",
       "average_latency_ms_per_batch                                                       5096.789718   \n",
       "throughput_queries_per_sec                                                            3.139231   \n",
       "throughput_tokens_per_sec                                                           401.821561   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2599944192   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  337.65622   \n",
       "gpu_power_process_1                                                                 428.929856   \n",
       "gpu_power_process_2                                                                 368.508736   \n",
       "gpu_power_process_3                                                                 359.454104   \n",
       "ram_power_process_0                                                                   0.907279   \n",
       "ram_power_process_1                                                                   0.976394   \n",
       "ram_power_process_2                                                                   0.968425   \n",
       "ram_power_process_3                                                                   0.974869   \n",
       "cpu_energy_process_0                                                                  0.001259   \n",
       "cpu_energy_process_1                                                                  0.001224   \n",
       "cpu_energy_process_2                                                                  0.001254   \n",
       "cpu_energy_process_3                                                                  0.001246   \n",
       "gpu_energy_process_0                                                                  0.004316   \n",
       "gpu_energy_process_1                                                                  0.004202   \n",
       "gpu_energy_process_2                                                                  0.004295   \n",
       "gpu_energy_process_3                                                                  0.004273   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000009   \n",
       "ram_energy_process_2                                                                  0.000009   \n",
       "ram_energy_process_3                                                                  0.000009   \n",
       "total_energy_kwh_process_0                                                            0.005583   \n",
       "total_energy_kwh_process_1                                                            0.005435   \n",
       "total_energy_kwh_process_2                                                            0.005558   \n",
       "total_energy_kwh_process_3                                                            0.005528   \n",
       "total_energy_joules_process_0                                                     20099.074693   \n",
       "total_energy_joules_process_1                                                     19566.465463   \n",
       "total_energy_joules_process_2                                                     20008.375337   \n",
       "total_energy_joules_process_3                                                     19901.660465   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       373.637229   \n",
       "ram_power_avg                                                                         0.956742   \n",
       "cpu_energy_total                                                                      0.004984   \n",
       "gpu_energy_total                                                                      0.017087   \n",
       "ram_energy_total                                                                      0.000034   \n",
       "per-process_emissions_0                                                               0.002117   \n",
       "per-process_emissions_1                                                               0.002106   \n",
       "per-process_emissions_2                                                               0.002127   \n",
       "per-process_emissions_3                                                               0.002071   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_simulate                                                               True   \n",
       "latency_simulation_delay_max                                                               0.6   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            88  \\\n",
       "config_name                                  latency_True_latency_0.05_latency_0.2_latency_...   \n",
       "experiment_id                                                                              331   \n",
       "date_time                                                        April 11, 2025 at 06:56:55 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                              0.05   \n",
       "latency_simulation_simulate_burst                                                         True   \n",
       "latency_simulation_burst_size                                                                5   \n",
       "latency_simulation_burst_interval                                                          4.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022489   \n",
       "total_energy_joules                                                               80959.555151   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.202373   \n",
       "joules_per_token                                                                      4.941379   \n",
       "flops_per_joule                                                               209363440.318309   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             41.930226   \n",
       "average_latency_ms_per_batch                                                       5241.278282   \n",
       "throughput_queries_per_sec                                                             3.05269   \n",
       "throughput_tokens_per_sec                                                           390.744374   \n",
       "cpu_usage_percent                                                                          2.4   \n",
       "cpu_memory_usage_bytes                                                              2624958464   \n",
       "gpu_utilization_percent_0                                                                 19.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840   \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                 376.718852   \n",
       "gpu_power_process_1                                                                 514.105205   \n",
       "gpu_power_process_2                                                                 251.841776   \n",
       "gpu_power_process_3                                                                 391.040796   \n",
       "ram_power_process_0                                                                   0.916534   \n",
       "ram_power_process_1                                                                   0.967009   \n",
       "ram_power_process_2                                                                   0.960388   \n",
       "ram_power_process_3                                                                   0.975692   \n",
       "cpu_energy_process_0                                                                  0.001291   \n",
       "cpu_energy_process_1                                                                  0.001274   \n",
       "cpu_energy_process_2                                                                  0.001304   \n",
       "cpu_energy_process_3                                                                  0.001283   \n",
       "gpu_energy_process_0                                                                  0.004347   \n",
       "gpu_energy_process_1                                                                   0.00428   \n",
       "gpu_energy_process_2                                                                  0.004366   \n",
       "gpu_energy_process_3                                                                  0.004307   \n",
       "ram_energy_process_0                                                                  0.000008   \n",
       "ram_energy_process_1                                                                  0.000009   \n",
       "ram_energy_process_2                                                                  0.000009   \n",
       "ram_energy_process_3                                                                  0.000009   \n",
       "total_energy_kwh_process_0                                                            0.005647   \n",
       "total_energy_kwh_process_1                                                            0.005563   \n",
       "total_energy_kwh_process_2                                                             0.00568   \n",
       "total_energy_kwh_process_3                                                            0.005599   \n",
       "total_energy_joules_process_0                                                     20329.463438   \n",
       "total_energy_joules_process_1                                                     20028.173657   \n",
       "total_energy_joules_process_2                                                     20446.391921   \n",
       "total_energy_joules_process_3                                                     20155.526135   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       383.426657   \n",
       "ram_power_avg                                                                         0.954906   \n",
       "cpu_energy_total                                                                      0.005153   \n",
       "gpu_energy_total                                                                      0.017301   \n",
       "ram_energy_total                                                                      0.000035   \n",
       "per-process_emissions_0                                                               0.002151   \n",
       "per-process_emissions_1                                                               0.002119   \n",
       "per-process_emissions_2                                                               0.002133   \n",
       "per-process_emissions_3                                                               0.002164   \n",
       "models                                                                          16949970993152   \n",
       "decoder_config_decoding_mode                                                               NaN   \n",
       "latency_simulation_simulate                                                               True   \n",
       "latency_simulation_delay_max                                                               0.2   \n",
       "total_generated_tokens                                                                   16384   \n",
       "\n",
       "                                                                                            89  \n",
       "config_name                                  latency_True_latency_0.2_latency_0.6_latency_T...  \n",
       "experiment_id                                                                              332  \n",
       "date_time                                                        April 11, 2025 at 06:58:10 PM  \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0  \n",
       "num_processes                                                                                4  \n",
       "batch_size___fixed_batching                                                                 16  \n",
       "decoder_temperature                                                                        1.0  \n",
       "decoder_top_k                                                                                0  \n",
       "decoder_top_p                                                                              0.0  \n",
       "latency_simulation_delay_min                                                               0.2  \n",
       "latency_simulation_simulate_burst                                                         True  \n",
       "latency_simulation_burst_size                                                                8  \n",
       "latency_simulation_burst_interval                                                          5.0  \n",
       "fp_precision                                                                     torch.float16  \n",
       "quantization                                                                              True  \n",
       "load_in_8bit                                                                             False  \n",
       "load_in_4bit                                                                              True  \n",
       "sharding_strategy                                                                     NO_SHARD  \n",
       "sharding_config_fsdp_config_use_orig_params                                              False  \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False  \n",
       "adaptive_batching                                                                        False  \n",
       "adaptive_max_tokens                                                                          0  \n",
       "query_rate                                                                                 1.0  \n",
       "total_input_tokens                                                                       16384  \n",
       "is_encoder_decoder                                                                       False  \n",
       "task_type                                                                      text_generation  \n",
       "available_gpu_count                                                                          4  \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB  \n",
       "available_cpu_count                                                                        128  \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor  \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31  \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]  \n",
       "country                                                                                Germany  \n",
       "region                                                                                  saxony  \n",
       "distributed_type                                                     DistributedType.MULTI_GPU  \n",
       "decode_token_to_text                                                                      True  \n",
       "inference_type                                                                 pure_generative  \n",
       "backend                                                                                pytorch  \n",
       "total_params                                                                         615606272  \n",
       "model_arch                                                       Unknown (no config attribute)  \n",
       "max_input_tokens                                                                           128  \n",
       "max_output_tokens                                                                          128  \n",
       "number_input_prompts                                                                       128  \n",
       "total_energy_kwh                                                                      0.023464  \n",
       "total_energy_joules                                                               84471.974521  \n",
       "flops                                                                           16949970993152  \n",
       "tokens_per_joule                                                                      0.193958  \n",
       "joules_per_token                                                                       5.15576  \n",
       "flops_per_joule                                                               200657923.402639  \n",
       "joules_per_flop                                                                            0.0  \n",
       "total_inference_time_sec                                                             45.240207  \n",
       "average_latency_ms_per_batch                                                       5655.025877  \n",
       "throughput_queries_per_sec                                                            2.829342  \n",
       "throughput_tokens_per_sec                                                           362.155726  \n",
       "cpu_usage_percent                                                                          2.3  \n",
       "cpu_memory_usage_bytes                                                              2628886528  \n",
       "gpu_utilization_percent_0                                                                  0.0  \n",
       "gpu_utilization_percent_1                                                                100.0  \n",
       "gpu_utilization_percent_2                                                                100.0  \n",
       "gpu_utilization_percent_3                                                                100.0  \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704  \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704  \n",
       "gpu_current_memory_reserved_bytes                                                   1929379840  \n",
       "gpu_max_memory_reserved_bytes                                                       1929379840  \n",
       "cpu_power_process_0                                                                      112.5  \n",
       "cpu_power_process_1                                                                      112.5  \n",
       "cpu_power_process_2                                                                      112.5  \n",
       "cpu_power_process_3                                                                      112.5  \n",
       "gpu_power_process_0                                                                 309.058879  \n",
       "gpu_power_process_1                                                                 398.189354  \n",
       "gpu_power_process_2                                                                 337.432713  \n",
       "gpu_power_process_3                                                                 299.517947  \n",
       "ram_power_process_0                                                                   0.916922  \n",
       "ram_power_process_1                                                                   0.975125  \n",
       "ram_power_process_2                                                                   0.978689  \n",
       "ram_power_process_3                                                                   0.975831  \n",
       "cpu_energy_process_0                                                                  0.001398  \n",
       "cpu_energy_process_1                                                                  0.001375  \n",
       "cpu_energy_process_2                                                                  0.001408  \n",
       "cpu_energy_process_3                                                                  0.001436  \n",
       "gpu_energy_process_0                                                                   0.00443  \n",
       "gpu_energy_process_1                                                                   0.00437  \n",
       "gpu_energy_process_2                                                                  0.004469  \n",
       "gpu_energy_process_3                                                                  0.004539  \n",
       "ram_energy_process_0                                                                  0.000009  \n",
       "ram_energy_process_1                                                                   0.00001  \n",
       "ram_energy_process_2                                                                   0.00001  \n",
       "ram_energy_process_3                                                                   0.00001  \n",
       "total_energy_kwh_process_0                                                            0.005837  \n",
       "total_energy_kwh_process_1                                                            0.005755  \n",
       "total_energy_kwh_process_2                                                            0.005886  \n",
       "total_energy_kwh_process_3                                                            0.005986  \n",
       "total_energy_joules_process_0                                                     21013.466101  \n",
       "total_energy_joules_process_1                                                     20718.303797  \n",
       "total_energy_joules_process_2                                                     21191.396944  \n",
       "total_energy_joules_process_3                                                      21548.80768  \n",
       "cpu_power_avg                                                                            112.5  \n",
       "gpu_power_avg                                                                       336.049723  \n",
       "ram_power_avg                                                                         0.961642  \n",
       "cpu_energy_total                                                                      0.005617  \n",
       "gpu_energy_total                                                                      0.017808  \n",
       "ram_energy_total                                                                      0.000039  \n",
       "per-process_emissions_0                                                               0.002224  \n",
       "per-process_emissions_1                                                               0.002192  \n",
       "per-process_emissions_2                                                               0.002242  \n",
       "per-process_emissions_3                                                                0.00228  \n",
       "models                                                                          16949970993152  \n",
       "decoder_config_decoding_mode                                                               NaN  \n",
       "latency_simulation_simulate                                                               True  \n",
       "latency_simulation_delay_max                                                               0.6  \n",
       "total_generated_tokens                                                                   16384  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found & inspecting: df_scenarios_cleaned\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>config_name</th>\n",
       "      <td>A1_Max_Throughput_Exploit</td>\n",
       "      <td>A2_Precision_Minimalist</td>\n",
       "      <td>A3_Quantisation_Gaming</td>\n",
       "      <td>default</td>\n",
       "      <td>A5_Parallel_Overdrive</td>\n",
       "      <td>R2_Low_Latency_Chatbot_Deployment</td>\n",
       "      <td>R3_Balanced_Enterprise_Service</td>\n",
       "      <td>R4_High_Load_Cloud_API_Deployment</td>\n",
       "      <td>R5_Real_Time_Mobile_Inference</td>\n",
       "      <td>R6_Medium_Scale_Language_Model_Serving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <td>220</td>\n",
       "      <td>221</td>\n",
       "      <td>222</td>\n",
       "      <td>223</td>\n",
       "      <td>224</td>\n",
       "      <td>228</td>\n",
       "      <td>229</td>\n",
       "      <td>230</td>\n",
       "      <td>231</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <td>April 11, 2025 at 04:28:24 PM</td>\n",
       "      <td>April 11, 2025 at 04:29:05 PM</td>\n",
       "      <td>April 11, 2025 at 04:29:46 PM</td>\n",
       "      <td>April 11, 2025 at 04:31:30 PM</td>\n",
       "      <td>April 11, 2025 at 04:32:11 PM</td>\n",
       "      <td>April 11, 2025 at 04:35:15 PM</td>\n",
       "      <td>April 11, 2025 at 04:36:43 PM</td>\n",
       "      <td>April 11, 2025 at 04:38:09 PM</td>\n",
       "      <td>April 11, 2025 at 04:55:10 PM</td>\n",
       "      <td>April 11, 2025 at 04:55:58 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_processes</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size___fixed_batching</th>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_temperature</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_k</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_p</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate_burst</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_size</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_interval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp_precision</th>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantization</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_8bit</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_4bit</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharding_strategy</th>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "      <td>NO_SHARD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharding_config_fsdp_config_use_orig_params</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharding_config_fsdp_config_cpu_offload</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive_batching</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaptive_max_tokens</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>query_rate</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_input_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_encoder_decoder</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>task_type</th>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "      <td>text_generation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_gpu_count</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_model</th>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "      <td>4 x NVIDIA A100-PCIE-40GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available_cpu_count</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_model</th>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "      <td>AMD EPYC 7742 64-Core Processor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>os</th>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "      <td>Linux-5.15.0-113-generic-x86_64-with-glibc2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>python_version</th>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "      <td>3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>region</th>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "      <td>saxony</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distributed_type</th>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "      <td>DistributedType.MULTI_GPU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decode_token_to_text</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inference_type</th>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "      <td>pure_generative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backend</th>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "      <td>pytorch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_params</th>\n",
       "      <td>1100048384</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_arch</th>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "      <td>Unknown (no config attribute)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_input_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_output_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_input_prompts</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh</th>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.022337</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.045144</td>\n",
       "      <td>0.008436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules</th>\n",
       "      <td>26276.086899</td>\n",
       "      <td>5043.594678</td>\n",
       "      <td>2748.678723</td>\n",
       "      <td>11613.150827</td>\n",
       "      <td>19803.636424</td>\n",
       "      <td>20669.796894</td>\n",
       "      <td>80411.455879</td>\n",
       "      <td>10468.775683</td>\n",
       "      <td>162518.073262</td>\n",
       "      <td>30368.288695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops</th>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens_per_joule</th>\n",
       "      <td>0.623533</td>\n",
       "      <td>3.248477</td>\n",
       "      <td>5.960682</td>\n",
       "      <td>1.410814</td>\n",
       "      <td>0.827323</td>\n",
       "      <td>0.792654</td>\n",
       "      <td>0.203752</td>\n",
       "      <td>1.565035</td>\n",
       "      <td>0.086883</td>\n",
       "      <td>0.53951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_token</th>\n",
       "      <td>1.603765</td>\n",
       "      <td>0.307837</td>\n",
       "      <td>0.167766</td>\n",
       "      <td>0.70881</td>\n",
       "      <td>1.208718</td>\n",
       "      <td>1.261584</td>\n",
       "      <td>4.907926</td>\n",
       "      <td>0.638963</td>\n",
       "      <td>11.509779</td>\n",
       "      <td>1.853533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops_per_joule</th>\n",
       "      <td>645072116.656167</td>\n",
       "      <td>3360692536.878901</td>\n",
       "      <td>6166588640.753133</td>\n",
       "      <td>1459549716.198339</td>\n",
       "      <td>855901948.028895</td>\n",
       "      <td>820035682.010454</td>\n",
       "      <td>210790500.032728</td>\n",
       "      <td>1619097734.639612</td>\n",
       "      <td>104295914.004625</td>\n",
       "      <td>558147058.058945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_flop</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_inference_time_sec</th>\n",
       "      <td>12.157593</td>\n",
       "      <td>5.11736</td>\n",
       "      <td>9.56734</td>\n",
       "      <td>71.473257</td>\n",
       "      <td>6.201934</td>\n",
       "      <td>88.568613</td>\n",
       "      <td>46.186702</td>\n",
       "      <td>56.839973</td>\n",
       "      <td>984.640872</td>\n",
       "      <td>12.265104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_latency_ms_per_batch</th>\n",
       "      <td>12157.593134</td>\n",
       "      <td>5117.360245</td>\n",
       "      <td>4783.670129</td>\n",
       "      <td>8934.157172</td>\n",
       "      <td>3100.966923</td>\n",
       "      <td>2767.769153</td>\n",
       "      <td>11546.675429</td>\n",
       "      <td>3552.498301</td>\n",
       "      <td>7692.506816</td>\n",
       "      <td>3066.276043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_queries_per_sec</th>\n",
       "      <td>10.5284</td>\n",
       "      <td>25.012896</td>\n",
       "      <td>13.378849</td>\n",
       "      <td>1.79088</td>\n",
       "      <td>20.638724</td>\n",
       "      <td>1.445207</td>\n",
       "      <td>2.77136</td>\n",
       "      <td>2.251936</td>\n",
       "      <td>0.129997</td>\n",
       "      <td>10.436112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_tokens_per_sec</th>\n",
       "      <td>1347.635163</td>\n",
       "      <td>3201.650698</td>\n",
       "      <td>1712.492663</td>\n",
       "      <td>229.232591</td>\n",
       "      <td>2641.756654</td>\n",
       "      <td>184.986526</td>\n",
       "      <td>354.734142</td>\n",
       "      <td>288.247851</td>\n",
       "      <td>14.340254</td>\n",
       "      <td>1335.822327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_usage_percent</th>\n",
       "      <td>2.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_memory_usage_bytes</th>\n",
       "      <td>2697252864</td>\n",
       "      <td>2639552512</td>\n",
       "      <td>2605256704</td>\n",
       "      <td>2712571904</td>\n",
       "      <td>3103969280</td>\n",
       "      <td>2008952832</td>\n",
       "      <td>2719707136</td>\n",
       "      <td>3101462528</td>\n",
       "      <td>2698420224</td>\n",
       "      <td>3102679040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_1</th>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_2</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_utilization_percent_3</th>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_current_memory_allocated_bytes</th>\n",
       "      <td>1577541632</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1576560640</td>\n",
       "      <td>4419853312</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>1576947200</td>\n",
       "      <td>4419853312</td>\n",
       "      <td>1576167936</td>\n",
       "      <td>4419853312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_max_memory_allocated_bytes</th>\n",
       "      <td>1577541632</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1087688704</td>\n",
       "      <td>1576560640</td>\n",
       "      <td>4419853312</td>\n",
       "      <td>8818209280</td>\n",
       "      <td>1576947200</td>\n",
       "      <td>4419853312</td>\n",
       "      <td>1576167936</td>\n",
       "      <td>4419853312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_current_memory_reserved_bytes</th>\n",
       "      <td>3577741312</td>\n",
       "      <td>2621440000</td>\n",
       "      <td>1986002944</td>\n",
       "      <td>2707423232</td>\n",
       "      <td>6870269952</td>\n",
       "      <td>12614369280</td>\n",
       "      <td>2839543808</td>\n",
       "      <td>6339690496</td>\n",
       "      <td>2665480192</td>\n",
       "      <td>6870269952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_max_memory_reserved_bytes</th>\n",
       "      <td>3577741312</td>\n",
       "      <td>2621440000</td>\n",
       "      <td>1986002944</td>\n",
       "      <td>2707423232</td>\n",
       "      <td>6870269952</td>\n",
       "      <td>12614369280</td>\n",
       "      <td>2839543808</td>\n",
       "      <td>6339690496</td>\n",
       "      <td>2665480192</td>\n",
       "      <td>6870269952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_0</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_1</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_2</th>\n",
       "      <td>112.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_process_3</th>\n",
       "      <td>112.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_0</th>\n",
       "      <td>2188.362421</td>\n",
       "      <td>223.037084</td>\n",
       "      <td>59.55226</td>\n",
       "      <td>69.072265</td>\n",
       "      <td>65.821461</td>\n",
       "      <td>50.244713</td>\n",
       "      <td>72.113809</td>\n",
       "      <td>81.048935</td>\n",
       "      <td>65.177186</td>\n",
       "      <td>457.382282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_1</th>\n",
       "      <td>4047.539154</td>\n",
       "      <td>5196.196127</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3296.806187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.898898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>632.013391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_2</th>\n",
       "      <td>606.487311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.723614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>270.713047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>595.359303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_process_3</th>\n",
       "      <td>904.604009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.87737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>620.415433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>457.642175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_0</th>\n",
       "      <td>0.941245</td>\n",
       "      <td>0.921142</td>\n",
       "      <td>0.909635</td>\n",
       "      <td>0.947124</td>\n",
       "      <td>1.082698</td>\n",
       "      <td>0.699726</td>\n",
       "      <td>0.949295</td>\n",
       "      <td>1.081179</td>\n",
       "      <td>0.942028</td>\n",
       "      <td>1.081884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_1</th>\n",
       "      <td>0.987205</td>\n",
       "      <td>0.963023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.854483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.990586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.881813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_2</th>\n",
       "      <td>0.992191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.878247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.993442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.85207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_process_3</th>\n",
       "      <td>0.987415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.870719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994052</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.871551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_0</th>\n",
       "      <td>0.000357</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.00188</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.029285</td>\n",
       "      <td>0.0004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_1</th>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_2</th>\n",
       "      <td>0.000286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001329</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_process_3</th>\n",
       "      <td>0.000343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_0</th>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.000574</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.015628</td>\n",
       "      <td>0.001729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_1</th>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001132</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_2</th>\n",
       "      <td>0.00149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_process_3</th>\n",
       "      <td>0.001491</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_0</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_1</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_2</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_process_3</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_0</th>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.00139</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.005224</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.045144</td>\n",
       "      <td>0.002133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_1</th>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_2</th>\n",
       "      <td>0.001778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_3</th>\n",
       "      <td>0.001837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_0</th>\n",
       "      <td>6662.637517</td>\n",
       "      <td>2639.913724</td>\n",
       "      <td>2748.678723</td>\n",
       "      <td>11613.150827</td>\n",
       "      <td>5003.111618</td>\n",
       "      <td>20669.796894</td>\n",
       "      <td>18808.052129</td>\n",
       "      <td>10468.775683</td>\n",
       "      <td>162518.073262</td>\n",
       "      <td>7678.122128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_1</th>\n",
       "      <td>6597.153684</td>\n",
       "      <td>2403.680954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4805.88441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20989.350576</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7591.403266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_2</th>\n",
       "      <td>6402.043435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4999.457194</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20570.657494</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7565.211911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules_process_3</th>\n",
       "      <td>6614.252263</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4995.183202</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20043.39568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7533.551389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_power_avg</th>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "      <td>112.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_avg</th>\n",
       "      <td>1936.748224</td>\n",
       "      <td>2709.616605</td>\n",
       "      <td>59.55226</td>\n",
       "      <td>69.072265</td>\n",
       "      <td>873.557158</td>\n",
       "      <td>50.244713</td>\n",
       "      <td>255.785297</td>\n",
       "      <td>81.048935</td>\n",
       "      <td>65.177186</td>\n",
       "      <td>535.599288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_avg</th>\n",
       "      <td>0.977014</td>\n",
       "      <td>0.942083</td>\n",
       "      <td>0.909635</td>\n",
       "      <td>0.947124</td>\n",
       "      <td>0.921537</td>\n",
       "      <td>0.699726</td>\n",
       "      <td>0.981844</td>\n",
       "      <td>1.081179</td>\n",
       "      <td>0.942028</td>\n",
       "      <td>0.921829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_total</th>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.00188</td>\n",
       "      <td>0.00091</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.005052</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.029285</td>\n",
       "      <td>0.001521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_total</th>\n",
       "      <td>0.005963</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.004585</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.017239</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.015628</td>\n",
       "      <td>0.006904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_energy_total</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_0</th>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.000279</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.001229</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.002177</td>\n",
       "      <td>0.001108</td>\n",
       "      <td>0.017198</td>\n",
       "      <td>0.000803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_1</th>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_2</th>\n",
       "      <td>0.0007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00199</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>per-process_emissions_3</th>\n",
       "      <td>0.000705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_config_decoding_mode</th>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_k</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_k</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_p</td>\n",
       "      <td>greedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_generated_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>14120</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>models</th>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                             0  \\\n",
       "config_name                                                          A1_Max_Throughput_Exploit   \n",
       "experiment_id                                                                              220   \n",
       "date_time                                                        April 11, 2025 at 04:28:24 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                256   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                              True   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.007299   \n",
       "total_energy_joules                                                               26276.086899   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.623533   \n",
       "joules_per_token                                                                      1.603765   \n",
       "flops_per_joule                                                               645072116.656167   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             12.157593   \n",
       "average_latency_ms_per_batch                                                      12157.593134   \n",
       "throughput_queries_per_sec                                                             10.5284   \n",
       "throughput_tokens_per_sec                                                          1347.635163   \n",
       "cpu_usage_percent                                                                          2.7   \n",
       "cpu_memory_usage_bytes                                                              2697252864   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1577541632   \n",
       "gpu_max_memory_allocated_bytes                                                      1577541632   \n",
       "gpu_current_memory_reserved_bytes                                                   3577741312   \n",
       "gpu_max_memory_reserved_bytes                                                       3577741312   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                2188.362421   \n",
       "gpu_power_process_1                                                                4047.539154   \n",
       "gpu_power_process_2                                                                 606.487311   \n",
       "gpu_power_process_3                                                                 904.604009   \n",
       "ram_power_process_0                                                                   0.941245   \n",
       "ram_power_process_1                                                                   0.987205   \n",
       "ram_power_process_2                                                                   0.992191   \n",
       "ram_power_process_3                                                                   0.987415   \n",
       "cpu_energy_process_0                                                                  0.000357   \n",
       "cpu_energy_process_1                                                                  0.000338   \n",
       "cpu_energy_process_2                                                                  0.000286   \n",
       "cpu_energy_process_3                                                                  0.000343   \n",
       "gpu_energy_process_0                                                                  0.001491   \n",
       "gpu_energy_process_1                                                                  0.001491   \n",
       "gpu_energy_process_2                                                                   0.00149   \n",
       "gpu_energy_process_3                                                                  0.001491   \n",
       "ram_energy_process_0                                                                  0.000003   \n",
       "ram_energy_process_1                                                                  0.000003   \n",
       "ram_energy_process_2                                                                  0.000003   \n",
       "ram_energy_process_3                                                                  0.000003   \n",
       "total_energy_kwh_process_0                                                            0.001851   \n",
       "total_energy_kwh_process_1                                                            0.001833   \n",
       "total_energy_kwh_process_2                                                            0.001778   \n",
       "total_energy_kwh_process_3                                                            0.001837   \n",
       "total_energy_joules_process_0                                                      6662.637517   \n",
       "total_energy_joules_process_1                                                      6597.153684   \n",
       "total_energy_joules_process_2                                                      6402.043435   \n",
       "total_energy_joules_process_3                                                      6614.252263   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      1936.748224   \n",
       "ram_power_avg                                                                         0.977014   \n",
       "cpu_energy_total                                                                      0.001324   \n",
       "gpu_energy_total                                                                      0.005963   \n",
       "ram_energy_total                                                                      0.000012   \n",
       "per-process_emissions_0                                                               0.000698   \n",
       "per-process_emissions_1                                                               0.000677   \n",
       "per-process_emissions_2                                                                 0.0007   \n",
       "per-process_emissions_3                                                               0.000705   \n",
       "latency_simulation_simulate                                                              False   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                          16949970993152   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "\n",
       "                                                                                             1  \\\n",
       "config_name                                                            A2_Precision_Minimalist   \n",
       "experiment_id                                                                              221   \n",
       "date_time                                                        April 11, 2025 at 04:29:05 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                2   \n",
       "batch_size___fixed_batching                                                                128   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          2   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.001401   \n",
       "total_energy_joules                                                                5043.594678   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      3.248477   \n",
       "joules_per_token                                                                      0.307837   \n",
       "flops_per_joule                                                              3360692536.878901   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                               5.11736   \n",
       "average_latency_ms_per_batch                                                       5117.360245   \n",
       "throughput_queries_per_sec                                                           25.012896   \n",
       "throughput_tokens_per_sec                                                          3201.650698   \n",
       "cpu_usage_percent                                                                          1.6   \n",
       "cpu_memory_usage_bytes                                                              2639552512   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                  0.0   \n",
       "gpu_utilization_percent_3                                                                  0.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   2621440000   \n",
       "gpu_max_memory_reserved_bytes                                                       2621440000   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                        NaN   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                 223.037084   \n",
       "gpu_power_process_1                                                                5196.196127   \n",
       "gpu_power_process_2                                                                        NaN   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   0.921142   \n",
       "ram_power_process_1                                                                   0.963023   \n",
       "ram_power_process_2                                                                        NaN   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                  0.000158   \n",
       "cpu_energy_process_1                                                                  0.000096   \n",
       "cpu_energy_process_2                                                                       NaN   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                  0.000574   \n",
       "gpu_energy_process_1                                                                  0.000571   \n",
       "gpu_energy_process_2                                                                       NaN   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                  0.000001   \n",
       "ram_energy_process_1                                                                  0.000001   \n",
       "ram_energy_process_2                                                                       NaN   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.000733   \n",
       "total_energy_kwh_process_1                                                            0.000668   \n",
       "total_energy_kwh_process_2                                                                 NaN   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                      2639.913724   \n",
       "total_energy_joules_process_1                                                      2403.680954   \n",
       "total_energy_joules_process_2                                                              NaN   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                      2709.616605   \n",
       "ram_power_avg                                                                         0.942083   \n",
       "cpu_energy_total                                                                      0.000254   \n",
       "gpu_energy_total                                                                      0.001145   \n",
       "ram_energy_total                                                                      0.000002   \n",
       "per-process_emissions_0                                                               0.000279   \n",
       "per-process_emissions_1                                                               0.000254   \n",
       "per-process_emissions_2                                                                    NaN   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                          16949970993152   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "\n",
       "                                                                                             2  \\\n",
       "config_name                                                             A3_Quantisation_Gaming   \n",
       "experiment_id                                                                              222   \n",
       "date_time                                                        April 11, 2025 at 04:29:46 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                1   \n",
       "batch_size___fixed_batching                                                                 64   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                              True   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          1   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                         615606272   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.000764   \n",
       "total_energy_joules                                                                2748.678723   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      5.960682   \n",
       "joules_per_token                                                                      0.167766   \n",
       "flops_per_joule                                                              6166588640.753133   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                               9.56734   \n",
       "average_latency_ms_per_batch                                                       4783.670129   \n",
       "throughput_queries_per_sec                                                           13.378849   \n",
       "throughput_tokens_per_sec                                                          1712.492663   \n",
       "cpu_usage_percent                                                                          0.3   \n",
       "cpu_memory_usage_bytes                                                              2605256704   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                  0.0   \n",
       "gpu_utilization_percent_2                                                                  0.0   \n",
       "gpu_utilization_percent_3                                                                  0.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1087688704   \n",
       "gpu_max_memory_allocated_bytes                                                      1087688704   \n",
       "gpu_current_memory_reserved_bytes                                                   1986002944   \n",
       "gpu_max_memory_reserved_bytes                                                       1986002944   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                        NaN   \n",
       "cpu_power_process_2                                                                        NaN   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                   59.55226   \n",
       "gpu_power_process_1                                                                        NaN   \n",
       "gpu_power_process_2                                                                        NaN   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   0.909635   \n",
       "ram_power_process_1                                                                        NaN   \n",
       "ram_power_process_2                                                                        NaN   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                  0.000374   \n",
       "cpu_energy_process_1                                                                       NaN   \n",
       "cpu_energy_process_2                                                                       NaN   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                  0.000387   \n",
       "gpu_energy_process_1                                                                       NaN   \n",
       "gpu_energy_process_2                                                                       NaN   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                  0.000003   \n",
       "ram_energy_process_1                                                                       NaN   \n",
       "ram_energy_process_2                                                                       NaN   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.000764   \n",
       "total_energy_kwh_process_1                                                                 NaN   \n",
       "total_energy_kwh_process_2                                                                 NaN   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                      2748.678723   \n",
       "total_energy_joules_process_1                                                              NaN   \n",
       "total_energy_joules_process_2                                                              NaN   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                         59.55226   \n",
       "ram_power_avg                                                                         0.909635   \n",
       "cpu_energy_total                                                                      0.000374   \n",
       "gpu_energy_total                                                                      0.000387   \n",
       "ram_energy_total                                                                      0.000003   \n",
       "per-process_emissions_0                                                               0.000291   \n",
       "per-process_emissions_1                                                                    NaN   \n",
       "per-process_emissions_2                                                                    NaN   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                          16949970993152   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "\n",
       "                                                                                             3  \\\n",
       "config_name                                                                            default   \n",
       "experiment_id                                                                              223   \n",
       "date_time                                                        April 11, 2025 at 04:31:30 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                1   \n",
       "batch_size___fixed_batching                                                                 16   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                              True   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          1   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.003226   \n",
       "total_energy_joules                                                               11613.150827   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      1.410814   \n",
       "joules_per_token                                                                       0.70881   \n",
       "flops_per_joule                                                              1459549716.198339   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             71.473257   \n",
       "average_latency_ms_per_batch                                                       8934.157172   \n",
       "throughput_queries_per_sec                                                             1.79088   \n",
       "throughput_tokens_per_sec                                                           229.232591   \n",
       "cpu_usage_percent                                                                          0.8   \n",
       "cpu_memory_usage_bytes                                                              2712571904   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                  0.0   \n",
       "gpu_utilization_percent_2                                                                  0.0   \n",
       "gpu_utilization_percent_3                                                                  0.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1576560640   \n",
       "gpu_max_memory_allocated_bytes                                                      1576560640   \n",
       "gpu_current_memory_reserved_bytes                                                   2707423232   \n",
       "gpu_max_memory_reserved_bytes                                                       2707423232   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                        NaN   \n",
       "cpu_power_process_2                                                                        NaN   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                  69.072265   \n",
       "gpu_power_process_1                                                                        NaN   \n",
       "gpu_power_process_2                                                                        NaN   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   0.947124   \n",
       "ram_power_process_1                                                                        NaN   \n",
       "ram_power_process_2                                                                        NaN   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                   0.00188   \n",
       "cpu_energy_process_1                                                                       NaN   \n",
       "cpu_energy_process_2                                                                       NaN   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                   0.00133   \n",
       "gpu_energy_process_1                                                                       NaN   \n",
       "gpu_energy_process_2                                                                       NaN   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                  0.000016   \n",
       "ram_energy_process_1                                                                       NaN   \n",
       "ram_energy_process_2                                                                       NaN   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.003226   \n",
       "total_energy_kwh_process_1                                                                 NaN   \n",
       "total_energy_kwh_process_2                                                                 NaN   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                     11613.150827   \n",
       "total_energy_joules_process_1                                                              NaN   \n",
       "total_energy_joules_process_2                                                              NaN   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        69.072265   \n",
       "ram_power_avg                                                                         0.947124   \n",
       "cpu_energy_total                                                                       0.00188   \n",
       "gpu_energy_total                                                                       0.00133   \n",
       "ram_energy_total                                                                      0.000016   \n",
       "per-process_emissions_0                                                               0.001229   \n",
       "per-process_emissions_1                                                                    NaN   \n",
       "per-process_emissions_2                                                                    NaN   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "latency_simulation_simulate                                                              False   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                          16949970993152   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "\n",
       "                                                                                             4  \\\n",
       "config_name                                                              A5_Parallel_Overdrive   \n",
       "experiment_id                                                                              224   \n",
       "date_time                                                        April 11, 2025 at 04:32:11 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 64   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.0   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.005501   \n",
       "total_energy_joules                                                               19803.636424   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.827323   \n",
       "joules_per_token                                                                      1.208718   \n",
       "flops_per_joule                                                               855901948.028895   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                              6.201934   \n",
       "average_latency_ms_per_batch                                                       3100.966923   \n",
       "throughput_queries_per_sec                                                           20.638724   \n",
       "throughput_tokens_per_sec                                                          2641.756654   \n",
       "cpu_usage_percent                                                                          2.9   \n",
       "cpu_memory_usage_bytes                                                              3103969280   \n",
       "gpu_utilization_percent_0                                                                  0.0   \n",
       "gpu_utilization_percent_1                                                                100.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                100.0   \n",
       "gpu_current_memory_allocated_bytes                                                  4419853312   \n",
       "gpu_max_memory_allocated_bytes                                                      4419853312   \n",
       "gpu_current_memory_reserved_bytes                                                   6870269952   \n",
       "gpu_max_memory_reserved_bytes                                                       6870269952   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  65.821461   \n",
       "gpu_power_process_1                                                                3296.806187   \n",
       "gpu_power_process_2                                                                  64.723614   \n",
       "gpu_power_process_3                                                                   66.87737   \n",
       "ram_power_process_0                                                                   1.082698   \n",
       "ram_power_process_1                                                                   0.854483   \n",
       "ram_power_process_2                                                                   0.878247   \n",
       "ram_power_process_3                                                                   0.870719   \n",
       "cpu_energy_process_0                                                                  0.000237   \n",
       "cpu_energy_process_1                                                                  0.000201   \n",
       "cpu_energy_process_2                                                                  0.000237   \n",
       "cpu_energy_process_3                                                                  0.000235   \n",
       "gpu_energy_process_0                                                                  0.001151   \n",
       "gpu_energy_process_1                                                                  0.001132   \n",
       "gpu_energy_process_2                                                                   0.00115   \n",
       "gpu_energy_process_3                                                                  0.001151   \n",
       "ram_energy_process_0                                                                  0.000002   \n",
       "ram_energy_process_1                                                                  0.000002   \n",
       "ram_energy_process_2                                                                  0.000002   \n",
       "ram_energy_process_3                                                                  0.000002   \n",
       "total_energy_kwh_process_0                                                             0.00139   \n",
       "total_energy_kwh_process_1                                                            0.001335   \n",
       "total_energy_kwh_process_2                                                            0.001389   \n",
       "total_energy_kwh_process_3                                                            0.001388   \n",
       "total_energy_joules_process_0                                                      5003.111618   \n",
       "total_energy_joules_process_1                                                       4805.88441   \n",
       "total_energy_joules_process_2                                                      4999.457194   \n",
       "total_energy_joules_process_3                                                      4995.183202   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       873.557158   \n",
       "ram_power_avg                                                                         0.921537   \n",
       "cpu_energy_total                                                                       0.00091   \n",
       "gpu_energy_total                                                                      0.004585   \n",
       "ram_energy_total                                                                      0.000007   \n",
       "per-process_emissions_0                                                               0.000529   \n",
       "per-process_emissions_1                                                               0.000529   \n",
       "per-process_emissions_2                                                               0.000509   \n",
       "per-process_emissions_3                                                               0.000529   \n",
       "latency_simulation_simulate                                                              False   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                          16949970993152   \n",
       "latency_simulation_delay_max                                                               0.0   \n",
       "\n",
       "                                                                                             5  \\\n",
       "config_name                                                  R2_Low_Latency_Chatbot_Deployment   \n",
       "experiment_id                                                                              228   \n",
       "date_time                                                        April 11, 2025 at 04:35:15 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                1   \n",
       "batch_size___fixed_batching                                                                  4   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                              0.01   \n",
       "latency_simulation_simulate_burst                                                        False   \n",
       "latency_simulation_burst_size                                                                0   \n",
       "latency_simulation_burst_interval                                                          0.0   \n",
       "fp_precision                                                                     torch.float32   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          1   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.005742   \n",
       "total_energy_joules                                                               20669.796894   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.792654   \n",
       "joules_per_token                                                                      1.261584   \n",
       "flops_per_joule                                                               820035682.010454   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             88.568613   \n",
       "average_latency_ms_per_batch                                                       2767.769153   \n",
       "throughput_queries_per_sec                                                            1.445207   \n",
       "throughput_tokens_per_sec                                                           184.986526   \n",
       "cpu_usage_percent                                                                          1.2   \n",
       "cpu_memory_usage_bytes                                                              2008952832   \n",
       "gpu_utilization_percent_0                                                                 14.0   \n",
       "gpu_utilization_percent_1                                                                 10.0   \n",
       "gpu_utilization_percent_2                                                                 10.0   \n",
       "gpu_utilization_percent_3                                                                  9.0   \n",
       "gpu_current_memory_allocated_bytes                                                  8818209280   \n",
       "gpu_max_memory_allocated_bytes                                                      8818209280   \n",
       "gpu_current_memory_reserved_bytes                                                  12614369280   \n",
       "gpu_max_memory_reserved_bytes                                                      12614369280   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                        NaN   \n",
       "cpu_power_process_2                                                                        NaN   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                  50.244713   \n",
       "gpu_power_process_1                                                                        NaN   \n",
       "gpu_power_process_2                                                                        NaN   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   0.699726   \n",
       "ram_power_process_1                                                                        NaN   \n",
       "ram_power_process_2                                                                        NaN   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                  0.002531   \n",
       "cpu_energy_process_1                                                                       NaN   \n",
       "cpu_energy_process_2                                                                       NaN   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                  0.003197   \n",
       "gpu_energy_process_1                                                                       NaN   \n",
       "gpu_energy_process_2                                                                       NaN   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                  0.000014   \n",
       "ram_energy_process_1                                                                       NaN   \n",
       "ram_energy_process_2                                                                       NaN   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.005742   \n",
       "total_energy_kwh_process_1                                                                 NaN   \n",
       "total_energy_kwh_process_2                                                                 NaN   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                     20669.796894   \n",
       "total_energy_joules_process_1                                                              NaN   \n",
       "total_energy_joules_process_2                                                              NaN   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        50.244713   \n",
       "ram_power_avg                                                                         0.699726   \n",
       "cpu_energy_total                                                                      0.002531   \n",
       "gpu_energy_total                                                                      0.003197   \n",
       "ram_energy_total                                                                      0.000014   \n",
       "per-process_emissions_0                                                               0.002187   \n",
       "per-process_emissions_1                                                                    NaN   \n",
       "per-process_emissions_2                                                                    NaN   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "latency_simulation_simulate                                                               True   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                          16949970993152   \n",
       "latency_simulation_delay_max                                                              0.05   \n",
       "\n",
       "                                                                                             6  \\\n",
       "config_name                                                     R3_Balanced_Enterprise_Service   \n",
       "experiment_id                                                                              229   \n",
       "date_time                                                        April 11, 2025 at 04:36:43 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                4   \n",
       "batch_size___fixed_batching                                                                 32   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                               50   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                               0.5   \n",
       "latency_simulation_simulate_burst                                                         True   \n",
       "latency_simulation_burst_size                                                                5   \n",
       "latency_simulation_burst_interval                                                          4.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                              True   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          4   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.022337   \n",
       "total_energy_joules                                                               80411.455879   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.203752   \n",
       "joules_per_token                                                                      4.907926   \n",
       "flops_per_joule                                                               210790500.032728   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             46.186702   \n",
       "average_latency_ms_per_batch                                                      11546.675429   \n",
       "throughput_queries_per_sec                                                             2.77136   \n",
       "throughput_tokens_per_sec                                                           354.734142   \n",
       "cpu_usage_percent                                                                          3.5   \n",
       "cpu_memory_usage_bytes                                                              2719707136   \n",
       "gpu_utilization_percent_0                                                                  1.0   \n",
       "gpu_utilization_percent_1                                                                 82.0   \n",
       "gpu_utilization_percent_2                                                                100.0   \n",
       "gpu_utilization_percent_3                                                                 99.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1576947200   \n",
       "gpu_max_memory_allocated_bytes                                                      1576947200   \n",
       "gpu_current_memory_reserved_bytes                                                   2839543808   \n",
       "gpu_max_memory_reserved_bytes                                                       2839543808   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                      112.5   \n",
       "cpu_power_process_2                                                                      112.5   \n",
       "cpu_power_process_3                                                                      112.5   \n",
       "gpu_power_process_0                                                                  72.113809   \n",
       "gpu_power_process_1                                                                  59.898898   \n",
       "gpu_power_process_2                                                                 270.713047   \n",
       "gpu_power_process_3                                                                 620.415433   \n",
       "ram_power_process_0                                                                   0.949295   \n",
       "ram_power_process_1                                                                   0.990586   \n",
       "ram_power_process_2                                                                   0.993442   \n",
       "ram_power_process_3                                                                   0.994052   \n",
       "cpu_energy_process_0                                                                  0.001097   \n",
       "cpu_energy_process_1                                                                  0.001346   \n",
       "cpu_energy_process_2                                                                  0.001329   \n",
       "cpu_energy_process_3                                                                  0.001281   \n",
       "gpu_energy_process_0                                                                  0.004117   \n",
       "gpu_energy_process_1                                                                  0.004473   \n",
       "gpu_energy_process_2                                                                  0.004374   \n",
       "gpu_energy_process_3                                                                  0.004276   \n",
       "ram_energy_process_0                                                                   0.00001   \n",
       "ram_energy_process_1                                                                  0.000012   \n",
       "ram_energy_process_2                                                                  0.000011   \n",
       "ram_energy_process_3                                                                  0.000011   \n",
       "total_energy_kwh_process_0                                                            0.005224   \n",
       "total_energy_kwh_process_1                                                             0.00583   \n",
       "total_energy_kwh_process_2                                                            0.005714   \n",
       "total_energy_kwh_process_3                                                            0.005568   \n",
       "total_energy_joules_process_0                                                     18808.052129   \n",
       "total_energy_joules_process_1                                                     20989.350576   \n",
       "total_energy_joules_process_2                                                     20570.657494   \n",
       "total_energy_joules_process_3                                                      20043.39568   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                       255.785297   \n",
       "ram_power_avg                                                                         0.981844   \n",
       "cpu_energy_total                                                                      0.005052   \n",
       "gpu_energy_total                                                                      0.017239   \n",
       "ram_energy_total                                                                      0.000045   \n",
       "per-process_emissions_0                                                               0.002177   \n",
       "per-process_emissions_1                                                               0.002121   \n",
       "per-process_emissions_2                                                                0.00199   \n",
       "per-process_emissions_3                                                               0.002221   \n",
       "latency_simulation_simulate                                                               True   \n",
       "decoder_config_decoding_mode                                                             top_k   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                          16949970993152   \n",
       "latency_simulation_delay_max                                                               1.5   \n",
       "\n",
       "                                                                                             7  \\\n",
       "config_name                                                  R4_High_Load_Cloud_API_Deployment   \n",
       "experiment_id                                                                              230   \n",
       "date_time                                                        April 11, 2025 at 04:38:09 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                1   \n",
       "batch_size___fixed_batching                                                                  8   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.0   \n",
       "latency_simulation_delay_min                                                              0.05   \n",
       "latency_simulation_simulate_burst                                                         True   \n",
       "latency_simulation_burst_size                                                                5   \n",
       "latency_simulation_burst_interval                                                          2.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                             False   \n",
       "load_in_8bit                                                                             False   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          1   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.002908   \n",
       "total_energy_joules                                                               10468.775683   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      1.565035   \n",
       "joules_per_token                                                                      0.638963   \n",
       "flops_per_joule                                                              1619097734.639612   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                             56.839973   \n",
       "average_latency_ms_per_batch                                                       3552.498301   \n",
       "throughput_queries_per_sec                                                            2.251936   \n",
       "throughput_tokens_per_sec                                                           288.247851   \n",
       "cpu_usage_percent                                                                          0.9   \n",
       "cpu_memory_usage_bytes                                                              3101462528   \n",
       "gpu_utilization_percent_0                                                                  3.0   \n",
       "gpu_utilization_percent_1                                                                  8.0   \n",
       "gpu_utilization_percent_2                                                                 10.0   \n",
       "gpu_utilization_percent_3                                                                  8.0   \n",
       "gpu_current_memory_allocated_bytes                                                  4419853312   \n",
       "gpu_max_memory_allocated_bytes                                                      4419853312   \n",
       "gpu_current_memory_reserved_bytes                                                   6339690496   \n",
       "gpu_max_memory_reserved_bytes                                                       6339690496   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                        NaN   \n",
       "cpu_power_process_2                                                                        NaN   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                  81.048935   \n",
       "gpu_power_process_1                                                                        NaN   \n",
       "gpu_power_process_2                                                                        NaN   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   1.081179   \n",
       "ram_power_process_1                                                                        NaN   \n",
       "ram_power_process_2                                                                        NaN   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                  0.001609   \n",
       "cpu_energy_process_1                                                                       NaN   \n",
       "cpu_energy_process_2                                                                       NaN   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                  0.001284   \n",
       "gpu_energy_process_1                                                                       NaN   \n",
       "gpu_energy_process_2                                                                       NaN   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                  0.000015   \n",
       "ram_energy_process_1                                                                       NaN   \n",
       "ram_energy_process_2                                                                       NaN   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.002908   \n",
       "total_energy_kwh_process_1                                                                 NaN   \n",
       "total_energy_kwh_process_2                                                                 NaN   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                     10468.775683   \n",
       "total_energy_joules_process_1                                                              NaN   \n",
       "total_energy_joules_process_2                                                              NaN   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        81.048935   \n",
       "ram_power_avg                                                                         1.081179   \n",
       "cpu_energy_total                                                                      0.001609   \n",
       "gpu_energy_total                                                                      0.001284   \n",
       "ram_energy_total                                                                      0.000015   \n",
       "per-process_emissions_0                                                               0.001108   \n",
       "per-process_emissions_1                                                                    NaN   \n",
       "per-process_emissions_2                                                                    NaN   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "latency_simulation_simulate                                                               True   \n",
       "decoder_config_decoding_mode                                                            greedy   \n",
       "total_generated_tokens                                                                   16384   \n",
       "models                                                                          16949970993152   \n",
       "latency_simulation_delay_max                                                               0.2   \n",
       "\n",
       "                                                                                             8  \\\n",
       "config_name                                                      R5_Real_Time_Mobile_Inference   \n",
       "experiment_id                                                                              231   \n",
       "date_time                                                        April 11, 2025 at 04:55:10 PM   \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                                1   \n",
       "batch_size___fixed_batching                                                                  1   \n",
       "decoder_temperature                                                                        1.0   \n",
       "decoder_top_k                                                                                0   \n",
       "decoder_top_p                                                                              0.9   \n",
       "latency_simulation_delay_min                                                               0.2   \n",
       "latency_simulation_simulate_burst                                                         True   \n",
       "latency_simulation_burst_size                                                                8   \n",
       "latency_simulation_burst_interval                                                          5.0   \n",
       "fp_precision                                                                     torch.float16   \n",
       "quantization                                                                              True   \n",
       "load_in_8bit                                                                              True   \n",
       "load_in_4bit                                                                             False   \n",
       "sharding_strategy                                                                     NO_SHARD   \n",
       "sharding_config_fsdp_config_use_orig_params                                              False   \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False   \n",
       "adaptive_batching                                                                        False   \n",
       "adaptive_max_tokens                                                                          0   \n",
       "query_rate                                                                                 1.0   \n",
       "total_input_tokens                                                                       16384   \n",
       "is_encoder_decoder                                                                       False   \n",
       "task_type                                                                      text_generation   \n",
       "available_gpu_count                                                                          1   \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB   \n",
       "available_cpu_count                                                                        128   \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor   \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31   \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]   \n",
       "country                                                                                Germany   \n",
       "region                                                                                  saxony   \n",
       "distributed_type                                                     DistributedType.MULTI_GPU   \n",
       "decode_token_to_text                                                                      True   \n",
       "inference_type                                                                 pure_generative   \n",
       "backend                                                                                pytorch   \n",
       "total_params                                                                        1100048384   \n",
       "model_arch                                                       Unknown (no config attribute)   \n",
       "max_input_tokens                                                                           128   \n",
       "max_output_tokens                                                                          128   \n",
       "number_input_prompts                                                                       128   \n",
       "total_energy_kwh                                                                      0.045144   \n",
       "total_energy_joules                                                              162518.073262   \n",
       "flops                                                                           16949970993152   \n",
       "tokens_per_joule                                                                      0.086883   \n",
       "joules_per_token                                                                     11.509779   \n",
       "flops_per_joule                                                               104295914.004625   \n",
       "joules_per_flop                                                                            0.0   \n",
       "total_inference_time_sec                                                            984.640872   \n",
       "average_latency_ms_per_batch                                                       7692.506816   \n",
       "throughput_queries_per_sec                                                            0.129997   \n",
       "throughput_tokens_per_sec                                                            14.340254   \n",
       "cpu_usage_percent                                                                          1.1   \n",
       "cpu_memory_usage_bytes                                                              2698420224   \n",
       "gpu_utilization_percent_0                                                                  4.0   \n",
       "gpu_utilization_percent_1                                                                 11.0   \n",
       "gpu_utilization_percent_2                                                                 10.0   \n",
       "gpu_utilization_percent_3                                                                 10.0   \n",
       "gpu_current_memory_allocated_bytes                                                  1576167936   \n",
       "gpu_max_memory_allocated_bytes                                                      1576167936   \n",
       "gpu_current_memory_reserved_bytes                                                   2665480192   \n",
       "gpu_max_memory_reserved_bytes                                                       2665480192   \n",
       "cpu_power_process_0                                                                      112.5   \n",
       "cpu_power_process_1                                                                        NaN   \n",
       "cpu_power_process_2                                                                        NaN   \n",
       "cpu_power_process_3                                                                        NaN   \n",
       "gpu_power_process_0                                                                  65.177186   \n",
       "gpu_power_process_1                                                                        NaN   \n",
       "gpu_power_process_2                                                                        NaN   \n",
       "gpu_power_process_3                                                                        NaN   \n",
       "ram_power_process_0                                                                   0.942028   \n",
       "ram_power_process_1                                                                        NaN   \n",
       "ram_power_process_2                                                                        NaN   \n",
       "ram_power_process_3                                                                        NaN   \n",
       "cpu_energy_process_0                                                                  0.029285   \n",
       "cpu_energy_process_1                                                                       NaN   \n",
       "cpu_energy_process_2                                                                       NaN   \n",
       "cpu_energy_process_3                                                                       NaN   \n",
       "gpu_energy_process_0                                                                  0.015628   \n",
       "gpu_energy_process_1                                                                       NaN   \n",
       "gpu_energy_process_2                                                                       NaN   \n",
       "gpu_energy_process_3                                                                       NaN   \n",
       "ram_energy_process_0                                                                  0.000231   \n",
       "ram_energy_process_1                                                                       NaN   \n",
       "ram_energy_process_2                                                                       NaN   \n",
       "ram_energy_process_3                                                                       NaN   \n",
       "total_energy_kwh_process_0                                                            0.045144   \n",
       "total_energy_kwh_process_1                                                                 NaN   \n",
       "total_energy_kwh_process_2                                                                 NaN   \n",
       "total_energy_kwh_process_3                                                                 NaN   \n",
       "total_energy_joules_process_0                                                    162518.073262   \n",
       "total_energy_joules_process_1                                                              NaN   \n",
       "total_energy_joules_process_2                                                              NaN   \n",
       "total_energy_joules_process_3                                                              NaN   \n",
       "cpu_power_avg                                                                            112.5   \n",
       "gpu_power_avg                                                                        65.177186   \n",
       "ram_power_avg                                                                         0.942028   \n",
       "cpu_energy_total                                                                      0.029285   \n",
       "gpu_energy_total                                                                      0.015628   \n",
       "ram_energy_total                                                                      0.000231   \n",
       "per-process_emissions_0                                                               0.017198   \n",
       "per-process_emissions_1                                                                    NaN   \n",
       "per-process_emissions_2                                                                    NaN   \n",
       "per-process_emissions_3                                                                    NaN   \n",
       "latency_simulation_simulate                                                               True   \n",
       "decoder_config_decoding_mode                                                             top_p   \n",
       "total_generated_tokens                                                                   14120   \n",
       "models                                                                          16949970993152   \n",
       "latency_simulation_delay_max                                                               0.6   \n",
       "\n",
       "                                                                                             9  \n",
       "config_name                                             R6_Medium_Scale_Language_Model_Serving  \n",
       "experiment_id                                                                              232  \n",
       "date_time                                                        April 11, 2025 at 04:55:58 PM  \n",
       "model                                                       TinyLlama/TinyLlama-1.1B-Chat-v1.0  \n",
       "num_processes                                                                                4  \n",
       "batch_size___fixed_batching                                                                 32  \n",
       "decoder_temperature                                                                        1.0  \n",
       "decoder_top_k                                                                                0  \n",
       "decoder_top_p                                                                              0.0  \n",
       "latency_simulation_delay_min                                                              0.01  \n",
       "latency_simulation_simulate_burst                                                        False  \n",
       "latency_simulation_burst_size                                                                0  \n",
       "latency_simulation_burst_interval                                                          0.0  \n",
       "fp_precision                                                                     torch.float16  \n",
       "quantization                                                                             False  \n",
       "load_in_8bit                                                                             False  \n",
       "load_in_4bit                                                                             False  \n",
       "sharding_strategy                                                                     NO_SHARD  \n",
       "sharding_config_fsdp_config_use_orig_params                                              False  \n",
       "sharding_config_fsdp_config_cpu_offload                                                  False  \n",
       "adaptive_batching                                                                        False  \n",
       "adaptive_max_tokens                                                                          0  \n",
       "query_rate                                                                                 1.0  \n",
       "total_input_tokens                                                                       16384  \n",
       "is_encoder_decoder                                                                       False  \n",
       "task_type                                                                      text_generation  \n",
       "available_gpu_count                                                                          4  \n",
       "gpu_model                                                            4 x NVIDIA A100-PCIE-40GB  \n",
       "available_cpu_count                                                                        128  \n",
       "cpu_model                                                      AMD EPYC 7742 64-Core Processor  \n",
       "os                                              Linux-5.15.0-113-generic-x86_64-with-glibc2.31  \n",
       "python_version                               3.10.14 (main, Apr  6 2024, 18:45:05) [GCC 9.4.0]  \n",
       "country                                                                                Germany  \n",
       "region                                                                                  saxony  \n",
       "distributed_type                                                     DistributedType.MULTI_GPU  \n",
       "decode_token_to_text                                                                      True  \n",
       "inference_type                                                                 pure_generative  \n",
       "backend                                                                                pytorch  \n",
       "total_params                                                                        1100048384  \n",
       "model_arch                                                       Unknown (no config attribute)  \n",
       "max_input_tokens                                                                           128  \n",
       "max_output_tokens                                                                          128  \n",
       "number_input_prompts                                                                       128  \n",
       "total_energy_kwh                                                                      0.008436  \n",
       "total_energy_joules                                                               30368.288695  \n",
       "flops                                                                           16949970993152  \n",
       "tokens_per_joule                                                                       0.53951  \n",
       "joules_per_token                                                                      1.853533  \n",
       "flops_per_joule                                                               558147058.058945  \n",
       "joules_per_flop                                                                            0.0  \n",
       "total_inference_time_sec                                                             12.265104  \n",
       "average_latency_ms_per_batch                                                       3066.276043  \n",
       "throughput_queries_per_sec                                                           10.436112  \n",
       "throughput_tokens_per_sec                                                          1335.822327  \n",
       "cpu_usage_percent                                                                          3.9  \n",
       "cpu_memory_usage_bytes                                                              3102679040  \n",
       "gpu_utilization_percent_0                                                                  5.0  \n",
       "gpu_utilization_percent_1                                                                100.0  \n",
       "gpu_utilization_percent_2                                                                100.0  \n",
       "gpu_utilization_percent_3                                                                100.0  \n",
       "gpu_current_memory_allocated_bytes                                                  4419853312  \n",
       "gpu_max_memory_allocated_bytes                                                      4419853312  \n",
       "gpu_current_memory_reserved_bytes                                                   6870269952  \n",
       "gpu_max_memory_reserved_bytes                                                       6870269952  \n",
       "cpu_power_process_0                                                                      112.5  \n",
       "cpu_power_process_1                                                                      112.5  \n",
       "cpu_power_process_2                                                                      112.5  \n",
       "cpu_power_process_3                                                                      112.5  \n",
       "gpu_power_process_0                                                                 457.382282  \n",
       "gpu_power_process_1                                                                 632.013391  \n",
       "gpu_power_process_2                                                                 595.359303  \n",
       "gpu_power_process_3                                                                 457.642175  \n",
       "ram_power_process_0                                                                   1.081884  \n",
       "ram_power_process_1                                                                   0.881813  \n",
       "ram_power_process_2                                                                    0.85207  \n",
       "ram_power_process_3                                                                   0.871551  \n",
       "cpu_energy_process_0                                                                    0.0004  \n",
       "cpu_energy_process_1                                                                  0.000378  \n",
       "cpu_energy_process_2                                                                   0.00037  \n",
       "cpu_energy_process_3                                                                  0.000373  \n",
       "gpu_energy_process_0                                                                  0.001729  \n",
       "gpu_energy_process_1                                                                  0.001728  \n",
       "gpu_energy_process_2                                                                  0.001729  \n",
       "gpu_energy_process_3                                                                  0.001717  \n",
       "ram_energy_process_0                                                                  0.000003  \n",
       "ram_energy_process_1                                                                  0.000002  \n",
       "ram_energy_process_2                                                                  0.000002  \n",
       "ram_energy_process_3                                                                  0.000002  \n",
       "total_energy_kwh_process_0                                                            0.002133  \n",
       "total_energy_kwh_process_1                                                            0.002109  \n",
       "total_energy_kwh_process_2                                                            0.002101  \n",
       "total_energy_kwh_process_3                                                            0.002093  \n",
       "total_energy_joules_process_0                                                      7678.122128  \n",
       "total_energy_joules_process_1                                                      7591.403266  \n",
       "total_energy_joules_process_2                                                      7565.211911  \n",
       "total_energy_joules_process_3                                                      7533.551389  \n",
       "cpu_power_avg                                                                            112.5  \n",
       "gpu_power_avg                                                                       535.599288  \n",
       "ram_power_avg                                                                         0.921829  \n",
       "cpu_energy_total                                                                      0.001521  \n",
       "gpu_energy_total                                                                      0.006904  \n",
       "ram_energy_total                                                                      0.000011  \n",
       "per-process_emissions_0                                                               0.000803  \n",
       "per-process_emissions_1                                                               0.000812  \n",
       "per-process_emissions_2                                                               0.000797  \n",
       "per-process_emissions_3                                                               0.000801  \n",
       "latency_simulation_simulate                                                               True  \n",
       "decoder_config_decoding_mode                                                            greedy  \n",
       "total_generated_tokens                                                                   16384  \n",
       "models                                                                          16949970993152  \n",
       "latency_simulation_delay_max                                                               0.1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid did not exist: [Errno 2] No such file or directory: 'analysis_results/grid_results.csv'\n",
      "text_generation did not exist: [Errno 2] No such file or directory: 'analysis_results/text_generation_results.csv'\n"
     ]
    }
   ],
   "source": [
    "def clean_column(col: str) -> str:\n",
    "    \"\"\"\n",
    "    Clean a single column name by:\n",
    "      - Stripping whitespace and replacing any non-standard quotes.\n",
    "      - Checking for per-process metric patterns.\n",
    "      - Applying special renames.\n",
    "      - Removing the 'variables_' prefix if present.\n",
    "      - Otherwise, attempting to strip off any messy prefixes using a known list of tokens.\n",
    "    \n",
    "    If no known token is found, the original (normalized) column name is returned.\n",
    "    \"\"\"\n",
    "    # Normalize the column string: remove extra whitespace and fix common issues with quotes.\n",
    "    col = col.strip()\n",
    "    col = col.replace(\"“\", \"\\\"\").replace(\"”\", \"\\\"\")\n",
    "    \n",
    "    # 1. Special exact mappings.\n",
    "    special_mappings = {\n",
    "        \"setup_cpu_model\": \"cpu_model\",\n",
    "        \"setup_gpu_model\": \"gpu_model\",\n",
    "        \"model_architecture_total_params\": \"total_params\",  # now maps to total_params\n",
    "        \"model_architecture_architecture\": \"model_arch\"\n",
    "    }\n",
    "    if col in special_mappings:\n",
    "        return special_mappings[col]\n",
    "    \n",
    "    # 2. Remove the 'variables_' prefix if it exists.\n",
    "    if col.startswith(\"variables_\"):\n",
    "        col = col[len(\"variables_\"):]\n",
    "    \n",
    "    # 3. First, check if it is a per-process metric column.\n",
    "    per_process_patterns = [\n",
    "        r'(cpu_power_process_\\d+)',\n",
    "        r'(gpu_power_process_\\d+)',\n",
    "        r'(ram_power_process_\\d+)',\n",
    "        r'(cpu_energy_process_\\d+)',\n",
    "        r'(gpu_energy_process_\\d+)',\n",
    "        r'(ram_energy_process_\\d+)',\n",
    "        r'(total_energy_kwh_process_\\d+)',\n",
    "        r'(total_energy_joules_process_\\d+)'\n",
    "    ]\n",
    "    for pattern in per_process_patterns:\n",
    "        match = re.search(pattern, col)\n",
    "        if match:\n",
    "            return match.group(1)\n",
    "    \n",
    "    # 4. For non-per-process columns, search for a known token in the cleaned column.\n",
    "    tokens = [\n",
    "        \"config_name\", \"experiment_id\", \"date_time\", \"model\", \"is_encoder_decoder\",\n",
    "        \"task_type\", \"available_gpu_count\", \"gpu_model\", \"available_cpu_count\", \"cpu_model\",\n",
    "        \"os\", \"python_version\", \"country\", \"region\", \"fsdp_use_orig_params\", \"fsdp_cpu_offload\",\n",
    "        \"sharding_strategy\", \"distributed_type\", \"num_processes\", \"max_input_tokens\", \"max_output_tokens\",\n",
    "        \"number_input_prompts\", \"decode_token_to_text\", \"decoder_temperature\", \"decoder_top_k\", \"decoder_top_p\",\n",
    "        \"query_rate\", \"latency_simulate\", \"latency_delay_min\", \"latency_delay_max\", \"latency_simulate_burst\",\n",
    "        \"latency_burst_interval\", \"latency_burst_size\", \"fp_precision\", \"quantization\", \"load_in_8bit\",\n",
    "        \"load_in_4bit\", \"cached_flops_for_quantised_models\", \"batch_size___fixed_batching\", \"adaptive_batching\",\n",
    "        \"adaptive_max_tokens\", \"max_batch_size___adaptive_batching\", \"inference_type\", \"backend\", \"total_params\",\n",
    "        \"architecture\", \"total_input_tokens\", \"total_generated_tokens\", \"total_inference_time_sec\", \n",
    "        \"average_latency_ms_per_batch\", \"throughput_queries_per_sec\", \"throughput_tokens_per_sec\", \"flops\",\n",
    "        \"gpu_current_memory_allocated_bytes\", \"gpu_max_memory_allocated_bytes\", \"gpu_current_memory_reserved_bytes\",\n",
    "        \"gpu_max_memory_reserved_bytes\", \"gpu_utilization_percent\", \"cpu_usage_percent\", \"cpu_memory_usage_bytes\",\n",
    "        # Per-process metrics:\n",
    "        \"cpu_power_process_0\", \"gpu_power_process_0\", \"ram_power_process_0\",\n",
    "        \"cpu_energy_process_0\", \"gpu_energy_process_0\", \"ram_energy_process_0\",\n",
    "        \"total_energy_kwh_process_0\", \"total_energy_joules_process_0\",\n",
    "        # Global averages and totals:\n",
    "        \"cpu_power_avg\", \"gpu_power_avg\", \"ram_power_avg\", \"cpu_energy_total\", \"gpu_energy_total\", \"ram_energy_total\",\n",
    "        \"total_energy_kwh\", \"total_energy_joules\", \"tokens_per_joule\", \"joules_per_token\", \"flops_per_joule\", \"joules_per_flop\",\n",
    "        \"per-process_emissions\"\n",
    "    ]\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in col:\n",
    "            idx = col.find(token)\n",
    "            return col[idx:]\n",
    "    \n",
    "    return col\n",
    "\n",
    "def resolve_duplicates(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Resolve duplicate columns in the DataFrame.\n",
    "    \n",
    "    For any column that appears more than once:\n",
    "      - For 'adaptive_batching', if duplicates exist, prefer the one with a boolean dtype;\n",
    "        otherwise, pick the first occurrence.\n",
    "      - For all other columns (including 'experiment_id' and 'number_input_prompts'),\n",
    "        keep only the first occurrence.\n",
    "    \"\"\"\n",
    "    # Build a mapping of column name to list of indices where it occurs.\n",
    "    seen = {}\n",
    "    for idx, col in enumerate(df.columns):\n",
    "        seen.setdefault(col, []).append(idx)\n",
    "    \n",
    "    # Choose one index per duplicate group.\n",
    "    chosen_indices = []\n",
    "    for col, indices in seen.items():\n",
    "        if len(indices) == 1:\n",
    "            chosen_indices.append(indices[0])\n",
    "        else:\n",
    "            if col == \"adaptive_batching\":\n",
    "                # Look for a column with boolean type.\n",
    "                bool_idx = None\n",
    "                for i in indices:\n",
    "                    if pd.api.types.is_bool_dtype(df.iloc[:, i]):\n",
    "                        bool_idx = i\n",
    "                        break\n",
    "                chosen_indices.append(bool_idx if bool_idx is not None else indices[0])\n",
    "            else:\n",
    "                # For experiment_id, number_input_prompts, or any duplicate, keep the first occurrence.\n",
    "                chosen_indices.append(indices[0])\n",
    "    \n",
    "    # Sort indices to preserve the original order.\n",
    "    chosen_indices.sort()\n",
    "    return df.iloc[:, chosen_indices]\n",
    "\n",
    "def clean_and_reorder_columns(df: pd.DataFrame, desired_order: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean DataFrame columns by:\n",
    "      1. Renaming each column to remove extraneous prefixes and apply special mappings.\n",
    "      2. Removing duplicates (applying special resolution for some columns).\n",
    "      3. Reordering columns into the order specified by 'desired_order'. Any columns not explicitly mentioned\n",
    "         will be appended at the end.\n",
    "    \n",
    "    Parameters:\n",
    "        df (pd.DataFrame): Input DataFrame with messy, flattened column names.\n",
    "        desired_order (list): List of column names (after cleaning) indicating the preferred ordering.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with cleaned and reordered columns.\n",
    "    \"\"\"\n",
    "    # Build mapping from original column names to cleaned names.\n",
    "    mapping = {col: clean_column(col) for col in df.columns}\n",
    "    \n",
    "    # Rename columns in the DataFrame.\n",
    "    df = df.rename(columns=mapping)\n",
    "    \n",
    "    # Resolve duplicates as required.\n",
    "    df = resolve_duplicates(df)\n",
    "    \n",
    "    # Reorder columns: first, the ones matching the desired order.\n",
    "    ordered_cols = [col for col in desired_order if col in df.columns]\n",
    "    # Then, append any remaining columns.\n",
    "    remaining_cols = [col for col in df.columns if col not in desired_order]\n",
    "    final_order = ordered_cols + remaining_cols\n",
    "    \n",
    "    return df[final_order]\n",
    "\n",
    "# Example desired order list\n",
    "desired_order = [\n",
    "    \"config_name\",\n",
    "    \"experiment_id\",\n",
    "    \"date_time\",\n",
    "    \"model\",\n",
    "    # num_process\n",
    "    \"num_processes\",\n",
    "    # batching\n",
    "    \"batch_size___fixed_batching\",\n",
    "    # decodeer\n",
    "    \"decoder_temperature\",\n",
    "    \"decoder_top_k\",\n",
    "    \"decoder_top_p\",\n",
    "    # latency\n",
    "    \"latency_simulation_simulate\"\n",
    "    \"latency_simulation_delay_max\",\n",
    "    \"latency_simulation_delay_min\",\n",
    "    \"latency_simulation_simulate_burst\",\n",
    "    \"latency_simulation_burst_size\",\n",
    "    \"latency_simulation_burst_interval\",\n",
    "    # precision / quantisation\n",
    "    \"fp_precision\",\n",
    "    \"quantization\",\n",
    "    \"load_in_8bit\",\n",
    "    \"load_in_4bit\",\n",
    "    \"cached_flops_for_quantised_models\",\n",
    "    \n",
    "    # UNUSED PARAMS\n",
    "    \"sharding_strategy\",\n",
    "    \"sharding_config_fsdp_config_use_orig_params\",\n",
    "    \"sharding_config_fsdp_config_cpu_offload\",\n",
    "    \"adaptive_batching\",\n",
    "    \"adaptive_max_tokens\",\n",
    "    \"query_rate\",\n",
    "    \"total_input_tokens\",\n",
    "    \"total_generated_tokens\"\n",
    "    \n",
    "    # CONSTANT SETUP ====\n",
    "    \"date_time\",\n",
    "    \"is_encoder_decoder\",\n",
    "    \"task_type\",\n",
    "    \"available_gpu_count\",\n",
    "    \"gpu_model\",\n",
    "    \"available_cpu_count\",\n",
    "    \"cpu_model\",\n",
    "    \"os\",\n",
    "    \"python_version\",\n",
    "    \"country\",\n",
    "    \"region\",\n",
    "    \"distributed_type\",\n",
    "    \"decode_token_to_text\",\n",
    "    \"inference_type\",\n",
    "    \"backend\",\n",
    "    \"total_params\",\n",
    "    \"model_arch\",\n",
    "\n",
    "    # Validation (should be same):\n",
    "    \"max_input_tokens\",\n",
    "    \"max_output_tokens\",\n",
    "    \"number_input_prompts\",\n",
    "    \n",
    "    # RESULTS =====\n",
    "    # energy\n",
    "    \"total_energy_kwh\",\n",
    "    \"total_energy_joules\",\n",
    "    # FLOPS\n",
    "    \"flops\",\n",
    "    \"tokens_per_joule\",\n",
    "    \"joules_per_token\",\n",
    "    \"flops_per_joule\",\n",
    "    \"joules_per_flop\",\n",
    "    \"total_inference_time_sec\", \n",
    "    # inference performance\n",
    "    \"average_latency_ms_per_batch\",\n",
    "    \"throughput_queries_per_sec\",\n",
    "    \"throughput_tokens_per_sec\",\n",
    "    # CPU utilization\n",
    "    \"cpu_usage_percent\",\n",
    "    \"cpu_memory_usage_bytes\",\n",
    "    # GPU utilization\n",
    "    \"gpu_utilization_percent_0\", \"gpu_utilization_percent_1\", \"gpu_utilization_percent_2\", \"gpu_utilization_percent_3\",\n",
    "    # Compute mem\n",
    "    \"gpu_current_memory_allocated_bytes\",\n",
    "    \"gpu_max_memory_allocated_bytes\",\n",
    "    \"gpu_current_memory_reserved_bytes\",\n",
    "    \"gpu_max_memory_reserved_bytes\",\n",
    "    # Per-process metrics:\n",
    "    \"cpu_power_process_0\", \"cpu_power_process_1\", \"cpu_power_process_2\", \"cpu_power_process_3\",\n",
    "    \"gpu_power_process_0\", \"gpu_power_process_1\", \"gpu_power_process_2\", \"gpu_power_process_3\",\n",
    "    \"ram_power_process_0\", \"ram_power_process_1\", \"ram_power_process_2\", \"ram_power_process_3\",\n",
    "    \"cpu_energy_process_0\", \"cpu_energy_process_1\", \"cpu_energy_process_2\", \"cpu_energy_process_3\",\n",
    "    \"gpu_energy_process_0\", \"gpu_energy_process_1\", \"gpu_energy_process_2\", \"gpu_energy_process_3\",\n",
    "    \"ram_energy_process_0\", \"ram_energy_process_1\", \"ram_energy_process_2\", \"ram_energy_process_3\",\n",
    "    \"total_energy_kwh_process_0\", \"total_energy_kwh_process_1\", \"total_energy_kwh_process_2\", \"total_energy_kwh_process_3\",\n",
    "    \"total_energy_joules_process_0\", \"total_energy_joules_process_1\", \"total_energy_joules_process_2\", \"total_energy_joules_process_3\",\n",
    "    # Global averages and totals:\n",
    "    \"cpu_power_avg\",\n",
    "    \"gpu_power_avg\",\n",
    "    \"ram_power_avg\",\n",
    "    \"cpu_energy_total\",\n",
    "    \"gpu_energy_total\",\n",
    "    \"ram_energy_total\",\n",
    "    # per-process_emsisisons\n",
    "    \"per-process_emissions_0\", \"per-process_emissions_1\", \"per-process_emissions_2\",\"per-process_emissions_3\"\n",
    "]\n",
    "\n",
    "def inspect_results(name, desired_order):\n",
    "    input_file = f\"analysis_results/{name}_results.csv\"\n",
    "    \n",
    "    df = pd.read_csv(input_file)\n",
    "    df_cleaned = clean_and_reorder_columns(df, desired_order)\n",
    "    \n",
    "    return df_cleaned\n",
    "\n",
    "\n",
    "# ========================\n",
    "\n",
    "possible_files = [\"controlled\", \"scenarios\", \"grid\", \"text_generation\"]\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "for file in possible_files:\n",
    "    try:\n",
    "        var_name = f\"df_{file}_cleaned\"\n",
    "        globals()[var_name] = inspect_results(file, desired_order)  # dynamically create variable\n",
    "        print(f\"Found & inspecting: {var_name}\")\n",
    "        display(globals()[var_name].T)\n",
    "    except Exception as e:\n",
    "        print(f\"{file} did not exist: {e}\")\n",
    "\n",
    "# COME BACK TO THIS\n",
    "#process_possible_files(func=clean_and_reorder_columns, \n",
    "#                       desired_order=desired_order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found & inspecting dropped version: df_controlled_dropped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>config_name</th>\n",
       "      <td>num_processes_1</td>\n",
       "      <td>num_processes_2</td>\n",
       "      <td>num_processes_3</td>\n",
       "      <td>num_processes_4</td>\n",
       "      <td>batching_1</td>\n",
       "      <td>batching_2</td>\n",
       "      <td>batching_4</td>\n",
       "      <td>batching_8</td>\n",
       "      <td>batching_16</td>\n",
       "      <td>batching_32</td>\n",
       "      <td>batching_64</td>\n",
       "      <td>precis_float32_quant_False_quant8_False_quant4...</td>\n",
       "      <td>precis_float16_quant_False_quant8_False_quant4...</td>\n",
       "      <td>precis_float16_quant_True_quant8_True_quant4_F...</td>\n",
       "      <td>precis_float16_quant_True_quant8_False_quant4_...</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.2</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.4</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.6</td>\n",
       "      <td>decoding_greedy_decoder_temperature_0.8</td>\n",
       "      <td>decoding_greedy_decoder_temperature_1.0</td>\n",
       "      <td>decoding_greedy_decoder_temperature_1.2</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_20_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_50_decoder_temper...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_100_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_200_decoder_tempe...</td>\n",
       "      <td>decoding_top_k_decoder_top_k_500_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.7_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.8_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.9_decoder_tempe...</td>\n",
       "      <td>decoding_top_p_decoder_top_p_0.98_decoder_temp...</td>\n",
       "      <td>latency_False</td>\n",
       "      <td>latency_True_latency_0.05_latency_0.2_latency_...</td>\n",
       "      <td>latency_True_latency_0.2_latency_0.6_latency_F...</td>\n",
       "      <td>latency_True_latency_0.05_latency_0.2_latency_...</td>\n",
       "      <td>latency_True_latency_0.2_latency_0.6_latency_T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <td>233</td>\n",
       "      <td>234</td>\n",
       "      <td>235</td>\n",
       "      <td>236</td>\n",
       "      <td>237</td>\n",
       "      <td>238</td>\n",
       "      <td>239</td>\n",
       "      <td>240</td>\n",
       "      <td>241</td>\n",
       "      <td>242</td>\n",
       "      <td>243</td>\n",
       "      <td>244</td>\n",
       "      <td>245</td>\n",
       "      <td>246</td>\n",
       "      <td>247</td>\n",
       "      <td>248</td>\n",
       "      <td>249</td>\n",
       "      <td>250</td>\n",
       "      <td>251</td>\n",
       "      <td>252</td>\n",
       "      <td>253</td>\n",
       "      <td>254</td>\n",
       "      <td>256</td>\n",
       "      <td>257</td>\n",
       "      <td>258</td>\n",
       "      <td>259</td>\n",
       "      <td>260</td>\n",
       "      <td>261</td>\n",
       "      <td>262</td>\n",
       "      <td>263</td>\n",
       "      <td>264</td>\n",
       "      <td>265</td>\n",
       "      <td>266</td>\n",
       "      <td>267</td>\n",
       "      <td>268</td>\n",
       "      <td>269</td>\n",
       "      <td>270</td>\n",
       "      <td>271</td>\n",
       "      <td>272</td>\n",
       "      <td>273</td>\n",
       "      <td>274</td>\n",
       "      <td>275</td>\n",
       "      <td>276</td>\n",
       "      <td>277</td>\n",
       "      <td>278</td>\n",
       "      <td>279</td>\n",
       "      <td>280</td>\n",
       "      <td>281</td>\n",
       "      <td>282</td>\n",
       "      <td>283</td>\n",
       "      <td>284</td>\n",
       "      <td>285</td>\n",
       "      <td>286</td>\n",
       "      <td>287</td>\n",
       "      <td>288</td>\n",
       "      <td>289</td>\n",
       "      <td>290</td>\n",
       "      <td>296</td>\n",
       "      <td>297</td>\n",
       "      <td>298</td>\n",
       "      <td>299</td>\n",
       "      <td>300</td>\n",
       "      <td>301</td>\n",
       "      <td>302</td>\n",
       "      <td>303</td>\n",
       "      <td>304</td>\n",
       "      <td>305</td>\n",
       "      <td>306</td>\n",
       "      <td>307</td>\n",
       "      <td>308</td>\n",
       "      <td>309</td>\n",
       "      <td>310</td>\n",
       "      <td>311</td>\n",
       "      <td>312</td>\n",
       "      <td>313</td>\n",
       "      <td>314</td>\n",
       "      <td>315</td>\n",
       "      <td>316</td>\n",
       "      <td>317</td>\n",
       "      <td>318</td>\n",
       "      <td>319</td>\n",
       "      <td>320</td>\n",
       "      <td>321</td>\n",
       "      <td>322</td>\n",
       "      <td>323</td>\n",
       "      <td>328</td>\n",
       "      <td>329</td>\n",
       "      <td>330</td>\n",
       "      <td>331</td>\n",
       "      <td>332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <td>April 11, 2025 at 05:02:12 PM</td>\n",
       "      <td>April 11, 2025 at 05:03:25 PM</td>\n",
       "      <td>April 11, 2025 at 05:04:40 PM</td>\n",
       "      <td>April 11, 2025 at 05:05:55 PM</td>\n",
       "      <td>April 11, 2025 at 05:13:02 PM</td>\n",
       "      <td>April 11, 2025 at 05:18:36 PM</td>\n",
       "      <td>April 11, 2025 at 05:21:39 PM</td>\n",
       "      <td>April 11, 2025 at 05:23:23 PM</td>\n",
       "      <td>April 11, 2025 at 05:24:30 PM</td>\n",
       "      <td>April 11, 2025 at 05:25:17 PM</td>\n",
       "      <td>April 11, 2025 at 05:25:56 PM</td>\n",
       "      <td>April 11, 2025 at 05:26:49 PM</td>\n",
       "      <td>April 11, 2025 at 05:27:40 PM</td>\n",
       "      <td>April 11, 2025 at 05:29:22 PM</td>\n",
       "      <td>April 11, 2025 at 05:30:29 PM</td>\n",
       "      <td>April 11, 2025 at 05:31:35 PM</td>\n",
       "      <td>April 11, 2025 at 05:32:41 PM</td>\n",
       "      <td>April 11, 2025 at 05:33:46 PM</td>\n",
       "      <td>April 11, 2025 at 05:34:52 PM</td>\n",
       "      <td>April 11, 2025 at 05:35:58 PM</td>\n",
       "      <td>April 11, 2025 at 05:37:04 PM</td>\n",
       "      <td>April 11, 2025 at 05:38:09 PM</td>\n",
       "      <td>April 11, 2025 at 05:39:42 PM</td>\n",
       "      <td>April 11, 2025 at 05:40:48 PM</td>\n",
       "      <td>April 11, 2025 at 05:41:54 PM</td>\n",
       "      <td>April 11, 2025 at 05:43:00 PM</td>\n",
       "      <td>April 11, 2025 at 05:44:05 PM</td>\n",
       "      <td>April 11, 2025 at 05:45:11 PM</td>\n",
       "      <td>April 11, 2025 at 05:46:17 PM</td>\n",
       "      <td>April 11, 2025 at 05:47:23 PM</td>\n",
       "      <td>April 11, 2025 at 05:48:29 PM</td>\n",
       "      <td>April 11, 2025 at 05:49:38 PM</td>\n",
       "      <td>April 11, 2025 at 05:50:44 PM</td>\n",
       "      <td>April 11, 2025 at 05:51:50 PM</td>\n",
       "      <td>April 11, 2025 at 05:52:55 PM</td>\n",
       "      <td>April 11, 2025 at 05:54:01 PM</td>\n",
       "      <td>April 11, 2025 at 05:55:07 PM</td>\n",
       "      <td>April 11, 2025 at 05:56:12 PM</td>\n",
       "      <td>April 11, 2025 at 05:57:18 PM</td>\n",
       "      <td>April 11, 2025 at 05:58:24 PM</td>\n",
       "      <td>April 11, 2025 at 05:59:29 PM</td>\n",
       "      <td>April 11, 2025 at 06:00:36 PM</td>\n",
       "      <td>April 11, 2025 at 06:01:44 PM</td>\n",
       "      <td>April 11, 2025 at 06:02:51 PM</td>\n",
       "      <td>April 11, 2025 at 06:03:57 PM</td>\n",
       "      <td>April 11, 2025 at 06:05:03 PM</td>\n",
       "      <td>April 11, 2025 at 06:06:10 PM</td>\n",
       "      <td>April 11, 2025 at 06:07:16 PM</td>\n",
       "      <td>April 11, 2025 at 06:08:21 PM</td>\n",
       "      <td>April 11, 2025 at 06:09:27 PM</td>\n",
       "      <td>April 11, 2025 at 06:10:32 PM</td>\n",
       "      <td>April 11, 2025 at 06:11:38 PM</td>\n",
       "      <td>April 11, 2025 at 06:12:45 PM</td>\n",
       "      <td>April 11, 2025 at 06:13:51 PM</td>\n",
       "      <td>April 11, 2025 at 06:14:58 PM</td>\n",
       "      <td>April 11, 2025 at 06:16:04 PM</td>\n",
       "      <td>April 11, 2025 at 06:17:15 PM</td>\n",
       "      <td>April 11, 2025 at 06:20:42 PM</td>\n",
       "      <td>April 11, 2025 at 06:21:47 PM</td>\n",
       "      <td>April 11, 2025 at 06:22:52 PM</td>\n",
       "      <td>April 11, 2025 at 06:23:58 PM</td>\n",
       "      <td>April 11, 2025 at 06:25:04 PM</td>\n",
       "      <td>April 11, 2025 at 06:26:10 PM</td>\n",
       "      <td>April 11, 2025 at 06:27:16 PM</td>\n",
       "      <td>April 11, 2025 at 06:28:21 PM</td>\n",
       "      <td>April 11, 2025 at 06:29:27 PM</td>\n",
       "      <td>April 11, 2025 at 06:30:33 PM</td>\n",
       "      <td>April 11, 2025 at 06:31:40 PM</td>\n",
       "      <td>April 11, 2025 at 06:32:49 PM</td>\n",
       "      <td>April 11, 2025 at 06:33:55 PM</td>\n",
       "      <td>April 11, 2025 at 06:35:01 PM</td>\n",
       "      <td>April 11, 2025 at 06:36:06 PM</td>\n",
       "      <td>April 11, 2025 at 06:37:12 PM</td>\n",
       "      <td>April 11, 2025 at 06:38:18 PM</td>\n",
       "      <td>April 11, 2025 at 06:39:24 PM</td>\n",
       "      <td>April 11, 2025 at 06:40:30 PM</td>\n",
       "      <td>April 11, 2025 at 06:41:37 PM</td>\n",
       "      <td>April 11, 2025 at 06:42:44 PM</td>\n",
       "      <td>April 11, 2025 at 06:43:50 PM</td>\n",
       "      <td>April 11, 2025 at 06:44:56 PM</td>\n",
       "      <td>April 11, 2025 at 06:46:02 PM</td>\n",
       "      <td>April 11, 2025 at 06:47:09 PM</td>\n",
       "      <td>April 11, 2025 at 06:48:16 PM</td>\n",
       "      <td>April 11, 2025 at 06:49:22 PM</td>\n",
       "      <td>April 11, 2025 at 06:50:29 PM</td>\n",
       "      <td>April 11, 2025 at 06:53:27 PM</td>\n",
       "      <td>April 11, 2025 at 06:54:34 PM</td>\n",
       "      <td>April 11, 2025 at 06:55:45 PM</td>\n",
       "      <td>April 11, 2025 at 06:56:55 PM</td>\n",
       "      <td>April 11, 2025 at 06:58:10 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_processes</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size___fixed_batching</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>32</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_temperature</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_k</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>20</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_p</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate_burst</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_size</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_interval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp_precision</th>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantization</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_8bit</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_4bit</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_input_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_params</th>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_input_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_output_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_input_prompts</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh</th>\n",
       "      <td>0.003973</td>\n",
       "      <td>0.009084</td>\n",
       "      <td>0.014652</td>\n",
       "      <td>0.022451</td>\n",
       "      <td>0.173708</td>\n",
       "      <td>0.121135</td>\n",
       "      <td>0.064102</td>\n",
       "      <td>0.035372</td>\n",
       "      <td>0.021079</td>\n",
       "      <td>0.012114</td>\n",
       "      <td>0.007437</td>\n",
       "      <td>0.021202</td>\n",
       "      <td>0.012864</td>\n",
       "      <td>0.025157</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.020611</td>\n",
       "      <td>0.021126</td>\n",
       "      <td>0.021079</td>\n",
       "      <td>0.021087</td>\n",
       "      <td>0.021035</td>\n",
       "      <td>0.021028</td>\n",
       "      <td>0.021053</td>\n",
       "      <td>0.020493</td>\n",
       "      <td>0.020526</td>\n",
       "      <td>0.020592</td>\n",
       "      <td>0.020612</td>\n",
       "      <td>0.020695</td>\n",
       "      <td>0.021096</td>\n",
       "      <td>0.021167</td>\n",
       "      <td>0.021317</td>\n",
       "      <td>0.021256</td>\n",
       "      <td>0.021237</td>\n",
       "      <td>0.021173</td>\n",
       "      <td>0.021219</td>\n",
       "      <td>0.021218</td>\n",
       "      <td>0.021238</td>\n",
       "      <td>0.021238</td>\n",
       "      <td>0.021201</td>\n",
       "      <td>0.021264</td>\n",
       "      <td>0.021225</td>\n",
       "      <td>0.021234</td>\n",
       "      <td>0.021319</td>\n",
       "      <td>0.021258</td>\n",
       "      <td>0.021287</td>\n",
       "      <td>0.021207</td>\n",
       "      <td>0.021255</td>\n",
       "      <td>0.021197</td>\n",
       "      <td>0.021211</td>\n",
       "      <td>0.021179</td>\n",
       "      <td>0.02115</td>\n",
       "      <td>0.021163</td>\n",
       "      <td>0.021133</td>\n",
       "      <td>0.021166</td>\n",
       "      <td>0.021162</td>\n",
       "      <td>0.021253</td>\n",
       "      <td>0.021272</td>\n",
       "      <td>0.021315</td>\n",
       "      <td>0.020483</td>\n",
       "      <td>0.020574</td>\n",
       "      <td>0.020635</td>\n",
       "      <td>0.02061</td>\n",
       "      <td>0.021128</td>\n",
       "      <td>0.021085</td>\n",
       "      <td>0.021104</td>\n",
       "      <td>0.021038</td>\n",
       "      <td>0.021123</td>\n",
       "      <td>0.021142</td>\n",
       "      <td>0.021125</td>\n",
       "      <td>0.021159</td>\n",
       "      <td>0.021188</td>\n",
       "      <td>0.021216</td>\n",
       "      <td>0.021275</td>\n",
       "      <td>0.021175</td>\n",
       "      <td>0.021218</td>\n",
       "      <td>0.021133</td>\n",
       "      <td>0.021153</td>\n",
       "      <td>0.021139</td>\n",
       "      <td>0.021052</td>\n",
       "      <td>0.021089</td>\n",
       "      <td>0.021076</td>\n",
       "      <td>0.021173</td>\n",
       "      <td>0.021169</td>\n",
       "      <td>0.021177</td>\n",
       "      <td>0.021209</td>\n",
       "      <td>0.021157</td>\n",
       "      <td>0.020897</td>\n",
       "      <td>0.021343</td>\n",
       "      <td>0.022104</td>\n",
       "      <td>0.022489</td>\n",
       "      <td>0.023464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules</th>\n",
       "      <td>14303.761229</td>\n",
       "      <td>32700.724679</td>\n",
       "      <td>52747.350103</td>\n",
       "      <td>80824.506502</td>\n",
       "      <td>625349.848478</td>\n",
       "      <td>436084.529304</td>\n",
       "      <td>230767.542556</td>\n",
       "      <td>127338.055234</td>\n",
       "      <td>75884.699531</td>\n",
       "      <td>43611.764042</td>\n",
       "      <td>26773.911916</td>\n",
       "      <td>76325.798731</td>\n",
       "      <td>46310.921387</td>\n",
       "      <td>90564.656156</td>\n",
       "      <td>75601.377686</td>\n",
       "      <td>74199.651611</td>\n",
       "      <td>76054.746039</td>\n",
       "      <td>75884.577747</td>\n",
       "      <td>75912.204543</td>\n",
       "      <td>75727.619266</td>\n",
       "      <td>75701.472545</td>\n",
       "      <td>75790.175016</td>\n",
       "      <td>73773.389464</td>\n",
       "      <td>73892.703968</td>\n",
       "      <td>74129.708593</td>\n",
       "      <td>74203.606308</td>\n",
       "      <td>74501.001648</td>\n",
       "      <td>75946.539604</td>\n",
       "      <td>76201.793024</td>\n",
       "      <td>76742.959091</td>\n",
       "      <td>76520.796084</td>\n",
       "      <td>76452.8938</td>\n",
       "      <td>76223.569931</td>\n",
       "      <td>76386.637887</td>\n",
       "      <td>76383.180866</td>\n",
       "      <td>76458.267707</td>\n",
       "      <td>76456.077645</td>\n",
       "      <td>76322.508765</td>\n",
       "      <td>76552.127557</td>\n",
       "      <td>76410.590357</td>\n",
       "      <td>76443.543844</td>\n",
       "      <td>76748.976626</td>\n",
       "      <td>76530.379229</td>\n",
       "      <td>76631.935788</td>\n",
       "      <td>76346.735078</td>\n",
       "      <td>76517.116778</td>\n",
       "      <td>76308.943626</td>\n",
       "      <td>76361.089511</td>\n",
       "      <td>76245.168806</td>\n",
       "      <td>76141.04486</td>\n",
       "      <td>76187.233345</td>\n",
       "      <td>76079.755405</td>\n",
       "      <td>76195.841449</td>\n",
       "      <td>76181.591128</td>\n",
       "      <td>76512.58586</td>\n",
       "      <td>76578.514995</td>\n",
       "      <td>76733.750114</td>\n",
       "      <td>73737.29051</td>\n",
       "      <td>74065.599056</td>\n",
       "      <td>74286.409458</td>\n",
       "      <td>74197.531957</td>\n",
       "      <td>76059.345286</td>\n",
       "      <td>75905.904876</td>\n",
       "      <td>75972.984254</td>\n",
       "      <td>75736.281912</td>\n",
       "      <td>76043.391166</td>\n",
       "      <td>76110.532775</td>\n",
       "      <td>76051.292784</td>\n",
       "      <td>76172.032345</td>\n",
       "      <td>76276.785887</td>\n",
       "      <td>76377.761846</td>\n",
       "      <td>76590.669268</td>\n",
       "      <td>76229.985716</td>\n",
       "      <td>76384.326872</td>\n",
       "      <td>76078.501706</td>\n",
       "      <td>76152.181146</td>\n",
       "      <td>76101.321315</td>\n",
       "      <td>75787.25771</td>\n",
       "      <td>75921.972142</td>\n",
       "      <td>75872.506432</td>\n",
       "      <td>76223.661305</td>\n",
       "      <td>76208.729832</td>\n",
       "      <td>76236.684702</td>\n",
       "      <td>76352.285347</td>\n",
       "      <td>76166.395123</td>\n",
       "      <td>75230.05363</td>\n",
       "      <td>76834.458713</td>\n",
       "      <td>79575.575957</td>\n",
       "      <td>80959.555151</td>\n",
       "      <td>84471.974521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops</th>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens_per_joule</th>\n",
       "      <td>1.145433</td>\n",
       "      <td>0.501029</td>\n",
       "      <td>0.310613</td>\n",
       "      <td>0.202711</td>\n",
       "      <td>0.023441</td>\n",
       "      <td>0.037341</td>\n",
       "      <td>0.070998</td>\n",
       "      <td>0.128665</td>\n",
       "      <td>0.215907</td>\n",
       "      <td>0.375678</td>\n",
       "      <td>0.611939</td>\n",
       "      <td>0.214659</td>\n",
       "      <td>0.353783</td>\n",
       "      <td>0.180909</td>\n",
       "      <td>0.216716</td>\n",
       "      <td>0.22081</td>\n",
       "      <td>0.215424</td>\n",
       "      <td>0.215907</td>\n",
       "      <td>0.215828</td>\n",
       "      <td>0.216354</td>\n",
       "      <td>0.216429</td>\n",
       "      <td>0.216176</td>\n",
       "      <td>0.222085</td>\n",
       "      <td>0.221727</td>\n",
       "      <td>0.221018</td>\n",
       "      <td>0.220798</td>\n",
       "      <td>0.219917</td>\n",
       "      <td>0.215731</td>\n",
       "      <td>0.215008</td>\n",
       "      <td>0.213492</td>\n",
       "      <td>0.214112</td>\n",
       "      <td>0.214302</td>\n",
       "      <td>0.214947</td>\n",
       "      <td>0.214488</td>\n",
       "      <td>0.214497</td>\n",
       "      <td>0.214287</td>\n",
       "      <td>0.214293</td>\n",
       "      <td>0.214668</td>\n",
       "      <td>0.214024</td>\n",
       "      <td>0.214421</td>\n",
       "      <td>0.214328</td>\n",
       "      <td>0.213475</td>\n",
       "      <td>0.214085</td>\n",
       "      <td>0.213801</td>\n",
       "      <td>0.2146</td>\n",
       "      <td>0.214122</td>\n",
       "      <td>0.214706</td>\n",
       "      <td>0.21456</td>\n",
       "      <td>0.214886</td>\n",
       "      <td>0.21518</td>\n",
       "      <td>0.215049</td>\n",
       "      <td>0.215353</td>\n",
       "      <td>0.215025</td>\n",
       "      <td>0.215065</td>\n",
       "      <td>0.214135</td>\n",
       "      <td>0.21395</td>\n",
       "      <td>0.213518</td>\n",
       "      <td>0.222194</td>\n",
       "      <td>0.221209</td>\n",
       "      <td>0.220552</td>\n",
       "      <td>0.220816</td>\n",
       "      <td>0.215411</td>\n",
       "      <td>0.215846</td>\n",
       "      <td>0.215656</td>\n",
       "      <td>0.21633</td>\n",
       "      <td>0.215456</td>\n",
       "      <td>0.215266</td>\n",
       "      <td>0.215434</td>\n",
       "      <td>0.215092</td>\n",
       "      <td>0.214797</td>\n",
       "      <td>0.214513</td>\n",
       "      <td>0.213916</td>\n",
       "      <td>0.214929</td>\n",
       "      <td>0.214494</td>\n",
       "      <td>0.215357</td>\n",
       "      <td>0.215148</td>\n",
       "      <td>0.215292</td>\n",
       "      <td>0.216184</td>\n",
       "      <td>0.215801</td>\n",
       "      <td>0.215941</td>\n",
       "      <td>0.214946</td>\n",
       "      <td>0.214988</td>\n",
       "      <td>0.21491</td>\n",
       "      <td>0.214584</td>\n",
       "      <td>0.215108</td>\n",
       "      <td>0.217785</td>\n",
       "      <td>0.213238</td>\n",
       "      <td>0.205892</td>\n",
       "      <td>0.202373</td>\n",
       "      <td>0.193958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_token</th>\n",
       "      <td>0.873032</td>\n",
       "      <td>1.995894</td>\n",
       "      <td>3.219443</td>\n",
       "      <td>4.933136</td>\n",
       "      <td>42.659789</td>\n",
       "      <td>26.779939</td>\n",
       "      <td>14.084933</td>\n",
       "      <td>7.772098</td>\n",
       "      <td>4.631634</td>\n",
       "      <td>2.661851</td>\n",
       "      <td>1.63415</td>\n",
       "      <td>4.658557</td>\n",
       "      <td>2.826594</td>\n",
       "      <td>5.527628</td>\n",
       "      <td>4.614342</td>\n",
       "      <td>4.528787</td>\n",
       "      <td>4.642013</td>\n",
       "      <td>4.631627</td>\n",
       "      <td>4.633313</td>\n",
       "      <td>4.622047</td>\n",
       "      <td>4.620451</td>\n",
       "      <td>4.625865</td>\n",
       "      <td>4.50277</td>\n",
       "      <td>4.510053</td>\n",
       "      <td>4.524518</td>\n",
       "      <td>4.529029</td>\n",
       "      <td>4.54718</td>\n",
       "      <td>4.635409</td>\n",
       "      <td>4.650988</td>\n",
       "      <td>4.684018</td>\n",
       "      <td>4.670459</td>\n",
       "      <td>4.666314</td>\n",
       "      <td>4.652318</td>\n",
       "      <td>4.66227</td>\n",
       "      <td>4.662059</td>\n",
       "      <td>4.666642</td>\n",
       "      <td>4.666509</td>\n",
       "      <td>4.658356</td>\n",
       "      <td>4.672371</td>\n",
       "      <td>4.663732</td>\n",
       "      <td>4.665744</td>\n",
       "      <td>4.684386</td>\n",
       "      <td>4.671044</td>\n",
       "      <td>4.677242</td>\n",
       "      <td>4.659835</td>\n",
       "      <td>4.670234</td>\n",
       "      <td>4.657528</td>\n",
       "      <td>4.660711</td>\n",
       "      <td>4.653636</td>\n",
       "      <td>4.647281</td>\n",
       "      <td>4.6501</td>\n",
       "      <td>4.64354</td>\n",
       "      <td>4.650625</td>\n",
       "      <td>4.649755</td>\n",
       "      <td>4.669958</td>\n",
       "      <td>4.673982</td>\n",
       "      <td>4.683456</td>\n",
       "      <td>4.500567</td>\n",
       "      <td>4.520605</td>\n",
       "      <td>4.534083</td>\n",
       "      <td>4.528658</td>\n",
       "      <td>4.642294</td>\n",
       "      <td>4.632929</td>\n",
       "      <td>4.637023</td>\n",
       "      <td>4.622576</td>\n",
       "      <td>4.64132</td>\n",
       "      <td>4.645418</td>\n",
       "      <td>4.641803</td>\n",
       "      <td>4.649172</td>\n",
       "      <td>4.655566</td>\n",
       "      <td>4.661729</td>\n",
       "      <td>4.674723</td>\n",
       "      <td>4.652709</td>\n",
       "      <td>4.662129</td>\n",
       "      <td>4.643463</td>\n",
       "      <td>4.64796</td>\n",
       "      <td>4.644856</td>\n",
       "      <td>4.625687</td>\n",
       "      <td>4.633909</td>\n",
       "      <td>4.63089</td>\n",
       "      <td>4.652323</td>\n",
       "      <td>4.651412</td>\n",
       "      <td>4.653118</td>\n",
       "      <td>4.660174</td>\n",
       "      <td>4.648828</td>\n",
       "      <td>4.591678</td>\n",
       "      <td>4.689603</td>\n",
       "      <td>4.856908</td>\n",
       "      <td>4.941379</td>\n",
       "      <td>5.15576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops_per_joule</th>\n",
       "      <td>1185000974.364989</td>\n",
       "      <td>518336249.72279</td>\n",
       "      <td>321342606.972544</td>\n",
       "      <td>209713263.05247</td>\n",
       "      <td>27104781.482585</td>\n",
       "      <td>38868544.637947</td>\n",
       "      <td>73450411.636865</td>\n",
       "      <td>133110019.326187</td>\n",
       "      <td>223364803.416953</td>\n",
       "      <td>388655936.426967</td>\n",
       "      <td>633077864.986458</td>\n",
       "      <td>222073941.90463</td>\n",
       "      <td>366003752.151563</td>\n",
       "      <td>187158784.81295</td>\n",
       "      <td>224201879.805033</td>\n",
       "      <td>228437339.327415</td>\n",
       "      <td>222865394.679583</td>\n",
       "      <td>223365161.886555</td>\n",
       "      <td>223283872.404349</td>\n",
       "      <td>223828124.501124</td>\n",
       "      <td>223905433.056266</td>\n",
       "      <td>223643381.078152</td>\n",
       "      <td>229757248.73563</td>\n",
       "      <td>229386259.846373</td>\n",
       "      <td>228652875.007557</td>\n",
       "      <td>228425164.711328</td>\n",
       "      <td>227513330.26575</td>\n",
       "      <td>223182926.853609</td>\n",
       "      <td>222435330.199059</td>\n",
       "      <td>220866789.524664</td>\n",
       "      <td>221508032.594712</td>\n",
       "      <td>221704766.827728</td>\n",
       "      <td>222371780.91456</td>\n",
       "      <td>221897068.152067</td>\n",
       "      <td>221907110.976747</td>\n",
       "      <td>221689184.198326</td>\n",
       "      <td>221695534.41967</td>\n",
       "      <td>222083514.646961</td>\n",
       "      <td>221417373.154566</td>\n",
       "      <td>221827509.955699</td>\n",
       "      <td>221731883.961792</td>\n",
       "      <td>220849472.375148</td>\n",
       "      <td>221480295.326627</td>\n",
       "      <td>221186778.315872</td>\n",
       "      <td>222013043.200503</td>\n",
       "      <td>221518683.752156</td>\n",
       "      <td>222122993.553691</td>\n",
       "      <td>221971308.970354</td>\n",
       "      <td>222308787.015928</td>\n",
       "      <td>222612797.398213</td>\n",
       "      <td>222477838.462899</td>\n",
       "      <td>222792133.111257</td>\n",
       "      <td>222452704.383082</td>\n",
       "      <td>222494315.782651</td>\n",
       "      <td>221531801.63285</td>\n",
       "      <td>221341077.118197</td>\n",
       "      <td>220893296.207842</td>\n",
       "      <td>229869729.08804</td>\n",
       "      <td>228850791.85564</td>\n",
       "      <td>228170551.204544</td>\n",
       "      <td>228443865.261377</td>\n",
       "      <td>222851918.188743</td>\n",
       "      <td>223302403.426195</td>\n",
       "      <td>223105241.417056</td>\n",
       "      <td>223802523.245601</td>\n",
       "      <td>222898673.155884</td>\n",
       "      <td>222702041.034166</td>\n",
       "      <td>222875514.308708</td>\n",
       "      <td>222522236.459516</td>\n",
       "      <td>222216638.996013</td>\n",
       "      <td>221922855.337331</td>\n",
       "      <td>221305952.215789</td>\n",
       "      <td>222353065.317298</td>\n",
       "      <td>221903781.669947</td>\n",
       "      <td>222795804.50584</td>\n",
       "      <td>222580243.115083</td>\n",
       "      <td>222728997.344947</td>\n",
       "      <td>223651989.862195</td>\n",
       "      <td>223255146.236354</td>\n",
       "      <td>223400699.280619</td>\n",
       "      <td>222371514.343019</td>\n",
       "      <td>222415083.292085</td>\n",
       "      <td>222333526.955779</td>\n",
       "      <td>221996904.429798</td>\n",
       "      <td>222538705.760019</td>\n",
       "      <td>225308506.046856</td>\n",
       "      <td>220603766.552551</td>\n",
       "      <td>213004691.317366</td>\n",
       "      <td>209363440.318309</td>\n",
       "      <td>200657923.402639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_flop</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_inference_time_sec</th>\n",
       "      <td>37.07336</td>\n",
       "      <td>37.114287</td>\n",
       "      <td>37.785984</td>\n",
       "      <td>37.507834</td>\n",
       "      <td>384.649219</td>\n",
       "      <td>292.383712</td>\n",
       "      <td>147.516985</td>\n",
       "      <td>74.266558</td>\n",
       "      <td>37.168908</td>\n",
       "      <td>18.70642</td>\n",
       "      <td>9.628563</td>\n",
       "      <td>22.945557</td>\n",
       "      <td>23.267255</td>\n",
       "      <td>72.234728</td>\n",
       "      <td>37.354927</td>\n",
       "      <td>36.263684</td>\n",
       "      <td>37.233629</td>\n",
       "      <td>36.712846</td>\n",
       "      <td>37.177409</td>\n",
       "      <td>37.286998</td>\n",
       "      <td>36.730154</td>\n",
       "      <td>36.862467</td>\n",
       "      <td>36.388011</td>\n",
       "      <td>36.456038</td>\n",
       "      <td>36.447105</td>\n",
       "      <td>36.306288</td>\n",
       "      <td>36.211281</td>\n",
       "      <td>37.147624</td>\n",
       "      <td>37.538299</td>\n",
       "      <td>37.345801</td>\n",
       "      <td>37.266966</td>\n",
       "      <td>37.24014</td>\n",
       "      <td>37.286302</td>\n",
       "      <td>37.472509</td>\n",
       "      <td>37.066333</td>\n",
       "      <td>37.176715</td>\n",
       "      <td>37.421394</td>\n",
       "      <td>36.979404</td>\n",
       "      <td>37.373825</td>\n",
       "      <td>37.459553</td>\n",
       "      <td>36.784267</td>\n",
       "      <td>37.335853</td>\n",
       "      <td>36.763149</td>\n",
       "      <td>37.198482</td>\n",
       "      <td>36.812719</td>\n",
       "      <td>37.283309</td>\n",
       "      <td>37.419533</td>\n",
       "      <td>37.420523</td>\n",
       "      <td>37.239923</td>\n",
       "      <td>37.278837</td>\n",
       "      <td>37.05608</td>\n",
       "      <td>36.896263</td>\n",
       "      <td>37.303935</td>\n",
       "      <td>37.005236</td>\n",
       "      <td>37.377651</td>\n",
       "      <td>37.014072</td>\n",
       "      <td>37.463349</td>\n",
       "      <td>36.610644</td>\n",
       "      <td>36.43053</td>\n",
       "      <td>36.471863</td>\n",
       "      <td>36.407234</td>\n",
       "      <td>37.230651</td>\n",
       "      <td>37.061346</td>\n",
       "      <td>36.947661</td>\n",
       "      <td>36.866788</td>\n",
       "      <td>36.912187</td>\n",
       "      <td>37.250632</td>\n",
       "      <td>36.874463</td>\n",
       "      <td>37.227124</td>\n",
       "      <td>36.74442</td>\n",
       "      <td>37.353906</td>\n",
       "      <td>36.856164</td>\n",
       "      <td>36.478415</td>\n",
       "      <td>36.804445</td>\n",
       "      <td>36.749301</td>\n",
       "      <td>37.267507</td>\n",
       "      <td>37.349722</td>\n",
       "      <td>36.404344</td>\n",
       "      <td>36.764964</td>\n",
       "      <td>36.751617</td>\n",
       "      <td>36.289531</td>\n",
       "      <td>36.688996</td>\n",
       "      <td>36.790459</td>\n",
       "      <td>36.692678</td>\n",
       "      <td>36.887141</td>\n",
       "      <td>36.504055</td>\n",
       "      <td>37.91957</td>\n",
       "      <td>40.774318</td>\n",
       "      <td>41.930226</td>\n",
       "      <td>45.240207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_latency_ms_per_batch</th>\n",
       "      <td>4634.170037</td>\n",
       "      <td>4639.28586</td>\n",
       "      <td>4723.248003</td>\n",
       "      <td>4688.479238</td>\n",
       "      <td>3005.072024</td>\n",
       "      <td>4568.495493</td>\n",
       "      <td>4609.905773</td>\n",
       "      <td>4641.65987</td>\n",
       "      <td>4646.113508</td>\n",
       "      <td>4676.605061</td>\n",
       "      <td>4814.281646</td>\n",
       "      <td>2868.194596</td>\n",
       "      <td>2908.406936</td>\n",
       "      <td>9029.341061</td>\n",
       "      <td>4669.365846</td>\n",
       "      <td>4532.960497</td>\n",
       "      <td>4654.203603</td>\n",
       "      <td>4589.105755</td>\n",
       "      <td>4647.176079</td>\n",
       "      <td>4660.874719</td>\n",
       "      <td>4591.269241</td>\n",
       "      <td>4607.80839</td>\n",
       "      <td>4548.501365</td>\n",
       "      <td>4557.004705</td>\n",
       "      <td>4555.888145</td>\n",
       "      <td>4538.285978</td>\n",
       "      <td>4526.410158</td>\n",
       "      <td>4643.452946</td>\n",
       "      <td>4692.287417</td>\n",
       "      <td>4668.225076</td>\n",
       "      <td>4658.370769</td>\n",
       "      <td>4655.01752</td>\n",
       "      <td>4660.787711</td>\n",
       "      <td>4684.063664</td>\n",
       "      <td>4633.29158</td>\n",
       "      <td>4647.089355</td>\n",
       "      <td>4677.674297</td>\n",
       "      <td>4622.425475</td>\n",
       "      <td>4671.72815</td>\n",
       "      <td>4682.444169</td>\n",
       "      <td>4598.03337</td>\n",
       "      <td>4666.981563</td>\n",
       "      <td>4595.393663</td>\n",
       "      <td>4649.810295</td>\n",
       "      <td>4601.58986</td>\n",
       "      <td>4660.413619</td>\n",
       "      <td>4677.441662</td>\n",
       "      <td>4677.565389</td>\n",
       "      <td>4654.990417</td>\n",
       "      <td>4659.854676</td>\n",
       "      <td>4632.01002</td>\n",
       "      <td>4612.032873</td>\n",
       "      <td>4662.991815</td>\n",
       "      <td>4625.654561</td>\n",
       "      <td>4672.206413</td>\n",
       "      <td>4626.75899</td>\n",
       "      <td>4682.918639</td>\n",
       "      <td>4576.330444</td>\n",
       "      <td>4553.816217</td>\n",
       "      <td>4558.982923</td>\n",
       "      <td>4550.904239</td>\n",
       "      <td>4653.831399</td>\n",
       "      <td>4632.668298</td>\n",
       "      <td>4618.457622</td>\n",
       "      <td>4608.348549</td>\n",
       "      <td>4614.023335</td>\n",
       "      <td>4656.328988</td>\n",
       "      <td>4609.307881</td>\n",
       "      <td>4653.39056</td>\n",
       "      <td>4593.052498</td>\n",
       "      <td>4669.238309</td>\n",
       "      <td>4607.020464</td>\n",
       "      <td>4559.80192</td>\n",
       "      <td>4600.555674</td>\n",
       "      <td>4593.6626</td>\n",
       "      <td>4658.438392</td>\n",
       "      <td>4668.715262</td>\n",
       "      <td>4550.543062</td>\n",
       "      <td>4595.620491</td>\n",
       "      <td>4593.952187</td>\n",
       "      <td>4536.191409</td>\n",
       "      <td>4586.124506</td>\n",
       "      <td>4598.807349</td>\n",
       "      <td>4586.584774</td>\n",
       "      <td>4610.892601</td>\n",
       "      <td>4563.006856</td>\n",
       "      <td>4739.946273</td>\n",
       "      <td>5096.789718</td>\n",
       "      <td>5241.278282</td>\n",
       "      <td>5655.025877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_queries_per_sec</th>\n",
       "      <td>3.452614</td>\n",
       "      <td>3.448807</td>\n",
       "      <td>3.387499</td>\n",
       "      <td>3.41262</td>\n",
       "      <td>0.332771</td>\n",
       "      <td>0.437781</td>\n",
       "      <td>0.867697</td>\n",
       "      <td>1.723521</td>\n",
       "      <td>3.443739</td>\n",
       "      <td>6.842571</td>\n",
       "      <td>13.29378</td>\n",
       "      <td>5.578422</td>\n",
       "      <td>5.501293</td>\n",
       "      <td>1.772001</td>\n",
       "      <td>3.42659</td>\n",
       "      <td>3.529702</td>\n",
       "      <td>3.437752</td>\n",
       "      <td>3.486518</td>\n",
       "      <td>3.442951</td>\n",
       "      <td>3.432832</td>\n",
       "      <td>3.484875</td>\n",
       "      <td>3.472367</td>\n",
       "      <td>3.517642</td>\n",
       "      <td>3.511078</td>\n",
       "      <td>3.511939</td>\n",
       "      <td>3.52556</td>\n",
       "      <td>3.53481</td>\n",
       "      <td>3.445712</td>\n",
       "      <td>3.409851</td>\n",
       "      <td>3.427427</td>\n",
       "      <td>3.434677</td>\n",
       "      <td>3.437151</td>\n",
       "      <td>3.432896</td>\n",
       "      <td>3.415837</td>\n",
       "      <td>3.453269</td>\n",
       "      <td>3.443015</td>\n",
       "      <td>3.420503</td>\n",
       "      <td>3.461386</td>\n",
       "      <td>3.424857</td>\n",
       "      <td>3.417019</td>\n",
       "      <td>3.479749</td>\n",
       "      <td>3.42834</td>\n",
       "      <td>3.481747</td>\n",
       "      <td>3.441001</td>\n",
       "      <td>3.477059</td>\n",
       "      <td>3.433172</td>\n",
       "      <td>3.420673</td>\n",
       "      <td>3.420583</td>\n",
       "      <td>3.437171</td>\n",
       "      <td>3.433583</td>\n",
       "      <td>3.454224</td>\n",
       "      <td>3.469186</td>\n",
       "      <td>3.431273</td>\n",
       "      <td>3.45897</td>\n",
       "      <td>3.424506</td>\n",
       "      <td>3.458144</td>\n",
       "      <td>3.416673</td>\n",
       "      <td>3.496251</td>\n",
       "      <td>3.513537</td>\n",
       "      <td>3.509555</td>\n",
       "      <td>3.515785</td>\n",
       "      <td>3.438027</td>\n",
       "      <td>3.453733</td>\n",
       "      <td>3.46436</td>\n",
       "      <td>3.47196</td>\n",
       "      <td>3.467689</td>\n",
       "      <td>3.436183</td>\n",
       "      <td>3.471237</td>\n",
       "      <td>3.438353</td>\n",
       "      <td>3.483522</td>\n",
       "      <td>3.426683</td>\n",
       "      <td>3.47296</td>\n",
       "      <td>3.508924</td>\n",
       "      <td>3.477841</td>\n",
       "      <td>3.483059</td>\n",
       "      <td>3.434627</td>\n",
       "      <td>3.427067</td>\n",
       "      <td>3.516064</td>\n",
       "      <td>3.481576</td>\n",
       "      <td>3.48284</td>\n",
       "      <td>3.527188</td>\n",
       "      <td>3.488784</td>\n",
       "      <td>3.479163</td>\n",
       "      <td>3.488434</td>\n",
       "      <td>3.470044</td>\n",
       "      <td>3.50646</td>\n",
       "      <td>3.375566</td>\n",
       "      <td>3.139231</td>\n",
       "      <td>3.05269</td>\n",
       "      <td>2.829342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_tokens_per_sec</th>\n",
       "      <td>441.934582</td>\n",
       "      <td>441.447253</td>\n",
       "      <td>433.599929</td>\n",
       "      <td>436.815414</td>\n",
       "      <td>38.110047</td>\n",
       "      <td>55.693937</td>\n",
       "      <td>111.065177</td>\n",
       "      <td>220.610736</td>\n",
       "      <td>440.798529</td>\n",
       "      <td>875.849029</td>\n",
       "      <td>1701.603812</td>\n",
       "      <td>714.038023</td>\n",
       "      <td>704.16556</td>\n",
       "      <td>226.816108</td>\n",
       "      <td>438.603457</td>\n",
       "      <td>451.801864</td>\n",
       "      <td>440.032318</td>\n",
       "      <td>446.274309</td>\n",
       "      <td>440.697741</td>\n",
       "      <td>439.402499</td>\n",
       "      <td>446.064017</td>\n",
       "      <td>444.462926</td>\n",
       "      <td>450.258192</td>\n",
       "      <td>449.418013</td>\n",
       "      <td>449.528157</td>\n",
       "      <td>451.271694</td>\n",
       "      <td>452.455683</td>\n",
       "      <td>441.051094</td>\n",
       "      <td>436.460902</td>\n",
       "      <td>438.710638</td>\n",
       "      <td>439.638685</td>\n",
       "      <td>439.95538</td>\n",
       "      <td>439.410702</td>\n",
       "      <td>437.227191</td>\n",
       "      <td>442.018372</td>\n",
       "      <td>440.705965</td>\n",
       "      <td>437.824412</td>\n",
       "      <td>443.057441</td>\n",
       "      <td>438.381673</td>\n",
       "      <td>437.378413</td>\n",
       "      <td>445.407816</td>\n",
       "      <td>438.827532</td>\n",
       "      <td>445.663669</td>\n",
       "      <td>440.448076</td>\n",
       "      <td>445.063568</td>\n",
       "      <td>439.445974</td>\n",
       "      <td>437.846188</td>\n",
       "      <td>437.834606</td>\n",
       "      <td>439.957941</td>\n",
       "      <td>439.498684</td>\n",
       "      <td>442.140667</td>\n",
       "      <td>444.055811</td>\n",
       "      <td>439.203001</td>\n",
       "      <td>442.74815</td>\n",
       "      <td>438.336798</td>\n",
       "      <td>442.642464</td>\n",
       "      <td>437.334098</td>\n",
       "      <td>447.520131</td>\n",
       "      <td>449.732686</td>\n",
       "      <td>449.223003</td>\n",
       "      <td>450.020456</td>\n",
       "      <td>440.067511</td>\n",
       "      <td>442.077841</td>\n",
       "      <td>443.438084</td>\n",
       "      <td>444.410829</td>\n",
       "      <td>443.864249</td>\n",
       "      <td>439.831465</td>\n",
       "      <td>444.318334</td>\n",
       "      <td>440.109201</td>\n",
       "      <td>445.890832</td>\n",
       "      <td>438.615437</td>\n",
       "      <td>444.538941</td>\n",
       "      <td>449.142317</td>\n",
       "      <td>445.163616</td>\n",
       "      <td>445.831612</td>\n",
       "      <td>439.632303</td>\n",
       "      <td>438.664576</td>\n",
       "      <td>450.056174</td>\n",
       "      <td>445.641672</td>\n",
       "      <td>445.803508</td>\n",
       "      <td>451.480067</td>\n",
       "      <td>446.564413</td>\n",
       "      <td>445.332854</td>\n",
       "      <td>446.5196</td>\n",
       "      <td>444.165626</td>\n",
       "      <td>448.826851</td>\n",
       "      <td>432.072408</td>\n",
       "      <td>401.821561</td>\n",
       "      <td>390.744374</td>\n",
       "      <td>362.155726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_0</th>\n",
       "      <td>0.003973</td>\n",
       "      <td>0.004542</td>\n",
       "      <td>0.004947</td>\n",
       "      <td>0.005594</td>\n",
       "      <td>0.04328</td>\n",
       "      <td>0.030147</td>\n",
       "      <td>0.01602</td>\n",
       "      <td>0.008813</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>0.003248</td>\n",
       "      <td>0.006229</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.005151</td>\n",
       "      <td>0.00528</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.00517</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.00517</td>\n",
       "      <td>0.005295</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>0.005347</td>\n",
       "      <td>0.00534</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.00533</td>\n",
       "      <td>0.005341</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.005335</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.005338</td>\n",
       "      <td>0.005282</td>\n",
       "      <td>0.005281</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.005317</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.005281</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.00536</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.005171</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.00532</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.00529</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.005287</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.005328</td>\n",
       "      <td>0.005208</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>0.005245</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.005171</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.005583</td>\n",
       "      <td>0.005647</td>\n",
       "      <td>0.005837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004542</td>\n",
       "      <td>0.004858</td>\n",
       "      <td>0.00558</td>\n",
       "      <td>0.04346</td>\n",
       "      <td>0.030251</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.003201</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>0.005213</td>\n",
       "      <td>0.005167</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.005257</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.00512</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.005169</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>0.005199</td>\n",
       "      <td>0.00525</td>\n",
       "      <td>0.00533</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.00528</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>0.005295</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.00526</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.005335</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.005316</td>\n",
       "      <td>0.005352</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>0.005133</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>0.005148</td>\n",
       "      <td>0.00522</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.005295</td>\n",
       "      <td>0.005266</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.005257</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.00532</td>\n",
       "      <td>0.005353</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.005228</td>\n",
       "      <td>0.005281</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>0.005328</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.00537</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.005563</td>\n",
       "      <td>0.005755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004846</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>0.043619</td>\n",
       "      <td>0.030646</td>\n",
       "      <td>0.016074</td>\n",
       "      <td>0.008825</td>\n",
       "      <td>0.005238</td>\n",
       "      <td>0.00299</td>\n",
       "      <td>0.001853</td>\n",
       "      <td>0.005283</td>\n",
       "      <td>0.003249</td>\n",
       "      <td>0.006312</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>0.005155</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.005263</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.005138</td>\n",
       "      <td>0.005143</td>\n",
       "      <td>0.005158</td>\n",
       "      <td>0.005116</td>\n",
       "      <td>0.005132</td>\n",
       "      <td>0.005203</td>\n",
       "      <td>0.005233</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.005355</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.005314</td>\n",
       "      <td>0.005276</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.00534</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.005322</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.005364</td>\n",
       "      <td>0.005293</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>0.005234</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.005249</td>\n",
       "      <td>0.005273</td>\n",
       "      <td>0.005281</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>0.005235</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>0.00531</td>\n",
       "      <td>0.005334</td>\n",
       "      <td>0.005125</td>\n",
       "      <td>0.00513</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.00525</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.00526</td>\n",
       "      <td>0.005287</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.005332</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.005264</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.00533</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>0.005284</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.005298</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.005339</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>0.00568</td>\n",
       "      <td>0.005886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005633</td>\n",
       "      <td>0.043349</td>\n",
       "      <td>0.030091</td>\n",
       "      <td>0.016138</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.00186</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.003166</td>\n",
       "      <td>0.006265</td>\n",
       "      <td>0.005278</td>\n",
       "      <td>0.005138</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.00523</td>\n",
       "      <td>0.005261</td>\n",
       "      <td>0.005291</td>\n",
       "      <td>0.005244</td>\n",
       "      <td>0.005255</td>\n",
       "      <td>0.005119</td>\n",
       "      <td>0.005112</td>\n",
       "      <td>0.005088</td>\n",
       "      <td>0.005151</td>\n",
       "      <td>0.005193</td>\n",
       "      <td>0.005348</td>\n",
       "      <td>0.005289</td>\n",
       "      <td>0.005321</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.00529</td>\n",
       "      <td>0.005215</td>\n",
       "      <td>0.00531</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>0.005317</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.005336</td>\n",
       "      <td>0.00532</td>\n",
       "      <td>0.005324</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.00533</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.005268</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>0.005329</td>\n",
       "      <td>0.005297</td>\n",
       "      <td>0.005083</td>\n",
       "      <td>0.005172</td>\n",
       "      <td>0.00516</td>\n",
       "      <td>0.005077</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.005328</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.005237</td>\n",
       "      <td>0.00531</td>\n",
       "      <td>0.00529</td>\n",
       "      <td>0.005313</td>\n",
       "      <td>0.005299</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.005307</td>\n",
       "      <td>0.005335</td>\n",
       "      <td>0.005285</td>\n",
       "      <td>0.005305</td>\n",
       "      <td>0.00527</td>\n",
       "      <td>0.00525</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>0.005296</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.00521</td>\n",
       "      <td>0.005327</td>\n",
       "      <td>0.00532</td>\n",
       "      <td>0.005304</td>\n",
       "      <td>0.005354</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.005214</td>\n",
       "      <td>0.005309</td>\n",
       "      <td>0.005528</td>\n",
       "      <td>0.005599</td>\n",
       "      <td>0.005986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_avg</th>\n",
       "      <td>46.225986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>284.802324</td>\n",
       "      <td>453.303389</td>\n",
       "      <td>691.338204</td>\n",
       "      <td>268.587557</td>\n",
       "      <td>358.312906</td>\n",
       "      <td>320.232011</td>\n",
       "      <td>1118.538726</td>\n",
       "      <td>492.01174</td>\n",
       "      <td>677.800449</td>\n",
       "      <td>437.204647</td>\n",
       "      <td>391.714159</td>\n",
       "      <td>204.366104</td>\n",
       "      <td>382.524126</td>\n",
       "      <td>266.289626</td>\n",
       "      <td>234.621729</td>\n",
       "      <td>285.611934</td>\n",
       "      <td>391.571721</td>\n",
       "      <td>409.822402</td>\n",
       "      <td>429.799515</td>\n",
       "      <td>432.050167</td>\n",
       "      <td>421.301499</td>\n",
       "      <td>393.303811</td>\n",
       "      <td>292.735859</td>\n",
       "      <td>495.914887</td>\n",
       "      <td>412.077225</td>\n",
       "      <td>383.197083</td>\n",
       "      <td>390.294755</td>\n",
       "      <td>571.329062</td>\n",
       "      <td>392.706854</td>\n",
       "      <td>367.056529</td>\n",
       "      <td>474.542887</td>\n",
       "      <td>334.40488</td>\n",
       "      <td>367.160655</td>\n",
       "      <td>503.445063</td>\n",
       "      <td>410.155781</td>\n",
       "      <td>195.802022</td>\n",
       "      <td>291.842585</td>\n",
       "      <td>337.884587</td>\n",
       "      <td>439.834917</td>\n",
       "      <td>432.162595</td>\n",
       "      <td>367.760453</td>\n",
       "      <td>397.983108</td>\n",
       "      <td>584.680567</td>\n",
       "      <td>404.882464</td>\n",
       "      <td>373.916889</td>\n",
       "      <td>373.171862</td>\n",
       "      <td>581.747394</td>\n",
       "      <td>396.201549</td>\n",
       "      <td>525.567555</td>\n",
       "      <td>399.772335</td>\n",
       "      <td>389.105744</td>\n",
       "      <td>277.971773</td>\n",
       "      <td>384.025206</td>\n",
       "      <td>1477.347167</td>\n",
       "      <td>451.401374</td>\n",
       "      <td>555.380175</td>\n",
       "      <td>406.571211</td>\n",
       "      <td>375.751597</td>\n",
       "      <td>371.866695</td>\n",
       "      <td>311.990543</td>\n",
       "      <td>297.637035</td>\n",
       "      <td>319.099187</td>\n",
       "      <td>422.491341</td>\n",
       "      <td>385.364127</td>\n",
       "      <td>529.887179</td>\n",
       "      <td>384.95846</td>\n",
       "      <td>323.807523</td>\n",
       "      <td>416.411664</td>\n",
       "      <td>375.259303</td>\n",
       "      <td>555.406601</td>\n",
       "      <td>412.056644</td>\n",
       "      <td>333.941971</td>\n",
       "      <td>441.068223</td>\n",
       "      <td>367.534498</td>\n",
       "      <td>296.116516</td>\n",
       "      <td>426.171555</td>\n",
       "      <td>464.683503</td>\n",
       "      <td>373.273991</td>\n",
       "      <td>102.99226</td>\n",
       "      <td>415.753303</td>\n",
       "      <td>441.421415</td>\n",
       "      <td>281.424198</td>\n",
       "      <td>422.539237</td>\n",
       "      <td>354.061436</td>\n",
       "      <td>221.602844</td>\n",
       "      <td>373.637229</td>\n",
       "      <td>383.426657</td>\n",
       "      <td>336.049723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_avg</th>\n",
       "      <td>0.923219</td>\n",
       "      <td>0.94983</td>\n",
       "      <td>0.954332</td>\n",
       "      <td>0.958816</td>\n",
       "      <td>0.951091</td>\n",
       "      <td>0.957124</td>\n",
       "      <td>0.958018</td>\n",
       "      <td>0.954639</td>\n",
       "      <td>0.954839</td>\n",
       "      <td>0.959702</td>\n",
       "      <td>0.955094</td>\n",
       "      <td>0.664005</td>\n",
       "      <td>0.928296</td>\n",
       "      <td>0.9769</td>\n",
       "      <td>0.947205</td>\n",
       "      <td>0.952953</td>\n",
       "      <td>0.962324</td>\n",
       "      <td>0.963021</td>\n",
       "      <td>0.963892</td>\n",
       "      <td>0.955985</td>\n",
       "      <td>0.959559</td>\n",
       "      <td>0.956723</td>\n",
       "      <td>0.95529</td>\n",
       "      <td>0.954029</td>\n",
       "      <td>0.955858</td>\n",
       "      <td>0.951728</td>\n",
       "      <td>0.948094</td>\n",
       "      <td>0.962667</td>\n",
       "      <td>0.963921</td>\n",
       "      <td>0.95377</td>\n",
       "      <td>0.96025</td>\n",
       "      <td>0.961562</td>\n",
       "      <td>0.958358</td>\n",
       "      <td>0.952374</td>\n",
       "      <td>0.95813</td>\n",
       "      <td>0.95802</td>\n",
       "      <td>0.962087</td>\n",
       "      <td>0.958308</td>\n",
       "      <td>0.95993</td>\n",
       "      <td>0.964699</td>\n",
       "      <td>0.955347</td>\n",
       "      <td>0.959208</td>\n",
       "      <td>0.960846</td>\n",
       "      <td>0.962158</td>\n",
       "      <td>0.962879</td>\n",
       "      <td>0.962166</td>\n",
       "      <td>0.965268</td>\n",
       "      <td>0.959845</td>\n",
       "      <td>0.963443</td>\n",
       "      <td>0.963372</td>\n",
       "      <td>0.966059</td>\n",
       "      <td>0.954208</td>\n",
       "      <td>0.963354</td>\n",
       "      <td>0.962415</td>\n",
       "      <td>0.957899</td>\n",
       "      <td>0.96216</td>\n",
       "      <td>0.960668</td>\n",
       "      <td>0.953066</td>\n",
       "      <td>0.949621</td>\n",
       "      <td>0.955473</td>\n",
       "      <td>0.956434</td>\n",
       "      <td>0.945956</td>\n",
       "      <td>0.955248</td>\n",
       "      <td>0.959702</td>\n",
       "      <td>0.958246</td>\n",
       "      <td>0.95934</td>\n",
       "      <td>0.964747</td>\n",
       "      <td>0.956913</td>\n",
       "      <td>0.954762</td>\n",
       "      <td>0.957826</td>\n",
       "      <td>0.956864</td>\n",
       "      <td>0.958314</td>\n",
       "      <td>0.947865</td>\n",
       "      <td>0.95182</td>\n",
       "      <td>0.964067</td>\n",
       "      <td>0.958583</td>\n",
       "      <td>0.964557</td>\n",
       "      <td>0.960877</td>\n",
       "      <td>0.962227</td>\n",
       "      <td>0.963644</td>\n",
       "      <td>0.962694</td>\n",
       "      <td>0.962244</td>\n",
       "      <td>0.958251</td>\n",
       "      <td>0.954216</td>\n",
       "      <td>0.962374</td>\n",
       "      <td>0.962766</td>\n",
       "      <td>0.960215</td>\n",
       "      <td>0.956742</td>\n",
       "      <td>0.954906</td>\n",
       "      <td>0.961642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_total</th>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.004173</td>\n",
       "      <td>0.042788</td>\n",
       "      <td>0.03621</td>\n",
       "      <td>0.018196</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>0.004569</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.002912</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.00899</td>\n",
       "      <td>0.004573</td>\n",
       "      <td>0.004507</td>\n",
       "      <td>0.004626</td>\n",
       "      <td>0.004612</td>\n",
       "      <td>0.004569</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.00454</td>\n",
       "      <td>0.004495</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.00447</td>\n",
       "      <td>0.004483</td>\n",
       "      <td>0.004568</td>\n",
       "      <td>0.004614</td>\n",
       "      <td>0.004592</td>\n",
       "      <td>0.004588</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.004563</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.004591</td>\n",
       "      <td>0.004617</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.004642</td>\n",
       "      <td>0.004581</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.004604</td>\n",
       "      <td>0.004579</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>0.00456</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.004577</td>\n",
       "      <td>0.004582</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.004564</td>\n",
       "      <td>0.004612</td>\n",
       "      <td>0.004634</td>\n",
       "      <td>0.004625</td>\n",
       "      <td>0.004598</td>\n",
       "      <td>0.004594</td>\n",
       "      <td>0.004497</td>\n",
       "      <td>0.004512</td>\n",
       "      <td>0.004496</td>\n",
       "      <td>0.004484</td>\n",
       "      <td>0.004586</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>0.00456</td>\n",
       "      <td>0.004529</td>\n",
       "      <td>0.004583</td>\n",
       "      <td>0.004589</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.004575</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>0.004589</td>\n",
       "      <td>0.004586</td>\n",
       "      <td>0.00454</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.004556</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>0.004555</td>\n",
       "      <td>0.004593</td>\n",
       "      <td>0.004558</td>\n",
       "      <td>0.004651</td>\n",
       "      <td>0.004565</td>\n",
       "      <td>0.004546</td>\n",
       "      <td>0.004586</td>\n",
       "      <td>0.004548</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.004726</td>\n",
       "      <td>0.004984</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>0.005617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_total</th>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.006706</td>\n",
       "      <td>0.011857</td>\n",
       "      <td>0.018244</td>\n",
       "      <td>0.130587</td>\n",
       "      <td>0.084684</td>\n",
       "      <td>0.045785</td>\n",
       "      <td>0.026333</td>\n",
       "      <td>0.01648</td>\n",
       "      <td>0.009785</td>\n",
       "      <td>0.006235</td>\n",
       "      <td>0.018275</td>\n",
       "      <td>0.009992</td>\n",
       "      <td>0.016105</td>\n",
       "      <td>0.016397</td>\n",
       "      <td>0.016074</td>\n",
       "      <td>0.016469</td>\n",
       "      <td>0.016436</td>\n",
       "      <td>0.016487</td>\n",
       "      <td>0.016428</td>\n",
       "      <td>0.01645</td>\n",
       "      <td>0.016483</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.016032</td>\n",
       "      <td>0.016062</td>\n",
       "      <td>0.016112</td>\n",
       "      <td>0.016181</td>\n",
       "      <td>0.016497</td>\n",
       "      <td>0.016523</td>\n",
       "      <td>0.016694</td>\n",
       "      <td>0.016637</td>\n",
       "      <td>0.016611</td>\n",
       "      <td>0.016579</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.016596</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>0.01659</td>\n",
       "      <td>0.016545</td>\n",
       "      <td>0.016591</td>\n",
       "      <td>0.016613</td>\n",
       "      <td>0.016648</td>\n",
       "      <td>0.016684</td>\n",
       "      <td>0.016649</td>\n",
       "      <td>0.016622</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>0.016612</td>\n",
       "      <td>0.016566</td>\n",
       "      <td>0.016577</td>\n",
       "      <td>0.016571</td>\n",
       "      <td>0.016538</td>\n",
       "      <td>0.016558</td>\n",
       "      <td>0.016539</td>\n",
       "      <td>0.016522</td>\n",
       "      <td>0.016496</td>\n",
       "      <td>0.016597</td>\n",
       "      <td>0.016642</td>\n",
       "      <td>0.01669</td>\n",
       "      <td>0.015956</td>\n",
       "      <td>0.016032</td>\n",
       "      <td>0.016109</td>\n",
       "      <td>0.016096</td>\n",
       "      <td>0.016511</td>\n",
       "      <td>0.016489</td>\n",
       "      <td>0.016512</td>\n",
       "      <td>0.016479</td>\n",
       "      <td>0.016509</td>\n",
       "      <td>0.016522</td>\n",
       "      <td>0.016523</td>\n",
       "      <td>0.016553</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.016596</td>\n",
       "      <td>0.016658</td>\n",
       "      <td>0.016605</td>\n",
       "      <td>0.016603</td>\n",
       "      <td>0.016546</td>\n",
       "      <td>0.016551</td>\n",
       "      <td>0.016534</td>\n",
       "      <td>0.016466</td>\n",
       "      <td>0.016465</td>\n",
       "      <td>0.016487</td>\n",
       "      <td>0.016491</td>\n",
       "      <td>0.016573</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.016591</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.016585</td>\n",
       "      <td>0.017087</td>\n",
       "      <td>0.017301</td>\n",
       "      <td>0.017808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_config_decoding_mode</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_k</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_p</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_generated_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>14659</td>\n",
       "      <td>16284</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   0   \\\n",
       "config_name                                           num_processes_1   \n",
       "experiment_id                                                     233   \n",
       "date_time                               April 11, 2025 at 05:02:12 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       1   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.003973   \n",
       "total_energy_joules                                      14303.761229   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             1.145433   \n",
       "joules_per_token                                             0.873032   \n",
       "flops_per_joule                                     1185000974.364989   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     37.07336   \n",
       "average_latency_ms_per_batch                              4634.170037   \n",
       "throughput_queries_per_sec                                   3.452614   \n",
       "throughput_tokens_per_sec                                  441.934582   \n",
       "total_energy_kwh_process_0                                   0.003973   \n",
       "total_energy_kwh_process_1                                        NaN   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                               46.225986   \n",
       "ram_power_avg                                                0.923219   \n",
       "cpu_energy_total                                             0.001241   \n",
       "gpu_energy_total                                             0.002724   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "\n",
       "                                                                   1   \\\n",
       "config_name                                           num_processes_2   \n",
       "experiment_id                                                     234   \n",
       "date_time                               April 11, 2025 at 05:03:25 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       2   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.009084   \n",
       "total_energy_joules                                      32700.724679   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.501029   \n",
       "joules_per_token                                             1.995894   \n",
       "flops_per_joule                                       518336249.72279   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    37.114287   \n",
       "average_latency_ms_per_batch                               4639.28586   \n",
       "throughput_queries_per_sec                                   3.448807   \n",
       "throughput_tokens_per_sec                                  441.447253   \n",
       "total_energy_kwh_process_0                                   0.004542   \n",
       "total_energy_kwh_process_1                                   0.004542   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                                     0.0   \n",
       "ram_power_avg                                                 0.94983   \n",
       "cpu_energy_total                                             0.002359   \n",
       "gpu_energy_total                                             0.006706   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "\n",
       "                                                                   2   \\\n",
       "config_name                                           num_processes_3   \n",
       "experiment_id                                                     235   \n",
       "date_time                               April 11, 2025 at 05:04:40 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       3   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.014652   \n",
       "total_energy_joules                                      52747.350103   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.310613   \n",
       "joules_per_token                                             3.219443   \n",
       "flops_per_joule                                      321342606.972544   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    37.785984   \n",
       "average_latency_ms_per_batch                              4723.248003   \n",
       "throughput_queries_per_sec                                   3.387499   \n",
       "throughput_tokens_per_sec                                  433.599929   \n",
       "total_energy_kwh_process_0                                   0.004947   \n",
       "total_energy_kwh_process_1                                   0.004858   \n",
       "total_energy_kwh_process_2                                   0.004846   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                              284.802324   \n",
       "ram_power_avg                                                0.954332   \n",
       "cpu_energy_total                                             0.002769   \n",
       "gpu_energy_total                                             0.011857   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "\n",
       "                                                                   3   \\\n",
       "config_name                                           num_processes_4   \n",
       "experiment_id                                                     236   \n",
       "date_time                               April 11, 2025 at 05:05:55 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.022451   \n",
       "total_energy_joules                                      80824.506502   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.202711   \n",
       "joules_per_token                                             4.933136   \n",
       "flops_per_joule                                       209713263.05247   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    37.507834   \n",
       "average_latency_ms_per_batch                              4688.479238   \n",
       "throughput_queries_per_sec                                    3.41262   \n",
       "throughput_tokens_per_sec                                  436.815414   \n",
       "total_energy_kwh_process_0                                   0.005594   \n",
       "total_energy_kwh_process_1                                    0.00558   \n",
       "total_energy_kwh_process_2                                   0.005645   \n",
       "total_energy_kwh_process_3                                   0.005633   \n",
       "gpu_power_avg                                              453.303389   \n",
       "ram_power_avg                                                0.958816   \n",
       "cpu_energy_total                                             0.004173   \n",
       "gpu_energy_total                                             0.018244   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "\n",
       "                                                                   4   \\\n",
       "config_name                                                batching_1   \n",
       "experiment_id                                                     237   \n",
       "date_time                               April 11, 2025 at 05:13:02 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                         1   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.173708   \n",
       "total_energy_joules                                     625349.848478   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.023441   \n",
       "joules_per_token                                            42.659789   \n",
       "flops_per_joule                                       27104781.482585   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                   384.649219   \n",
       "average_latency_ms_per_batch                              3005.072024   \n",
       "throughput_queries_per_sec                                   0.332771   \n",
       "throughput_tokens_per_sec                                   38.110047   \n",
       "total_energy_kwh_process_0                                    0.04328   \n",
       "total_energy_kwh_process_1                                    0.04346   \n",
       "total_energy_kwh_process_2                                   0.043619   \n",
       "total_energy_kwh_process_3                                   0.043349   \n",
       "gpu_power_avg                                              691.338204   \n",
       "ram_power_avg                                                0.951091   \n",
       "cpu_energy_total                                             0.042788   \n",
       "gpu_energy_total                                             0.130587   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          14659   \n",
       "\n",
       "                                                                   5   \\\n",
       "config_name                                                batching_2   \n",
       "experiment_id                                                     238   \n",
       "date_time                               April 11, 2025 at 05:18:36 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                         2   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.121135   \n",
       "total_energy_joules                                     436084.529304   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.037341   \n",
       "joules_per_token                                            26.779939   \n",
       "flops_per_joule                                       38868544.637947   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                   292.383712   \n",
       "average_latency_ms_per_batch                              4568.495493   \n",
       "throughput_queries_per_sec                                   0.437781   \n",
       "throughput_tokens_per_sec                                   55.693937   \n",
       "total_energy_kwh_process_0                                   0.030147   \n",
       "total_energy_kwh_process_1                                   0.030251   \n",
       "total_energy_kwh_process_2                                   0.030646   \n",
       "total_energy_kwh_process_3                                   0.030091   \n",
       "gpu_power_avg                                              268.587557   \n",
       "ram_power_avg                                                0.957124   \n",
       "cpu_energy_total                                              0.03621   \n",
       "gpu_energy_total                                             0.084684   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16284   \n",
       "\n",
       "                                                                   6   \\\n",
       "config_name                                                batching_4   \n",
       "experiment_id                                                     239   \n",
       "date_time                               April 11, 2025 at 05:21:39 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                         4   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.064102   \n",
       "total_energy_joules                                     230767.542556   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.070998   \n",
       "joules_per_token                                            14.084933   \n",
       "flops_per_joule                                       73450411.636865   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                   147.516985   \n",
       "average_latency_ms_per_batch                              4609.905773   \n",
       "throughput_queries_per_sec                                   0.867697   \n",
       "throughput_tokens_per_sec                                  111.065177   \n",
       "total_energy_kwh_process_0                                    0.01602   \n",
       "total_energy_kwh_process_1                                    0.01587   \n",
       "total_energy_kwh_process_2                                   0.016074   \n",
       "total_energy_kwh_process_3                                   0.016138   \n",
       "gpu_power_avg                                              358.312906   \n",
       "ram_power_avg                                                0.958018   \n",
       "cpu_energy_total                                             0.018196   \n",
       "gpu_energy_total                                             0.045785   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "\n",
       "                                                                   7   \\\n",
       "config_name                                                batching_8   \n",
       "experiment_id                                                     240   \n",
       "date_time                               April 11, 2025 at 05:23:23 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                         8   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.035372   \n",
       "total_energy_joules                                     127338.055234   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.128665   \n",
       "joules_per_token                                             7.772098   \n",
       "flops_per_joule                                      133110019.326187   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    74.266558   \n",
       "average_latency_ms_per_batch                               4641.65987   \n",
       "throughput_queries_per_sec                                   1.723521   \n",
       "throughput_tokens_per_sec                                  220.610736   \n",
       "total_energy_kwh_process_0                                   0.008813   \n",
       "total_energy_kwh_process_1                                   0.008805   \n",
       "total_energy_kwh_process_2                                   0.008825   \n",
       "total_energy_kwh_process_3                                   0.008929   \n",
       "gpu_power_avg                                              320.232011   \n",
       "ram_power_avg                                                0.954639   \n",
       "cpu_energy_total                                             0.008976   \n",
       "gpu_energy_total                                             0.026333   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "\n",
       "                                                                   8   \\\n",
       "config_name                                               batching_16   \n",
       "experiment_id                                                     241   \n",
       "date_time                               April 11, 2025 at 05:24:30 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.021079   \n",
       "total_energy_joules                                      75884.699531   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.215907   \n",
       "joules_per_token                                             4.631634   \n",
       "flops_per_joule                                      223364803.416953   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    37.168908   \n",
       "average_latency_ms_per_batch                              4646.113508   \n",
       "throughput_queries_per_sec                                   3.443739   \n",
       "throughput_tokens_per_sec                                  440.798529   \n",
       "total_energy_kwh_process_0                                   0.005296   \n",
       "total_energy_kwh_process_1                                   0.005256   \n",
       "total_energy_kwh_process_2                                   0.005238   \n",
       "total_energy_kwh_process_3                                   0.005289   \n",
       "gpu_power_avg                                             1118.538726   \n",
       "ram_power_avg                                                0.954839   \n",
       "cpu_energy_total                                             0.004569   \n",
       "gpu_energy_total                                              0.01648   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "\n",
       "                                                                   9   \\\n",
       "config_name                                               batching_32   \n",
       "experiment_id                                                     242   \n",
       "date_time                               April 11, 2025 at 05:25:17 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        32   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.012114   \n",
       "total_energy_joules                                      43611.764042   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.375678   \n",
       "joules_per_token                                             2.661851   \n",
       "flops_per_joule                                      388655936.426967   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     18.70642   \n",
       "average_latency_ms_per_batch                              4676.605061   \n",
       "throughput_queries_per_sec                                   6.842571   \n",
       "throughput_tokens_per_sec                                  875.849029   \n",
       "total_energy_kwh_process_0                                   0.003041   \n",
       "total_energy_kwh_process_1                                   0.003042   \n",
       "total_energy_kwh_process_2                                    0.00299   \n",
       "total_energy_kwh_process_3                                   0.003042   \n",
       "gpu_power_avg                                               492.01174   \n",
       "ram_power_avg                                                0.959702   \n",
       "cpu_energy_total                                             0.002314   \n",
       "gpu_energy_total                                             0.009785   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "\n",
       "                                                                   10  \\\n",
       "config_name                                               batching_64   \n",
       "experiment_id                                                     243   \n",
       "date_time                               April 11, 2025 at 05:25:56 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        64   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.007437   \n",
       "total_energy_joules                                      26773.911916   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.611939   \n",
       "joules_per_token                                              1.63415   \n",
       "flops_per_joule                                      633077864.986458   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     9.628563   \n",
       "average_latency_ms_per_batch                              4814.281646   \n",
       "throughput_queries_per_sec                                   13.29378   \n",
       "throughput_tokens_per_sec                                 1701.603812   \n",
       "total_energy_kwh_process_0                                   0.001865   \n",
       "total_energy_kwh_process_1                                   0.001859   \n",
       "total_energy_kwh_process_2                                   0.001853   \n",
       "total_energy_kwh_process_3                                    0.00186   \n",
       "gpu_power_avg                                              677.800449   \n",
       "ram_power_avg                                                0.955094   \n",
       "cpu_energy_total                                             0.001194   \n",
       "gpu_energy_total                                             0.006235   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "\n",
       "                                                                                  11  \\\n",
       "config_name                        precis_float32_quant_False_quant8_False_quant4...   \n",
       "experiment_id                                                                    244   \n",
       "date_time                                              April 11, 2025 at 05:26:49 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float32   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021202   \n",
       "total_energy_joules                                                     76325.798731   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214659   \n",
       "joules_per_token                                                            4.658557   \n",
       "flops_per_joule                                                      222073941.90463   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   22.945557   \n",
       "average_latency_ms_per_batch                                             2868.194596   \n",
       "throughput_queries_per_sec                                                  5.578422   \n",
       "throughput_tokens_per_sec                                                 714.038023   \n",
       "total_energy_kwh_process_0                                                  0.005286   \n",
       "total_energy_kwh_process_1                                                  0.005333   \n",
       "total_energy_kwh_process_2                                                  0.005283   \n",
       "total_energy_kwh_process_3                                                  0.005299   \n",
       "gpu_power_avg                                                             437.204647   \n",
       "ram_power_avg                                                               0.664005   \n",
       "cpu_energy_total                                                            0.002912   \n",
       "gpu_energy_total                                                            0.018275   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  12  \\\n",
       "config_name                        precis_float16_quant_False_quant8_False_quant4...   \n",
       "experiment_id                                                                    245   \n",
       "date_time                                              April 11, 2025 at 05:27:40 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                   False   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.012864   \n",
       "total_energy_joules                                                     46310.921387   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.353783   \n",
       "joules_per_token                                                            2.826594   \n",
       "flops_per_joule                                                     366003752.151563   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   23.267255   \n",
       "average_latency_ms_per_batch                                             2908.406936   \n",
       "throughput_queries_per_sec                                                  5.501293   \n",
       "throughput_tokens_per_sec                                                  704.16556   \n",
       "total_energy_kwh_process_0                                                  0.003248   \n",
       "total_energy_kwh_process_1                                                  0.003201   \n",
       "total_energy_kwh_process_2                                                  0.003249   \n",
       "total_energy_kwh_process_3                                                  0.003166   \n",
       "gpu_power_avg                                                             391.714159   \n",
       "ram_power_avg                                                               0.928296   \n",
       "cpu_energy_total                                                            0.002852   \n",
       "gpu_energy_total                                                            0.009992   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  13  \\\n",
       "config_name                        precis_float16_quant_True_quant8_True_quant4_F...   \n",
       "experiment_id                                                                    246   \n",
       "date_time                                              April 11, 2025 at 05:29:22 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                    True   \n",
       "load_in_4bit                                                                   False   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                              1100048384   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.025157   \n",
       "total_energy_joules                                                     90564.656156   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.180909   \n",
       "joules_per_token                                                            5.527628   \n",
       "flops_per_joule                                                      187158784.81295   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   72.234728   \n",
       "average_latency_ms_per_batch                                             9029.341061   \n",
       "throughput_queries_per_sec                                                  1.772001   \n",
       "throughput_tokens_per_sec                                                 226.816108   \n",
       "total_energy_kwh_process_0                                                  0.006229   \n",
       "total_energy_kwh_process_1                                                  0.006351   \n",
       "total_energy_kwh_process_2                                                  0.006312   \n",
       "total_energy_kwh_process_3                                                  0.006265   \n",
       "gpu_power_avg                                                             204.366104   \n",
       "ram_power_avg                                                                 0.9769   \n",
       "cpu_energy_total                                                             0.00899   \n",
       "gpu_energy_total                                                            0.016105   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  14  \\\n",
       "config_name                        precis_float16_quant_True_quant8_False_quant4_...   \n",
       "experiment_id                                                                    247   \n",
       "date_time                                              April 11, 2025 at 05:30:29 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                               0.021   \n",
       "total_energy_joules                                                     75601.377686   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.216716   \n",
       "joules_per_token                                                            4.614342   \n",
       "flops_per_joule                                                     224201879.805033   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.354927   \n",
       "average_latency_ms_per_batch                                             4669.365846   \n",
       "throughput_queries_per_sec                                                   3.42659   \n",
       "throughput_tokens_per_sec                                                 438.603457   \n",
       "total_energy_kwh_process_0                                                  0.005292   \n",
       "total_energy_kwh_process_1                                                  0.005213   \n",
       "total_energy_kwh_process_2                                                  0.005217   \n",
       "total_energy_kwh_process_3                                                  0.005278   \n",
       "gpu_power_avg                                                             382.524126   \n",
       "ram_power_avg                                                               0.947205   \n",
       "cpu_energy_total                                                            0.004573   \n",
       "gpu_energy_total                                                            0.016397   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                      15  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_0   \n",
       "experiment_id                                                        248   \n",
       "date_time                                  April 11, 2025 at 05:31:35 PM   \n",
       "model                                 TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                          4   \n",
       "batch_size___fixed_batching                                           16   \n",
       "decoder_temperature                                                  0.0   \n",
       "decoder_top_k                                                          0   \n",
       "decoder_top_p                                                        0.0   \n",
       "latency_simulation_delay_min                                         0.0   \n",
       "latency_simulation_simulate_burst                                  False   \n",
       "latency_simulation_burst_size                                          0   \n",
       "latency_simulation_burst_interval                                    0.0   \n",
       "fp_precision                                               torch.float16   \n",
       "quantization                                                        True   \n",
       "load_in_8bit                                                       False   \n",
       "load_in_4bit                                                        True   \n",
       "total_input_tokens                                                 16384   \n",
       "total_params                                                   615606272   \n",
       "max_input_tokens                                                     128   \n",
       "max_output_tokens                                                    128   \n",
       "number_input_prompts                                                 128   \n",
       "total_energy_kwh                                                0.020611   \n",
       "total_energy_joules                                         74199.651611   \n",
       "flops                                                     16949970993152   \n",
       "tokens_per_joule                                                 0.22081   \n",
       "joules_per_token                                                4.528787   \n",
       "flops_per_joule                                         228437339.327415   \n",
       "joules_per_flop                                                      0.0   \n",
       "total_inference_time_sec                                       36.263684   \n",
       "average_latency_ms_per_batch                                 4532.960497   \n",
       "throughput_queries_per_sec                                      3.529702   \n",
       "throughput_tokens_per_sec                                     451.801864   \n",
       "total_energy_kwh_process_0                                      0.005151   \n",
       "total_energy_kwh_process_1                                      0.005167   \n",
       "total_energy_kwh_process_2                                      0.005155   \n",
       "total_energy_kwh_process_3                                      0.005138   \n",
       "gpu_power_avg                                                 266.289626   \n",
       "ram_power_avg                                                   0.952953   \n",
       "cpu_energy_total                                                0.004507   \n",
       "gpu_energy_total                                                0.016074   \n",
       "decoder_config_decoding_mode                                      greedy   \n",
       "latency_simulation_simulate                                        False   \n",
       "latency_simulation_delay_max                                         0.0   \n",
       "total_generated_tokens                                             16384   \n",
       "\n",
       "                                                                        16  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_0.2   \n",
       "experiment_id                                                          249   \n",
       "date_time                                    April 11, 2025 at 05:32:41 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    0.2   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float16   \n",
       "quantization                                                          True   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                          True   \n",
       "total_input_tokens                                                   16384   \n",
       "total_params                                                     615606272   \n",
       "max_input_tokens                                                       128   \n",
       "max_output_tokens                                                      128   \n",
       "number_input_prompts                                                   128   \n",
       "total_energy_kwh                                                  0.021126   \n",
       "total_energy_joules                                           76054.746039   \n",
       "flops                                                       16949970993152   \n",
       "tokens_per_joule                                                  0.215424   \n",
       "joules_per_token                                                  4.642013   \n",
       "flops_per_joule                                           222865394.679583   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                         37.233629   \n",
       "average_latency_ms_per_batch                                   4654.203603   \n",
       "throughput_queries_per_sec                                        3.437752   \n",
       "throughput_tokens_per_sec                                       440.032318   \n",
       "total_energy_kwh_process_0                                         0.00528   \n",
       "total_energy_kwh_process_1                                        0.005296   \n",
       "total_energy_kwh_process_2                                        0.005279   \n",
       "total_energy_kwh_process_3                                         0.00527   \n",
       "gpu_power_avg                                                   234.621729   \n",
       "ram_power_avg                                                     0.962324   \n",
       "cpu_energy_total                                                  0.004626   \n",
       "gpu_energy_total                                                  0.016469   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "latency_simulation_simulate                                          False   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "total_generated_tokens                                               16384   \n",
       "\n",
       "                                                                        17  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_0.4   \n",
       "experiment_id                                                          250   \n",
       "date_time                                    April 11, 2025 at 05:33:46 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    0.4   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float16   \n",
       "quantization                                                          True   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                          True   \n",
       "total_input_tokens                                                   16384   \n",
       "total_params                                                     615606272   \n",
       "max_input_tokens                                                       128   \n",
       "max_output_tokens                                                      128   \n",
       "number_input_prompts                                                   128   \n",
       "total_energy_kwh                                                  0.021079   \n",
       "total_energy_joules                                           75884.577747   \n",
       "flops                                                       16949970993152   \n",
       "tokens_per_joule                                                  0.215907   \n",
       "joules_per_token                                                  4.631627   \n",
       "flops_per_joule                                           223365161.886555   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                         36.712846   \n",
       "average_latency_ms_per_batch                                   4589.105755   \n",
       "throughput_queries_per_sec                                        3.486518   \n",
       "throughput_tokens_per_sec                                       446.274309   \n",
       "total_energy_kwh_process_0                                        0.005228   \n",
       "total_energy_kwh_process_1                                        0.005299   \n",
       "total_energy_kwh_process_2                                        0.005323   \n",
       "total_energy_kwh_process_3                                         0.00523   \n",
       "gpu_power_avg                                                   285.611934   \n",
       "ram_power_avg                                                     0.963021   \n",
       "cpu_energy_total                                                  0.004612   \n",
       "gpu_energy_total                                                  0.016436   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "latency_simulation_simulate                                          False   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "total_generated_tokens                                               16384   \n",
       "\n",
       "                                                                        18  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_0.6   \n",
       "experiment_id                                                          251   \n",
       "date_time                                    April 11, 2025 at 05:34:52 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    0.6   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float16   \n",
       "quantization                                                          True   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                          True   \n",
       "total_input_tokens                                                   16384   \n",
       "total_params                                                     615606272   \n",
       "max_input_tokens                                                       128   \n",
       "max_output_tokens                                                      128   \n",
       "number_input_prompts                                                   128   \n",
       "total_energy_kwh                                                  0.021087   \n",
       "total_energy_joules                                           75912.204543   \n",
       "flops                                                       16949970993152   \n",
       "tokens_per_joule                                                  0.215828   \n",
       "joules_per_token                                                  4.633313   \n",
       "flops_per_joule                                           223283872.404349   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                         37.177409   \n",
       "average_latency_ms_per_batch                                   4647.176079   \n",
       "throughput_queries_per_sec                                        3.442951   \n",
       "throughput_tokens_per_sec                                       440.697741   \n",
       "total_energy_kwh_process_0                                        0.005296   \n",
       "total_energy_kwh_process_1                                        0.005267   \n",
       "total_energy_kwh_process_2                                        0.005263   \n",
       "total_energy_kwh_process_3                                        0.005261   \n",
       "gpu_power_avg                                                   391.571721   \n",
       "ram_power_avg                                                     0.963892   \n",
       "cpu_energy_total                                                  0.004569   \n",
       "gpu_energy_total                                                  0.016487   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "latency_simulation_simulate                                          False   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "total_generated_tokens                                               16384   \n",
       "\n",
       "                                                                        19  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_0.8   \n",
       "experiment_id                                                          252   \n",
       "date_time                                    April 11, 2025 at 05:35:58 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    0.8   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float16   \n",
       "quantization                                                          True   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                          True   \n",
       "total_input_tokens                                                   16384   \n",
       "total_params                                                     615606272   \n",
       "max_input_tokens                                                       128   \n",
       "max_output_tokens                                                      128   \n",
       "number_input_prompts                                                   128   \n",
       "total_energy_kwh                                                  0.021035   \n",
       "total_energy_joules                                           75727.619266   \n",
       "flops                                                       16949970993152   \n",
       "tokens_per_joule                                                  0.216354   \n",
       "joules_per_token                                                  4.622047   \n",
       "flops_per_joule                                           223828124.501124   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                         37.286998   \n",
       "average_latency_ms_per_batch                                   4660.874719   \n",
       "throughput_queries_per_sec                                        3.432832   \n",
       "throughput_tokens_per_sec                                       439.402499   \n",
       "total_energy_kwh_process_0                                        0.005289   \n",
       "total_energy_kwh_process_1                                          0.0052   \n",
       "total_energy_kwh_process_2                                        0.005255   \n",
       "total_energy_kwh_process_3                                        0.005291   \n",
       "gpu_power_avg                                                   409.822402   \n",
       "ram_power_avg                                                     0.955985   \n",
       "cpu_energy_total                                                  0.004577   \n",
       "gpu_energy_total                                                  0.016428   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "latency_simulation_simulate                                          False   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "total_generated_tokens                                               16384   \n",
       "\n",
       "                                                                        20  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_1.0   \n",
       "experiment_id                                                          253   \n",
       "date_time                                    April 11, 2025 at 05:37:04 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    1.0   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float16   \n",
       "quantization                                                          True   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                          True   \n",
       "total_input_tokens                                                   16384   \n",
       "total_params                                                     615606272   \n",
       "max_input_tokens                                                       128   \n",
       "max_output_tokens                                                      128   \n",
       "number_input_prompts                                                   128   \n",
       "total_energy_kwh                                                  0.021028   \n",
       "total_energy_joules                                           75701.472545   \n",
       "flops                                                       16949970993152   \n",
       "tokens_per_joule                                                  0.216429   \n",
       "joules_per_token                                                  4.620451   \n",
       "flops_per_joule                                           223905433.056266   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                         36.730154   \n",
       "average_latency_ms_per_batch                                   4591.269241   \n",
       "throughput_queries_per_sec                                        3.484875   \n",
       "throughput_tokens_per_sec                                       446.064017   \n",
       "total_energy_kwh_process_0                                        0.005251   \n",
       "total_energy_kwh_process_1                                        0.005257   \n",
       "total_energy_kwh_process_2                                        0.005277   \n",
       "total_energy_kwh_process_3                                        0.005244   \n",
       "gpu_power_avg                                                   429.799515   \n",
       "ram_power_avg                                                     0.959559   \n",
       "cpu_energy_total                                                  0.004548   \n",
       "gpu_energy_total                                                   0.01645   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "latency_simulation_simulate                                          False   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "total_generated_tokens                                               16384   \n",
       "\n",
       "                                                                        21  \\\n",
       "config_name                        decoding_greedy_decoder_temperature_1.2   \n",
       "experiment_id                                                          254   \n",
       "date_time                                    April 11, 2025 at 05:38:09 PM   \n",
       "model                                   TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                            4   \n",
       "batch_size___fixed_batching                                             16   \n",
       "decoder_temperature                                                    1.2   \n",
       "decoder_top_k                                                            0   \n",
       "decoder_top_p                                                          0.0   \n",
       "latency_simulation_delay_min                                           0.0   \n",
       "latency_simulation_simulate_burst                                    False   \n",
       "latency_simulation_burst_size                                            0   \n",
       "latency_simulation_burst_interval                                      0.0   \n",
       "fp_precision                                                 torch.float16   \n",
       "quantization                                                          True   \n",
       "load_in_8bit                                                         False   \n",
       "load_in_4bit                                                          True   \n",
       "total_input_tokens                                                   16384   \n",
       "total_params                                                     615606272   \n",
       "max_input_tokens                                                       128   \n",
       "max_output_tokens                                                      128   \n",
       "number_input_prompts                                                   128   \n",
       "total_energy_kwh                                                  0.021053   \n",
       "total_energy_joules                                           75790.175016   \n",
       "flops                                                       16949970993152   \n",
       "tokens_per_joule                                                  0.216176   \n",
       "joules_per_token                                                  4.625865   \n",
       "flops_per_joule                                           223643381.078152   \n",
       "joules_per_flop                                                        0.0   \n",
       "total_inference_time_sec                                         36.862467   \n",
       "average_latency_ms_per_batch                                    4607.80839   \n",
       "throughput_queries_per_sec                                        3.472367   \n",
       "throughput_tokens_per_sec                                       444.462926   \n",
       "total_energy_kwh_process_0                                        0.005273   \n",
       "total_energy_kwh_process_1                                        0.005256   \n",
       "total_energy_kwh_process_2                                        0.005268   \n",
       "total_energy_kwh_process_3                                        0.005255   \n",
       "gpu_power_avg                                                   432.050167   \n",
       "ram_power_avg                                                     0.956723   \n",
       "cpu_energy_total                                                   0.00454   \n",
       "gpu_energy_total                                                  0.016483   \n",
       "decoder_config_decoding_mode                                        greedy   \n",
       "latency_simulation_simulate                                          False   \n",
       "latency_simulation_delay_max                                           0.0   \n",
       "total_generated_tokens                                               16384   \n",
       "\n",
       "                                                                                  22  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    256   \n",
       "date_time                                              April 11, 2025 at 05:39:42 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.020493   \n",
       "total_energy_joules                                                     73773.389464   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.222085   \n",
       "joules_per_token                                                             4.50277   \n",
       "flops_per_joule                                                      229757248.73563   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.388011   \n",
       "average_latency_ms_per_batch                                             4548.501365   \n",
       "throughput_queries_per_sec                                                  3.517642   \n",
       "throughput_tokens_per_sec                                                 450.258192   \n",
       "total_energy_kwh_process_0                                                  0.005115   \n",
       "total_energy_kwh_process_1                                                   0.00512   \n",
       "total_energy_kwh_process_2                                                  0.005138   \n",
       "total_energy_kwh_process_3                                                  0.005119   \n",
       "gpu_power_avg                                                             421.301499   \n",
       "ram_power_avg                                                                0.95529   \n",
       "cpu_energy_total                                                            0.004495   \n",
       "gpu_energy_total                                                            0.015968   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  23  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    257   \n",
       "date_time                                              April 11, 2025 at 05:40:48 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.020526   \n",
       "total_energy_joules                                                     73892.703968   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.221727   \n",
       "joules_per_token                                                            4.510053   \n",
       "flops_per_joule                                                     229386259.846373   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.456038   \n",
       "average_latency_ms_per_batch                                             4557.004705   \n",
       "throughput_queries_per_sec                                                  3.511078   \n",
       "throughput_tokens_per_sec                                                 449.418013   \n",
       "total_energy_kwh_process_0                                                   0.00517   \n",
       "total_energy_kwh_process_1                                                    0.0051   \n",
       "total_energy_kwh_process_2                                                  0.005143   \n",
       "total_energy_kwh_process_3                                                  0.005112   \n",
       "gpu_power_avg                                                             393.303811   \n",
       "ram_power_avg                                                               0.954029   \n",
       "cpu_energy_total                                                            0.004464   \n",
       "gpu_energy_total                                                            0.016032   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  24  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    258   \n",
       "date_time                                              April 11, 2025 at 05:41:54 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.020592   \n",
       "total_energy_joules                                                     74129.708593   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.221018   \n",
       "joules_per_token                                                            4.524518   \n",
       "flops_per_joule                                                     228652875.007557   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.447105   \n",
       "average_latency_ms_per_batch                                             4555.888145   \n",
       "throughput_queries_per_sec                                                  3.511939   \n",
       "throughput_tokens_per_sec                                                 449.528157   \n",
       "total_energy_kwh_process_0                                                  0.005177   \n",
       "total_energy_kwh_process_1                                                  0.005169   \n",
       "total_energy_kwh_process_2                                                  0.005158   \n",
       "total_energy_kwh_process_3                                                  0.005088   \n",
       "gpu_power_avg                                                             292.735859   \n",
       "ram_power_avg                                                               0.955858   \n",
       "cpu_energy_total                                                              0.0045   \n",
       "gpu_energy_total                                                            0.016062   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  25  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    259   \n",
       "date_time                                              April 11, 2025 at 05:43:00 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.020612   \n",
       "total_energy_joules                                                     74203.606308   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.220798   \n",
       "joules_per_token                                                            4.529029   \n",
       "flops_per_joule                                                     228425164.711328   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.306288   \n",
       "average_latency_ms_per_batch                                             4538.285978   \n",
       "throughput_queries_per_sec                                                   3.52556   \n",
       "throughput_tokens_per_sec                                                 451.271694   \n",
       "total_energy_kwh_process_0                                                  0.005172   \n",
       "total_energy_kwh_process_1                                                  0.005173   \n",
       "total_energy_kwh_process_2                                                  0.005116   \n",
       "total_energy_kwh_process_3                                                  0.005151   \n",
       "gpu_power_avg                                                             495.914887   \n",
       "ram_power_avg                                                               0.951728   \n",
       "cpu_energy_total                                                             0.00447   \n",
       "gpu_energy_total                                                            0.016112   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  26  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    260   \n",
       "date_time                                              April 11, 2025 at 05:44:05 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.020695   \n",
       "total_energy_joules                                                     74501.001648   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.219917   \n",
       "joules_per_token                                                             4.54718   \n",
       "flops_per_joule                                                      227513330.26575   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.211281   \n",
       "average_latency_ms_per_batch                                             4526.410158   \n",
       "throughput_queries_per_sec                                                   3.53481   \n",
       "throughput_tokens_per_sec                                                 452.455683   \n",
       "total_energy_kwh_process_0                                                   0.00517   \n",
       "total_energy_kwh_process_1                                                  0.005199   \n",
       "total_energy_kwh_process_2                                                  0.005132   \n",
       "total_energy_kwh_process_3                                                  0.005193   \n",
       "gpu_power_avg                                                             412.077225   \n",
       "ram_power_avg                                                               0.948094   \n",
       "cpu_energy_total                                                            0.004483   \n",
       "gpu_energy_total                                                            0.016181   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  27  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    261   \n",
       "date_time                                              April 11, 2025 at 05:45:11 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021096   \n",
       "total_energy_joules                                                     75946.539604   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215731   \n",
       "joules_per_token                                                            4.635409   \n",
       "flops_per_joule                                                     223182926.853609   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.147624   \n",
       "average_latency_ms_per_batch                                             4643.452946   \n",
       "throughput_queries_per_sec                                                  3.445712   \n",
       "throughput_tokens_per_sec                                                 441.051094   \n",
       "total_energy_kwh_process_0                                                  0.005295   \n",
       "total_energy_kwh_process_1                                                   0.00525   \n",
       "total_energy_kwh_process_2                                                  0.005203   \n",
       "total_energy_kwh_process_3                                                  0.005348   \n",
       "gpu_power_avg                                                             383.197083   \n",
       "ram_power_avg                                                               0.962667   \n",
       "cpu_energy_total                                                            0.004568   \n",
       "gpu_energy_total                                                            0.016497   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  28  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    262   \n",
       "date_time                                              April 11, 2025 at 05:46:17 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021167   \n",
       "total_energy_joules                                                     76201.793024   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215008   \n",
       "joules_per_token                                                            4.650988   \n",
       "flops_per_joule                                                     222435330.199059   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.538299   \n",
       "average_latency_ms_per_batch                                             4692.287417   \n",
       "throughput_queries_per_sec                                                  3.409851   \n",
       "throughput_tokens_per_sec                                                 436.460902   \n",
       "total_energy_kwh_process_0                                                  0.005316   \n",
       "total_energy_kwh_process_1                                                   0.00533   \n",
       "total_energy_kwh_process_2                                                  0.005233   \n",
       "total_energy_kwh_process_3                                                  0.005289   \n",
       "gpu_power_avg                                                             390.294755   \n",
       "ram_power_avg                                                               0.963921   \n",
       "cpu_energy_total                                                            0.004614   \n",
       "gpu_energy_total                                                            0.016523   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  29  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    263   \n",
       "date_time                                              April 11, 2025 at 05:47:23 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021317   \n",
       "total_energy_joules                                                     76742.959091   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.213492   \n",
       "joules_per_token                                                            4.684018   \n",
       "flops_per_joule                                                     220866789.524664   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.345801   \n",
       "average_latency_ms_per_batch                                             4668.225076   \n",
       "throughput_queries_per_sec                                                  3.427427   \n",
       "throughput_tokens_per_sec                                                 438.710638   \n",
       "total_energy_kwh_process_0                                                  0.005347   \n",
       "total_energy_kwh_process_1                                                  0.005325   \n",
       "total_energy_kwh_process_2                                                  0.005325   \n",
       "total_energy_kwh_process_3                                                  0.005321   \n",
       "gpu_power_avg                                                             571.329062   \n",
       "ram_power_avg                                                                0.95377   \n",
       "cpu_energy_total                                                            0.004592   \n",
       "gpu_energy_total                                                            0.016694   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  30  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    264   \n",
       "date_time                                              April 11, 2025 at 05:48:29 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021256   \n",
       "total_energy_joules                                                     76520.796084   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214112   \n",
       "joules_per_token                                                            4.670459   \n",
       "flops_per_joule                                                     221508032.594712   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.266966   \n",
       "average_latency_ms_per_batch                                             4658.370769   \n",
       "throughput_queries_per_sec                                                  3.434677   \n",
       "throughput_tokens_per_sec                                                 439.638685   \n",
       "total_energy_kwh_process_0                                                   0.00534   \n",
       "total_energy_kwh_process_1                                                  0.005234   \n",
       "total_energy_kwh_process_2                                                  0.005355   \n",
       "total_energy_kwh_process_3                                                  0.005327   \n",
       "gpu_power_avg                                                             392.706854   \n",
       "ram_power_avg                                                                0.96025   \n",
       "cpu_energy_total                                                            0.004588   \n",
       "gpu_energy_total                                                            0.016637   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  31  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    265   \n",
       "date_time                                              April 11, 2025 at 05:49:38 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021237   \n",
       "total_energy_joules                                                       76452.8938   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214302   \n",
       "joules_per_token                                                            4.666314   \n",
       "flops_per_joule                                                     221704766.827728   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    37.24014   \n",
       "average_latency_ms_per_batch                                              4655.01752   \n",
       "throughput_queries_per_sec                                                  3.437151   \n",
       "throughput_tokens_per_sec                                                  439.95538   \n",
       "total_energy_kwh_process_0                                                  0.005323   \n",
       "total_energy_kwh_process_1                                                  0.005277   \n",
       "total_energy_kwh_process_2                                                  0.005304   \n",
       "total_energy_kwh_process_3                                                  0.005333   \n",
       "gpu_power_avg                                                             367.056529   \n",
       "ram_power_avg                                                               0.961562   \n",
       "cpu_energy_total                                                            0.004594   \n",
       "gpu_energy_total                                                            0.016611   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  32  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    266   \n",
       "date_time                                              April 11, 2025 at 05:50:44 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021173   \n",
       "total_energy_joules                                                     76223.569931   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214947   \n",
       "joules_per_token                                                            4.652318   \n",
       "flops_per_joule                                                      222371780.91456   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.286302   \n",
       "average_latency_ms_per_batch                                             4660.787711   \n",
       "throughput_queries_per_sec                                                  3.432896   \n",
       "throughput_tokens_per_sec                                                 439.410702   \n",
       "total_energy_kwh_process_0                                                   0.00533   \n",
       "total_energy_kwh_process_1                                                  0.005243   \n",
       "total_energy_kwh_process_2                                                  0.005314   \n",
       "total_energy_kwh_process_3                                                  0.005286   \n",
       "gpu_power_avg                                                             474.542887   \n",
       "ram_power_avg                                                               0.958358   \n",
       "cpu_energy_total                                                            0.004563   \n",
       "gpu_energy_total                                                            0.016579   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  33  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    267   \n",
       "date_time                                              April 11, 2025 at 05:51:50 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021219   \n",
       "total_energy_joules                                                     76386.637887   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214488   \n",
       "joules_per_token                                                             4.66227   \n",
       "flops_per_joule                                                     221897068.152067   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.472509   \n",
       "average_latency_ms_per_batch                                             4684.063664   \n",
       "throughput_queries_per_sec                                                  3.415837   \n",
       "throughput_tokens_per_sec                                                 437.227191   \n",
       "total_energy_kwh_process_0                                                  0.005341   \n",
       "total_energy_kwh_process_1                                                  0.005303   \n",
       "total_energy_kwh_process_2                                                  0.005276   \n",
       "total_energy_kwh_process_3                                                  0.005299   \n",
       "gpu_power_avg                                                              334.40488   \n",
       "ram_power_avg                                                               0.952374   \n",
       "cpu_energy_total                                                            0.004593   \n",
       "gpu_energy_total                                                            0.016594   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  34  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    268   \n",
       "date_time                                              April 11, 2025 at 05:52:55 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021218   \n",
       "total_energy_joules                                                     76383.180866   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214497   \n",
       "joules_per_token                                                            4.662059   \n",
       "flops_per_joule                                                     221907110.976747   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.066333   \n",
       "average_latency_ms_per_batch                                              4633.29158   \n",
       "throughput_queries_per_sec                                                  3.453269   \n",
       "throughput_tokens_per_sec                                                 442.018372   \n",
       "total_energy_kwh_process_0                                                  0.005302   \n",
       "total_energy_kwh_process_1                                                   0.00528   \n",
       "total_energy_kwh_process_2                                                  0.005318   \n",
       "total_energy_kwh_process_3                                                  0.005318   \n",
       "gpu_power_avg                                                             367.160655   \n",
       "ram_power_avg                                                                0.95813   \n",
       "cpu_energy_total                                                            0.004591   \n",
       "gpu_energy_total                                                            0.016596   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  35  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    269   \n",
       "date_time                                              April 11, 2025 at 05:54:01 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021238   \n",
       "total_energy_joules                                                     76458.267707   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214287   \n",
       "joules_per_token                                                            4.666642   \n",
       "flops_per_joule                                                     221689184.198326   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.176715   \n",
       "average_latency_ms_per_batch                                             4647.089355   \n",
       "throughput_queries_per_sec                                                  3.443015   \n",
       "throughput_tokens_per_sec                                                 440.705965   \n",
       "total_energy_kwh_process_0                                                  0.005306   \n",
       "total_energy_kwh_process_1                                                  0.005318   \n",
       "total_energy_kwh_process_2                                                  0.005307   \n",
       "total_energy_kwh_process_3                                                  0.005307   \n",
       "gpu_power_avg                                                             503.445063   \n",
       "ram_power_avg                                                                0.95802   \n",
       "cpu_energy_total                                                            0.004591   \n",
       "gpu_energy_total                                                            0.016617   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  36  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    270   \n",
       "date_time                                              April 11, 2025 at 05:55:07 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021238   \n",
       "total_energy_joules                                                     76456.077645   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214293   \n",
       "joules_per_token                                                            4.666509   \n",
       "flops_per_joule                                                      221695534.41967   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.421394   \n",
       "average_latency_ms_per_batch                                             4677.674297   \n",
       "throughput_queries_per_sec                                                  3.420503   \n",
       "throughput_tokens_per_sec                                                 437.824412   \n",
       "total_energy_kwh_process_0                                                  0.005313   \n",
       "total_energy_kwh_process_1                                                  0.005295   \n",
       "total_energy_kwh_process_2                                                   0.00534   \n",
       "total_energy_kwh_process_3                                                   0.00529   \n",
       "gpu_power_avg                                                             410.155781   \n",
       "ram_power_avg                                                               0.962087   \n",
       "cpu_energy_total                                                            0.004617   \n",
       "gpu_energy_total                                                             0.01659   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  37  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    271   \n",
       "date_time                                              April 11, 2025 at 05:56:12 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021201   \n",
       "total_energy_joules                                                     76322.508765   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214668   \n",
       "joules_per_token                                                            4.658356   \n",
       "flops_per_joule                                                     222083514.646961   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.979404   \n",
       "average_latency_ms_per_batch                                             4622.425475   \n",
       "throughput_queries_per_sec                                                  3.461386   \n",
       "throughput_tokens_per_sec                                                 443.057441   \n",
       "total_energy_kwh_process_0                                                  0.005335   \n",
       "total_energy_kwh_process_1                                                  0.005315   \n",
       "total_energy_kwh_process_2                                                  0.005337   \n",
       "total_energy_kwh_process_3                                                  0.005215   \n",
       "gpu_power_avg                                                             195.802022   \n",
       "ram_power_avg                                                               0.958308   \n",
       "cpu_energy_total                                                            0.004625   \n",
       "gpu_energy_total                                                            0.016545   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  38  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    272   \n",
       "date_time                                              April 11, 2025 at 05:57:18 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021264   \n",
       "total_energy_joules                                                     76552.127557   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214024   \n",
       "joules_per_token                                                            4.672371   \n",
       "flops_per_joule                                                     221417373.154566   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.373825   \n",
       "average_latency_ms_per_batch                                              4671.72815   \n",
       "throughput_queries_per_sec                                                  3.424857   \n",
       "throughput_tokens_per_sec                                                 438.381673   \n",
       "total_energy_kwh_process_0                                                  0.005321   \n",
       "total_energy_kwh_process_1                                                  0.005325   \n",
       "total_energy_kwh_process_2                                                  0.005309   \n",
       "total_energy_kwh_process_3                                                   0.00531   \n",
       "gpu_power_avg                                                             291.842585   \n",
       "ram_power_avg                                                                0.95993   \n",
       "cpu_energy_total                                                            0.004642   \n",
       "gpu_energy_total                                                            0.016591   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  39  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    273   \n",
       "date_time                                              April 11, 2025 at 05:58:24 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021225   \n",
       "total_energy_joules                                                     76410.590357   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214421   \n",
       "joules_per_token                                                            4.663732   \n",
       "flops_per_joule                                                     221827509.955699   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.459553   \n",
       "average_latency_ms_per_batch                                             4682.444169   \n",
       "throughput_queries_per_sec                                                  3.417019   \n",
       "throughput_tokens_per_sec                                                 437.378413   \n",
       "total_energy_kwh_process_0                                                  0.005359   \n",
       "total_energy_kwh_process_1                                                   0.00526   \n",
       "total_energy_kwh_process_2                                                  0.005322   \n",
       "total_energy_kwh_process_3                                                  0.005285   \n",
       "gpu_power_avg                                                             337.884587   \n",
       "ram_power_avg                                                               0.964699   \n",
       "cpu_energy_total                                                            0.004581   \n",
       "gpu_energy_total                                                            0.016613   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  40  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    274   \n",
       "date_time                                              April 11, 2025 at 05:59:29 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021234   \n",
       "total_energy_joules                                                     76443.543844   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214328   \n",
       "joules_per_token                                                            4.665744   \n",
       "flops_per_joule                                                     221731883.961792   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.784267   \n",
       "average_latency_ms_per_batch                                              4598.03337   \n",
       "throughput_queries_per_sec                                                  3.479749   \n",
       "throughput_tokens_per_sec                                                 445.407816   \n",
       "total_energy_kwh_process_0                                                  0.005304   \n",
       "total_energy_kwh_process_1                                                  0.005307   \n",
       "total_energy_kwh_process_2                                                  0.005307   \n",
       "total_energy_kwh_process_3                                                  0.005317   \n",
       "gpu_power_avg                                                             439.834917   \n",
       "ram_power_avg                                                               0.955347   \n",
       "cpu_energy_total                                                            0.004556   \n",
       "gpu_energy_total                                                            0.016648   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  41  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    275   \n",
       "date_time                                              April 11, 2025 at 06:00:36 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021319   \n",
       "total_energy_joules                                                     76748.976626   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.213475   \n",
       "joules_per_token                                                            4.684386   \n",
       "flops_per_joule                                                     220849472.375148   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.335853   \n",
       "average_latency_ms_per_batch                                             4666.981563   \n",
       "throughput_queries_per_sec                                                   3.42834   \n",
       "throughput_tokens_per_sec                                                 438.827532   \n",
       "total_energy_kwh_process_0                                                  0.005338   \n",
       "total_energy_kwh_process_1                                                  0.005326   \n",
       "total_energy_kwh_process_2                                                  0.005322   \n",
       "total_energy_kwh_process_3                                                  0.005333   \n",
       "gpu_power_avg                                                             432.162595   \n",
       "ram_power_avg                                                               0.959208   \n",
       "cpu_energy_total                                                            0.004604   \n",
       "gpu_energy_total                                                            0.016684   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  42  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    276   \n",
       "date_time                                              April 11, 2025 at 06:01:44 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021258   \n",
       "total_energy_joules                                                     76530.379229   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214085   \n",
       "joules_per_token                                                            4.671044   \n",
       "flops_per_joule                                                     221480295.326627   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.763149   \n",
       "average_latency_ms_per_batch                                             4595.393663   \n",
       "throughput_queries_per_sec                                                  3.481747   \n",
       "throughput_tokens_per_sec                                                 445.663669   \n",
       "total_energy_kwh_process_0                                                  0.005282   \n",
       "total_energy_kwh_process_1                                                  0.005309   \n",
       "total_energy_kwh_process_2                                                  0.005331   \n",
       "total_energy_kwh_process_3                                                  0.005336   \n",
       "gpu_power_avg                                                             367.760453   \n",
       "ram_power_avg                                                               0.960846   \n",
       "cpu_energy_total                                                            0.004579   \n",
       "gpu_energy_total                                                            0.016649   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  43  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    277   \n",
       "date_time                                              April 11, 2025 at 06:02:51 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021287   \n",
       "total_energy_joules                                                     76631.935788   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.213801   \n",
       "joules_per_token                                                            4.677242   \n",
       "flops_per_joule                                                     221186778.315872   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.198482   \n",
       "average_latency_ms_per_batch                                             4649.810295   \n",
       "throughput_queries_per_sec                                                  3.441001   \n",
       "throughput_tokens_per_sec                                                 440.448076   \n",
       "total_energy_kwh_process_0                                                  0.005281   \n",
       "total_energy_kwh_process_1                                                  0.005321   \n",
       "total_energy_kwh_process_2                                                  0.005364   \n",
       "total_energy_kwh_process_3                                                   0.00532   \n",
       "gpu_power_avg                                                             397.983108   \n",
       "ram_power_avg                                                               0.962158   \n",
       "cpu_energy_total                                                            0.004634   \n",
       "gpu_energy_total                                                            0.016622   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  44  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    278   \n",
       "date_time                                              April 11, 2025 at 06:03:57 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021207   \n",
       "total_energy_joules                                                     76346.735078   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                              0.2146   \n",
       "joules_per_token                                                            4.659835   \n",
       "flops_per_joule                                                     222013043.200503   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.812719   \n",
       "average_latency_ms_per_batch                                              4601.58986   \n",
       "throughput_queries_per_sec                                                  3.477059   \n",
       "throughput_tokens_per_sec                                                 445.063568   \n",
       "total_energy_kwh_process_0                                                  0.005293   \n",
       "total_energy_kwh_process_1                                                  0.005297   \n",
       "total_energy_kwh_process_2                                                  0.005293   \n",
       "total_energy_kwh_process_3                                                  0.005324   \n",
       "gpu_power_avg                                                             584.680567   \n",
       "ram_power_avg                                                               0.962879   \n",
       "cpu_energy_total                                                             0.00456   \n",
       "gpu_energy_total                                                            0.016617   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  45  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    279   \n",
       "date_time                                              April 11, 2025 at 06:05:03 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021255   \n",
       "total_energy_joules                                                     76517.116778   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214122   \n",
       "joules_per_token                                                            4.670234   \n",
       "flops_per_joule                                                     221518683.752156   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.283309   \n",
       "average_latency_ms_per_batch                                             4660.413619   \n",
       "throughput_queries_per_sec                                                  3.433172   \n",
       "throughput_tokens_per_sec                                                 439.445974   \n",
       "total_energy_kwh_process_0                                                  0.005315   \n",
       "total_energy_kwh_process_1                                                  0.005325   \n",
       "total_energy_kwh_process_2                                                  0.005315   \n",
       "total_energy_kwh_process_3                                                  0.005301   \n",
       "gpu_power_avg                                                             404.882464   \n",
       "ram_power_avg                                                               0.962166   \n",
       "cpu_energy_total                                                            0.004611   \n",
       "gpu_energy_total                                                            0.016612   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  46  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    280   \n",
       "date_time                                              April 11, 2025 at 06:06:10 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021197   \n",
       "total_energy_joules                                                     76308.943626   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214706   \n",
       "joules_per_token                                                            4.657528   \n",
       "flops_per_joule                                                     222122993.553691   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.419533   \n",
       "average_latency_ms_per_batch                                             4677.441662   \n",
       "throughput_queries_per_sec                                                  3.420673   \n",
       "throughput_tokens_per_sec                                                 437.846188   \n",
       "total_energy_kwh_process_0                                                  0.005325   \n",
       "total_energy_kwh_process_1                                                  0.005335   \n",
       "total_energy_kwh_process_2                                                  0.005234   \n",
       "total_energy_kwh_process_3                                                  0.005302   \n",
       "gpu_power_avg                                                             373.916889   \n",
       "ram_power_avg                                                               0.965268   \n",
       "cpu_energy_total                                                              0.0046   \n",
       "gpu_energy_total                                                            0.016566   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  47  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    281   \n",
       "date_time                                              April 11, 2025 at 06:07:16 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021211   \n",
       "total_energy_joules                                                     76361.089511   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                             0.21456   \n",
       "joules_per_token                                                            4.660711   \n",
       "flops_per_joule                                                     221971308.970354   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.420523   \n",
       "average_latency_ms_per_batch                                             4677.565389   \n",
       "throughput_queries_per_sec                                                  3.420583   \n",
       "throughput_tokens_per_sec                                                 437.834606   \n",
       "total_energy_kwh_process_0                                                  0.005327   \n",
       "total_energy_kwh_process_1                                                  0.005263   \n",
       "total_energy_kwh_process_2                                                  0.005292   \n",
       "total_energy_kwh_process_3                                                   0.00533   \n",
       "gpu_power_avg                                                             373.171862   \n",
       "ram_power_avg                                                               0.959845   \n",
       "cpu_energy_total                                                            0.004603   \n",
       "gpu_energy_total                                                            0.016577   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  48  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    282   \n",
       "date_time                                              April 11, 2025 at 06:08:21 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021179   \n",
       "total_energy_joules                                                     76245.168806   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214886   \n",
       "joules_per_token                                                            4.653636   \n",
       "flops_per_joule                                                     222308787.015928   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.239923   \n",
       "average_latency_ms_per_batch                                             4654.990417   \n",
       "throughput_queries_per_sec                                                  3.437171   \n",
       "throughput_tokens_per_sec                                                 439.957941   \n",
       "total_energy_kwh_process_0                                                  0.005317   \n",
       "total_energy_kwh_process_1                                                  0.005307   \n",
       "total_energy_kwh_process_2                                                  0.005249   \n",
       "total_energy_kwh_process_3                                                  0.005306   \n",
       "gpu_power_avg                                                             581.747394   \n",
       "ram_power_avg                                                               0.963443   \n",
       "cpu_energy_total                                                            0.004577   \n",
       "gpu_energy_total                                                            0.016571   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  49  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    283   \n",
       "date_time                                              April 11, 2025 at 06:09:27 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                             0.02115   \n",
       "total_energy_joules                                                      76141.04486   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                             0.21518   \n",
       "joules_per_token                                                            4.647281   \n",
       "flops_per_joule                                                     222612797.398213   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.278837   \n",
       "average_latency_ms_per_batch                                             4659.854676   \n",
       "throughput_queries_per_sec                                                  3.433583   \n",
       "throughput_tokens_per_sec                                                 439.498684   \n",
       "total_energy_kwh_process_0                                                  0.005316   \n",
       "total_energy_kwh_process_1                                                  0.005318   \n",
       "total_energy_kwh_process_2                                                  0.005273   \n",
       "total_energy_kwh_process_3                                                  0.005243   \n",
       "gpu_power_avg                                                             396.201549   \n",
       "ram_power_avg                                                               0.963372   \n",
       "cpu_energy_total                                                            0.004582   \n",
       "gpu_energy_total                                                            0.016538   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  50  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    284   \n",
       "date_time                                              April 11, 2025 at 06:10:32 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021163   \n",
       "total_energy_joules                                                     76187.233345   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215049   \n",
       "joules_per_token                                                              4.6501   \n",
       "flops_per_joule                                                     222477838.462899   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    37.05608   \n",
       "average_latency_ms_per_batch                                              4632.01002   \n",
       "throughput_queries_per_sec                                                  3.454224   \n",
       "throughput_tokens_per_sec                                                 442.140667   \n",
       "total_energy_kwh_process_0                                                  0.005299   \n",
       "total_energy_kwh_process_1                                                  0.005315   \n",
       "total_energy_kwh_process_2                                                  0.005281   \n",
       "total_energy_kwh_process_3                                                  0.005268   \n",
       "gpu_power_avg                                                             525.567555   \n",
       "ram_power_avg                                                               0.966059   \n",
       "cpu_energy_total                                                            0.004574   \n",
       "gpu_energy_total                                                            0.016558   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  51  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    285   \n",
       "date_time                                              April 11, 2025 at 06:11:38 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021133   \n",
       "total_energy_joules                                                     76079.755405   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215353   \n",
       "joules_per_token                                                             4.64354   \n",
       "flops_per_joule                                                     222792133.111257   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.896263   \n",
       "average_latency_ms_per_batch                                             4612.032873   \n",
       "throughput_queries_per_sec                                                  3.469186   \n",
       "throughput_tokens_per_sec                                                 444.055811   \n",
       "total_energy_kwh_process_0                                                  0.005281   \n",
       "total_energy_kwh_process_1                                                  0.005289   \n",
       "total_energy_kwh_process_2                                                  0.005327   \n",
       "total_energy_kwh_process_3                                                  0.005236   \n",
       "gpu_power_avg                                                             399.772335   \n",
       "ram_power_avg                                                               0.954208   \n",
       "cpu_energy_total                                                            0.004564   \n",
       "gpu_energy_total                                                            0.016539   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  52  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_20_decoder_temper...   \n",
       "experiment_id                                                                    286   \n",
       "date_time                                              April 11, 2025 at 06:12:45 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                     20   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021166   \n",
       "total_energy_joules                                                     76195.841449   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215025   \n",
       "joules_per_token                                                            4.650625   \n",
       "flops_per_joule                                                     222452704.383082   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.303935   \n",
       "average_latency_ms_per_batch                                             4662.991815   \n",
       "throughput_queries_per_sec                                                  3.431273   \n",
       "throughput_tokens_per_sec                                                 439.203001   \n",
       "total_energy_kwh_process_0                                                  0.005296   \n",
       "total_energy_kwh_process_1                                                  0.005289   \n",
       "total_energy_kwh_process_2                                                  0.005251   \n",
       "total_energy_kwh_process_3                                                  0.005329   \n",
       "gpu_power_avg                                                             389.105744   \n",
       "ram_power_avg                                                               0.963354   \n",
       "cpu_energy_total                                                            0.004612   \n",
       "gpu_energy_total                                                            0.016522   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  53  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_50_decoder_temper...   \n",
       "experiment_id                                                                    287   \n",
       "date_time                                              April 11, 2025 at 06:13:51 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                     50   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021162   \n",
       "total_energy_joules                                                     76181.591128   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215065   \n",
       "joules_per_token                                                            4.649755   \n",
       "flops_per_joule                                                     222494315.782651   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.005236   \n",
       "average_latency_ms_per_batch                                             4625.654561   \n",
       "throughput_queries_per_sec                                                   3.45897   \n",
       "throughput_tokens_per_sec                                                  442.74815   \n",
       "total_energy_kwh_process_0                                                  0.005303   \n",
       "total_energy_kwh_process_1                                                  0.005316   \n",
       "total_energy_kwh_process_2                                                  0.005235   \n",
       "total_energy_kwh_process_3                                                  0.005308   \n",
       "gpu_power_avg                                                             277.971773   \n",
       "ram_power_avg                                                               0.962415   \n",
       "cpu_energy_total                                                            0.004634   \n",
       "gpu_energy_total                                                            0.016496   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  54  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_100_decoder_tempe...   \n",
       "experiment_id                                                                    288   \n",
       "date_time                                              April 11, 2025 at 06:14:58 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                    100   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021253   \n",
       "total_energy_joules                                                      76512.58586   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214135   \n",
       "joules_per_token                                                            4.669958   \n",
       "flops_per_joule                                                      221531801.63285   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.377651   \n",
       "average_latency_ms_per_batch                                             4672.206413   \n",
       "throughput_queries_per_sec                                                  3.424506   \n",
       "throughput_tokens_per_sec                                                 438.336798   \n",
       "total_energy_kwh_process_0                                                  0.005313   \n",
       "total_energy_kwh_process_1                                                  0.005352   \n",
       "total_energy_kwh_process_2                                                  0.005294   \n",
       "total_energy_kwh_process_3                                                  0.005294   \n",
       "gpu_power_avg                                                             384.025206   \n",
       "ram_power_avg                                                               0.957899   \n",
       "cpu_energy_total                                                            0.004625   \n",
       "gpu_energy_total                                                            0.016597   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  55  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_200_decoder_tempe...   \n",
       "experiment_id                                                                    289   \n",
       "date_time                                              April 11, 2025 at 06:16:04 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                    200   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021272   \n",
       "total_energy_joules                                                     76578.514995   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                             0.21395   \n",
       "joules_per_token                                                            4.673982   \n",
       "flops_per_joule                                                     221341077.118197   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.014072   \n",
       "average_latency_ms_per_batch                                              4626.75899   \n",
       "throughput_queries_per_sec                                                  3.458144   \n",
       "throughput_tokens_per_sec                                                 442.642464   \n",
       "total_energy_kwh_process_0                                                  0.005304   \n",
       "total_energy_kwh_process_1                                                  0.005329   \n",
       "total_energy_kwh_process_2                                                   0.00531   \n",
       "total_energy_kwh_process_3                                                  0.005329   \n",
       "gpu_power_avg                                                            1477.347167   \n",
       "ram_power_avg                                                                0.96216   \n",
       "cpu_energy_total                                                            0.004598   \n",
       "gpu_energy_total                                                            0.016642   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  56  \\\n",
       "config_name                        decoding_top_k_decoder_top_k_500_decoder_tempe...   \n",
       "experiment_id                                                                    290   \n",
       "date_time                                              April 11, 2025 at 06:17:15 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                    500   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021315   \n",
       "total_energy_joules                                                     76733.750114   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.213518   \n",
       "joules_per_token                                                            4.683456   \n",
       "flops_per_joule                                                     220893296.207842   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.463349   \n",
       "average_latency_ms_per_batch                                             4682.918639   \n",
       "throughput_queries_per_sec                                                  3.416673   \n",
       "throughput_tokens_per_sec                                                 437.334098   \n",
       "total_energy_kwh_process_0                                                   0.00536   \n",
       "total_energy_kwh_process_1                                                  0.005324   \n",
       "total_energy_kwh_process_2                                                  0.005334   \n",
       "total_energy_kwh_process_3                                                  0.005297   \n",
       "gpu_power_avg                                                             451.401374   \n",
       "ram_power_avg                                                               0.960668   \n",
       "cpu_energy_total                                                            0.004594   \n",
       "gpu_energy_total                                                             0.01669   \n",
       "decoder_config_decoding_mode                                                   top_k   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  57  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    296   \n",
       "date_time                                              April 11, 2025 at 06:20:42 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.020483   \n",
       "total_energy_joules                                                      73737.29051   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.222194   \n",
       "joules_per_token                                                            4.500567   \n",
       "flops_per_joule                                                      229869729.08804   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.610644   \n",
       "average_latency_ms_per_batch                                             4576.330444   \n",
       "throughput_queries_per_sec                                                  3.496251   \n",
       "throughput_tokens_per_sec                                                 447.520131   \n",
       "total_energy_kwh_process_0                                                  0.005141   \n",
       "total_energy_kwh_process_1                                                  0.005133   \n",
       "total_energy_kwh_process_2                                                  0.005125   \n",
       "total_energy_kwh_process_3                                                  0.005083   \n",
       "gpu_power_avg                                                             555.380175   \n",
       "ram_power_avg                                                               0.953066   \n",
       "cpu_energy_total                                                            0.004497   \n",
       "gpu_energy_total                                                            0.015956   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  58  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    297   \n",
       "date_time                                              April 11, 2025 at 06:21:47 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.020574   \n",
       "total_energy_joules                                                     74065.599056   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.221209   \n",
       "joules_per_token                                                            4.520605   \n",
       "flops_per_joule                                                      228850791.85564   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    36.43053   \n",
       "average_latency_ms_per_batch                                             4553.816217   \n",
       "throughput_queries_per_sec                                                  3.513537   \n",
       "throughput_tokens_per_sec                                                 449.732686   \n",
       "total_energy_kwh_process_0                                                  0.005139   \n",
       "total_energy_kwh_process_1                                                  0.005133   \n",
       "total_energy_kwh_process_2                                                   0.00513   \n",
       "total_energy_kwh_process_3                                                  0.005172   \n",
       "gpu_power_avg                                                             406.571211   \n",
       "ram_power_avg                                                               0.949621   \n",
       "cpu_energy_total                                                            0.004512   \n",
       "gpu_energy_total                                                            0.016032   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  59  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    298   \n",
       "date_time                                              April 11, 2025 at 06:22:52 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.020635   \n",
       "total_energy_joules                                                     74286.409458   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.220552   \n",
       "joules_per_token                                                            4.534083   \n",
       "flops_per_joule                                                     228170551.204544   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.471863   \n",
       "average_latency_ms_per_batch                                             4558.982923   \n",
       "throughput_queries_per_sec                                                  3.509555   \n",
       "throughput_tokens_per_sec                                                 449.223003   \n",
       "total_energy_kwh_process_0                                                  0.005171   \n",
       "total_energy_kwh_process_1                                                  0.005132   \n",
       "total_energy_kwh_process_2                                                  0.005172   \n",
       "total_energy_kwh_process_3                                                   0.00516   \n",
       "gpu_power_avg                                                             375.751597   \n",
       "ram_power_avg                                                               0.955473   \n",
       "cpu_energy_total                                                            0.004496   \n",
       "gpu_energy_total                                                            0.016109   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  60  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    299   \n",
       "date_time                                              April 11, 2025 at 06:23:58 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                             0.02061   \n",
       "total_energy_joules                                                     74197.531957   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.220816   \n",
       "joules_per_token                                                            4.528658   \n",
       "flops_per_joule                                                     228443865.261377   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.407234   \n",
       "average_latency_ms_per_batch                                             4550.904239   \n",
       "throughput_queries_per_sec                                                  3.515785   \n",
       "throughput_tokens_per_sec                                                 450.020456   \n",
       "total_energy_kwh_process_0                                                  0.005172   \n",
       "total_energy_kwh_process_1                                                  0.005148   \n",
       "total_energy_kwh_process_2                                                  0.005214   \n",
       "total_energy_kwh_process_3                                                  0.005077   \n",
       "gpu_power_avg                                                             371.866695   \n",
       "ram_power_avg                                                               0.956434   \n",
       "cpu_energy_total                                                            0.004484   \n",
       "gpu_energy_total                                                            0.016096   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  61  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    300   \n",
       "date_time                                              April 11, 2025 at 06:25:04 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021128   \n",
       "total_energy_joules                                                     76059.345286   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215411   \n",
       "joules_per_token                                                            4.642294   \n",
       "flops_per_joule                                                     222851918.188743   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.230651   \n",
       "average_latency_ms_per_batch                                             4653.831399   \n",
       "throughput_queries_per_sec                                                  3.438027   \n",
       "throughput_tokens_per_sec                                                 440.067511   \n",
       "total_energy_kwh_process_0                                                   0.00532   \n",
       "total_energy_kwh_process_1                                                   0.00522   \n",
       "total_energy_kwh_process_2                                                  0.005261   \n",
       "total_energy_kwh_process_3                                                  0.005326   \n",
       "gpu_power_avg                                                             311.990543   \n",
       "ram_power_avg                                                               0.945956   \n",
       "cpu_energy_total                                                            0.004586   \n",
       "gpu_energy_total                                                            0.016511   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  62  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    301   \n",
       "date_time                                              April 11, 2025 at 06:26:10 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021085   \n",
       "total_energy_joules                                                     75905.904876   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215846   \n",
       "joules_per_token                                                            4.632929   \n",
       "flops_per_joule                                                     223302403.426195   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.061346   \n",
       "average_latency_ms_per_batch                                             4632.668298   \n",
       "throughput_queries_per_sec                                                  3.453733   \n",
       "throughput_tokens_per_sec                                                 442.077841   \n",
       "total_energy_kwh_process_0                                                  0.005293   \n",
       "total_energy_kwh_process_1                                                  0.005214   \n",
       "total_energy_kwh_process_2                                                   0.00525   \n",
       "total_energy_kwh_process_3                                                  0.005328   \n",
       "gpu_power_avg                                                             297.637035   \n",
       "ram_power_avg                                                               0.955248   \n",
       "cpu_energy_total                                                            0.004565   \n",
       "gpu_energy_total                                                            0.016489   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  63  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    302   \n",
       "date_time                                              April 11, 2025 at 06:27:16 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021104   \n",
       "total_energy_joules                                                     75972.984254   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215656   \n",
       "joules_per_token                                                            4.637023   \n",
       "flops_per_joule                                                     223105241.417056   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.947661   \n",
       "average_latency_ms_per_batch                                             4618.457622   \n",
       "throughput_queries_per_sec                                                   3.46436   \n",
       "throughput_tokens_per_sec                                                 443.438084   \n",
       "total_energy_kwh_process_0                                                  0.005289   \n",
       "total_energy_kwh_process_1                                                  0.005256   \n",
       "total_energy_kwh_process_2                                                  0.005255   \n",
       "total_energy_kwh_process_3                                                  0.005304   \n",
       "gpu_power_avg                                                             319.099187   \n",
       "ram_power_avg                                                               0.959702   \n",
       "cpu_energy_total                                                             0.00456   \n",
       "gpu_energy_total                                                            0.016512   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  64  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    303   \n",
       "date_time                                              April 11, 2025 at 06:28:21 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021038   \n",
       "total_energy_joules                                                     75736.281912   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                             0.21633   \n",
       "joules_per_token                                                            4.622576   \n",
       "flops_per_joule                                                     223802523.245601   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.866788   \n",
       "average_latency_ms_per_batch                                             4608.348549   \n",
       "throughput_queries_per_sec                                                   3.47196   \n",
       "throughput_tokens_per_sec                                                 444.410829   \n",
       "total_energy_kwh_process_0                                                   0.00529   \n",
       "total_energy_kwh_process_1                                                  0.005249   \n",
       "total_energy_kwh_process_2                                                  0.005262   \n",
       "total_energy_kwh_process_3                                                  0.005237   \n",
       "gpu_power_avg                                                             422.491341   \n",
       "ram_power_avg                                                               0.958246   \n",
       "cpu_energy_total                                                            0.004529   \n",
       "gpu_energy_total                                                            0.016479   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  65  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    304   \n",
       "date_time                                              April 11, 2025 at 06:29:27 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021123   \n",
       "total_energy_joules                                                     76043.391166   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215456   \n",
       "joules_per_token                                                             4.64132   \n",
       "flops_per_joule                                                     222898673.155884   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.912187   \n",
       "average_latency_ms_per_batch                                             4614.023335   \n",
       "throughput_queries_per_sec                                                  3.467689   \n",
       "throughput_tokens_per_sec                                                 443.864249   \n",
       "total_energy_kwh_process_0                                                  0.005258   \n",
       "total_energy_kwh_process_1                                                  0.005295   \n",
       "total_energy_kwh_process_2                                                   0.00526   \n",
       "total_energy_kwh_process_3                                                   0.00531   \n",
       "gpu_power_avg                                                             385.364127   \n",
       "ram_power_avg                                                                0.95934   \n",
       "cpu_energy_total                                                            0.004583   \n",
       "gpu_energy_total                                                            0.016509   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  66  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    305   \n",
       "date_time                                              April 11, 2025 at 06:30:33 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021142   \n",
       "total_energy_joules                                                     76110.532775   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215266   \n",
       "joules_per_token                                                            4.645418   \n",
       "flops_per_joule                                                     222702041.034166   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.250632   \n",
       "average_latency_ms_per_batch                                             4656.328988   \n",
       "throughput_queries_per_sec                                                  3.436183   \n",
       "throughput_tokens_per_sec                                                 439.831465   \n",
       "total_energy_kwh_process_0                                                  0.005299   \n",
       "total_energy_kwh_process_1                                                  0.005266   \n",
       "total_energy_kwh_process_2                                                  0.005287   \n",
       "total_energy_kwh_process_3                                                   0.00529   \n",
       "gpu_power_avg                                                             529.887179   \n",
       "ram_power_avg                                                               0.964747   \n",
       "cpu_energy_total                                                            0.004589   \n",
       "gpu_energy_total                                                            0.016522   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  67  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    306   \n",
       "date_time                                              April 11, 2025 at 06:31:40 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021125   \n",
       "total_energy_joules                                                     76051.292784   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215434   \n",
       "joules_per_token                                                            4.641803   \n",
       "flops_per_joule                                                     222875514.308708   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.874463   \n",
       "average_latency_ms_per_batch                                             4609.307881   \n",
       "throughput_queries_per_sec                                                  3.471237   \n",
       "throughput_tokens_per_sec                                                 444.318334   \n",
       "total_energy_kwh_process_0                                                  0.005263   \n",
       "total_energy_kwh_process_1                                                  0.005225   \n",
       "total_energy_kwh_process_2                                                  0.005324   \n",
       "total_energy_kwh_process_3                                                  0.005313   \n",
       "gpu_power_avg                                                              384.95846   \n",
       "ram_power_avg                                                               0.956913   \n",
       "cpu_energy_total                                                            0.004571   \n",
       "gpu_energy_total                                                            0.016523   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  68  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    307   \n",
       "date_time                                              April 11, 2025 at 06:32:49 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.4   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021159   \n",
       "total_energy_joules                                                     76172.032345   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215092   \n",
       "joules_per_token                                                            4.649172   \n",
       "flops_per_joule                                                     222522236.459516   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.227124   \n",
       "average_latency_ms_per_batch                                              4653.39056   \n",
       "throughput_queries_per_sec                                                  3.438353   \n",
       "throughput_tokens_per_sec                                                 440.109201   \n",
       "total_energy_kwh_process_0                                                  0.005315   \n",
       "total_energy_kwh_process_1                                                  0.005277   \n",
       "total_energy_kwh_process_2                                                  0.005268   \n",
       "total_energy_kwh_process_3                                                  0.005299   \n",
       "gpu_power_avg                                                             323.807523   \n",
       "ram_power_avg                                                               0.954762   \n",
       "cpu_energy_total                                                            0.004575   \n",
       "gpu_energy_total                                                            0.016553   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  69  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    308   \n",
       "date_time                                              April 11, 2025 at 06:33:55 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021188   \n",
       "total_energy_joules                                                     76276.785887   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214797   \n",
       "joules_per_token                                                            4.655566   \n",
       "flops_per_joule                                                     222216638.996013   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    36.74442   \n",
       "average_latency_ms_per_batch                                             4593.052498   \n",
       "throughput_queries_per_sec                                                  3.483522   \n",
       "throughput_tokens_per_sec                                                 445.890832   \n",
       "total_energy_kwh_process_0                                                  0.005287   \n",
       "total_energy_kwh_process_1                                                  0.005339   \n",
       "total_energy_kwh_process_2                                                  0.005292   \n",
       "total_energy_kwh_process_3                                                   0.00527   \n",
       "gpu_power_avg                                                             416.411664   \n",
       "ram_power_avg                                                               0.957826   \n",
       "cpu_energy_total                                                            0.004557   \n",
       "gpu_energy_total                                                              0.0166   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  70  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    309   \n",
       "date_time                                              April 11, 2025 at 06:35:01 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021216   \n",
       "total_energy_joules                                                     76377.761846   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214513   \n",
       "joules_per_token                                                            4.661729   \n",
       "flops_per_joule                                                     221922855.337331   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.353906   \n",
       "average_latency_ms_per_batch                                             4669.238309   \n",
       "throughput_queries_per_sec                                                  3.426683   \n",
       "throughput_tokens_per_sec                                                 438.615437   \n",
       "total_energy_kwh_process_0                                                  0.005331   \n",
       "total_energy_kwh_process_1                                                  0.005257   \n",
       "total_energy_kwh_process_2                                                  0.005321   \n",
       "total_energy_kwh_process_3                                                  0.005307   \n",
       "gpu_power_avg                                                             375.259303   \n",
       "ram_power_avg                                                               0.956864   \n",
       "cpu_energy_total                                                            0.004589   \n",
       "gpu_energy_total                                                            0.016596   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  71  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    310   \n",
       "date_time                                              April 11, 2025 at 06:36:06 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021275   \n",
       "total_energy_joules                                                     76590.669268   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.213916   \n",
       "joules_per_token                                                            4.674723   \n",
       "flops_per_joule                                                     221305952.215789   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.856164   \n",
       "average_latency_ms_per_batch                                             4607.020464   \n",
       "throughput_queries_per_sec                                                   3.47296   \n",
       "throughput_tokens_per_sec                                                 444.538941   \n",
       "total_energy_kwh_process_0                                                  0.005291   \n",
       "total_energy_kwh_process_1                                                  0.005326   \n",
       "total_energy_kwh_process_2                                                  0.005323   \n",
       "total_energy_kwh_process_3                                                  0.005335   \n",
       "gpu_power_avg                                                             555.406601   \n",
       "ram_power_avg                                                               0.958314   \n",
       "cpu_energy_total                                                            0.004586   \n",
       "gpu_energy_total                                                            0.016658   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  72  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    311   \n",
       "date_time                                              April 11, 2025 at 06:37:12 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.6   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021175   \n",
       "total_energy_joules                                                     76229.985716   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214929   \n",
       "joules_per_token                                                            4.652709   \n",
       "flops_per_joule                                                     222353065.317298   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.478415   \n",
       "average_latency_ms_per_batch                                              4559.80192   \n",
       "throughput_queries_per_sec                                                  3.508924   \n",
       "throughput_tokens_per_sec                                                 449.142317   \n",
       "total_energy_kwh_process_0                                                  0.005258   \n",
       "total_energy_kwh_process_1                                                   0.00532   \n",
       "total_energy_kwh_process_2                                                  0.005312   \n",
       "total_energy_kwh_process_3                                                  0.005285   \n",
       "gpu_power_avg                                                             412.056644   \n",
       "ram_power_avg                                                               0.947865   \n",
       "cpu_energy_total                                                             0.00454   \n",
       "gpu_energy_total                                                            0.016605   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  73  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    312   \n",
       "date_time                                              April 11, 2025 at 06:38:18 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021218   \n",
       "total_energy_joules                                                     76384.326872   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214494   \n",
       "joules_per_token                                                            4.662129   \n",
       "flops_per_joule                                                     221903781.669947   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.804445   \n",
       "average_latency_ms_per_batch                                             4600.555674   \n",
       "throughput_queries_per_sec                                                  3.477841   \n",
       "throughput_tokens_per_sec                                                 445.163616   \n",
       "total_energy_kwh_process_0                                                  0.005293   \n",
       "total_energy_kwh_process_1                                                  0.005353   \n",
       "total_energy_kwh_process_2                                                  0.005268   \n",
       "total_energy_kwh_process_3                                                  0.005305   \n",
       "gpu_power_avg                                                             333.941971   \n",
       "ram_power_avg                                                                0.95182   \n",
       "cpu_energy_total                                                            0.004584   \n",
       "gpu_energy_total                                                            0.016603   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  74  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    313   \n",
       "date_time                                              April 11, 2025 at 06:39:24 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021133   \n",
       "total_energy_joules                                                     76078.501706   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215357   \n",
       "joules_per_token                                                            4.643463   \n",
       "flops_per_joule                                                      222795804.50584   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.749301   \n",
       "average_latency_ms_per_batch                                               4593.6626   \n",
       "throughput_queries_per_sec                                                  3.483059   \n",
       "throughput_tokens_per_sec                                                 445.831612   \n",
       "total_energy_kwh_process_0                                                  0.005274   \n",
       "total_energy_kwh_process_1                                                  0.005269   \n",
       "total_energy_kwh_process_2                                                  0.005319   \n",
       "total_energy_kwh_process_3                                                   0.00527   \n",
       "gpu_power_avg                                                             441.068223   \n",
       "ram_power_avg                                                               0.964067   \n",
       "cpu_energy_total                                                            0.004556   \n",
       "gpu_energy_total                                                            0.016546   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  75  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    314   \n",
       "date_time                                              April 11, 2025 at 06:40:30 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021153   \n",
       "total_energy_joules                                                     76152.181146   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215148   \n",
       "joules_per_token                                                             4.64796   \n",
       "flops_per_joule                                                     222580243.115083   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.267507   \n",
       "average_latency_ms_per_batch                                             4658.438392   \n",
       "throughput_queries_per_sec                                                  3.434627   \n",
       "throughput_tokens_per_sec                                                 439.632303   \n",
       "total_energy_kwh_process_0                                                  0.005323   \n",
       "total_energy_kwh_process_1                                                  0.005249   \n",
       "total_energy_kwh_process_2                                                  0.005332   \n",
       "total_energy_kwh_process_3                                                   0.00525   \n",
       "gpu_power_avg                                                             367.534498   \n",
       "ram_power_avg                                                               0.958583   \n",
       "cpu_energy_total                                                            0.004571   \n",
       "gpu_energy_total                                                            0.016551   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  76  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    315   \n",
       "date_time                                              April 11, 2025 at 06:41:37 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              0.8   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021139   \n",
       "total_energy_joules                                                     76101.321315   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215292   \n",
       "joules_per_token                                                            4.644856   \n",
       "flops_per_joule                                                     222728997.344947   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   37.349722   \n",
       "average_latency_ms_per_batch                                             4668.715262   \n",
       "throughput_queries_per_sec                                                  3.427067   \n",
       "throughput_tokens_per_sec                                                 438.664576   \n",
       "total_energy_kwh_process_0                                                  0.005328   \n",
       "total_energy_kwh_process_1                                                  0.005228   \n",
       "total_energy_kwh_process_2                                                  0.005297   \n",
       "total_energy_kwh_process_3                                                  0.005286   \n",
       "gpu_power_avg                                                             296.116516   \n",
       "ram_power_avg                                                               0.964557   \n",
       "cpu_energy_total                                                            0.004574   \n",
       "gpu_energy_total                                                            0.016534   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  77  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    316   \n",
       "date_time                                              April 11, 2025 at 06:42:44 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021052   \n",
       "total_energy_joules                                                      75787.25771   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.216184   \n",
       "joules_per_token                                                            4.625687   \n",
       "flops_per_joule                                                     223651989.862195   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.404344   \n",
       "average_latency_ms_per_batch                                             4550.543062   \n",
       "throughput_queries_per_sec                                                  3.516064   \n",
       "throughput_tokens_per_sec                                                 450.056174   \n",
       "total_energy_kwh_process_0                                                  0.005208   \n",
       "total_energy_kwh_process_1                                                  0.005281   \n",
       "total_energy_kwh_process_2                                                  0.005268   \n",
       "total_energy_kwh_process_3                                                  0.005296   \n",
       "gpu_power_avg                                                             426.171555   \n",
       "ram_power_avg                                                               0.960877   \n",
       "cpu_energy_total                                                            0.004555   \n",
       "gpu_energy_total                                                            0.016466   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  78  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    317   \n",
       "date_time                                              April 11, 2025 at 06:43:50 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021089   \n",
       "total_energy_joules                                                     75921.972142   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215801   \n",
       "joules_per_token                                                            4.633909   \n",
       "flops_per_joule                                                     223255146.236354   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.764964   \n",
       "average_latency_ms_per_batch                                             4595.620491   \n",
       "throughput_queries_per_sec                                                  3.481576   \n",
       "throughput_tokens_per_sec                                                 445.641672   \n",
       "total_energy_kwh_process_0                                                  0.005225   \n",
       "total_energy_kwh_process_1                                                  0.005298   \n",
       "total_energy_kwh_process_2                                                  0.005264   \n",
       "total_energy_kwh_process_3                                                  0.005302   \n",
       "gpu_power_avg                                                             464.683503   \n",
       "ram_power_avg                                                               0.962227   \n",
       "cpu_energy_total                                                            0.004593   \n",
       "gpu_energy_total                                                            0.016465   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  79  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    318   \n",
       "date_time                                              April 11, 2025 at 06:44:56 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021076   \n",
       "total_energy_joules                                                     75872.506432   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215941   \n",
       "joules_per_token                                                             4.63089   \n",
       "flops_per_joule                                                     223400699.280619   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.751617   \n",
       "average_latency_ms_per_batch                                             4593.952187   \n",
       "throughput_queries_per_sec                                                   3.48284   \n",
       "throughput_tokens_per_sec                                                 445.803508   \n",
       "total_energy_kwh_process_0                                                  0.005262   \n",
       "total_energy_kwh_process_1                                                  0.005298   \n",
       "total_energy_kwh_process_2                                                  0.005306   \n",
       "total_energy_kwh_process_3                                                   0.00521   \n",
       "gpu_power_avg                                                             373.273991   \n",
       "ram_power_avg                                                               0.963644   \n",
       "cpu_energy_total                                                            0.004558   \n",
       "gpu_energy_total                                                            0.016487   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  80  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    319   \n",
       "date_time                                              April 11, 2025 at 06:46:02 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021173   \n",
       "total_energy_joules                                                     76223.661305   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214946   \n",
       "joules_per_token                                                            4.652323   \n",
       "flops_per_joule                                                     222371514.343019   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.289531   \n",
       "average_latency_ms_per_batch                                             4536.191409   \n",
       "throughput_queries_per_sec                                                  3.527188   \n",
       "throughput_tokens_per_sec                                                 451.480067   \n",
       "total_energy_kwh_process_0                                                  0.005188   \n",
       "total_energy_kwh_process_1                                                  0.005328   \n",
       "total_energy_kwh_process_2                                                   0.00533   \n",
       "total_energy_kwh_process_3                                                  0.005327   \n",
       "gpu_power_avg                                                              102.99226   \n",
       "ram_power_avg                                                               0.962694   \n",
       "cpu_energy_total                                                            0.004651   \n",
       "gpu_energy_total                                                            0.016491   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  81  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.7_decoder_tempe...   \n",
       "experiment_id                                                                    320   \n",
       "date_time                                              April 11, 2025 at 06:47:09 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.7   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021169   \n",
       "total_energy_joules                                                     76208.729832   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214988   \n",
       "joules_per_token                                                            4.651412   \n",
       "flops_per_joule                                                     222415083.292085   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.688996   \n",
       "average_latency_ms_per_batch                                             4586.124506   \n",
       "throughput_queries_per_sec                                                  3.488784   \n",
       "throughput_tokens_per_sec                                                 446.564413   \n",
       "total_energy_kwh_process_0                                                  0.005262   \n",
       "total_energy_kwh_process_1                                                  0.005314   \n",
       "total_energy_kwh_process_2                                                  0.005274   \n",
       "total_energy_kwh_process_3                                                   0.00532   \n",
       "gpu_power_avg                                                             415.753303   \n",
       "ram_power_avg                                                               0.962244   \n",
       "cpu_energy_total                                                            0.004565   \n",
       "gpu_energy_total                                                            0.016573   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  82  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.8_decoder_tempe...   \n",
       "experiment_id                                                                    321   \n",
       "date_time                                              April 11, 2025 at 06:48:16 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.8   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021177   \n",
       "total_energy_joules                                                     76236.684702   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                             0.21491   \n",
       "joules_per_token                                                            4.653118   \n",
       "flops_per_joule                                                     222333526.955779   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.790459   \n",
       "average_latency_ms_per_batch                                             4598.807349   \n",
       "throughput_queries_per_sec                                                  3.479163   \n",
       "throughput_tokens_per_sec                                                 445.332854   \n",
       "total_energy_kwh_process_0                                                  0.005286   \n",
       "total_energy_kwh_process_1                                                  0.005303   \n",
       "total_energy_kwh_process_2                                                  0.005284   \n",
       "total_energy_kwh_process_3                                                  0.005304   \n",
       "gpu_power_avg                                                             441.421415   \n",
       "ram_power_avg                                                               0.958251   \n",
       "cpu_energy_total                                                            0.004546   \n",
       "gpu_energy_total                                                              0.0166   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  83  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.9_decoder_tempe...   \n",
       "experiment_id                                                                    322   \n",
       "date_time                                              April 11, 2025 at 06:49:22 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.9   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021209   \n",
       "total_energy_joules                                                     76352.285347   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.214584   \n",
       "joules_per_token                                                            4.660174   \n",
       "flops_per_joule                                                     221996904.429798   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.692678   \n",
       "average_latency_ms_per_batch                                             4586.584774   \n",
       "throughput_queries_per_sec                                                  3.488434   \n",
       "throughput_tokens_per_sec                                                   446.5196   \n",
       "total_energy_kwh_process_0                                                  0.005245   \n",
       "total_energy_kwh_process_1                                                  0.005309   \n",
       "total_energy_kwh_process_2                                                  0.005301   \n",
       "total_energy_kwh_process_3                                                  0.005354   \n",
       "gpu_power_avg                                                             281.424198   \n",
       "ram_power_avg                                                               0.954216   \n",
       "cpu_energy_total                                                            0.004586   \n",
       "gpu_energy_total                                                            0.016591   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  84  \\\n",
       "config_name                        decoding_top_p_decoder_top_p_0.98_decoder_temp...   \n",
       "experiment_id                                                                    323   \n",
       "date_time                                              April 11, 2025 at 06:50:29 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.2   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                   0.98   \n",
       "latency_simulation_delay_min                                                     0.0   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021157   \n",
       "total_energy_joules                                                     76166.395123   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.215108   \n",
       "joules_per_token                                                            4.648828   \n",
       "flops_per_joule                                                     222538705.760019   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   36.887141   \n",
       "average_latency_ms_per_batch                                             4610.892601   \n",
       "throughput_queries_per_sec                                                  3.470044   \n",
       "throughput_tokens_per_sec                                                 444.165626   \n",
       "total_energy_kwh_process_0                                                  0.005301   \n",
       "total_energy_kwh_process_1                                                  0.005258   \n",
       "total_energy_kwh_process_2                                                  0.005298   \n",
       "total_energy_kwh_process_3                                                    0.0053   \n",
       "gpu_power_avg                                                             422.539237   \n",
       "ram_power_avg                                                               0.962374   \n",
       "cpu_energy_total                                                            0.004548   \n",
       "gpu_energy_total                                                            0.016578   \n",
       "decoder_config_decoding_mode                                                   top_p   \n",
       "latency_simulation_simulate                                                    False   \n",
       "latency_simulation_delay_max                                                     0.0   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                   85  \\\n",
       "config_name                                             latency_False   \n",
       "experiment_id                                                     328   \n",
       "date_time                               April 11, 2025 at 06:53:27 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.020897   \n",
       "total_energy_joules                                       75230.05363   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.217785   \n",
       "joules_per_token                                             4.591678   \n",
       "flops_per_joule                                      225308506.046856   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    36.504055   \n",
       "average_latency_ms_per_batch                              4563.006856   \n",
       "throughput_queries_per_sec                                    3.50646   \n",
       "throughput_tokens_per_sec                                  448.826851   \n",
       "total_energy_kwh_process_0                                   0.005171   \n",
       "total_energy_kwh_process_1                                   0.005258   \n",
       "total_energy_kwh_process_2                                   0.005255   \n",
       "total_energy_kwh_process_3                                   0.005214   \n",
       "gpu_power_avg                                              354.061436   \n",
       "ram_power_avg                                                0.962766   \n",
       "cpu_energy_total                                             0.004566   \n",
       "gpu_energy_total                                               0.0163   \n",
       "decoder_config_decoding_mode                                      NaN   \n",
       "latency_simulation_simulate                                     False   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "total_generated_tokens                                          16384   \n",
       "\n",
       "                                                                                  86  \\\n",
       "config_name                        latency_True_latency_0.05_latency_0.2_latency_...   \n",
       "experiment_id                                                                    329   \n",
       "date_time                                              April 11, 2025 at 06:54:34 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                    0.05   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.021343   \n",
       "total_energy_joules                                                     76834.458713   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.213238   \n",
       "joules_per_token                                                            4.689603   \n",
       "flops_per_joule                                                     220603766.552551   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                    37.91957   \n",
       "average_latency_ms_per_batch                                             4739.946273   \n",
       "throughput_queries_per_sec                                                  3.375566   \n",
       "throughput_tokens_per_sec                                                 432.072408   \n",
       "total_energy_kwh_process_0                                                  0.005325   \n",
       "total_energy_kwh_process_1                                                   0.00537   \n",
       "total_energy_kwh_process_2                                                  0.005339   \n",
       "total_energy_kwh_process_3                                                  0.005309   \n",
       "gpu_power_avg                                                             221.602844   \n",
       "ram_power_avg                                                               0.960215   \n",
       "cpu_energy_total                                                            0.004726   \n",
       "gpu_energy_total                                                            0.016585   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "latency_simulation_simulate                                                     True   \n",
       "latency_simulation_delay_max                                                     0.2   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  87  \\\n",
       "config_name                        latency_True_latency_0.2_latency_0.6_latency_F...   \n",
       "experiment_id                                                                    330   \n",
       "date_time                                              April 11, 2025 at 06:55:45 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                     0.2   \n",
       "latency_simulation_simulate_burst                                              False   \n",
       "latency_simulation_burst_size                                                      0   \n",
       "latency_simulation_burst_interval                                                0.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022104   \n",
       "total_energy_joules                                                     79575.575957   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.205892   \n",
       "joules_per_token                                                            4.856908   \n",
       "flops_per_joule                                                     213004691.317366   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   40.774318   \n",
       "average_latency_ms_per_batch                                             5096.789718   \n",
       "throughput_queries_per_sec                                                  3.139231   \n",
       "throughput_tokens_per_sec                                                 401.821561   \n",
       "total_energy_kwh_process_0                                                  0.005583   \n",
       "total_energy_kwh_process_1                                                  0.005435   \n",
       "total_energy_kwh_process_2                                                  0.005558   \n",
       "total_energy_kwh_process_3                                                  0.005528   \n",
       "gpu_power_avg                                                             373.637229   \n",
       "ram_power_avg                                                               0.956742   \n",
       "cpu_energy_total                                                            0.004984   \n",
       "gpu_energy_total                                                            0.017087   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "latency_simulation_simulate                                                     True   \n",
       "latency_simulation_delay_max                                                     0.6   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  88  \\\n",
       "config_name                        latency_True_latency_0.05_latency_0.2_latency_...   \n",
       "experiment_id                                                                    331   \n",
       "date_time                                              April 11, 2025 at 06:56:55 PM   \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                                      4   \n",
       "batch_size___fixed_batching                                                       16   \n",
       "decoder_temperature                                                              1.0   \n",
       "decoder_top_k                                                                      0   \n",
       "decoder_top_p                                                                    0.0   \n",
       "latency_simulation_delay_min                                                    0.05   \n",
       "latency_simulation_simulate_burst                                               True   \n",
       "latency_simulation_burst_size                                                      5   \n",
       "latency_simulation_burst_interval                                                4.0   \n",
       "fp_precision                                                           torch.float16   \n",
       "quantization                                                                    True   \n",
       "load_in_8bit                                                                   False   \n",
       "load_in_4bit                                                                    True   \n",
       "total_input_tokens                                                             16384   \n",
       "total_params                                                               615606272   \n",
       "max_input_tokens                                                                 128   \n",
       "max_output_tokens                                                                128   \n",
       "number_input_prompts                                                             128   \n",
       "total_energy_kwh                                                            0.022489   \n",
       "total_energy_joules                                                     80959.555151   \n",
       "flops                                                                 16949970993152   \n",
       "tokens_per_joule                                                            0.202373   \n",
       "joules_per_token                                                            4.941379   \n",
       "flops_per_joule                                                     209363440.318309   \n",
       "joules_per_flop                                                                  0.0   \n",
       "total_inference_time_sec                                                   41.930226   \n",
       "average_latency_ms_per_batch                                             5241.278282   \n",
       "throughput_queries_per_sec                                                   3.05269   \n",
       "throughput_tokens_per_sec                                                 390.744374   \n",
       "total_energy_kwh_process_0                                                  0.005647   \n",
       "total_energy_kwh_process_1                                                  0.005563   \n",
       "total_energy_kwh_process_2                                                   0.00568   \n",
       "total_energy_kwh_process_3                                                  0.005599   \n",
       "gpu_power_avg                                                             383.426657   \n",
       "ram_power_avg                                                               0.954906   \n",
       "cpu_energy_total                                                            0.005153   \n",
       "gpu_energy_total                                                            0.017301   \n",
       "decoder_config_decoding_mode                                                     NaN   \n",
       "latency_simulation_simulate                                                     True   \n",
       "latency_simulation_delay_max                                                     0.2   \n",
       "total_generated_tokens                                                         16384   \n",
       "\n",
       "                                                                                  89  \n",
       "config_name                        latency_True_latency_0.2_latency_0.6_latency_T...  \n",
       "experiment_id                                                                    332  \n",
       "date_time                                              April 11, 2025 at 06:58:10 PM  \n",
       "model                                             TinyLlama/TinyLlama-1.1B-Chat-v1.0  \n",
       "num_processes                                                                      4  \n",
       "batch_size___fixed_batching                                                       16  \n",
       "decoder_temperature                                                              1.0  \n",
       "decoder_top_k                                                                      0  \n",
       "decoder_top_p                                                                    0.0  \n",
       "latency_simulation_delay_min                                                     0.2  \n",
       "latency_simulation_simulate_burst                                               True  \n",
       "latency_simulation_burst_size                                                      8  \n",
       "latency_simulation_burst_interval                                                5.0  \n",
       "fp_precision                                                           torch.float16  \n",
       "quantization                                                                    True  \n",
       "load_in_8bit                                                                   False  \n",
       "load_in_4bit                                                                    True  \n",
       "total_input_tokens                                                             16384  \n",
       "total_params                                                               615606272  \n",
       "max_input_tokens                                                                 128  \n",
       "max_output_tokens                                                                128  \n",
       "number_input_prompts                                                             128  \n",
       "total_energy_kwh                                                            0.023464  \n",
       "total_energy_joules                                                     84471.974521  \n",
       "flops                                                                 16949970993152  \n",
       "tokens_per_joule                                                            0.193958  \n",
       "joules_per_token                                                             5.15576  \n",
       "flops_per_joule                                                     200657923.402639  \n",
       "joules_per_flop                                                                  0.0  \n",
       "total_inference_time_sec                                                   45.240207  \n",
       "average_latency_ms_per_batch                                             5655.025877  \n",
       "throughput_queries_per_sec                                                  2.829342  \n",
       "throughput_tokens_per_sec                                                 362.155726  \n",
       "total_energy_kwh_process_0                                                  0.005837  \n",
       "total_energy_kwh_process_1                                                  0.005755  \n",
       "total_energy_kwh_process_2                                                  0.005886  \n",
       "total_energy_kwh_process_3                                                  0.005986  \n",
       "gpu_power_avg                                                             336.049723  \n",
       "ram_power_avg                                                               0.961642  \n",
       "cpu_energy_total                                                            0.005617  \n",
       "gpu_energy_total                                                            0.017808  \n",
       "decoder_config_decoding_mode                                                     NaN  \n",
       "latency_simulation_simulate                                                     True  \n",
       "latency_simulation_delay_max                                                     0.6  \n",
       "total_generated_tokens                                                         16384  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found & inspecting dropped version: df_scenarios_dropped\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>config_name</th>\n",
       "      <td>A1_Max_Throughput_Exploit</td>\n",
       "      <td>A2_Precision_Minimalist</td>\n",
       "      <td>A3_Quantisation_Gaming</td>\n",
       "      <td>default</td>\n",
       "      <td>A5_Parallel_Overdrive</td>\n",
       "      <td>R2_Low_Latency_Chatbot_Deployment</td>\n",
       "      <td>R3_Balanced_Enterprise_Service</td>\n",
       "      <td>R4_High_Load_Cloud_API_Deployment</td>\n",
       "      <td>R5_Real_Time_Mobile_Inference</td>\n",
       "      <td>R6_Medium_Scale_Language_Model_Serving</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>experiment_id</th>\n",
       "      <td>220</td>\n",
       "      <td>221</td>\n",
       "      <td>222</td>\n",
       "      <td>223</td>\n",
       "      <td>224</td>\n",
       "      <td>228</td>\n",
       "      <td>229</td>\n",
       "      <td>230</td>\n",
       "      <td>231</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <td>April 11, 2025 at 04:28:24 PM</td>\n",
       "      <td>April 11, 2025 at 04:29:05 PM</td>\n",
       "      <td>April 11, 2025 at 04:29:46 PM</td>\n",
       "      <td>April 11, 2025 at 04:31:30 PM</td>\n",
       "      <td>April 11, 2025 at 04:32:11 PM</td>\n",
       "      <td>April 11, 2025 at 04:35:15 PM</td>\n",
       "      <td>April 11, 2025 at 04:36:43 PM</td>\n",
       "      <td>April 11, 2025 at 04:38:09 PM</td>\n",
       "      <td>April 11, 2025 at 04:55:10 PM</td>\n",
       "      <td>April 11, 2025 at 04:55:58 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "      <td>TinyLlama/TinyLlama-1.1B-Chat-v1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>num_processes</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>batch_size___fixed_batching</th>\n",
       "      <td>256</td>\n",
       "      <td>128</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_temperature</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_k</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_top_p</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate_burst</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_size</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_burst_interval</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fp_precision</th>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float32</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "      <td>torch.float16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantization</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_8bit</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>load_in_4bit</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_input_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_params</th>\n",
       "      <td>1100048384</td>\n",
       "      <td>615606272</td>\n",
       "      <td>615606272</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "      <td>1100048384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_input_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_output_tokens</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_input_prompts</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh</th>\n",
       "      <td>0.007299</td>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.022337</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.045144</td>\n",
       "      <td>0.008436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_joules</th>\n",
       "      <td>26276.086899</td>\n",
       "      <td>5043.594678</td>\n",
       "      <td>2748.678723</td>\n",
       "      <td>11613.150827</td>\n",
       "      <td>19803.636424</td>\n",
       "      <td>20669.796894</td>\n",
       "      <td>80411.455879</td>\n",
       "      <td>10468.775683</td>\n",
       "      <td>162518.073262</td>\n",
       "      <td>30368.288695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops</th>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "      <td>16949970993152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tokens_per_joule</th>\n",
       "      <td>0.623533</td>\n",
       "      <td>3.248477</td>\n",
       "      <td>5.960682</td>\n",
       "      <td>1.410814</td>\n",
       "      <td>0.827323</td>\n",
       "      <td>0.792654</td>\n",
       "      <td>0.203752</td>\n",
       "      <td>1.565035</td>\n",
       "      <td>0.086883</td>\n",
       "      <td>0.53951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_token</th>\n",
       "      <td>1.603765</td>\n",
       "      <td>0.307837</td>\n",
       "      <td>0.167766</td>\n",
       "      <td>0.70881</td>\n",
       "      <td>1.208718</td>\n",
       "      <td>1.261584</td>\n",
       "      <td>4.907926</td>\n",
       "      <td>0.638963</td>\n",
       "      <td>11.509779</td>\n",
       "      <td>1.853533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flops_per_joule</th>\n",
       "      <td>645072116.656167</td>\n",
       "      <td>3360692536.878901</td>\n",
       "      <td>6166588640.753133</td>\n",
       "      <td>1459549716.198339</td>\n",
       "      <td>855901948.028895</td>\n",
       "      <td>820035682.010454</td>\n",
       "      <td>210790500.032728</td>\n",
       "      <td>1619097734.639612</td>\n",
       "      <td>104295914.004625</td>\n",
       "      <td>558147058.058945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joules_per_flop</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_inference_time_sec</th>\n",
       "      <td>12.157593</td>\n",
       "      <td>5.11736</td>\n",
       "      <td>9.56734</td>\n",
       "      <td>71.473257</td>\n",
       "      <td>6.201934</td>\n",
       "      <td>88.568613</td>\n",
       "      <td>46.186702</td>\n",
       "      <td>56.839973</td>\n",
       "      <td>984.640872</td>\n",
       "      <td>12.265104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>average_latency_ms_per_batch</th>\n",
       "      <td>12157.593134</td>\n",
       "      <td>5117.360245</td>\n",
       "      <td>4783.670129</td>\n",
       "      <td>8934.157172</td>\n",
       "      <td>3100.966923</td>\n",
       "      <td>2767.769153</td>\n",
       "      <td>11546.675429</td>\n",
       "      <td>3552.498301</td>\n",
       "      <td>7692.506816</td>\n",
       "      <td>3066.276043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_queries_per_sec</th>\n",
       "      <td>10.5284</td>\n",
       "      <td>25.012896</td>\n",
       "      <td>13.378849</td>\n",
       "      <td>1.79088</td>\n",
       "      <td>20.638724</td>\n",
       "      <td>1.445207</td>\n",
       "      <td>2.77136</td>\n",
       "      <td>2.251936</td>\n",
       "      <td>0.129997</td>\n",
       "      <td>10.436112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>throughput_tokens_per_sec</th>\n",
       "      <td>1347.635163</td>\n",
       "      <td>3201.650698</td>\n",
       "      <td>1712.492663</td>\n",
       "      <td>229.232591</td>\n",
       "      <td>2641.756654</td>\n",
       "      <td>184.986526</td>\n",
       "      <td>354.734142</td>\n",
       "      <td>288.247851</td>\n",
       "      <td>14.340254</td>\n",
       "      <td>1335.822327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_0</th>\n",
       "      <td>0.001851</td>\n",
       "      <td>0.000733</td>\n",
       "      <td>0.000764</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.00139</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.005224</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.045144</td>\n",
       "      <td>0.002133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_1</th>\n",
       "      <td>0.001833</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_2</th>\n",
       "      <td>0.001778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005714</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_energy_kwh_process_3</th>\n",
       "      <td>0.001837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001388</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005568</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_power_avg</th>\n",
       "      <td>1936.748224</td>\n",
       "      <td>2709.616605</td>\n",
       "      <td>59.55226</td>\n",
       "      <td>69.072265</td>\n",
       "      <td>873.557158</td>\n",
       "      <td>50.244713</td>\n",
       "      <td>255.785297</td>\n",
       "      <td>81.048935</td>\n",
       "      <td>65.177186</td>\n",
       "      <td>535.599288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ram_power_avg</th>\n",
       "      <td>0.977014</td>\n",
       "      <td>0.942083</td>\n",
       "      <td>0.909635</td>\n",
       "      <td>0.947124</td>\n",
       "      <td>0.921537</td>\n",
       "      <td>0.699726</td>\n",
       "      <td>0.981844</td>\n",
       "      <td>1.081179</td>\n",
       "      <td>0.942028</td>\n",
       "      <td>0.921829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cpu_energy_total</th>\n",
       "      <td>0.001324</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>0.00188</td>\n",
       "      <td>0.00091</td>\n",
       "      <td>0.002531</td>\n",
       "      <td>0.005052</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.029285</td>\n",
       "      <td>0.001521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpu_energy_total</th>\n",
       "      <td>0.005963</td>\n",
       "      <td>0.001145</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.00133</td>\n",
       "      <td>0.004585</td>\n",
       "      <td>0.003197</td>\n",
       "      <td>0.017239</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.015628</td>\n",
       "      <td>0.006904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_simulate</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoder_config_decoding_mode</th>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_k</td>\n",
       "      <td>greedy</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_p</td>\n",
       "      <td>top_k</td>\n",
       "      <td>greedy</td>\n",
       "      <td>top_p</td>\n",
       "      <td>greedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_generated_tokens</th>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>14120</td>\n",
       "      <td>16384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>latency_simulation_delay_max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    0  \\\n",
       "config_name                                 A1_Max_Throughput_Exploit   \n",
       "experiment_id                                                     220   \n",
       "date_time                               April 11, 2025 at 04:28:24 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                       256   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                     True   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.007299   \n",
       "total_energy_joules                                      26276.086899   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.623533   \n",
       "joules_per_token                                             1.603765   \n",
       "flops_per_joule                                      645072116.656167   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    12.157593   \n",
       "average_latency_ms_per_batch                             12157.593134   \n",
       "throughput_queries_per_sec                                    10.5284   \n",
       "throughput_tokens_per_sec                                 1347.635163   \n",
       "total_energy_kwh_process_0                                   0.001851   \n",
       "total_energy_kwh_process_1                                   0.001833   \n",
       "total_energy_kwh_process_2                                   0.001778   \n",
       "total_energy_kwh_process_3                                   0.001837   \n",
       "gpu_power_avg                                             1936.748224   \n",
       "ram_power_avg                                                0.977014   \n",
       "cpu_energy_total                                             0.001324   \n",
       "gpu_energy_total                                             0.005963   \n",
       "latency_simulation_simulate                                     False   \n",
       "decoder_config_decoding_mode                                   greedy   \n",
       "total_generated_tokens                                          16384   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "\n",
       "                                                                    1  \\\n",
       "config_name                                   A2_Precision_Minimalist   \n",
       "experiment_id                                                     221   \n",
       "date_time                               April 11, 2025 at 04:29:05 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       2   \n",
       "batch_size___fixed_batching                                       128   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.001401   \n",
       "total_energy_joules                                       5043.594678   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             3.248477   \n",
       "joules_per_token                                             0.307837   \n",
       "flops_per_joule                                     3360692536.878901   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                      5.11736   \n",
       "average_latency_ms_per_batch                              5117.360245   \n",
       "throughput_queries_per_sec                                  25.012896   \n",
       "throughput_tokens_per_sec                                 3201.650698   \n",
       "total_energy_kwh_process_0                                   0.000733   \n",
       "total_energy_kwh_process_1                                   0.000668   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                             2709.616605   \n",
       "ram_power_avg                                                0.942083   \n",
       "cpu_energy_total                                             0.000254   \n",
       "gpu_energy_total                                             0.001145   \n",
       "latency_simulation_simulate                                     False   \n",
       "decoder_config_decoding_mode                                   greedy   \n",
       "total_generated_tokens                                          16384   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "\n",
       "                                                                    2  \\\n",
       "config_name                                    A3_Quantisation_Gaming   \n",
       "experiment_id                                                     222   \n",
       "date_time                               April 11, 2025 at 04:29:46 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       1   \n",
       "batch_size___fixed_batching                                        64   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                      50   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                     True   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                                615606272   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.000764   \n",
       "total_energy_joules                                       2748.678723   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             5.960682   \n",
       "joules_per_token                                             0.167766   \n",
       "flops_per_joule                                     6166588640.753133   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                      9.56734   \n",
       "average_latency_ms_per_batch                              4783.670129   \n",
       "throughput_queries_per_sec                                  13.378849   \n",
       "throughput_tokens_per_sec                                 1712.492663   \n",
       "total_energy_kwh_process_0                                   0.000764   \n",
       "total_energy_kwh_process_1                                        NaN   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                                59.55226   \n",
       "ram_power_avg                                                0.909635   \n",
       "cpu_energy_total                                             0.000374   \n",
       "gpu_energy_total                                             0.000387   \n",
       "latency_simulation_simulate                                     False   \n",
       "decoder_config_decoding_mode                                    top_k   \n",
       "total_generated_tokens                                          16384   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "\n",
       "                                                                    3  \\\n",
       "config_name                                                   default   \n",
       "experiment_id                                                     223   \n",
       "date_time                               April 11, 2025 at 04:31:30 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       1   \n",
       "batch_size___fixed_batching                                        16   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                     True   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.003226   \n",
       "total_energy_joules                                      11613.150827   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             1.410814   \n",
       "joules_per_token                                              0.70881   \n",
       "flops_per_joule                                     1459549716.198339   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    71.473257   \n",
       "average_latency_ms_per_batch                              8934.157172   \n",
       "throughput_queries_per_sec                                    1.79088   \n",
       "throughput_tokens_per_sec                                  229.232591   \n",
       "total_energy_kwh_process_0                                   0.003226   \n",
       "total_energy_kwh_process_1                                        NaN   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                               69.072265   \n",
       "ram_power_avg                                                0.947124   \n",
       "cpu_energy_total                                              0.00188   \n",
       "gpu_energy_total                                              0.00133   \n",
       "latency_simulation_simulate                                     False   \n",
       "decoder_config_decoding_mode                                   greedy   \n",
       "total_generated_tokens                                          16384   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "\n",
       "                                                                    4  \\\n",
       "config_name                                     A5_Parallel_Overdrive   \n",
       "experiment_id                                                     224   \n",
       "date_time                               April 11, 2025 at 04:32:11 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        64   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.0   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.005501   \n",
       "total_energy_joules                                      19803.636424   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.827323   \n",
       "joules_per_token                                             1.208718   \n",
       "flops_per_joule                                      855901948.028895   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                     6.201934   \n",
       "average_latency_ms_per_batch                              3100.966923   \n",
       "throughput_queries_per_sec                                  20.638724   \n",
       "throughput_tokens_per_sec                                 2641.756654   \n",
       "total_energy_kwh_process_0                                    0.00139   \n",
       "total_energy_kwh_process_1                                   0.001335   \n",
       "total_energy_kwh_process_2                                   0.001389   \n",
       "total_energy_kwh_process_3                                   0.001388   \n",
       "gpu_power_avg                                              873.557158   \n",
       "ram_power_avg                                                0.921537   \n",
       "cpu_energy_total                                              0.00091   \n",
       "gpu_energy_total                                             0.004585   \n",
       "latency_simulation_simulate                                     False   \n",
       "decoder_config_decoding_mode                                   greedy   \n",
       "total_generated_tokens                                          16384   \n",
       "latency_simulation_delay_max                                      0.0   \n",
       "\n",
       "                                                                    5  \\\n",
       "config_name                         R2_Low_Latency_Chatbot_Deployment   \n",
       "experiment_id                                                     228   \n",
       "date_time                               April 11, 2025 at 04:35:15 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       1   \n",
       "batch_size___fixed_batching                                         4   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.9   \n",
       "latency_simulation_delay_min                                     0.01   \n",
       "latency_simulation_simulate_burst                               False   \n",
       "latency_simulation_burst_size                                       0   \n",
       "latency_simulation_burst_interval                                 0.0   \n",
       "fp_precision                                            torch.float32   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.005742   \n",
       "total_energy_joules                                      20669.796894   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.792654   \n",
       "joules_per_token                                             1.261584   \n",
       "flops_per_joule                                      820035682.010454   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    88.568613   \n",
       "average_latency_ms_per_batch                              2767.769153   \n",
       "throughput_queries_per_sec                                   1.445207   \n",
       "throughput_tokens_per_sec                                  184.986526   \n",
       "total_energy_kwh_process_0                                   0.005742   \n",
       "total_energy_kwh_process_1                                        NaN   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                               50.244713   \n",
       "ram_power_avg                                                0.699726   \n",
       "cpu_energy_total                                             0.002531   \n",
       "gpu_energy_total                                             0.003197   \n",
       "latency_simulation_simulate                                      True   \n",
       "decoder_config_decoding_mode                                    top_p   \n",
       "total_generated_tokens                                          16384   \n",
       "latency_simulation_delay_max                                     0.05   \n",
       "\n",
       "                                                                    6  \\\n",
       "config_name                            R3_Balanced_Enterprise_Service   \n",
       "experiment_id                                                     229   \n",
       "date_time                               April 11, 2025 at 04:36:43 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       4   \n",
       "batch_size___fixed_batching                                        32   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                      50   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                      0.5   \n",
       "latency_simulation_simulate_burst                                True   \n",
       "latency_simulation_burst_size                                       5   \n",
       "latency_simulation_burst_interval                                 4.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                     True   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.022337   \n",
       "total_energy_joules                                      80411.455879   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.203752   \n",
       "joules_per_token                                             4.907926   \n",
       "flops_per_joule                                      210790500.032728   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    46.186702   \n",
       "average_latency_ms_per_batch                             11546.675429   \n",
       "throughput_queries_per_sec                                    2.77136   \n",
       "throughput_tokens_per_sec                                  354.734142   \n",
       "total_energy_kwh_process_0                                   0.005224   \n",
       "total_energy_kwh_process_1                                    0.00583   \n",
       "total_energy_kwh_process_2                                   0.005714   \n",
       "total_energy_kwh_process_3                                   0.005568   \n",
       "gpu_power_avg                                              255.785297   \n",
       "ram_power_avg                                                0.981844   \n",
       "cpu_energy_total                                             0.005052   \n",
       "gpu_energy_total                                             0.017239   \n",
       "latency_simulation_simulate                                      True   \n",
       "decoder_config_decoding_mode                                    top_k   \n",
       "total_generated_tokens                                          16384   \n",
       "latency_simulation_delay_max                                      1.5   \n",
       "\n",
       "                                                                    7  \\\n",
       "config_name                         R4_High_Load_Cloud_API_Deployment   \n",
       "experiment_id                                                     230   \n",
       "date_time                               April 11, 2025 at 04:38:09 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       1   \n",
       "batch_size___fixed_batching                                         8   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.0   \n",
       "latency_simulation_delay_min                                     0.05   \n",
       "latency_simulation_simulate_burst                                True   \n",
       "latency_simulation_burst_size                                       5   \n",
       "latency_simulation_burst_interval                                 2.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                    False   \n",
       "load_in_8bit                                                    False   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.002908   \n",
       "total_energy_joules                                      10468.775683   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             1.565035   \n",
       "joules_per_token                                             0.638963   \n",
       "flops_per_joule                                     1619097734.639612   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                    56.839973   \n",
       "average_latency_ms_per_batch                              3552.498301   \n",
       "throughput_queries_per_sec                                   2.251936   \n",
       "throughput_tokens_per_sec                                  288.247851   \n",
       "total_energy_kwh_process_0                                   0.002908   \n",
       "total_energy_kwh_process_1                                        NaN   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                               81.048935   \n",
       "ram_power_avg                                                1.081179   \n",
       "cpu_energy_total                                             0.001609   \n",
       "gpu_energy_total                                             0.001284   \n",
       "latency_simulation_simulate                                      True   \n",
       "decoder_config_decoding_mode                                   greedy   \n",
       "total_generated_tokens                                          16384   \n",
       "latency_simulation_delay_max                                      0.2   \n",
       "\n",
       "                                                                    8  \\\n",
       "config_name                             R5_Real_Time_Mobile_Inference   \n",
       "experiment_id                                                     231   \n",
       "date_time                               April 11, 2025 at 04:55:10 PM   \n",
       "model                              TinyLlama/TinyLlama-1.1B-Chat-v1.0   \n",
       "num_processes                                                       1   \n",
       "batch_size___fixed_batching                                         1   \n",
       "decoder_temperature                                               1.0   \n",
       "decoder_top_k                                                       0   \n",
       "decoder_top_p                                                     0.9   \n",
       "latency_simulation_delay_min                                      0.2   \n",
       "latency_simulation_simulate_burst                                True   \n",
       "latency_simulation_burst_size                                       8   \n",
       "latency_simulation_burst_interval                                 5.0   \n",
       "fp_precision                                            torch.float16   \n",
       "quantization                                                     True   \n",
       "load_in_8bit                                                     True   \n",
       "load_in_4bit                                                    False   \n",
       "total_input_tokens                                              16384   \n",
       "total_params                                               1100048384   \n",
       "max_input_tokens                                                  128   \n",
       "max_output_tokens                                                 128   \n",
       "number_input_prompts                                              128   \n",
       "total_energy_kwh                                             0.045144   \n",
       "total_energy_joules                                     162518.073262   \n",
       "flops                                                  16949970993152   \n",
       "tokens_per_joule                                             0.086883   \n",
       "joules_per_token                                            11.509779   \n",
       "flops_per_joule                                      104295914.004625   \n",
       "joules_per_flop                                                   0.0   \n",
       "total_inference_time_sec                                   984.640872   \n",
       "average_latency_ms_per_batch                              7692.506816   \n",
       "throughput_queries_per_sec                                   0.129997   \n",
       "throughput_tokens_per_sec                                   14.340254   \n",
       "total_energy_kwh_process_0                                   0.045144   \n",
       "total_energy_kwh_process_1                                        NaN   \n",
       "total_energy_kwh_process_2                                        NaN   \n",
       "total_energy_kwh_process_3                                        NaN   \n",
       "gpu_power_avg                                               65.177186   \n",
       "ram_power_avg                                                0.942028   \n",
       "cpu_energy_total                                             0.029285   \n",
       "gpu_energy_total                                             0.015628   \n",
       "latency_simulation_simulate                                      True   \n",
       "decoder_config_decoding_mode                                    top_p   \n",
       "total_generated_tokens                                          14120   \n",
       "latency_simulation_delay_max                                      0.6   \n",
       "\n",
       "                                                                        9  \n",
       "config_name                        R6_Medium_Scale_Language_Model_Serving  \n",
       "experiment_id                                                         232  \n",
       "date_time                                   April 11, 2025 at 04:55:58 PM  \n",
       "model                                  TinyLlama/TinyLlama-1.1B-Chat-v1.0  \n",
       "num_processes                                                           4  \n",
       "batch_size___fixed_batching                                            32  \n",
       "decoder_temperature                                                   1.0  \n",
       "decoder_top_k                                                           0  \n",
       "decoder_top_p                                                         0.0  \n",
       "latency_simulation_delay_min                                         0.01  \n",
       "latency_simulation_simulate_burst                                   False  \n",
       "latency_simulation_burst_size                                           0  \n",
       "latency_simulation_burst_interval                                     0.0  \n",
       "fp_precision                                                torch.float16  \n",
       "quantization                                                        False  \n",
       "load_in_8bit                                                        False  \n",
       "load_in_4bit                                                        False  \n",
       "total_input_tokens                                                  16384  \n",
       "total_params                                                   1100048384  \n",
       "max_input_tokens                                                      128  \n",
       "max_output_tokens                                                     128  \n",
       "number_input_prompts                                                  128  \n",
       "total_energy_kwh                                                 0.008436  \n",
       "total_energy_joules                                          30368.288695  \n",
       "flops                                                      16949970993152  \n",
       "tokens_per_joule                                                  0.53951  \n",
       "joules_per_token                                                 1.853533  \n",
       "flops_per_joule                                          558147058.058945  \n",
       "joules_per_flop                                                       0.0  \n",
       "total_inference_time_sec                                        12.265104  \n",
       "average_latency_ms_per_batch                                  3066.276043  \n",
       "throughput_queries_per_sec                                      10.436112  \n",
       "throughput_tokens_per_sec                                     1335.822327  \n",
       "total_energy_kwh_process_0                                       0.002133  \n",
       "total_energy_kwh_process_1                                       0.002109  \n",
       "total_energy_kwh_process_2                                       0.002101  \n",
       "total_energy_kwh_process_3                                       0.002093  \n",
       "gpu_power_avg                                                  535.599288  \n",
       "ram_power_avg                                                    0.921829  \n",
       "cpu_energy_total                                                 0.001521  \n",
       "gpu_energy_total                                                 0.006904  \n",
       "latency_simulation_simulate                                          True  \n",
       "decoder_config_decoding_mode                                       greedy  \n",
       "total_generated_tokens                                              16384  \n",
       "latency_simulation_delay_max                                          0.1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing grid: 'df_grid_cleaned'\n",
      "Error processing text_generation: 'df_text_generation_cleaned'\n"
     ]
    }
   ],
   "source": [
    "columns_to_drop = [\n",
    "    \"sharding_strategy\",\n",
    "    \"sharding_config_fsdp_config_use_orig_params\",\n",
    "    \"sharding_config_fsdp_config_cpu_offload\",\n",
    "    \"adaptive_batching\",\n",
    "    \"adaptive_max_tokens\",\n",
    "    \"query_rate\",\n",
    "    \"is_encoder_decoder\",\n",
    "    \"task_type\",\n",
    "    \"available_gpu_count\",\n",
    "    \"gpu_model\",\n",
    "    \"available_cpu_count\",\n",
    "    \"cpu_model\",\n",
    "    \"os\",\n",
    "    \"python_version\",\n",
    "    \"country\",\n",
    "    \"region\",\n",
    "    \"distributed_type\",\n",
    "    \"decode_token_to_text\",\n",
    "    \"inference_type\",\n",
    "    \"backend\",\n",
    "    \"model_arch\",\n",
    "    \"gpu_current_memory_allocated_bytes\",\n",
    "    \"gpu_max_memory_allocated_bytes\",\n",
    "    \"gpu_current_memory_reserved_bytes\",\n",
    "    \"gpu_max_memory_reserved_bytes\",\n",
    "    \"per-process_emissions_0\", \"per-process_emissions_1\", \"per-process_emissions_2\",\"per-process_emissions_3\" # OR IS THIS NICE TO HAVE?\n",
    "]\n",
    "\n",
    "# second round of dropping (at some point come back to these)\n",
    "columns_to_drop_2 = [\n",
    "    \"cpu_usage_percent\",\n",
    "    \"cpu_memory_usage_bytes\",\n",
    "    \"gpu_utilization_percent_0\",\n",
    "    \"gpu_utilization_percent_1\",\n",
    "    \"gpu_utilization_percent_2\",\n",
    "    \"gpu_utilization_percent_3\",\n",
    "    \"gpu_current_memory_allocated_bytes\",\n",
    "    \"gpu_max_memory_allocated_bytes\",\n",
    "    \"cpu_current_memory_allocated_bytes\",\n",
    "    \"cpu_max_memory_allocated_bytes\",\n",
    "    \"cpu_power_process_0\",\n",
    "    \"cpu_power_process_1\",\n",
    "    \"cpu_power_process_2\",\n",
    "    \"cpu_power_process_3\",\n",
    "    \"gpu_power_process_0\",\n",
    "    \"gpu_power_process_1\",\n",
    "    \"gpu_power_process_2\",\n",
    "    \"gpu_power_process_3\",\n",
    "    \"ram_power_process_0\",\n",
    "    \"ram_power_process_1\",\n",
    "    \"ram_power_process_2\",\n",
    "    \"ram_power_process_3\",\n",
    "    \"cpu_energy_process_0\",\n",
    "    \"cpu_energy_process_1\",\n",
    "    \"cpu_energy_process_2\",\n",
    "    \"cpu_energy_process_3\",\n",
    "    \"gpu_energy_process_0\",\n",
    "    \"gpu_energy_process_1\",\n",
    "    \"gpu_energy_process_2\",\n",
    "    \"gpu_energy_process_3\",\n",
    "    \"ram_energy_process_0\",\n",
    "    \"ram_energy_process_1\",\n",
    "    \"ram_energy_process_2\",\n",
    "    \"ram_energy_process_3\",\n",
    "    \"total_energy_joules_process_0\",\n",
    "    \"total_energy_joules_process_1\",\n",
    "    \"total_energy_joules_process_2\",\n",
    "    \"total_energy_joules_process_3\",\n",
    "    \"cpu_power_avg\",\n",
    "    \"ram_energy_total\",\n",
    "    \"models\"\n",
    "]\n",
    "\n",
    "for file in possible_files:\n",
    "    try:\n",
    "        cleaned_var = f\"df_{file}_cleaned\"   # e.g., df_controlled_cleaned\n",
    "        dropped_var = f\"df_{file}_dropped\"     # e.g., df_controlled_dropped\n",
    "        \n",
    "        # Drop the specified columns from the cleaned DataFrame.\n",
    "        globals()[dropped_var] = globals()[cleaned_var].drop(columns=columns_to_drop, errors='ignore')\n",
    "        globals()[dropped_var] = globals()[dropped_var].drop(columns=columns_to_drop_2, errors='ignore')\n",
    "        print(f\"Found & inspecting dropped version: {dropped_var}\")\n",
    "        display(globals()[dropped_var].T)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_controlled_dropped has only one unique FLOP value, skipping.\n",
      "--------------------------------------------------\n",
      "df_scenarios_dropped has only one unique FLOP value, skipping.\n",
      "--------------------------------------------------\n",
      "df_grid_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_text_generation_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# check all flops are constant\n",
    "\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    \n",
    "    if var_dropped in globals():\n",
    "        try:\n",
    "            df = globals()[var_dropped]\n",
    "            \n",
    "            # Check how many unique flops exist\n",
    "            unique_flops = df['flops'].unique()\n",
    "            \n",
    "            if len(unique_flops) > 1:\n",
    "                print(f\"\\n{var_dropped} has multiple FLOP counts:\")\n",
    "                print(f\"Unique FLOPs: {unique_flops}\")\n",
    "                \n",
    "                # Find rows for each different flop value\n",
    "                for flop_val in unique_flops:\n",
    "                    subset = df[df['flops'] == flop_val]\n",
    "                    config_names = subset['config_name'].unique()\n",
    "                    \n",
    "                    print(f\"FLOP value: {flop_val}\")\n",
    "                    print(f\"Associated config_name(s): {config_names}\")\n",
    "                print(\"-\" * 50)\n",
    "            else:\n",
    "                print(f\"{var_dropped} has only one unique FLOP value, skipping.\")\n",
    "                print(\"-\" * 50)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Problem inspecting {var_dropped}: {e}\")\n",
    "    else:\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_controlled_dropped has only one unique FLOP value, skipping.\n",
      "--------------------------------------------------\n",
      "df_scenarios_dropped has only one unique FLOP value, skipping.\n",
      "--------------------------------------------------\n",
      "df_grid_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_text_generation_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def identify_flop_differentiators(df, flops_col='flops', exclude_cols=None):\n",
    "    \"\"\"\n",
    "    Identify columns that are constant within each FLOP group but differ between groups.\n",
    "    \n",
    "    Parameters:\n",
    "      df (pd.DataFrame): The DataFrame containing the data.\n",
    "      flops_col (str): Name of the column used for grouping the FLOPs.\n",
    "      exclude_cols (list, optional): List of columns to exclude from the comparison.\n",
    "      \n",
    "    Returns:\n",
    "      dict: A dictionary where keys are the column names that differentiate FLOP groups,\n",
    "            and values are dictionaries mapping each unique FLOP value to the constant value\n",
    "            observed in that group.\n",
    "            \n",
    "    Example output:\n",
    "    {\n",
    "      'config_name': {1034544128000: 'A1_Max_Throughput_Exploit', \n",
    "                      16949970993152: 'A5_Parallel_Overdrive'},\n",
    "      'some_other_col': {1034544128000: 'value1', \n",
    "                         16949970993152: 'value2'}\n",
    "    }\n",
    "    \"\"\"\n",
    "    # Optionally exclude some columns, including the flops column itself.\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = []\n",
    "    exclude_cols = set(exclude_cols + [flops_col])\n",
    "    \n",
    "    differentiators = {}\n",
    "    unique_flops = df[flops_col].unique()\n",
    "    \n",
    "    # Loop over each column in df excluding the ones in exclude_cols.\n",
    "    for col in df.columns:\n",
    "        if col in exclude_cols:\n",
    "            continue\n",
    "        \n",
    "        # For each group (by flops), get the unique values for this column.\n",
    "        group_values = {}\n",
    "        valid = True  # assume column is constant per group unless we find more than one unique value.\n",
    "        for flop in unique_flops:\n",
    "            values = df[df[flops_col] == flop][col].unique()\n",
    "            if len(values) == 1:\n",
    "                group_values[flop] = values[0]\n",
    "            else:\n",
    "                # If any FLOP group has more than one value, then this column doesn't differentiate consistently.\n",
    "                valid = False\n",
    "                break\n",
    "        # Check if the column is valid and if it truly differentiates between groups.\n",
    "        if valid and len(set(group_values.values())) > 1:\n",
    "            differentiators[col] = group_values\n",
    "    \n",
    "    return differentiators\n",
    "\n",
    "\n",
    "\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    if var_dropped in globals():\n",
    "        try:\n",
    "            df = globals()[var_dropped]\n",
    "            \n",
    "            # Check if there is more than one FLOP count.\n",
    "            unique_flops = df['flops'].unique()\n",
    "            if len(unique_flops) > 1:\n",
    "                print(f\"\\n{var_dropped} has multiple FLOP counts:\")\n",
    "                print(f\"Unique FLOPs: {unique_flops}\")\n",
    "                \n",
    "                # Identify columns that differ consistently between FLOP groups.\n",
    "                diff_cols = identify_flop_differentiators(df)\n",
    "                if diff_cols:\n",
    "                    print(\"Differentiating columns:\")\n",
    "                    for col, mapping in diff_cols.items():\n",
    "                        print(f\"Column: {col}\")\n",
    "                        for flop, val in mapping.items():\n",
    "                            print(f\"  FLOP {flop}: {val}\")\n",
    "                else:\n",
    "                    print(\"No consistently differentiating columns were found.\")\n",
    "                print(\"-\" * 50)\n",
    "            else:\n",
    "                print(f\"{var_dropped} has only one unique FLOP value, skipping.\")\n",
    "                print(\"-\" * 50)\n",
    "        except Exception as e:\n",
    "            print(f\"Problem inspecting {var_dropped}: {e}\")\n",
    "    else:\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_grid_dropped does not exist, skipping.\n",
      "df_text_generation_dropped does not exist, skipping.\n"
     ]
    }
   ],
   "source": [
    "# DEFINE NEW VARS\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    \n",
    "    if var_dropped not in globals():\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df = globals()[var_dropped]\n",
    "        \n",
    "        df['flops_per_token'] = df['flops'] / df['total_generated_tokens']\n",
    "        df['energy_per_token_kwh'] = df['total_energy_kwh'] / df['total_generated_tokens']\n",
    "        df['divergence_energy_flops_per_token'] = df['energy_per_token_kwh'] / df['flops_per_token']\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {var_dropped}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['config_name', 'experiment_id', 'date_time', 'model', 'num_processes',\n",
      "       'batch_size___fixed_batching', 'decoder_temperature', 'decoder_top_k',\n",
      "       'decoder_top_p', 'latency_simulation_delay_min',\n",
      "       'latency_simulation_simulate_burst', 'latency_simulation_burst_size',\n",
      "       'latency_simulation_burst_interval', 'fp_precision', 'quantization',\n",
      "       'load_in_8bit', 'load_in_4bit', 'total_input_tokens', 'total_params',\n",
      "       'max_input_tokens', 'max_output_tokens', 'number_input_prompts',\n",
      "       'total_energy_kwh', 'total_energy_joules', 'flops', 'tokens_per_joule',\n",
      "       'joules_per_token', 'flops_per_joule', 'joules_per_flop',\n",
      "       'total_inference_time_sec', 'average_latency_ms_per_batch',\n",
      "       'throughput_queries_per_sec', 'throughput_tokens_per_sec',\n",
      "       'total_energy_kwh_process_0', 'total_energy_kwh_process_1',\n",
      "       'total_energy_kwh_process_2', 'total_energy_kwh_process_3',\n",
      "       'gpu_power_avg', 'ram_power_avg', 'cpu_energy_total',\n",
      "       'gpu_energy_total', 'decoder_config_decoding_mode',\n",
      "       'latency_simulation_simulate', 'latency_simulation_delay_max',\n",
      "       'total_generated_tokens', 'flops_per_token', 'energy_per_token_kwh',\n",
      "       'divergence_energy_flops_per_token'],\n",
      "      dtype='object')\n",
      "--------------------------------------------------\n",
      "Index(['config_name', 'experiment_id', 'date_time', 'model', 'num_processes',\n",
      "       'batch_size___fixed_batching', 'decoder_temperature', 'decoder_top_k',\n",
      "       'decoder_top_p', 'latency_simulation_delay_min',\n",
      "       'latency_simulation_simulate_burst', 'latency_simulation_burst_size',\n",
      "       'latency_simulation_burst_interval', 'fp_precision', 'quantization',\n",
      "       'load_in_8bit', 'load_in_4bit', 'total_input_tokens', 'total_params',\n",
      "       'max_input_tokens', 'max_output_tokens', 'number_input_prompts',\n",
      "       'total_energy_kwh', 'total_energy_joules', 'flops', 'tokens_per_joule',\n",
      "       'joules_per_token', 'flops_per_joule', 'joules_per_flop',\n",
      "       'total_inference_time_sec', 'average_latency_ms_per_batch',\n",
      "       'throughput_queries_per_sec', 'throughput_tokens_per_sec',\n",
      "       'total_energy_kwh_process_0', 'total_energy_kwh_process_1',\n",
      "       'total_energy_kwh_process_2', 'total_energy_kwh_process_3',\n",
      "       'gpu_power_avg', 'ram_power_avg', 'cpu_energy_total',\n",
      "       'gpu_energy_total', 'latency_simulation_simulate',\n",
      "       'decoder_config_decoding_mode', 'total_generated_tokens',\n",
      "       'latency_simulation_delay_max', 'flops_per_token',\n",
      "       'energy_per_token_kwh', 'divergence_energy_flops_per_token'],\n",
      "      dtype='object')\n",
      "--------------------------------------------------\n",
      "df_grid_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_text_generation_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# CHECK COLUMN NAMES\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    \n",
    "    if var_dropped not in globals():\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        print(\"-\" * 50)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        df = globals()[var_dropped]\n",
    "        print(df.columns)\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {var_dropped}: {e}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num_processes_1' 'num_processes_2' 'num_processes_3' 'num_processes_4'\n",
      " 'batching_1' 'batching_2' 'batching_4' 'batching_8' 'batching_16'\n",
      " 'batching_32' 'batching_64'\n",
      " 'precis_float32_quant_False_quant8_False_quant4_False'\n",
      " 'precis_float16_quant_False_quant8_False_quant4_False'\n",
      " 'precis_float16_quant_True_quant8_True_quant4_False'\n",
      " 'precis_float16_quant_True_quant8_False_quant4_True'\n",
      " 'decoding_greedy_decoder_temperature_0'\n",
      " 'decoding_greedy_decoder_temperature_0.2'\n",
      " 'decoding_greedy_decoder_temperature_0.4'\n",
      " 'decoding_greedy_decoder_temperature_0.6'\n",
      " 'decoding_greedy_decoder_temperature_0.8'\n",
      " 'decoding_greedy_decoder_temperature_1.0'\n",
      " 'decoding_greedy_decoder_temperature_1.2'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_0'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_0'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_0'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_0'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_0'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_0.2'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_0.2'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_0.2'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_0.2'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_0.2'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_0.4'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_0.4'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_0.4'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_0.4'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_0.4'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_0.6'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_0.6'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_0.6'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_0.6'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_0.6'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_0.8'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_0.8'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_0.8'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_0.8'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_0.8'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_1.0'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_1.0'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_1.0'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_1.0'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_1.0'\n",
      " 'decoding_top_k_decoder_top_k_20_decoder_temperature_1.2'\n",
      " 'decoding_top_k_decoder_top_k_50_decoder_temperature_1.2'\n",
      " 'decoding_top_k_decoder_top_k_100_decoder_temperature_1.2'\n",
      " 'decoding_top_k_decoder_top_k_200_decoder_temperature_1.2'\n",
      " 'decoding_top_k_decoder_top_k_500_decoder_temperature_1.2'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_0'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_0'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_0'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_0.2'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_0.2'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.2'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_0.2'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_0.4'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_0.4'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.4'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_0.4'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_0.6'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_0.6'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.6'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_0.6'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_0.8'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_0.8'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.8'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_0.8'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_1.0'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_1.0'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.0'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_1.0'\n",
      " 'decoding_top_p_decoder_top_p_0.7_decoder_temperature_1.2'\n",
      " 'decoding_top_p_decoder_top_p_0.8_decoder_temperature_1.2'\n",
      " 'decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.2'\n",
      " 'decoding_top_p_decoder_top_p_0.98_decoder_temperature_1.2'\n",
      " 'latency_False' 'latency_True_latency_0.05_latency_0.2_latency_False'\n",
      " 'latency_True_latency_0.2_latency_0.6_latency_False'\n",
      " 'latency_True_latency_0.05_latency_0.2_latency_True_latency_4.0_latency_5'\n",
      " 'latency_True_latency_0.2_latency_0.6_latency_True_latency_5.0_latency_8']\n",
      "--------------------------------------------------\n",
      "['A1_Max_Throughput_Exploit' 'A2_Precision_Minimalist'\n",
      " 'A3_Quantisation_Gaming' 'default' 'A5_Parallel_Overdrive'\n",
      " 'R2_Low_Latency_Chatbot_Deployment' 'R3_Balanced_Enterprise_Service'\n",
      " 'R4_High_Load_Cloud_API_Deployment' 'R5_Real_Time_Mobile_Inference'\n",
      " 'R6_Medium_Scale_Language_Model_Serving']\n",
      "--------------------------------------------------\n",
      "df_grid_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n",
      "df_text_generation_dropped does not exist, skipping.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# CHECK CONFIG NAMES\n",
    "for file in possible_files:\n",
    "    var_dropped = f\"df_{file}_dropped\"\n",
    "    \n",
    "    if var_dropped not in globals():\n",
    "        print(f\"{var_dropped} does not exist, skipping.\")\n",
    "        print(\"-\" * 50)\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        df = globals()[var_dropped]\n",
    "        print(df['config_name'].unique())\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {var_dropped}: {e}\")\n",
    "        print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cut this\n",
    "\n",
    "def extract_altered_value(config_name, family):\n",
    "    \"\"\"\n",
    "    Given a config name and a family, extract the altered value.\n",
    "    For each family, a different rule is applied:\n",
    "    \n",
    "    - num_processes: extract the integer after \"num_processes_\"\n",
    "    - batching: extract the integer after \"batching_\"\n",
    "    - precis: extract the precision setting; if quant4 is True, return \"load_in_4bit=True\",\n",
    "              otherwise return the float precision (e.g., \"float32\" or \"float16\")\n",
    "    - decoding: extract the decoder_temperature (as a float) from the config name.\n",
    "    - latency: if the config is exactly \"latency_False\", return \"No latency\"; otherwise, \n",
    "               extract and join all numeric values in the config string.\n",
    "    \"\"\"\n",
    "    if family == \"num_processes\":\n",
    "        m = re.search(r'num_processes_(\\d+)', config_name)\n",
    "        return int(m.group(1)) if m else config_name\n",
    "    \n",
    "    elif family == \"batching\":\n",
    "        m = re.search(r'batching_(\\d+)', config_name)\n",
    "        return int(m.group(1)) if m else config_name\n",
    "    \n",
    "    elif family == \"precis\":\n",
    "        m = re.search(r'precis_(float\\d+)', config_name)\n",
    "        precision = m.group(1) if m else None\n",
    "        # If quant4 is True, we assume load_in_4bit is the relevant setting. COME BACK TO THIS!!!\n",
    "        if \"quant4_True\" in config_name:\n",
    "            return \"load_in_4bit=True\"\n",
    "        else:\n",
    "            return precision\n",
    "        \n",
    "    elif family == \"decoding\":\n",
    "        # This family might have several variants. We extract the decoder_temperature. COME BACK TO\n",
    "        m = re.search(r'decoder_temperature_([\\d\\.]+)', config_name)\n",
    "        return float(m.group(1)) if m else config_name\n",
    "    \n",
    "    elif family == \"latency\":\n",
    "        # If it's simply \"latency_False\", nothing was altered.\n",
    "        if config_name == \"latency_False\":\n",
    "            return \"No latency\"\n",
    "        else:\n",
    "            # Find all numbers (either integer or float) in the string.\n",
    "            numbers = re.findall(r'\\d+\\.\\d+|\\d+', config_name)\n",
    "            return \", \".join(numbers)\n",
    "    else:\n",
    "        return config_name\n",
    "\n",
    "def plot_family(df, family, metric1, metric2):\n",
    "    \"\"\"\n",
    "    For a given family, subset the DataFrame (rows whose config_name starts with family).\n",
    "    Create a new column that holds the altered value for that family, sort the data by that value,\n",
    "    and plot two metrics against this altered value.\n",
    "    \n",
    "    Parameters:\n",
    "      - df: a DataFrame with a \"config_name\" column.\n",
    "      - family: the family string (e.g. \"num_processes\", \"batching\", etc).\n",
    "      - metric1: name of the first metric column to plot on the left Y axis (e.g., \"flops_per_token\").\n",
    "      - metric2: name of the second metric column to plot on the right Y axis (e.g., \"total_energy_kwh\").\n",
    "    \"\"\"\n",
    "    # Subset rows where config_name starts with the family string.\n",
    "    df_family = df[df['config_name'].str.startswith(family)].copy()\n",
    "    \n",
    "    # Apply the parser to create an \"altered_value\" column.\n",
    "    df_family['altered_value'] = df_family['config_name'].apply(lambda x: extract_altered_value(x, family))\n",
    "    \n",
    "    # Attempt to sort by altered_value.\n",
    "    # If the values are numeric, convert them.\n",
    "    try:\n",
    "        df_family['altered_value'] = pd.to_numeric(df_family['altered_value'])\n",
    "    except:\n",
    "        pass  # leave as string if conversion fails\n",
    "    \n",
    "    df_family.sort_values('altered_value', inplace=True)\n",
    "    \n",
    "    # Create a plot with twin y-axes.\n",
    "    fig, ax1 = plt.subplots(figsize=(8,5))\n",
    "    ax2 = ax1.twinx()\n",
    "    \n",
    "    # Plot metric1 on ax1 and metric2 on ax2.\n",
    "    ax1.plot(df_family['altered_value'], df_family[metric1], marker='o', label=metric1, color='blue')\n",
    "    ax2.plot(df_family['altered_value'], df_family[metric2], marker='s', label=metric2, color='red')\n",
    "    \n",
    "    ax1.set_xlabel(f'{family} configuration')\n",
    "    ax1.set_ylabel(metric1, color='blue')\n",
    "    ax2.set_ylabel(metric2, color='red')\n",
    "    plt.title(f'{family}: {metric1} and {metric2} vs altered setting')\n",
    "    \n",
    "    # Combine the legends.\n",
    "    lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "    lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines_1 + lines_2, labels_1 + labels_2, loc='best')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "families = [\"num_processes\", \"batching\", \"precis\", \"decoding\", \"latency\"]\n",
    "\n",
    "for fam in families:\n",
    "    plot_family(df_controlled_dropped, fam, metric1=\"flops_per_token\", metric2=\"energy_per_token_kwh\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "# RESTART FROM HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FOR CONTROLLED EXPERIMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FOCUS ON VARIATION AS A % OF TOTAL ENERGY???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'controlled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;241m==\u001b[39m possible_files[\u001b[43mcontrolled\u001b[49m]:\n\u001b[1;32m      3\u001b[0m     df \u001b[38;5;241m=\u001b[39m df_controlled_dropped\n\u001b[1;32m      5\u001b[0m     configs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnum_processes\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdecoder\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatency\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatching\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprecis\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'controlled' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "if file == possible_files[controlled]:\n",
    "    \n",
    "    df = df_controlled_dropped\n",
    "    \n",
    "    configs = ['num_processes', 'decoder', 'latency', 'batching', 'precis']\n",
    "    dfs = {config: df[df['config_name'].str.startswith(config)] for config in configs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == possible_files[controlled]:\n",
    "    \n",
    "for name, df in dfs:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # ----- First subplot: Divergence Energy vs Batch Size -----\n",
    "    axes[0].plot(\n",
    "        df['num_processes'],\n",
    "        df['divergence_energy_flops_per_token'],\n",
    "        marker='o', \n",
    "        linestyle='-',\n",
    "        color='orange'\n",
    "    )\n",
    "    axes[0].set_xlabel('Batch Size (Fixed Batching)')\n",
    "    axes[0].set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "    axes[0].set_title(f'Divergence Energy vs Batch Size ({name})')\n",
    "    axes[0].set_xticks(df['num_processes'])\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # ----- Second subplot: Two Y-axes with Energy per Token and FLOPs per Token -----\n",
    "    ax1 = axes[1]\n",
    "    line1, = ax1.plot(\n",
    "        df['num_processes'], \n",
    "        df['energy_per_token_kwh'], \n",
    "        marker='o', \n",
    "        linestyle='-', \n",
    "        color='blue', \n",
    "        label='Energy per Token (kWh)'\n",
    "    )\n",
    "    ax1.set_xlabel('Batch Size (Fixed Batching)')\n",
    "    ax1.set_ylabel('Energy per Token (kWh)', color='blue')\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax1.set_xticks(df['num_processes'])\n",
    "    ax1.set_title(f'Metrics vs Batch Size ({name})')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    line2, = ax2.plot(\n",
    "        df['num_processes'], \n",
    "        df['flops_per_token'], \n",
    "        marker='s', \n",
    "        linestyle='--', \n",
    "        color='red', \n",
    "        label='FLOPs per Token'\n",
    "    )\n",
    "    ax2.set_ylabel('FLOPs per Token', color='red')\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    # Combine legends\n",
    "    lines = [line1, line2]\n",
    "    labels = [line.get_label() for line in lines]\n",
    "    ax1.legend(lines, labels, loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Step 1: Create a new 'precision' column for plotting\n",
    "    def determine_precision(row):\n",
    "        if row.get('load_in_4bit', False):\n",
    "            return 'INT4'\n",
    "        elif row.get('load_in_8bit', False):\n",
    "            return 'INT8'\n",
    "        elif row.get('fp_precision') == 'torch.float16':\n",
    "            return 'FP16'\n",
    "        else:\n",
    "            return 'FP32'\n",
    "\n",
    "    precics_df['precision'] = precics_df.apply(determine_precision, axis=1)\n",
    "\n",
    "    # Step 2: Define custom precision order\n",
    "    precision_order = ['FP32', 'FP16', 'INT8', 'INT4']\n",
    "\n",
    "    # Step 3: Sort the dataframe according to precision order\n",
    "    precics_df['precision'] = pd.Categorical(precics_df['precision'], categories=precision_order, ordered=True)\n",
    "    precics_df = precics_df.sort_values('precision')\n",
    "\n",
    "    # Step 4: Plotting\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # ----- First subplot: Divergence Energy vs Precision -----\n",
    "    axes[0].plot(\n",
    "        precics_df['precision'],\n",
    "        precics_df['divergence_energy_flops_per_token'],\n",
    "        marker='o', \n",
    "        linestyle='-',\n",
    "        color='orange'\n",
    "    )\n",
    "    axes[0].set_xlabel('Precision')\n",
    "    axes[0].set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "    axes[0].set_title('Divergence Energy vs Precision')\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # ----- Second subplot: Two Y-axes with Energy per Token and FLOPs per Token -----\n",
    "    ax1 = axes[1]\n",
    "    line1, = ax1.plot(\n",
    "        precics_df['precision'], \n",
    "        precics_df['energy_per_token_kwh'], \n",
    "        marker='o', \n",
    "        linestyle='-', \n",
    "        color='blue', \n",
    "        label='Energy per Token (kWh)'\n",
    "    )\n",
    "    ax1.set_xlabel('Precision')\n",
    "    ax1.set_ylabel('Energy per Token (kWh)', color='blue')\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax1.set_title('Metrics vs Precision')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    line2, = ax2.plot(\n",
    "        precics_df['precision'], \n",
    "        precics_df['flops_per_token'], \n",
    "        marker='s', \n",
    "        linestyle='--', \n",
    "        color='red', \n",
    "        label='FLOPs per Token'\n",
    "    )\n",
    "    ax2.set_ylabel('FLOPs per Token', color='red')\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    # Combine legends\n",
    "    lines = [line1, line2]\n",
    "    labels = [line.get_label() for line in lines]\n",
    "    ax1.legend(lines, labels, loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == possible_files[controlled]:\n",
    "\n",
    "    # --- Step 1: Filter the dataframe based on the config names ---\n",
    "    config_names = [\n",
    "        'decoding_greedy_decoder_temperature_0',\n",
    "        'decoding_greedy_decoder_temperature_0.7',\n",
    "        'decoding_greedy_decoder_temperature_1.0',\n",
    "        'decoding_greedy_decoder_temperature_1.3',\n",
    "        'decoding_top_k_decoder_top_k_50_decoder_temperature_0',\n",
    "        'decoding_top_k_decoder_top_k_50_decoder_temperature_0.7',\n",
    "        'decoding_top_k_decoder_top_k_50_decoder_temperature_1.0',\n",
    "        'decoding_top_k_decoder_top_k_50_decoder_temperature_1.3',\n",
    "        'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0',\n",
    "        'decoding_top_p_decoder_top_p_0.9_decoder_temperature_0.7',\n",
    "        'decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.0',\n",
    "        'decoding_top_p_decoder_top_p_0.9_decoder_temperature_1.3'\n",
    "    ]\n",
    "    filtered_decoding = decoding_df[decoding_df['config_name'].isin(config_names)].copy()\n",
    "\n",
    "    # --- Step 2: Extract method and temperature from the config_name ---\n",
    "    def extract_method_and_temp(config):\n",
    "        if config.startswith(\"decoding_greedy_decoder_temperature_\"):\n",
    "            temp = float(config.split(\"decoding_greedy_decoder_temperature_\")[-1])\n",
    "            return \"greedy\", temp\n",
    "        elif config.startswith(\"decoding_top_k_decoder_top_k_50_decoder_temperature_\"):\n",
    "            temp = float(config.split(\"decoding_top_k_decoder_top_k_50_decoder_temperature_\")[-1])\n",
    "            return \"top_k\", temp\n",
    "        elif config.startswith(\"decoding_top_p_decoder_top_p_0.9_decoder_temperature_\"):\n",
    "            temp = float(config.split(\"decoding_top_p_decoder_top_p_0.9_decoder_temperature_\")[-1])\n",
    "            return \"top_p\", temp\n",
    "        else:\n",
    "            return \"unknown\", None\n",
    "\n",
    "    # Apply the extraction function and assign to new columns\n",
    "    filtered_decoding[['method', 'temperature']] = filtered_decoding['config_name'].apply(\n",
    "        lambda x: pd.Series(extract_method_and_temp(x))\n",
    "    )\n",
    "\n",
    "    # Optionally sort the dataframe by method and temperature for clarity.\n",
    "    filtered_decoding = filtered_decoding.sort_values(['method', 'temperature'])\n",
    "\n",
    "    # --- Step 3: Plotting ---\n",
    "\n",
    "    # Define colors for each method\n",
    "    colors = {\n",
    "        'greedy': 'blue',\n",
    "        'top_k': 'green',\n",
    "        'top_p': 'red'\n",
    "    }\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # --- Left subplot: Divergence Energy vs Temperature ---\n",
    "    ax_left = axes[0]\n",
    "    methods = filtered_decoding['method'].unique()\n",
    "    for m in methods:\n",
    "        subdf = filtered_decoding[filtered_decoding['method'] == m]\n",
    "        ax_left.plot(subdf['temperature'], subdf['divergence_energy_flops_per_token'],\n",
    "                    marker='o', linestyle='-', label=m, color=colors.get(m))\n",
    "    ax_left.set_xlabel('Decoder Temperature')\n",
    "    ax_left.set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "    ax_left.set_title('Divergence Energy vs Decoder Temperature')\n",
    "    ax_left.grid(True)\n",
    "    ax_left.legend(title=\"Method\")\n",
    "\n",
    "    # --- Right subplot: Two Y-axes with Energy per Token and FLOPs per Token ---\n",
    "    ax1 = axes[1]\n",
    "    # Primary axis for Energy per Token\n",
    "    for m in methods:\n",
    "        subdf = filtered_decoding[filtered_decoding['method'] == m]\n",
    "        ax1.plot(subdf['temperature'], subdf['energy_per_token_kwh'],\n",
    "                marker='o', linestyle='-', label=f'{m} Energy', color=colors.get(m))\n",
    "    ax1.set_xlabel('Decoder Temperature')\n",
    "    ax1.set_ylabel('Energy per Token (kWh)', color='black')\n",
    "    ax1.set_title('Metrics vs Decoder Temperature')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Secondary axis for FLOPs per Token\n",
    "    ax2 = ax1.twinx()\n",
    "    for m in methods:\n",
    "        subdf = filtered_decoding[filtered_decoding['method'] == m]\n",
    "        ax2.plot(subdf['temperature'], subdf['flops_per_token'],\n",
    "                marker='s', linestyle='--', label=f'{m} FLOPs', color=colors.get(m))\n",
    "    ax2.set_ylabel('FLOPs per Token', color='black')\n",
    "\n",
    "    # --- Combine legends from both axes ---\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1 + lines2, labels1 + labels2, loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == possible_files[controlled]:\n",
    "\n",
    "    # --- 1. Filter the latency_df to only keep the specified configurations ---\n",
    "    latency_configs = [\n",
    "        'latency_False',\n",
    "        'latency_True_latency_0.05_latency_0.2_latency_False',\n",
    "        'latency_True_latency_0.2_latency_0.6_latency_False',\n",
    "        'latency_True_latency_0.05_latency_0.2_latency_True_latency_4.0_latency_5',\n",
    "        'latency_True_latency_0.2_latency_0.6_latency_True_latency_5.0_latency_8'\n",
    "    ]\n",
    "    latency_filtered = latency_df[latency_df['config_name'].isin(latency_configs)].copy()\n",
    "\n",
    "    # --- 2. Define a function to parse the config string ---\n",
    "    def parse_latency_config(config):\n",
    "        \"\"\"\n",
    "        Parses a latency configuration string and returns a dict with:\n",
    "        - simulate (boolean)\n",
    "        - delay_min (float or None)\n",
    "        - delay_max (float or None)\n",
    "        - simulate_burst (boolean or None)\n",
    "        - burst_size (float or None)\n",
    "        - burst_interval (float or None)\n",
    "        \"\"\"\n",
    "        tokens = config.split('_')\n",
    "        \n",
    "        # There will be extra \"latency\" tokens in the string.\n",
    "        # Look at the total number of tokens:\n",
    "        # For baseline: e.g., \"latency_False\" -> tokens: [\"latency\", \"False\"]\n",
    "        # Without burst: 8 tokens, e.g.:\n",
    "        #   [\"latency\", \"True\", \"latency\", \"0.05\", \"latency\", \"0.2\", \"latency\", \"False\"]\n",
    "        # With burst: 12 tokens, e.g.:\n",
    "        #   [\"latency\", \"True\", \"latency\", \"0.05\", \"latency\", \"0.2\", \"latency\", \"True\", \"latency\", \"4.0\", \"latency\", \"5\"]\n",
    "        res = {}\n",
    "        if len(tokens) == 2:\n",
    "            # Baseline: no simulation\n",
    "            res['simulate'] = (tokens[1] == \"True\")\n",
    "            res['delay_min'] = None\n",
    "            res['delay_max'] = None\n",
    "            res['simulate_burst'] = None\n",
    "            res['burst_size'] = None\n",
    "            res['burst_interval'] = None\n",
    "        elif len(tokens) == 8:\n",
    "            # Without burst: tokens at positions 1, 3, 5, and 7 are our values.\n",
    "            res['simulate'] = (tokens[1] == \"True\")\n",
    "            res['delay_min'] = float(tokens[3])\n",
    "            res['delay_max'] = float(tokens[5])\n",
    "            res['simulate_burst'] = (tokens[7] == \"True\")\n",
    "            res['burst_size'] = None\n",
    "            res['burst_interval'] = None\n",
    "        elif len(tokens) == 12:\n",
    "            # With burst: tokens at positions 1, 3, 5, 7, 9, and 11.\n",
    "            res['simulate'] = (tokens[1] == \"True\")\n",
    "            res['delay_min'] = float(tokens[3])\n",
    "            res['delay_max'] = float(tokens[5])\n",
    "            res['simulate_burst'] = (tokens[7] == \"True\")\n",
    "            res['burst_size'] = float(tokens[9])\n",
    "            res['burst_interval'] = float(tokens[11])\n",
    "        else:\n",
    "            res['simulate'] = None\n",
    "            res['delay_min'] = None\n",
    "            res['delay_max'] = None\n",
    "            res['simulate_burst'] = None\n",
    "            res['burst_size'] = None\n",
    "            res['burst_interval'] = None\n",
    "        return res\n",
    "\n",
    "    # Apply the parser so that we have new columns for the latency parameters\n",
    "    latency_params = latency_filtered['config_name'].apply(lambda x: pd.Series(parse_latency_config(x)))\n",
    "    latency_filtered = pd.concat([latency_filtered, latency_params], axis=1)\n",
    "\n",
    "    # --- 3. Create a user-friendly label for each configuration ---\n",
    "    def make_latency_label(row):\n",
    "        if row['simulate'] is False:\n",
    "            return \"No simulation\"\n",
    "        elif row['simulate'] is True and row['simulate_burst'] is False:\n",
    "            return f\"Sim ({row['delay_min']}-{row['delay_max']})\"\n",
    "        elif row['simulate'] is True and row['simulate_burst'] is True:\n",
    "            return f\"Sim ({row['delay_min']}-{row['delay_max']}) Burst ({row['burst_size']},{row['burst_interval']})\"\n",
    "        else:\n",
    "            return \"Unknown\"\n",
    "\n",
    "    latency_filtered['latency_label'] = latency_filtered.apply(make_latency_label, axis=1)\n",
    "\n",
    "    # --- 4. Order the configurations as desired ---\n",
    "    order_labels = [\n",
    "        \"No simulation\",\n",
    "        \"Sim (0.05-0.2)\",\n",
    "        \"Sim (0.2-0.6)\",\n",
    "        \"Sim (0.05-0.2) Burst (4.0,5)\",\n",
    "        \"Sim (0.2-0.6) Burst (5.0,8)\"\n",
    "    ]\n",
    "    latency_filtered['latency_label'] = pd.Categorical(latency_filtered['latency_label'], \n",
    "                                                        categories=order_labels, ordered=True)\n",
    "    latency_filtered = latency_filtered.sort_values('latency_label')\n",
    "\n",
    "    # --- 5. Create the two subplots ---\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # Left Subplot: Divergence Energy vs Latency Configuration (categorical x-axis)\n",
    "    axes[0].plot(\n",
    "        latency_filtered['latency_label'],\n",
    "        latency_filtered['divergence_energy_flops_per_token'],\n",
    "        marker='o',\n",
    "        linestyle='-',\n",
    "        color='orange'\n",
    "    )\n",
    "    axes[0].set_xlabel('Latency Configuration')\n",
    "    axes[0].set_ylabel('Divergence Energy ~FLOPs per Token')\n",
    "    axes[0].set_title('Divergence Energy vs Latency Config')\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Right Subplot: Two y-axes for Energy per Token and FLOPs per Token\n",
    "    ax1 = axes[1]\n",
    "    line1, = ax1.plot(\n",
    "        latency_filtered['latency_label'],\n",
    "        latency_filtered['energy_per_token_kwh'],\n",
    "        marker='o',\n",
    "        linestyle='-',\n",
    "        color='blue',\n",
    "        label='Energy per Token (kWh)'\n",
    "    )\n",
    "    ax1.set_xlabel('Latency Configuration')\n",
    "    ax1.set_ylabel('Energy per Token (kWh)', color='blue')\n",
    "    ax1.tick_params(axis='y')\n",
    "    ax1.set_title('Metrics vs Latency Config')\n",
    "    ax1.grid(True)\n",
    "\n",
    "    # Create secondary y-axis for FLOPs per Token\n",
    "    ax2 = ax1.twinx()\n",
    "    line2, = ax2.plot(\n",
    "        latency_filtered['latency_label'],\n",
    "        latency_filtered['flops_per_token'],\n",
    "        marker='s',\n",
    "        linestyle='--',\n",
    "        color='red',\n",
    "        label='FLOPs per Token'\n",
    "    )\n",
    "    ax2.set_ylabel('FLOPs per Token', color='red')\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    # Combine legends from both axes\n",
    "    lines = [line1, line2]\n",
    "    labels = [line.get_label() for line in lines]\n",
    "    ax1.legend(lines, labels, loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == possible_files[controlled]:\n",
    "    print(f\"var energy: {df_controlled_dropped.total_energy_kwh.max()} / {df_controlled_dropped.total_energy_kwh.min()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WORK OUT STANDARD DEVIATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Histogram of raw total_energy_kwh\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(df_scenarios_dropped['total_energy_kwh'], bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Total Energy (kWh)')\n",
    "plt.xlabel('Total Energy (kWh)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Boxplot to spot outliers\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.boxplot(df_scenarios_dropped['total_energy_kwh'], vert=False)\n",
    "plt.title('Boxplot of Total Energy (kWh)')\n",
    "plt.xlabel('Total Energy (kWh)')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# If distribution is very skewed: log-transform\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(np.log(df_scenarios_dropped['total_energy_kwh']), bins=50, edgecolor='black')\n",
    "plt.title('Distribution of Log-Transformed Total Energy (kWh)')\n",
    "plt.xlabel('Log(Total Energy (kWh))')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# for Scenario Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if file == possible_files[\"scenario\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scenarios_dropped.total_energy_kwh.max() / df_scenarios_dropped.total_energy_kwh.min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

experiment_id,timestamp,suite,config,error_message
unknown,2025-04-25T18:39:09.372210,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int8_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpyszheeq4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-25T19:37:59.137939,grid,"{""config_name"": ""num_processes_3_batching_2_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpsm0358yv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-25T20:14:55.879881,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpuxqxywfb.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-25T20:29:29.958730,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgrd58krx.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-25T20:44:07.729332,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0g6zmxnr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-26T02:30:38.489915,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int8_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpk8iiund7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-26T14:56:21.569151,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5ncdwrqw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-26T15:02:10.270343,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp16_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp6ec20i5i.json', '--launched']' returned non-zero exit status 1."

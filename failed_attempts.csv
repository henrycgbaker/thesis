experiment_id,timestamp,suite,config,error_message
unknown,2025-04-17T01:11:05.372660,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqkg2y3e0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T01:11:24.423155,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp1dyx49z9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T01:11:43.229938,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvxfwgijk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T01:50:48.895915,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpkzo1pbnz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T01:51:08.037051,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmper440kup.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T01:51:26.924202,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4iyrim4r.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T02:28:41.627747,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpnssigrwp.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T02:29:00.307634,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvg23ohoi.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T02:29:26.100733,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp20en59nm.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T02:53:15.887824,controlled,"{""config_name"": ""batching_256"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 256}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4yy76_4c.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T03:03:58.997391,controlled,"{""config_name"": ""batching_256"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 256}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpr9loq9l_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T03:14:42.251240,controlled,"{""config_name"": ""batching_256"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 256}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp220pfoc3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T05:48:08.082229,controlled,"{""config_name"": ""latency_burst_0.1_0.2_4.0_5"", ""suite"": ""controlled"", ""controlled_variation"": {""latency_simulation.simulate"": true, ""latency_simulation.delay_min"": 0.1, ""latency_simulation.delay_max"": 0.2, ""latency_simulation.simulate_burst"": true, ""latency_simulation.burst_interval"": 4.0, ""latency_simulation.burst_size"": 5}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_8hselaf.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T06:33:02.180088,controlled,"{""config_name"": ""batching_128"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 128}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 128, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_0_h_hxa.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T06:43:52.777426,controlled,"{""config_name"": ""batching_128"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 128}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 128, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptto9r50e.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T06:54:35.203015,controlled,"{""config_name"": ""batching_128"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 128}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 128, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpxhw7tu_2.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T07:22:33.893283,controlled,"{""config_name"": ""batching_256"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 256}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpcagzoqy7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T07:33:15.219866,controlled,"{""config_name"": ""batching_256"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 256}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpl3nudfx3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T07:43:58.023170,controlled,"{""config_name"": ""batching_256"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 256}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp53nyu18h.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T08:16:25.854534,controlled,"{""config_name"": ""batching_128"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 128}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 128, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdb4zsfbm.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T08:27:07.615811,controlled,"{""config_name"": ""batching_128"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 128}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 128, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpds0p72j9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T08:37:50.143375,controlled,"{""config_name"": ""batching_128"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 128}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 128, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmphvapauqw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T08:48:23.017881,controlled,"{""config_name"": ""latency_const_0.4_0.5"", ""suite"": ""controlled"", ""controlled_variation"": {""latency_simulation.simulate"": true, ""latency_simulation.delay_min"": 0.4, ""latency_simulation.delay_max"": 0.5, ""latency_simulation.simulate_burst"": false}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpjc4idbps.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T09:33:15.350982,controlled,"{""config_name"": ""batching_64"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 64}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8nbj37bp.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T12:13:48.351326,controlled,"{""config_name"": ""decoding_top_k_topk_100_temp_1.0"", ""suite"": ""controlled"", ""controlled_variation"": {""decoder_config.decoding_mode"": ""top_k"", ""decoder_config.decoder_top_k"": 100, ""decoder_config.decoder_temperature"": 1.0}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": ""top_k"", ""decoder_temperature"": 1.0, ""decoder_top_k"": 100, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpw6t_8qe9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T13:16:09.572966,controlled,"{""config_name"": ""batching_256"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 256}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpttwio10t.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T13:27:07.371879,controlled,"{""config_name"": ""batching_256"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 256}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpx6cw5hna.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T13:38:01.235630,controlled,"{""config_name"": ""batching_256"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 256}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpve1gmedz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T14:33:53.168747,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgpvc085u.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T14:34:19.432644,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpt0gjur3i.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T14:35:36.304655,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdfz8hqbi.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T14:38:07.643629,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpxxvcrk3f.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T14:40:23.679656,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpy775frpf.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T14:42:24.483520,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpcb5m9fyv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T14:44:50.559670,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpu6r6qx0e.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T14:47:07.018678,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpx9nl7rm4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T14:49:00.356470,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3hbgv9wl.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T15:02:34.301737,controlled,"{""config_name"": ""batching_128"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 128}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 128, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpl1346adk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T15:13:31.498749,controlled,"{""config_name"": ""batching_128"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 128}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 128, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp1qs5x5ue.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T15:27:17.924978,controlled,"{""config_name"": ""batching_128"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 128}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 128, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpkapr7uq1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T15:39:15.381016,controlled,"{""config_name"": ""batching_256"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 256}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5eon7kgf.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T15:50:09.811537,controlled,"{""config_name"": ""batching_256"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 256}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmplz1qenrm.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T16:20:32.457587,controlled,"{""config_name"": ""batching_256"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 256}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqs_xdjyi.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T16:29:51.185786,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzyim4ofc.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T16:30:29.051140,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmphclia69a.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T16:31:07.283194,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmply4dco_d.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T16:31:48.669002,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqb07k7ab.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T16:32:26.427200,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp56q75_q7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T16:33:08.583537,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpujnhmf10.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T16:33:48.040730,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpje4axflj.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T16:35:42.388804,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpizv_gy4y.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T16:38:15.317527,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3z_x15t2.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T16:53:29.350473,controlled,"{""config_name"": ""batching_128"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 128}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 128, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpos3t1284.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-17T17:05:55.850028,controlled,"{""config_name"": ""batching_128"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 128}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 128, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8zcuijx0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:29:11.880535,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9tnuzym3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:29:22.594680,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0c3t_f4d.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:29:32.108781,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpnzil3hzh.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:29:44.605004,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpy2d4rgd9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:29:54.535295,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpy18fvwef.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:30:40.987546,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdcl5ol1v.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:31:05.360873,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp25p1_7zq.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:31:27.573370,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpy5ekuofu.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:31:51.209021,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4ojk0k7x.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:32:14.600075,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpy12ypfh5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:32:36.322812,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5ln55xh9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:33:00.049359,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpmou5vev0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:33:21.802113,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpj_w0h0hn.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:33:44.307648,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpsqswpl1j.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:44:35.732804,controlled,"{""config_name"": ""batching_256"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 256}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpoy6t7buw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:55:23.164872,controlled,"{""config_name"": ""batching_256"", ""suite"": ""controlled"", ""controlled_variation"": {""batching_options.batch_size___fixed_batching"": 256}, ""scenario_info"": {}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": null, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7j82b3_0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:59:06.731240,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9_6nzvda.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T13:59:45.757801,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpu2dkxu30.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T14:00:25.288294,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpjlyes0ox.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T14:01:04.359656,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpi5oldm5p.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T14:01:36.938503,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpq7mvj8f_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T14:02:00.027880,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4f2emkij.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T14:02:24.747402,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpy_o8oq9m.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T14:02:57.323569,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_sqf4vjo.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T14:03:34.347782,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpiirmz0hy.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T14:30:41.810735,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpjeys6qm9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T14:31:07.093984,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpkg4oud99.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T14:31:28.444468,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp1pl40gyi.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T15:11:43.019611,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpmt7chq3i.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T15:12:10.043818,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpz390h6h3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T15:12:32.010230,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5hp8m9al.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T15:50:20.045437,scenarios,"{""config_name"": ""R7_anti_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R7_anti_platonic_ideal"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 1, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 20}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.2, ""decoder_top_k"": null, ""decoder_top_p"": null, ""top_k"": 200}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp89mpol3z.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T16:00:49.986085,scenarios,"{""config_name"": ""R7_anti_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R7_anti_platonic_ideal"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 1, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 20}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.2, ""decoder_top_k"": null, ""decoder_top_p"": null, ""top_k"": 200}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp1iqulqg_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T16:11:17.098590,scenarios,"{""config_name"": ""R7_anti_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R7_anti_platonic_ideal"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 1, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 20}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.2, ""decoder_top_k"": null, ""decoder_top_p"": null, ""top_k"": 200}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2_izfejw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T16:15:14.198046,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpt6pzcfx0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T16:15:33.279328,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpxzripv24.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T16:15:54.534185,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpnc_b0kvt.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T16:40:22.581418,scenarios,"{""config_name"": ""A0_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""A0_platonic_ideal"", ""realistic"": false}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp01shg6_g.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T16:40:32.220429,scenarios,"{""config_name"": ""A0_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""A0_platonic_ideal"", ""realistic"": false}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpe2rsazy8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T16:40:46.232340,scenarios,"{""config_name"": ""A0_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""A0_platonic_ideal"", ""realistic"": false}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_04u_20b.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T16:40:59.849585,scenarios,"{""config_name"": ""R7_anti_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R7_anti_platonic_ideal"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 1, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 20}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.2, ""decoder_top_k"": null, ""decoder_top_p"": null, ""top_k"": 200}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqfgm4j43.json', '--launched']' died with <Signals.SIGKILL: 9>."
unknown,2025-04-18T16:41:14.136074,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpcrt4cs5s.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T16:41:24.129916,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfh1fzk2e.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T16:41:30.604024,scenarios,"{""config_name"": ""R7_anti_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R7_anti_platonic_ideal"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 1, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 20}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.2, ""decoder_top_k"": null, ""decoder_top_p"": null, ""top_k"": 200}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp1q2tlg3z.json', '--launched']' died with <Signals.SIGKILL: 9>."
unknown,2025-04-18T16:41:41.292686,scenarios,"{""config_name"": ""R7_anti_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R7_anti_platonic_ideal"", ""realistic"": true}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 1, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 20}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.2, ""decoder_top_k"": null, ""decoder_top_p"": null, ""top_k"": 200}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9qabtsc1.json', '--launched']' died with <Signals.SIGKILL: 9>."
unknown,2025-04-18T16:42:55.806635,scenarios,"{""config_name"": ""A2_Precision_Minimalist"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""A2_Precision_Minimalist"", ""realistic"": false}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 128, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqtgy2o89.json', '--launched']' died with <Signals.SIGKILL: 9>."
unknown,2025-04-18T16:43:55.646159,scenarios,"{""config_name"": ""A3_Quantisation_Gaming"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""A3_Quantisation_Gaming"", ""realistic"": false}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": ""top_k"", ""decoder_temperature"": 1.0, ""decoder_top_k"": 50, ""decoder_top_p"": null}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgurck5vc.json', '--launched']' died with <Signals.SIGKILL: 9>."
unknown,2025-04-18T16:44:40.465915,scenarios,"{""config_name"": ""A3_Quantisation_Gaming"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""A3_Quantisation_Gaming"", ""realistic"": false}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": ""top_k"", ""decoder_temperature"": 1.0, ""decoder_top_k"": 50, ""decoder_top_p"": null}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3jrrzhgp.json', '--launched']' died with <Signals.SIGKILL: 9>."
unknown,2025-04-18T17:27:39.207695,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', 'MAIN_a_single_experiment.py', '--config', '/tmp/tmps0uzwa5t.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T17:27:58.399735,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', 'MAIN_a_single_experiment.py', '--config', '/tmp/tmpsmvhulvi.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T17:28:20.474427,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', 'MAIN_a_single_experiment.py', '--config', '/tmp/tmpev4uyo0p.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T17:58:22.764197,scenarios,"{""config_name"": ""R7_anti_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R7_anti_platonic_ideal"", ""realistic"": true}, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 1, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 20}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.2, ""decoder_top_k"": null, ""decoder_top_p"": null, ""top_k"": 200}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', 'MAIN_a_single_experiment.py', '--config', '/tmp/tmpce3jjm9d.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T18:32:36.795641,scenarios,"{""config_name"": ""A0_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""A0_platonic_ideal"", ""realistic"": false}, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', 'MAIN_a_single_experiment.py', '--config', '/tmp/tmp5yv7h1q3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T18:32:53.119551,scenarios,"{""config_name"": ""A0_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""A0_platonic_ideal"", ""realistic"": false}, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', 'MAIN_a_single_experiment.py', '--config', '/tmp/tmpbiu2906m.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T18:40:51.470964,scenarios,"{""config_name"": ""A0_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""A0_platonic_ideal"", ""realistic"": false}, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', 'MAIN_a_single_experiment.py', '--config', '/tmp/tmprtkmuj4u.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T18:41:06.178003,scenarios,"{""config_name"": ""A0_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""A0_platonic_ideal"", ""realistic"": false}, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', 'MAIN_a_single_experiment.py', '--config', '/tmp/tmp85o3c8g0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T18:41:21.223793,scenarios,"{""config_name"": ""A0_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""A0_platonic_ideal"", ""realistic"": false}, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', 'MAIN_a_single_experiment.py', '--config', '/tmp/tmp66x6uqir.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T18:41:36.508565,scenarios,"{""config_name"": ""R7_anti_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R7_anti_platonic_ideal"", ""realistic"": true}, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 1, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 20}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.2, ""decoder_top_k"": null, ""decoder_top_p"": null, ""top_k"": 200}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', 'MAIN_a_single_experiment.py', '--config', '/tmp/tmpv1ihy7zc.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T18:41:51.652696,scenarios,"{""config_name"": ""R7_anti_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R7_anti_platonic_ideal"", ""realistic"": true}, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 1, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 20}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.2, ""decoder_top_k"": null, ""decoder_top_p"": null, ""top_k"": 200}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', 'MAIN_a_single_experiment.py', '--config', '/tmp/tmpt1zevo4n.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T18:42:06.956640,scenarios,"{""config_name"": ""R7_anti_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R7_anti_platonic_ideal"", ""realistic"": true}, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 1, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 20}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.2, ""decoder_top_k"": null, ""decoder_top_p"": null, ""top_k"": 200}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', 'MAIN_a_single_experiment.py', '--config', '/tmp/tmpj4bnvqwz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T18:42:22.140353,scenarios,"{""config_name"": ""A1_Max_Throughput_Exploit"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""A1_Max_Throughput_Exploit"", ""realistic"": false}, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', 'MAIN_a_single_experiment.py', '--config', '/tmp/tmpiofqo3ct.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T18:43:02.112261,scenarios,"{""config_name"": ""A0_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""A0_platonic_ideal"", ""realistic"": false}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', 'MAIN_a_single_experiment.py', '--config', '/tmp/tmp_sjebcfg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-18T18:43:16.535550,scenarios,"{""config_name"": ""A0_platonic_ideal"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""A0_platonic_ideal"", ""realistic"": false}, ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 256, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": null, ""load_in_4bit"": null, ""cached_flops_for_quantised_models"": 16949970993152}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', 'MAIN_a_single_experiment.py', '--config', '/tmp/tmp67e1jvjp.json', '--launched']' returned non-zero exit status 1."

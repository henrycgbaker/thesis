experiment_id,timestamp,suite,config,error_message
unknown,2025-04-25T18:39:09.372210,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int8_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpyszheeq4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-25T19:37:59.137939,grid,"{""config_name"": ""num_processes_3_batching_2_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpsm0358yv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-25T20:14:55.879881,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpuxqxywfb.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-25T20:29:29.958730,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgrd58krx.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-25T20:44:07.729332,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0g6zmxnr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-26T02:30:38.489915,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int8_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpk8iiund7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-26T14:56:21.569151,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5ncdwrqw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-26T15:02:10.270343,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp16_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp6ec20i5i.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-26T17:11:03.919989,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdd0ykoei.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-26T17:24:47.418113,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvt9o9ef9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-26T17:38:27.623190,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpw2r6f6e4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:45:57.552276,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpcof4nm_z.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:46:06.862697,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpywqgakbl.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:46:16.235556,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7qo0vulg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:46:27.528845,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvm80rxkc.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:46:36.855574,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp79pgeijh.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:46:46.189912,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0qhpsale.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:46:57.500595,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfo7715vk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:47:06.774604,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmphrvfaim1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:47:16.676315,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdrx80vhp.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:47:25.964302,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgy4vqju7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:47:35.292286,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2dqjtzj3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:47:46.600248,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfbel9rmz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:47:55.923839,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpkq_cruj1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:48:05.237256,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpz1sshiqu.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:48:18.735494,grid,"{""config_name"": ""num_processes_2_batching_4_precision_int4_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpp_ag0q9m.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:48:28.063658,grid,"{""config_name"": ""num_processes_2_batching_4_precision_int4_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzd0llnxn.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:48:37.370705,grid,"{""config_name"": ""num_processes_2_batching_4_precision_int4_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptxhmh5ik.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:48:48.631871,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpau_v5_mk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:48:57.962284,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp969iq4jr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:49:07.241971,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfaeufef7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:49:18.555224,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpz2jzmaxb.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:49:27.895408,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpi0nfxa51.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:49:37.164875,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2desno56.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:49:51.941624,grid,"{""config_name"": ""num_processes_3_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpnsfau7jq.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:50:01.259591,grid,"{""config_name"": ""num_processes_3_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp87_xk31s.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:50:10.636014,grid,"{""config_name"": ""num_processes_3_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp1v2ap1t3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:50:21.963355,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmph7gokjoy.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:50:31.473623,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp73lqv1f5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:50:40.809334,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0loulmxy.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:50:52.135809,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpythqd3r4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:51:01.451970,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgodsxrwz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:51:10.754808,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpjkf3g5rx.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:51:22.108218,grid,"{""config_name"": ""num_processes_1_batching_16_precision_int4_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpsdmlvxx9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:51:31.412176,grid,"{""config_name"": ""num_processes_1_batching_16_precision_int4_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpspm7xel5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:51:40.675840,grid,"{""config_name"": ""num_processes_1_batching_16_precision_int4_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_ejy8cwi.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:51:52.079091,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp1y0oty6b.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:52:01.428870,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpysfbk9_q.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:52:10.702540,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9scazlcm.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:52:22.025377,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp6t6lxke7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:52:31.339875,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpcwi2oasr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:52:40.645223,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpi5rbjcwk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:52:51.932885,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdt9o6b_3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:53:01.248520,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8sv09bcj.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:53:10.521750,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_gqju0m4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:53:21.843153,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwfx2n2ve.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:53:31.158682,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp1eqourit.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:53:40.461781,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpn6oljqcs.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:53:51.786146,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpbeujb58t.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:54:01.086164,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpms7tt7u8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:54:10.397638,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpg1v1otod.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:54:21.679976,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfsojw0ki.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:54:30.985437,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpswyuj7i1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:54:40.269421,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmplu28axts.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:54:51.573438,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpifr10cl6.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:55:00.828620,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpnbkx3b29.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:55:10.104712,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpksojpoq5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:55:21.429206,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppbz8lkxh.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:55:30.721450,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpkltjqxi2.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:55:39.996795,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpsiyc0cju.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:55:51.340418,grid,"{""config_name"": ""num_processes_3_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwq05g_iu.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:56:00.643013,grid,"{""config_name"": ""num_processes_3_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_5z2wz1n.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:56:09.914207,grid,"{""config_name"": ""num_processes_3_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptqvisory.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:56:21.209813,grid,"{""config_name"": ""num_processes_1_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpm58kv_40.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:56:30.562461,grid,"{""config_name"": ""num_processes_1_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpejr8d_6u.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:56:39.856640,grid,"{""config_name"": ""num_processes_1_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpql0i0hov.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:56:51.141909,grid,"{""config_name"": ""num_processes_1_batching_4_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpxfzbsbbe.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:57:03.823583,grid,"{""config_name"": ""num_processes_3_batching_2_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpmxligzok.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:57:13.144377,grid,"{""config_name"": ""num_processes_3_batching_2_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppvigvsy4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:57:22.464027,grid,"{""config_name"": ""num_processes_3_batching_2_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp6p86hv8p.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:57:33.787081,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0shy5je1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:57:43.069946,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpmk68dwuz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:57:52.355271,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0hs0wqh5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:58:03.675363,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7thtx3x9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:58:12.959072,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3t71823g.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:58:22.244673,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpaebejj6j.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:58:33.564557,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4fe29o5f.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:58:42.865401,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmprchv3u8d.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:58:52.236844,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptawxch6x.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:59:03.626297,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp32_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5m3l4chs.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:59:12.930807,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp32_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpbm4m_c3s.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:59:22.250083,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp32_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppd8qthqg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:59:33.554369,grid,"{""config_name"": ""num_processes_2_batching_2_precision_int8_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2x_k0dg_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:59:42.816793,grid,"{""config_name"": ""num_processes_2_batching_2_precision_int8_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpb2fvqfeh.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T18:59:52.149039,grid,"{""config_name"": ""num_processes_2_batching_2_precision_int8_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpsap54jp5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:00:03.633982,grid,"{""config_name"": ""num_processes_3_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdhivga9b.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:00:13.209340,grid,"{""config_name"": ""num_processes_3_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2j_xh95x.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:00:22.740045,grid,"{""config_name"": ""num_processes_3_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpk6zuke2x.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:00:34.084792,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptdjjx4o0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:00:43.525380,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpcjowne1_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:00:52.863581,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2w75q8dh.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:01:09.662756,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8ikliiz5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:01:19.059398,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpcrtriatc.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:01:28.489404,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpduniqlme.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:01:39.839213,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpndw212q5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:01:49.188191,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfwyfhi1u.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:01:58.538109,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp56i6iqqv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:02:09.959792,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpn8i743pn.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:02:19.317275,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqbvkp1ka.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:02:28.641116,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp6krfkm3t.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:02:40.053676,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpz_4z8n7q.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:02:54.757515,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpah2_xrkq.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:03:04.126691,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpt48_q24c.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:03:13.656117,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpit_a92wv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:03:25.039018,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5uameeyw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:03:34.418260,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwktcuy09.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:03:47.653752,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgrrwynop.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:03:57.061428,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppdv3m28a.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:04:06.659528,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5oqkv41n.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:04:18.126677,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpf3lm3xhg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:04:27.553837,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9q0picyw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:04:36.980303,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpr0a53snt.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:04:48.349953,grid,"{""config_name"": ""num_processes_2_batching_4_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3qq339iv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:04:58.031622,grid,"{""config_name"": ""num_processes_3_batching_4_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgf5mxids.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:05:07.377510,grid,"{""config_name"": ""num_processes_3_batching_4_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpi7piyte6.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:05:16.758362,grid,"{""config_name"": ""num_processes_3_batching_4_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvvbyefhf.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:05:28.119322,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpm6dm2ijr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:05:37.498753,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpl9lqxlbu.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:05:46.878739,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8otbzjbm.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:05:58.259635,grid,"{""config_name"": ""num_processes_3_batching_16_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpz7gedxdm.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:06:07.634287,grid,"{""config_name"": ""num_processes_3_batching_16_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8epyrssj.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:06:17.033920,grid,"{""config_name"": ""num_processes_3_batching_16_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpbok15h5c.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:06:28.475190,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3rjo71b1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:06:37.838852,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpahy30229.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:06:47.175416,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmps2d22fx9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:06:58.506958,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqzibgroe.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:07:07.875852,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpx53n7e6r.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:07:17.234615,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpod7veifl.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:07:28.544595,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptzvs7vtn.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:07:37.952384,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5gu0pg5f.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:07:47.364575,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpamxrf7n5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:07:58.775029,grid,"{""config_name"": ""num_processes_4_batching_2_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqadgzsti.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:08:08.171771,grid,"{""config_name"": ""num_processes_4_batching_2_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp6yjcm49_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:08:17.519619,grid,"{""config_name"": ""num_processes_4_batching_2_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfysa93v5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:08:28.968562,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpk10krx29.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:08:38.335499,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4dfs8w37.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:08:47.697557,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvv9ubeh3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:08:59.065323,grid,"{""config_name"": ""num_processes_3_batching_16_precision_int8_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpq76od04q.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:09:08.423759,grid,"{""config_name"": ""num_processes_3_batching_16_precision_int8_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpw4hh1mjm.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:09:23.753837,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfjdh4g6y.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:09:33.154464,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmps8yw_2es.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:09:42.604939,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp06vqp9gu.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:09:54.028171,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8p68zr22.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:10:03.348762,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfn4y9g1s.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:10:12.702206,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpalz7n49k.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:10:24.173191,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int8_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgxoo61rh.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:10:33.587297,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int8_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmplj1acanv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:10:42.961705,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int8_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdxon102i.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:10:54.348004,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8xhn0r31.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:11:03.725035,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpikmflkt1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:11:13.098302,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfh2kpj8k.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:11:30.205441,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpi1vjit44.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:11:39.494051,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp82s136qe.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:11:48.802026,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpd5w1hao1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:12:00.088770,grid,"{""config_name"": ""num_processes_3_batching_4_precision_fp32_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp55kh9qtp.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:12:09.353596,grid,"{""config_name"": ""num_processes_3_batching_4_precision_fp32_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8ccoiur5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:12:18.649649,grid,"{""config_name"": ""num_processes_3_batching_4_precision_fp32_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpv36jyvsg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:12:29.945264,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3eebi81g.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:12:39.257944,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwcdvscmp.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:12:48.537358,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpy6r1inyj.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:13:02.961115,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpelbo9ity.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:13:12.250830,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4fzme4fz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:13:21.508871,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwcr4o_3a.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:13:32.801796,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpkytnq1mm.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:13:42.055946,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpxveexuo4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:13:51.325243,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4hx4qb9s.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:14:02.568598,grid,"{""config_name"": ""num_processes_2_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpyv01ugnp.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:14:11.831613,grid,"{""config_name"": ""num_processes_2_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpb2n5wq_a.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:14:21.109032,grid,"{""config_name"": ""num_processes_2_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_91yjlal.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:14:32.405979,grid,"{""config_name"": ""num_processes_1_batching_2_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpcqk8ygui.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:14:41.677564,grid,"{""config_name"": ""num_processes_1_batching_2_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_260erxq.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:14:57.908444,grid,"{""config_name"": ""num_processes_1_batching_2_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpkevnmqz_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:15:09.680950,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgbb85b2v.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:15:20.046688,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5awprdd4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:15:30.260934,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpm4bjt_7d.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:15:42.807156,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpc2r1s6q_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:15:52.082952,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2iyfm6vd.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:16:01.397698,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_iguftg3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:16:12.686356,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpw42437ou.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:16:22.001673,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpuec79bsx.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:16:31.277965,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpeijbuk77.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:16:42.543511,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwvldrf7s.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:16:51.823981,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9qqlofd3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:17:01.200139,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppjzaoscq.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:17:12.507967,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpk2flguoq.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:17:21.817288,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0qi1efnn.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:17:31.079857,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgldgfm55.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:17:42.370222,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvoe9od3k.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:17:51.651230,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2abegeik.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:18:00.945747,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpbpi185li.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:18:12.268743,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3q6bntzx.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:18:21.543507,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0n54luta.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:18:30.835677,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpnp0_fr9w.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:18:42.104598,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int4_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7ihlkyff.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:18:51.406635,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int4_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpjd_n3p24.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:19:00.676687,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int4_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmput3kd0ly.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:19:11.968058,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppv_ffszu.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:19:21.284194,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0jsvxeqg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:19:30.543425,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfkgptvy3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:19:41.837307,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpe6ll8i8i.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:19:51.127543,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp77uvmzq_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:20:00.427083,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpl4ttaiou.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:20:11.842132,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int4_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2t7b4f1_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:20:21.140375,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int4_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpa90hswuu.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:20:30.426838,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int4_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0rpdwvvz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:20:41.730817,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpc0r2m8kl.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:20:51.081582,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzolb4kgm.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:21:00.484328,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_e0dr0yf.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:21:11.816379,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpm13y6avw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:21:27.201796,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_25cy0xm.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:21:36.489540,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpi85i5wjd.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:21:45.878055,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvbxyvt75.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:21:57.195203,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpubzj3bq9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:22:06.516727,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_klymxew.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:22:15.816838,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptyleogfr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:22:27.103692,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp829of7aa.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:22:37.618323,grid,"{""config_name"": ""num_processes_3_batching_32_precision_int4_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp1ovswisr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:22:46.931498,grid,"{""config_name"": ""num_processes_3_batching_32_precision_int4_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0xcy4pbp.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:22:56.249660,grid,"{""config_name"": ""num_processes_3_batching_32_precision_int4_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp94uwfqfp.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:23:07.571557,grid,"{""config_name"": ""num_processes_1_batching_8_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpm9h9ehe0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:23:16.879525,grid,"{""config_name"": ""num_processes_1_batching_8_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5d91y7w_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:23:26.199853,grid,"{""config_name"": ""num_processes_1_batching_8_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpatjz4hpv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:23:38.540005,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpludr3tlf.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:23:47.866163,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpmb0xy9pt.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:23:57.205432,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9r9b04o0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:24:08.472494,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpon6jb65b.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:24:17.752749,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpocov_fpn.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:24:27.032237,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpndk26_tq.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:24:38.315244,grid,"{""config_name"": ""num_processes_4_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqo_trfuk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:24:47.593627,grid,"{""config_name"": ""num_processes_4_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpi_vmurfv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:24:56.884147,grid,"{""config_name"": ""num_processes_4_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpb98hjqcf.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:25:08.341954,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpv8q6qd8c.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:25:18.553009,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdh07fvfd.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:25:28.796552,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppftt4ro0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:25:41.124438,grid,"{""config_name"": ""num_processes_4_batching_2_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpd_bvwy3i.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:25:51.612966,grid,"{""config_name"": ""num_processes_4_batching_2_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5dmlqq24.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:26:02.028316,grid,"{""config_name"": ""num_processes_4_batching_2_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpuaiqcxt6.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:26:14.316463,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpu5i6_7uq.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:26:24.628840,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppolj_v1b.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:26:34.888219,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpl7d6ege7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:26:47.668909,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmprrvd7atr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:26:59.932957,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpl2e6xz1_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:27:10.236821,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9y1svmgk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:27:20.537002,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp6jnap6_j.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:27:32.868833,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpa70r5mjx.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:27:43.580887,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzsvef1ls.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:27:53.896953,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpswg6yun1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:28:06.189023,grid,"{""config_name"": ""num_processes_2_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpust4uyew.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:28:16.452977,grid,"{""config_name"": ""num_processes_2_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzydm83hh.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:28:26.764980,grid,"{""config_name"": ""num_processes_2_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpejnqi4fo.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:28:39.037425,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0zapoo91.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:28:49.276364,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpak7rvuau.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:28:59.536965,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0scda27l.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:29:12.196944,grid,"{""config_name"": ""num_processes_3_batching_32_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp1q5maexd.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:29:22.384920,grid,"{""config_name"": ""num_processes_3_batching_32_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpkhsvo4jr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:29:33.164651,grid,"{""config_name"": ""num_processes_3_batching_32_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8g81elh3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:29:45.432946,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2awg6o8y.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:29:55.675666,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppcjiao6b.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:30:05.820961,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpq6lhg8ho.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:30:18.076963,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2t_yh2_y.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:30:28.316924,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppveh6fjx.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:30:38.484908,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpv_1dt5_w.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:30:50.647297,grid,"{""config_name"": ""num_processes_4_batching_16_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpf968tufs.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:31:00.792523,grid,"{""config_name"": ""num_processes_4_batching_16_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpelxl0cnv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:31:10.893293,grid,"{""config_name"": ""num_processes_4_batching_16_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpoaomf2e1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:31:23.758225,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpjsrfqvx1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:31:33.959969,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp98kc2g21.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:31:44.220826,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpm75js10x.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:31:56.573531,grid,"{""config_name"": ""num_processes_2_batching_64_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpk8vmo4n4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:32:07.136957,grid,"{""config_name"": ""num_processes_2_batching_64_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpquil4q19.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:32:17.316959,grid,"{""config_name"": ""num_processes_2_batching_64_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpc69843an.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:32:29.521813,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpslfuzz2x.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:32:39.778380,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpu91itsa3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:32:52.736056,grid,"{""config_name"": ""num_processes_4_batching_2_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8qi5m31r.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:33:03.092887,grid,"{""config_name"": ""num_processes_4_batching_2_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpsvc8897f.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:33:13.274933,grid,"{""config_name"": ""num_processes_4_batching_2_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvu2h4c07.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:33:25.551191,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpca0do3fs.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:33:35.816500,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpf0lfgobv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:33:46.184919,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_0_f55kg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:33:58.462445,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpn5r00tep.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:34:08.660981,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpflfr6otn.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:34:18.816960,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzdj5wjey.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:34:31.149113,grid,"{""config_name"": ""num_processes_3_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpmjneypux.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:34:41.535269,grid,"{""config_name"": ""num_processes_3_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpp3wv63e0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-27T19:34:51.740929,grid,"{""config_name"": ""num_processes_3_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpyljoi316.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:54:17.040184,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmproxzepzs.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:54:26.230289,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp1756ix_e.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:54:35.446998,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfcmdlihr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:54:46.667772,grid,"{""config_name"": ""num_processes_1_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5q0krcvg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:54:55.885212,grid,"{""config_name"": ""num_processes_1_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpg1gnundw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:55:05.071096,grid,"{""config_name"": ""num_processes_1_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4rfs7cmr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:55:16.280691,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5d149vf7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:55:25.509117,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp67zh6dgr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:55:34.737691,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpn0nxplbd.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:55:45.933072,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpun4hw9u5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:55:55.123159,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzotps3aw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:56:04.310150,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpmszb79yg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:56:15.501673,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp76c3_osy.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:56:24.731198,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_rtmnj3b.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:56:33.912411,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptxsjfmpg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:56:45.122779,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmprh7npvjr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:56:54.401014,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpveo1hesi.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:57:03.613849,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpv3978qnj.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:57:14.843877,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpenmbi1q4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:57:24.213641,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp11d7n_02.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:57:33.384836,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdq8ey6c9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:57:44.540632,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfxnffpl3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:57:53.717615,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpjd65ebir.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:58:02.895908,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpn7dvocso.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:58:14.092670,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpquq_egke.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:58:29.422887,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpl2zv_o7n.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:58:38.588535,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7p0qjq65.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:58:47.754875,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgbnc0wjb.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:59:08.284051,grid,"{""config_name"": ""num_processes_4_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpxnv0a65o.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-28T17:59:17.531443,grid,"{""config_name"": ""num_processes_4_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpl3pa1pzl.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-29T12:27:36.423449,grid,"{""config_name"": ""num_processes_2_batching_2_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpb3thfpzi.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-29T12:37:51.239476,grid,"{""config_name"": ""num_processes_2_batching_2_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpp09617xv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-29T12:48:06.534308,grid,"{""config_name"": ""num_processes_2_batching_2_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3s47o_j0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-29T13:22:07.268442,scenarios,"{""config_name"": ""R6_Medium_Scale_Language_Model_Serving"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R6_Medium_Scale_Language_Model_Serving"", ""realistic"": true}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.01, ""delay_max"": 0.1, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwh3hkhj1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-29T13:22:16.455804,scenarios,"{""config_name"": ""R6_Medium_Scale_Language_Model_Serving"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R6_Medium_Scale_Language_Model_Serving"", ""realistic"": true}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.01, ""delay_max"": 0.1, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8u0nssv7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-29T13:22:25.609382,scenarios,"{""config_name"": ""R6_Medium_Scale_Language_Model_Serving"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R6_Medium_Scale_Language_Model_Serving"", ""realistic"": true}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.01, ""delay_max"": 0.1, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": ""greedy"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": null}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppofwppw4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-29T14:41:07.917471,scenarios,"{""config_name"": ""R4_Standard_DualGPU_TopP_4bit"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R4_Standard_DualGPU_TopP_4bit"", ""realistic"": true}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.05, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 3.0, ""burst_size"": 6}, ""decoder_config"": {""decoding_mode"": ""top_p"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.9}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": null, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpe5me0vw7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-29T15:07:13.433096,scenarios,"{""config_name"": ""R4_Standard_DualGPU_TopP_4bit"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R4_Standard_DualGPU_TopP_4bit"", ""realistic"": true}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.05, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 3.0, ""burst_size"": 6}, ""decoder_config"": {""decoding_mode"": ""top_p"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.9}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": null, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpe1ppro0o.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-30T14:20:22.891599,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpt3zotus8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-30T14:42:04.534167,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmphqbmwv0p.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-30T15:14:10.792895,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9gv7oomh.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-30T15:24:45.756548,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpnut_4h6g.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:09:49.883347,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8xnfl72_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:09:59.103845,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpuz5as6wy.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:10:08.430144,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppz2j45uv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:10:19.661447,grid,"{""config_name"": ""num_processes_1_batching_2_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpd0llvbxz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:10:28.894977,grid,"{""config_name"": ""num_processes_1_batching_2_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmphw9z54f6.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:10:38.088923,grid,"{""config_name"": ""num_processes_1_batching_2_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmplr2s513j.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:10:49.287774,grid,"{""config_name"": ""num_processes_1_batching_32_precision_int4_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptbv5v7f6.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:10:58.448749,grid,"{""config_name"": ""num_processes_1_batching_32_precision_int4_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqb4o6cva.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:11:07.651128,grid,"{""config_name"": ""num_processes_1_batching_32_precision_int4_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpu8syg_al.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:11:18.861047,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp32_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9756jfsm.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:11:28.055070,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp32_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5ruw03u5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:11:37.202449,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp32_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5idp1pqt.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:11:48.382822,grid,"{""config_name"": ""num_processes_3_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpjp8sacpc.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:11:57.565695,grid,"{""config_name"": ""num_processes_3_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp17ftxu6v.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:12:06.783294,grid,"{""config_name"": ""num_processes_3_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp6r95gsd2.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:12:17.977919,grid,"{""config_name"": ""num_processes_1_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp48hfdc33.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:12:27.176565,grid,"{""config_name"": ""num_processes_1_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvuxv_85b.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:12:36.345498,grid,"{""config_name"": ""num_processes_1_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpv0yekkns.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:12:47.595525,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3txqwf82.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:12:56.867868,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmparvugxco.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:13:06.064105,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpf1g0afa8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:13:17.223124,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7wclxtv0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:13:26.396780,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpy9adxayq.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:13:40.461353,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpo8saqfvh.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:13:49.678402,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpapkabrh1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:13:58.875616,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpcaqx57dw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:14:10.026480,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp70r0fiku.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:14:19.212087,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4by3pikc.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:14:28.390482,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfudj6gyl.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:14:39.603018,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp1nc_k3gt.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:14:48.799091,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmphls7e5se.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:14:57.945964,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_mix6v86.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:15:09.158850,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpj1q2tldn.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:15:19.434995,grid,"{""config_name"": ""num_processes_3_batching_2_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpouajww5q.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:15:28.633347,grid,"{""config_name"": ""num_processes_3_batching_2_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4w0c7sw6.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:15:37.820127,grid,"{""config_name"": ""num_processes_3_batching_2_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4mj18luh.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:15:48.974827,grid,"{""config_name"": ""num_processes_3_batching_16_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqga_1dau.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:15:58.184390,grid,"{""config_name"": ""num_processes_3_batching_16_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp12bh8i_t.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:16:07.378711,grid,"{""config_name"": ""num_processes_3_batching_16_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpjuldjzal.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:16:18.617163,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvsssdufz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:16:27.821886,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0xm1o0yt.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:16:37.007645,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpu714jcom.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:16:48.238209,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpge2s794u.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:16:57.421919,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmphzqcz7j2.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:17:06.581414,grid,"{""config_name"": ""num_processes_2_batching_32_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpyptwuhnk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:17:17.851153,grid,"{""config_name"": ""num_processes_2_batching_4_precision_int4_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpf40ywk4k.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:17:27.060079,grid,"{""config_name"": ""num_processes_2_batching_4_precision_int4_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpg2x_znyt.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:17:36.243063,grid,"{""config_name"": ""num_processes_2_batching_4_precision_int4_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3tayyn6h.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:17:47.400142,grid,"{""config_name"": ""num_processes_3_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpew2e7c5x.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:17:56.553250,grid,"{""config_name"": ""num_processes_3_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpp40baxn3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:18:05.715767,grid,"{""config_name"": ""num_processes_3_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmplfx2z74i.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:18:18.287269,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_a1n4hxw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:18:27.499623,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfhv50mvn.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:18:36.662770,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpootr19g5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:18:47.868746,grid,"{""config_name"": ""num_processes_1_batching_4_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpov8433bo.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:18:57.089060,grid,"{""config_name"": ""num_processes_1_batching_4_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpitimq3fj.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:19:06.270942,grid,"{""config_name"": ""num_processes_1_batching_4_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpw5x0lakv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:19:17.481715,grid,"{""config_name"": ""num_processes_3_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpyoe6bbz8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:19:26.644764,grid,"{""config_name"": ""num_processes_3_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdi5nr7yu.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:19:35.827385,grid,"{""config_name"": ""num_processes_3_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpuyu5v41k.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:19:47.029884,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpyqy4vgbf.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:19:56.216347,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpjcu6f2_m.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:20:05.417513,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdfzxkv9w.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:20:16.594388,grid,"{""config_name"": ""num_processes_1_batching_32_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmprqko72y2.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:20:25.782690,grid,"{""config_name"": ""num_processes_1_batching_32_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpb6vean59.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:20:34.974004,grid,"{""config_name"": ""num_processes_1_batching_32_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmplst5cv_6.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:20:46.137606,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmphf53945t.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:20:56.016980,grid,"{""config_name"": ""num_processes_1_batching_2_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5d32d56u.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:21:05.218335,grid,"{""config_name"": ""num_processes_1_batching_2_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8ffdr6iu.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:21:14.551388,grid,"{""config_name"": ""num_processes_1_batching_2_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpmt2dl06p.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:21:25.751079,grid,"{""config_name"": ""num_processes_1_batching_2_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpnxkvyxc5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:21:34.927662,grid,"{""config_name"": ""num_processes_1_batching_2_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp632omhv1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:21:44.084826,grid,"{""config_name"": ""num_processes_1_batching_2_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp52ec_qhs.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:21:55.295927,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpjmq2ocme.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:22:04.465437,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpkgxd8k20.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:22:13.650952,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0iwyslku.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:22:25.029500,grid,"{""config_name"": ""num_processes_4_batching_64_precision_int4_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzlwd0kxt.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:22:34.220493,grid,"{""config_name"": ""num_processes_4_batching_64_precision_int4_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpm8fnxix8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:22:43.410148,grid,"{""config_name"": ""num_processes_4_batching_64_precision_int4_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4d4uzs9z.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:22:54.609286,grid,"{""config_name"": ""num_processes_1_batching_8_precision_int8_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpo4tsefmd.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:23:03.786053,grid,"{""config_name"": ""num_processes_1_batching_8_precision_int8_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_2_k7okk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:23:12.970124,grid,"{""config_name"": ""num_processes_1_batching_8_precision_int8_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp0_2ktsda.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:23:27.133576,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpb2fza0us.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:23:36.337730,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpafmqb9pj.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:23:45.519125,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdyr69hj6.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:24:02.666011,grid,"{""config_name"": ""num_processes_2_batching_4_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptxye3sk8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:24:11.904761,grid,"{""config_name"": ""num_processes_2_batching_4_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_scy342p.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:24:21.079539,grid,"{""config_name"": ""num_processes_2_batching_4_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp45il2b3c.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:24:32.238865,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpa6moifh1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:24:41.407639,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpxxona3y2.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:24:50.599341,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp72gqk0oz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:25:01.805032,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpk0o3vxdy.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:25:10.995038,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpyv_1c39v.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:25:25.114965,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpsg5718g7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:25:34.329439,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpashe4l_y.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:25:43.485637,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpmrhqjbou.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:25:54.695882,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpmo7lnfke.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:26:03.880435,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpj89d66dc.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:26:17.746048,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzwznh3hu.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:26:27.015386,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_0085v2j.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:26:36.213439,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2y91gdrj.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:26:47.436207,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwjj4e_1i.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:27:01.687806,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpn5lyiw44.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:27:10.916878,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpf0xji3z9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:27:20.098229,grid,"{""config_name"": ""num_processes_1_batching_4_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwxmwucn7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:27:31.266614,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4yvx8pta.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:27:40.450681,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_uqtfcnz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:27:49.587505,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9_p7stm8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:28:00.775037,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp147tviog.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:28:09.966507,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5z3af3zp.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:28:19.130507,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpuyj88hjz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:28:30.286429,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7syjpdhb.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:28:39.455545,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp559lzyno.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:51:40.872805,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpe04i2ca7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:51:52.158400,grid,"{""config_name"": ""num_processes_3_batching_4_precision_fp16_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfvekl_4c.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:52:01.367254,grid,"{""config_name"": ""num_processes_3_batching_4_precision_fp16_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpz8qrpa5u.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:52:30.702453,grid,"{""config_name"": ""num_processes_2_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp11715qj1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-11T10:52:39.894311,grid,"{""config_name"": ""num_processes_2_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpg8wufvis.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-12T21:58:03.229104,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp32_temp_0.0_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp30_4usc2.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:36:44.801189,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgy2ocmrz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:36:54.070278,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpaua4l7h9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:37:03.259392,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpk_bt68a4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:37:14.523291,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpryphpq5m.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:37:23.727564,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpeda52ruz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:37:32.976164,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7vyv24pc.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:37:44.216432,grid,"{""config_name"": ""num_processes_1_batching_32_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpaupd4r9f.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:37:53.478123,grid,"{""config_name"": ""num_processes_1_batching_32_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpi75z0k5f.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:38:02.719985,grid,"{""config_name"": ""num_processes_1_batching_32_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3emk8vlx.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:38:13.927344,grid,"{""config_name"": ""num_processes_1_batching_2_precision_int8_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpyh23e1f1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:38:23.169314,grid,"{""config_name"": ""num_processes_1_batching_2_precision_int8_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpie5uj3d2.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:38:32.417833,grid,"{""config_name"": ""num_processes_1_batching_2_precision_int8_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2m4erh7l.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:38:43.639057,grid,"{""config_name"": ""num_processes_3_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqix0_wnk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:38:52.858801,grid,"{""config_name"": ""num_processes_3_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpr3e74mg_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:39:02.116933,grid,"{""config_name"": ""num_processes_3_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpiij2nau9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:39:13.353507,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmplgit701l.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:39:22.564058,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdk9s5fj5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:39:31.799329,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvlqzjryl.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:39:43.083079,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpmruvctty.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:39:52.309286,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_dh7pj8f.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:40:01.514642,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpj4p4hgyd.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:40:12.760154,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp16_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2g6hvmr8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:40:22.026574,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp16_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpz2wd6wdj.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:40:31.231694,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp16_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpo5ggmbe3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:40:42.463194,grid,"{""config_name"": ""num_processes_3_batching_2_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmps7dj0yqb.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:40:51.704828,grid,"{""config_name"": ""num_processes_3_batching_2_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpn9dwocbk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:41:00.950361,grid,"{""config_name"": ""num_processes_3_batching_2_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpx0i9qfn6.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:41:12.166746,grid,"{""config_name"": ""num_processes_4_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpinlel4qg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:41:27.079604,grid,"{""config_name"": ""num_processes_2_batching_2_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmplmyeift3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:41:36.319127,grid,"{""config_name"": ""num_processes_2_batching_2_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp73_uqyle.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:41:45.529535,grid,"{""config_name"": ""num_processes_2_batching_2_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdrj4l68q.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:41:56.750007,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpw3s4l_ql.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:42:05.938833,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9_d8m_50.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:42:15.191082,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpuzgsie2q.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:42:26.402021,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp6ni3lff6.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:42:35.622092,grid,"{""config_name"": ""num_processes_4_batching_2_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgp2ofwmp.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:42:48.611852,grid,"{""config_name"": ""num_processes_3_batching_4_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpd6aipvjc.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:42:57.890611,grid,"{""config_name"": ""num_processes_3_batching_4_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpb_l4bx_w.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:43:07.078245,grid,"{""config_name"": ""num_processes_3_batching_4_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpyckiu7dg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:43:18.320222,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpglsvxbn5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:43:27.564171,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpot6u662v.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:43:36.800157,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzc7ffh3x.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:43:48.071272,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int8_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpk0vqroaw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:43:57.276139,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int8_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpmfsxfiv7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:44:06.531783,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int8_temp_0.0_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_28uoa_g.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:44:17.787793,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpcbgw6cl7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:44:27.035699,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgob7yw59.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:44:36.274370,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpsvuq5g1p.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:44:47.517315,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpbrloe2dp.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:44:56.754984,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzi0__mvn.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:45:06.038778,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpntq2v55m.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:45:17.304472,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpcjz043mo.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:45:26.545055,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpq1f_1wnl.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:45:35.805197,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp26nkkksq.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:45:46.988436,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpk_nc1o21.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:45:56.245620,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpg19zbx16.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:46:05.502991,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7tdtlheg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:46:16.761268,grid,"{""config_name"": ""num_processes_4_batching_64_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpl50sutc1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:46:26.033019,grid,"{""config_name"": ""num_processes_4_batching_64_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7pms4vwd.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:46:35.258136,grid,"{""config_name"": ""num_processes_4_batching_64_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmph4sshrms.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:46:46.500827,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3pkuutbd.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:46:55.750766,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpz4i6a9ux.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:47:04.982469,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2cbmh141.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:47:16.218535,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpauoik2i4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:47:25.462866,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpxkfpnitf.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:47:34.655531,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp33gsfexu.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:47:45.910346,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int4_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpn42zvv51.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:47:55.178908,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int4_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp62r88gfp.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:48:04.423583,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int4_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp37n335eo.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:48:15.676855,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpd8ax0gzf.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:48:24.898609,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3lkqg8kr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:48:34.144774,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpp0k6nmsl.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-13T09:48:45.412268,grid,"{""config_name"": ""num_processes_4_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpq404uqif.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T13:59:51.300508,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwdln4vql.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:00:00.573842,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmprz16d7r1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:00:11.967010,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpeazf59sd.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:00:21.171113,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpy8d9q0yy.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:00:30.396977,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpv266p7oi.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:00:47.301185,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int4_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmph77h_zw4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:00:56.528400,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int4_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpt8s_7z5j.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:01:05.766857,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int4_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppfdys0kx.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:01:16.945479,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzvzao4vn.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:01:26.125910,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpf69mu9lf.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:01:35.339630,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpy0eqagum.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:01:46.528060,grid,"{""config_name"": ""num_processes_3_batching_2_precision_int8_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgsue52b4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:01:55.710724,grid,"{""config_name"": ""num_processes_3_batching_2_precision_int8_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpbj_513n4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:02:05.075921,grid,"{""config_name"": ""num_processes_3_batching_2_precision_int8_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpy_sfs59a.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:02:16.308767,grid,"{""config_name"": ""num_processes_2_batching_16_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp89dc564a.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:02:25.506289,grid,"{""config_name"": ""num_processes_2_batching_16_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp1liwafyp.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:02:34.724725,grid,"{""config_name"": ""num_processes_2_batching_16_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvi4fsp4o.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:02:45.910960,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppuzctlp3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:02:55.121437,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_1gd0p57.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:03:04.359009,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp785vdy78.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:03:15.597510,grid,"{""config_name"": ""num_processes_3_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpebrk6c49.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:03:24.827654,grid,"{""config_name"": ""num_processes_3_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpn_vqup91.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:03:34.031700,grid,"{""config_name"": ""num_processes_3_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp31zq0hcv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:03:45.286908,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8kz3r7o_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:03:54.508703,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_kmqr4zp.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:04:03.717416,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpgcudovls.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:04:17.489753,grid,"{""config_name"": ""num_processes_4_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpglreerv4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:04:26.695695,grid,"{""config_name"": ""num_processes_4_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpk2dry25q.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:04:35.903658,grid,"{""config_name"": ""num_processes_4_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp88fhbrx5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:04:47.238498,grid,"{""config_name"": ""num_processes_3_batching_4_precision_int8_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpaikib7ev.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:04:56.432805,grid,"{""config_name"": ""num_processes_3_batching_4_precision_int8_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_vt5rbix.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:05:05.672730,grid,"{""config_name"": ""num_processes_3_batching_4_precision_int8_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpg2hgmwr8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:05:16.933753,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp15kmsrjl.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:05:26.107436,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp117nywkh.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:05:35.318326,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpessb3nix.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:05:46.537985,grid,"{""config_name"": ""num_processes_2_batching_64_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2h8ebag0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:05:55.779254,grid,"{""config_name"": ""num_processes_2_batching_64_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwx69fm6l.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:06:04.981234,grid,"{""config_name"": ""num_processes_2_batching_64_precision_int8_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmprzx7pow8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:06:16.160775,grid,"{""config_name"": ""num_processes_3_batching_4_precision_fp32_temp_0.0_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp36_og154.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:06:28.409408,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpl0cmhspz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:06:37.616300,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpn1sue5w1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T14:06:46.809510,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmplpygf3ib.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:22:43.183477,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpq0bzsl3b.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:22:52.377642,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvlql4xcw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:23:01.606317,grid,"{""config_name"": ""num_processes_2_batching_8_precision_int4_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpbmrfqg7w.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:23:17.435430,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpou82mnz4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:23:26.677451,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpxkgitou9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:23:35.864614,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpyazlrfo2.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:23:47.140738,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8nv_bilg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:23:56.351032,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp27cyk621.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:24:07.652366,grid,"{""config_name"": ""num_processes_1_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp99vnj84e.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:24:16.859341,grid,"{""config_name"": ""num_processes_1_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5gq5uw10.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:24:26.055809,grid,"{""config_name"": ""num_processes_1_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8klix6e_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:24:37.266601,grid,"{""config_name"": ""num_processes_2_batching_64_precision_fp32_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpl90g810e.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:24:48.469604,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp4ztlyded.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:24:57.664729,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptmjr53sb.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:25:06.870003,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpuri7ivk0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:25:18.099886,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpavmnifyy.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:25:30.787928,grid,"{""config_name"": ""num_processes_4_batching_8_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp98x__pvp.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:25:40.012427,grid,"{""config_name"": ""num_processes_4_batching_8_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpthrladpl.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:25:49.177714,grid,"{""config_name"": ""num_processes_4_batching_8_precision_fp32_temp_0.0_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9xnl_imc.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:26:00.395373,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7qqx416v.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:26:09.617244,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpaqi8smmq.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:26:18.792196,grid,"{""config_name"": ""num_processes_1_batching_16_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptkinznyf.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:26:29.998929,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpq0ifizk3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:26:39.197633,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvg2bo3al.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:26:48.413821,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvcb63dy8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:26:59.634536,grid,"{""config_name"": ""num_processes_1_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp03yl0amo.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-14T18:27:12.922519,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvbfxizt1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-15T00:58:11.647591,scenarios,"{""config_name"": ""R4_Standard_DualGPU_TopP_4bit"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R4_Standard_DualGPU_TopP_4bit"", ""realistic"": true}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.05, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 3.0, ""burst_size"": 6}, ""decoder_config"": {""decoding_mode"": ""top_p"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.9}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": null, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpe8s8n2t9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-15T01:08:28.959686,scenarios,"{""config_name"": ""R4_Standard_DualGPU_TopP_4bit"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R4_Standard_DualGPU_TopP_4bit"", ""realistic"": true}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.05, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 3.0, ""burst_size"": 6}, ""decoder_config"": {""decoding_mode"": ""top_p"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.9}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": null, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpn8nuli1s.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-15T01:18:46.512278,scenarios,"{""config_name"": ""R4_Standard_DualGPU_TopP_4bit"", ""suite"": ""scenarios"", ""controlled_variation"": {}, ""scenario_info"": {""name"": ""R4_Standard_DualGPU_TopP_4bit"", ""realistic"": true}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.05, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 3.0, ""burst_size"": 6}, ""decoder_config"": {""decoding_mode"": ""top_p"", ""decoder_temperature"": 1.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.9}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": null, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdc5b5x7d.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-15T08:51:50.670722,grid,"{""config_name"": ""num_processes_3_batching_64_precision_fp16_temp_0.0_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.0, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.0, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpm_e9jnyh.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-16T14:35:56.540392,grid,"{""config_name"": ""num_processes_2_batching_2_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpd7qnp8d3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-16T15:24:15.369489,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 1, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpo_m5kf8r.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:29:00.041292,grid,"{""config_name"": ""num_processes_2_batching_4_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpf2188suu.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:29:09.273100,grid,"{""config_name"": ""num_processes_2_batching_4_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvcfwkykb.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:29:18.509311,grid,"{""config_name"": ""num_processes_2_batching_4_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_8_blpgo.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:29:29.702677,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpza24hwyb.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:29:38.885316,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpi3kpyg2o.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:29:48.057629,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwz7wun11.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:29:59.244183,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_woxqw5q.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:30:08.501599,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp6hggyk9e.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:30:17.694816,grid,"{""config_name"": ""num_processes_2_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzezs2vv4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:30:28.899700,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvbgqaz8e.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:30:38.056703,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8pv1546z.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:30:47.201208,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmphxuzaxyk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:30:58.387305,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int8_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmprn8vh0jr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:31:07.564437,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int8_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpj89rfpmv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:31:16.762795,grid,"{""config_name"": ""num_processes_2_batching_32_precision_int8_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpnhytdctg.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:31:27.937498,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpcf877rzy.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:31:37.107110,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdkpde93a.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:31:46.272670,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpcxj_si2m.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:31:57.468396,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpmiddtta1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:32:06.635653,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpcwq_fx1r.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:32:15.840250,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_5bcsg0g.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:32:27.011822,grid,"{""config_name"": ""num_processes_3_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpshvo6hg5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:32:36.188050,grid,"{""config_name"": ""num_processes_3_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5a05pvc2.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:32:45.382677,grid,"{""config_name"": ""num_processes_3_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5piufm1_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:32:56.566104,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp51ekkzam.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:33:05.770096,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzyucvqnl.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:33:14.927053,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppco_5yf0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:33:26.094098,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3aq2mk6l.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:33:35.238079,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpjrm00oc3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:33:44.403764,grid,"{""config_name"": ""num_processes_2_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpk4lehe6f.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:33:55.689561,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_729mjk_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:34:04.968755,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpay4nf_9e.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:34:14.157989,grid,"{""config_name"": ""num_processes_4_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpmfmqiy8n.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:34:25.331684,grid,"{""config_name"": ""num_processes_2_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdr07mrps.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:34:34.512478,grid,"{""config_name"": ""num_processes_2_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpifzokt1c.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:34:43.697497,grid,"{""config_name"": ""num_processes_2_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpy9ti28ch.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:34:54.890475,grid,"{""config_name"": ""num_processes_1_batching_2_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqy6ktedf.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:35:04.117018,grid,"{""config_name"": ""num_processes_1_batching_2_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8r3iknto.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:35:13.342087,grid,"{""config_name"": ""num_processes_1_batching_2_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_ngn8mcb.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:35:24.557433,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp32_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwpzd_ohw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:35:33.715912,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp32_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpags2x5lx.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:35:42.891061,grid,"{""config_name"": ""num_processes_4_batching_64_precision_fp32_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpxkhcysfw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:35:54.069777,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpefp66uny.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:36:03.262327,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwjcuefwo.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:36:12.451441,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp32_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9sc62xsk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:36:23.641425,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5or75vt6.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:36:32.819765,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqzbzafyv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:36:41.970660,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmppg99775t.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:36:53.172877,grid,"{""config_name"": ""num_processes_1_batching_2_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7nlpaj1g.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:37:02.360275,grid,"{""config_name"": ""num_processes_1_batching_2_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp_pa_szhv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:37:11.544909,grid,"{""config_name"": ""num_processes_1_batching_2_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpm8wntpoa.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:37:22.735849,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzmzgo_vv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:37:31.903334,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpi_dg97n1.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:37:41.144183,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpji2irop5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:37:52.334410,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp6to23ia2.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:38:01.531727,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpktipx7mx.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:38:10.721185,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpxvacjpmt.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:38:21.884355,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int8_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpiynglj5s.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:38:36.774188,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp1s61d3d0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:38:45.967900,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpf2uencg6.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:38:55.204835,grid,"{""config_name"": ""num_processes_3_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp1u8kkaee.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:39:06.379450,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpb_td9rnf.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:39:15.577240,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpk6_zqovj.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:39:24.765358,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpeu_2g1p5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:39:35.992181,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp32_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpo2usv5e3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:39:45.232843,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp32_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdwxkvqys.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:39:54.411740,grid,"{""config_name"": ""num_processes_2_batching_2_precision_fp32_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpd1i86h0z.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:40:05.854495,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2kicc6ct.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:40:15.013258,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdgfeoriv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:40:24.251015,grid,"{""config_name"": ""num_processes_2_batching_4_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpkowsg0l4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:40:41.030370,grid,"{""config_name"": ""num_processes_2_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpc388nwjz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:40:50.228779,grid,"{""config_name"": ""num_processes_2_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpp5kzjuql.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:40:59.519467,grid,"{""config_name"": ""num_processes_2_batching_16_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 2, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpzln9zp3r.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:41:10.761056,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqr85i8d4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:41:19.980200,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp24d9afy2.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:41:29.210081,grid,"{""config_name"": ""num_processes_4_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7fathkvc.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:41:40.713745,grid,"{""config_name"": ""num_processes_1_batching_32_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvxbfkndt.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:41:49.944827,grid,"{""config_name"": ""num_processes_1_batching_32_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9yjndngw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:41:59.165787,grid,"{""config_name"": ""num_processes_1_batching_32_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmplbwvwacu.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:42:10.360843,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int4_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpsdy0utai.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:42:19.521720,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int4_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8jsw1m_a.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:42:28.710010,grid,"{""config_name"": ""num_processes_3_batching_64_precision_int4_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpq0osyh2p.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:42:39.883677,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int8_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3ingz8il.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:42:49.051883,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int8_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpr9t8raul.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:42:58.233948,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int8_temp_0.8_topp_0.8_latency_const_0.4_0.5"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.4_0.5""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpx02_d5du.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:43:09.385948,grid,"{""config_name"": ""num_processes_3_batching_16_precision_int8_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwsg71y32.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:43:18.558886,grid,"{""config_name"": ""num_processes_3_batching_16_precision_int8_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmph9jatrg7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:43:27.733963,grid,"{""config_name"": ""num_processes_3_batching_16_precision_int8_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpaxy58urk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:43:38.949483,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpu89tkw8v.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:43:48.119592,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp17e8yn1s.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:43:57.283446,grid,"{""config_name"": ""num_processes_3_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpggitqoa7.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:44:08.483488,grid,"{""config_name"": ""num_processes_3_batching_2_precision_int4_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpz7ika28o.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:44:17.675436,grid,"{""config_name"": ""num_processes_3_batching_2_precision_int4_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8m4j7sw9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:44:26.866881,grid,"{""config_name"": ""num_processes_3_batching_2_precision_int4_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 2, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 2, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpozlqelyi.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:44:38.069588,grid,"{""config_name"": ""num_processes_4_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpp8vqufn2.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:44:47.253796,grid,"{""config_name"": ""num_processes_4_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqie5d_7z.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:44:56.449629,grid,"{""config_name"": ""num_processes_4_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwee1ym1f.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:45:07.683159,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp3ymey4tc.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:45:16.903390,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpn11i2gok.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:45:26.125492,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i4_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i4_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpb87hkst5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:45:37.313933,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqjl6zfq5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:45:46.511854,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpn4czcnb2.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:45:55.768124,grid,"{""config_name"": ""num_processes_4_batching_32_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp25b95i5h.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:46:06.981965,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int4_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqp7reh44.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:46:16.169875,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int4_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8eaiggg9.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:46:25.352130,grid,"{""config_name"": ""num_processes_4_batching_4_precision_int4_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpfx55bmed.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:46:36.524092,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpby36xp6c.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:46:45.717455,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpc003d1k3.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:46:54.932837,grid,"{""config_name"": ""num_processes_1_batching_8_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpay8dp9is.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:47:06.095806,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp6lvsgn44.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:47:15.284222,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpf9erj_cz.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:47:24.512747,grid,"{""config_name"": ""num_processes_3_batching_8_precision_int8_temp_0.8_topp_0.8_latency_bursty_0.1_0.2_i6_s8"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 8}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 3, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.1_0.2_i6_s8""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp2q0k6itb.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:47:35.735071,grid,"{""config_name"": ""num_processes_1_batching_8_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5cl6qwpi.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:47:44.917664,grid,"{""config_name"": ""num_processes_1_batching_8_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp6ivraoqi.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:47:54.095332,grid,"{""config_name"": ""num_processes_1_batching_8_precision_int8_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 8, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": true, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 8, ""precision"": ""int8"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpsv5s1h8x.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:48:08.750924,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmphwl9a8rm.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:48:17.977310,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmplbi9ucx8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:48:27.199554,grid,"{""config_name"": ""num_processes_1_batching_64_precision_int4_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i6_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 64, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 6.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": true, ""load_in_8bit"": false, ""load_in_4bit"": true, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 64, ""precision"": ""int4"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i6_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp80hdq0fa.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:48:38.382955,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmph_s4wvba.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:48:47.595886,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp20vewahq.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:48:57.002058,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp16_temp_0.8_topp_0.8_latency_bursty_0.4_0.5_i4_s16"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.4, ""delay_max"": 0.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 16}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float16"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp16"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""bursty_0.4_0.5_i4_s16""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptv36r3d8.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:49:08.180475,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp32_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpi_wdiarp.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:49:17.356844,grid,"{""config_name"": ""num_processes_1_batching_32_precision_fp32_temp_0.8_topp_0.8_latency_no_latency"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 32, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 1, ""batching_options.batch_size___fixed_batching"": 32, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""no_latency""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvhah2zcw.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:49:29.820669,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7t40zoa_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:49:39.010636,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpu_zsqsnr.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:49:48.214414,grid,"{""config_name"": ""num_processes_4_batching_16_precision_fp32_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 16, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpljb59jzq.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:49:59.401467,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5lcurgyv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:50:08.605608,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpabzjv0ks.json', '--launched']' returned non-zero exit status 1."
unknown,2025-05-17T13:50:17.805887,grid,"{""config_name"": ""num_processes_4_batching_4_precision_fp32_temp_0.8_topp_0.8_latency_const_0.1_0.2"", ""suite"": ""grid"", ""controlled_variation"": {}, ""scenario_info"": {}, ""cycle_id"": 2, ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""min_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.1, ""delay_max"": 0.2, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoding_mode"": null, ""decoder_temperature"": 0.8, ""decoder_top_k"": null, ""decoder_top_p"": 0.8}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 52638582308864}, ""grid_variation"": {""num_processes"": 4, ""batching_options.batch_size___fixed_batching"": 4, ""precision"": ""fp32"", ""decoder_config.decoder_temperature"": 0.8, ""decoder_config.decoder_top_p"": 0.8, ""latency"": ""const_0.1_0.2""}}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpj7jwkoce.json', '--launched']' returned non-zero exit status 1."

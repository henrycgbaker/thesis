experiment_id,timestamp,suite,config,error_message
unknown,2025-04-07T19:45:08.238010,unknown,"{""config_name"": ""default"", ""model_name"": ""meta-llama/Llama-3.2-1B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 50, ""max_output_tokens"": 50, ""num_input_prompts"": 10, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 3000, ""max_batch_size___adaptive_batching"": 100}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 4, ""delay_max"": 0.3, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 50, ""decoder_top_p"": 0.95}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": null}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpcms8ai9z.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-07T20:00:12.001651,unknown,"{""config_name"": ""default"", ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 50, ""max_output_tokens"": 50, ""num_input_prompts"": 10, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 3000, ""max_batch_size___adaptive_batching"": 100}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 4, ""delay_max"": 0.3, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 50, ""decoder_top_p"": 0.95}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": null}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8y13su2k.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-07T22:35:27.354263,unknown,"{""config_name"": ""default"", ""model_name"": ""meta-llama/Llama-3.2-3B"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 50, ""max_output_tokens"": 50, ""num_input_prompts"": 10, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 3000, ""max_batch_size___adaptive_batching"": 100}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 4, ""delay_max"": 0.3, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 50, ""decoder_top_p"": 0.95}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": null}}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpq_uawcsa.json', '--launched']' returned non-zero exit status 1."

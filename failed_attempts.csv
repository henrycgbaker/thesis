experiment_id,timestamp,suite,config,error_message
unknown,2025-04-10T22:30:58.787700,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 500, ""max_output_tokens"": 500, ""num_input_prompts"": 1000, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0, ""decoding_mode"": ""greedy""}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""suite"": ""scenarios""}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpybhlgw3r.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-10T22:31:15.273549,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 500, ""max_output_tokens"": 500, ""num_input_prompts"": 1000, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0, ""decoding_mode"": ""greedy""}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""suite"": ""scenarios""}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7aauwuai.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-10T22:31:31.736243,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 500, ""max_output_tokens"": 500, ""num_input_prompts"": 1000, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0, ""decoding_mode"": ""greedy""}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""suite"": ""scenarios""}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpi3c68n0t.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-10T22:31:49.612387,scenarios,"{""config_name"": ""R2_Low_Latency_Chatbot_Deployment"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 500, ""max_output_tokens"": 500, ""num_input_prompts"": 1000, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.01, ""delay_max"": 0.05, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.9, ""decoding_mode"": ""top_p""}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""scenario_info"": {""name"": ""R2_Low_Latency_Chatbot_Deployment"", ""realistic"": true}, ""suite"": ""scenarios""}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp6p1j5qq_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-10T22:32:05.681204,scenarios,"{""config_name"": ""R2_Low_Latency_Chatbot_Deployment"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 500, ""max_output_tokens"": 500, ""num_input_prompts"": 1000, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.01, ""delay_max"": 0.05, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.9, ""decoding_mode"": ""top_p""}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""scenario_info"": {""name"": ""R2_Low_Latency_Chatbot_Deployment"", ""realistic"": true}, ""suite"": ""scenarios""}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpbg58dvog.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-10T22:32:22.851755,scenarios,"{""config_name"": ""R2_Low_Latency_Chatbot_Deployment"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 500, ""max_output_tokens"": 500, ""num_input_prompts"": 1000, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 4, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.01, ""delay_max"": 0.05, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.9, ""decoding_mode"": ""top_p""}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""scenario_info"": {""name"": ""R2_Low_Latency_Chatbot_Deployment"", ""realistic"": true}, ""suite"": ""scenarios""}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpt5hqp5ux.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T00:59:33.939627,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0, ""decoding_mode"": ""greedy""}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""suite"": ""scenarios""}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpx1me5byv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T00:59:52.706638,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0, ""decoding_mode"": ""greedy""}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""suite"": ""scenarios""}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpwqthpjw4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T01:00:12.176850,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0, ""decoding_mode"": ""greedy""}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""suite"": ""scenarios""}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpmu6qgcmv.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T09:21:45.373228,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0, ""decoding_mode"": ""greedy""}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""suite"": ""scenarios""}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpga2g2eje.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T09:22:04.293476,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0, ""decoding_mode"": ""greedy""}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""suite"": ""scenarios""}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpyn_pwovb.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T09:29:48.570874,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0, ""decoding_mode"": ""greedy""}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""suite"": ""scenarios""}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp8zymwe3u.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T09:30:07.628797,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0, ""decoding_mode"": ""greedy""}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""suite"": ""scenarios""}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpdrapm4j4.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T09:30:26.229543,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0, ""decoding_mode"": ""greedy""}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""suite"": ""scenarios""}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpu1ir227b.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T10:37:04.097127,controlled,"{""config_name"": ""num_processes_1"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""controlled_variation"": {""num_processes"": 1}, ""suite"": ""controlled""}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpvi97jrw_.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T10:37:13.232369,controlled,"{""config_name"": ""num_processes_1"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""controlled_variation"": {""num_processes"": 1}, ""suite"": ""controlled""}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpqvy3l_ot.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T10:37:22.325983,controlled,"{""config_name"": ""num_processes_1"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 1, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""controlled_variation"": {""num_processes"": 1}, ""suite"": ""controlled""}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '1', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpbnmrailj.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T10:37:31.405627,controlled,"{""config_name"": ""num_processes_2"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""controlled_variation"": {""num_processes"": 2}, ""suite"": ""controlled""}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpel2w0wz0.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T10:37:40.704035,controlled,"{""config_name"": ""num_processes_2"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""controlled_variation"": {""num_processes"": 2}, ""suite"": ""controlled""}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpt7h90hcc.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T10:37:49.790218,controlled,"{""config_name"": ""num_processes_2"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 2, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""controlled_variation"": {""num_processes"": 2}, ""suite"": ""controlled""}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '2', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmptvo6ml2z.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T10:37:58.831659,controlled,"{""config_name"": ""num_processes_3"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""controlled_variation"": {""num_processes"": 3}, ""suite"": ""controlled""}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp1b_rk_h6.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T10:38:07.891215,controlled,"{""config_name"": ""num_processes_3"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""controlled_variation"": {""num_processes"": 3}, ""suite"": ""controlled""}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpv2m825on.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T10:38:16.946453,controlled,"{""config_name"": ""num_processes_3"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""controlled_variation"": {""num_processes"": 3}, ""suite"": ""controlled""}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp7zu8wy3a.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T10:38:29.217588,controlled,"{""config_name"": ""num_processes_3"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""controlled_variation"": {""num_processes"": 3}, ""suite"": ""controlled""}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpxbybt8dl.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T10:38:38.337580,controlled,"{""config_name"": ""num_processes_3"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""controlled_variation"": {""num_processes"": 3}, ""suite"": ""controlled""}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpor62wnuk.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T10:38:47.462528,controlled,"{""config_name"": ""num_processes_3"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 3, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""controlled_variation"": {""num_processes"": 3}, ""suite"": ""controlled""}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '3', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmph9i2yncj.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T10:38:56.588863,controlled,"{""config_name"": ""num_processes_4"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""controlled_variation"": {""num_processes"": 4}, ""suite"": ""controlled""}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp5cobsi56.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T10:39:05.731023,controlled,"{""config_name"": ""num_processes_4"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""controlled_variation"": {""num_processes"": 4}, ""suite"": ""controlled""}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpa5rrj17s.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T10:39:15.508558,controlled,"{""config_name"": ""num_processes_4"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 2, 3], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": false, ""delay_min"": 0, ""delay_max"": 0, ""simulate_burst"": false, ""burst_interval"": 0.0, ""burst_size"": 0}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 1034544128000}, ""controlled_variation"": {""num_processes"": 4}, ""suite"": ""controlled""}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp6aiap5ld.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T16:32:33.543605,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0, ""decoding_mode"": ""greedy""}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""suite"": ""scenarios""}","Attempt 1: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmpu21e2kit.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T16:32:54.220267,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0, ""decoding_mode"": ""greedy""}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""suite"": ""scenarios""}","Attempt 2: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmplrfwgfj5.json', '--launched']' returned non-zero exit status 1."
unknown,2025-04-11T16:33:17.323359,scenarios,"{""config_name"": ""R1_Standard_Production_Config"", ""model_name"": ""TinyLlama/TinyLlama-1.1B-Chat-v1.0"", ""is_encoder_decoder"": false, ""task_type"": ""text_generation"", ""inference_type"": ""pure_generative"", ""gpu_list"": [0, 1, 3, 4], ""backend"": ""pytorch"", ""save_outputs"": true, ""max_input_tokens"": 128, ""max_output_tokens"": 128, ""num_input_prompts"": 128, ""decode_token_to_text"": true, ""num_processes"": 4, ""batching_options"": {""batch_size___fixed_batching"": 16, ""adaptive_batching"": false, ""adaptive_max_tokens"": 0, ""max_batch_size___adaptive_batching"": 0}, ""sharding_config"": {""fsdp_config"": {""use_orig_params"": false, ""cpu_offload"": false}, ""sharding_strategy"": ""NO_SHARD""}, ""query_rate"": 1.0, ""latency_simulation"": {""simulate"": true, ""delay_min"": 0.5, ""delay_max"": 1.5, ""simulate_burst"": true, ""burst_interval"": 4.0, ""burst_size"": 5}, ""decoder_config"": {""decoder_temperature"": 1.0, ""decoder_top_k"": 0, ""decoder_top_p"": 0.0, ""decoding_mode"": ""greedy""}, ""fp_precision"": ""float32"", ""quantization_config"": {""quantization"": false, ""load_in_8bit"": false, ""load_in_4bit"": false, ""cached_flops_for_quantised_models"": 16949970993152}, ""scenario_info"": {""name"": ""R1_Standard_Production_Config"", ""realistic"": true}, ""suite"": ""scenarios""}","Attempt 3: Command '['accelerate', 'launch', '--num_processes', '4', '/home/228755@hertie-school.lan/thesis/MAIN_a_single_experiment.py', '--config', '/tmp/tmp9royxg84.json', '--launched']' returned non-zero exit status 1."
